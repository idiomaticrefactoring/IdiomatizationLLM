repo_name,file_path,file_html,class_name,me_code,old_code,new_code,bool_code,chatGPT_code,if_correct,reversed_code,non_replace_var_refactored_code,refactored_code,acc,instruction,sys_msg,exam_msg,user_msg
sympy,https://github.com/sympy/sympy/tree/master/sympy/printing/julia.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/sympy/sympy/printing/julia.py,JuliaCodePrinter,"def _print_Indexed(self, expr):
    inds = [self._print(i) for i in expr.indices]
    return '%s[%s]' % (self._print(expr.base.label), ','.join(inds))","'%s[%s]' % (self._print(expr.base.label), ','.join(inds))","f""{self._print(expr.base.label)}[{','.join(inds)}]""",1,,,,,,,,,,
galaxy,https://github.com/ansible/galaxy/tree/master/lib/tool_shed/dependencies/repository/relation_builder.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/galaxy/lib/tool_shed/dependencies/repository/relation_builder.py,RelationBuilder,"def get_updated_changeset_revisions_for_repository_dependencies(self, key_rd_dicts):
    updated_key_rd_dicts = []
    for key_rd_dict in key_rd_dicts:
        key = next(iter(key_rd_dict))
        repository_dependency = key_rd_dict[key]
        (rd_toolshed, rd_name, rd_owner, rd_changeset_revision, rd_prior_installation_required, rd_only_if_compiling_contained_td) = common_util.parse_repository_dependency_tuple(repository_dependency)
        if suc.tool_shed_is_this_tool_shed(rd_toolshed):
            repository = tool_shed.util.repository_util.get_repository_by_name_and_owner(self.app, rd_name, rd_owner)
            if repository:
                repository_id = self.app.security.encode_id(repository.id)
                repository_metadata = metadata_util.get_repository_metadata_by_repository_id_changeset_revision(self.app, repository_id, rd_changeset_revision)
                if repository_metadata:
                    new_key_rd_dict = {}
                    new_key_rd_dict[key] = repository_dependency
                    updated_key_rd_dicts.append(key_rd_dict)
                else:
                    changeset_revision = metadata_util.get_next_downloadable_changeset_revision(self.app, repository, rd_changeset_revision)
                    if changeset_revision != rd_changeset_revision:
                        repository_metadata = metadata_util.get_repository_metadata_by_repository_id_changeset_revision(self.app, repository_id, changeset_revision)
                    if repository_metadata:
                        new_key_rd_dict = {}
                        new_key_rd_dict[key] = [rd_toolshed, rd_name, rd_owner, repository_metadata.changeset_revision, rd_prior_installation_required, rd_only_if_compiling_contained_td]
                        updated_key_rd_dicts.append(new_key_rd_dict)
                    else:
                        repository_components_tuple = container_util.get_components_from_key(key)
                        components_list = tool_shed.util.repository_util.extract_components_from_tuple(repository_components_tuple)
                        (toolshed, repository_name, repository_owner, repository_changeset_revision) = components_list[0:4]
                        if len(components_list) in (4, 5):
                            rd_only_if_compiling_contained_td = 'False'
                        message = 'The revision %s defined for repository %s owned by %s is invalid, so repository ' % (str(rd_changeset_revision), str(rd_name), str(rd_owner))
                        message += f'dependencies defined for repository {str(repository_name)} will be ignored.'
                        log.debug(message)
            else:
                repository_components_tuple = container_util.get_components_from_key(key)
                components_list = tool_shed.util.repository_util.extract_components_from_tuple(repository_components_tuple)
                (toolshed, repository_name, repository_owner, repository_changeset_revision) = components_list[0:4]
                message = 'The revision %s defined for repository %s owned by %s is invalid, so repository ' % (str(rd_changeset_revision), str(rd_name), str(rd_owner))
                message += f'dependencies defined for repository {str(repository_name)} will be ignored.'
                log.debug(message)
    return updated_key_rd_dicts","'The revision %s defined for repository %s owned by %s is invalid, so repository ' % (str(rd_changeset_revision), str(rd_name), str(rd_owner))","f""The revision {str(rd_changeset_revision)} defined for repository {str(rd_name)} owned by {str(rd_owner)} is invalid, so repository""",1,,,,,,,,,,
galaxy,https://github.com/ansible/galaxy/tree/master/lib/tool_shed/dependencies/repository/relation_builder.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/galaxy/lib/tool_shed/dependencies/repository/relation_builder.py,RelationBuilder,"def get_updated_changeset_revisions_for_repository_dependencies(self, key_rd_dicts):
    updated_key_rd_dicts = []
    for key_rd_dict in key_rd_dicts:
        key = next(iter(key_rd_dict))
        repository_dependency = key_rd_dict[key]
        (rd_toolshed, rd_name, rd_owner, rd_changeset_revision, rd_prior_installation_required, rd_only_if_compiling_contained_td) = common_util.parse_repository_dependency_tuple(repository_dependency)
        if suc.tool_shed_is_this_tool_shed(rd_toolshed):
            repository = tool_shed.util.repository_util.get_repository_by_name_and_owner(self.app, rd_name, rd_owner)
            if repository:
                repository_id = self.app.security.encode_id(repository.id)
                repository_metadata = metadata_util.get_repository_metadata_by_repository_id_changeset_revision(self.app, repository_id, rd_changeset_revision)
                if repository_metadata:
                    new_key_rd_dict = {}
                    new_key_rd_dict[key] = repository_dependency
                    updated_key_rd_dicts.append(key_rd_dict)
                else:
                    changeset_revision = metadata_util.get_next_downloadable_changeset_revision(self.app, repository, rd_changeset_revision)
                    if changeset_revision != rd_changeset_revision:
                        repository_metadata = metadata_util.get_repository_metadata_by_repository_id_changeset_revision(self.app, repository_id, changeset_revision)
                    if repository_metadata:
                        new_key_rd_dict = {}
                        new_key_rd_dict[key] = [rd_toolshed, rd_name, rd_owner, repository_metadata.changeset_revision, rd_prior_installation_required, rd_only_if_compiling_contained_td]
                        updated_key_rd_dicts.append(new_key_rd_dict)
                    else:
                        repository_components_tuple = container_util.get_components_from_key(key)
                        components_list = tool_shed.util.repository_util.extract_components_from_tuple(repository_components_tuple)
                        (toolshed, repository_name, repository_owner, repository_changeset_revision) = components_list[0:4]
                        if len(components_list) in (4, 5):
                            rd_only_if_compiling_contained_td = 'False'
                        message = 'The revision %s defined for repository %s owned by %s is invalid, so repository ' % (str(rd_changeset_revision), str(rd_name), str(rd_owner))
                        message += f'dependencies defined for repository {str(repository_name)} will be ignored.'
                        log.debug(message)
            else:
                repository_components_tuple = container_util.get_components_from_key(key)
                components_list = tool_shed.util.repository_util.extract_components_from_tuple(repository_components_tuple)
                (toolshed, repository_name, repository_owner, repository_changeset_revision) = components_list[0:4]
                message = 'The revision %s defined for repository %s owned by %s is invalid, so repository ' % (str(rd_changeset_revision), str(rd_name), str(rd_owner))
                message += f'dependencies defined for repository {str(repository_name)} will be ignored.'
                log.debug(message)
    return updated_key_rd_dicts","'The revision %s defined for repository %s owned by %s is invalid, so repository ' % (str(rd_changeset_revision), str(rd_name), str(rd_owner))","f""The revision {str(rd_changeset_revision)} defined for repository {str(rd_name)} owned by {str(rd_owner)} is invalid, so repository""",1,,,,,,,,,,
lingvo,https://github.com/tensorflow/lingvo/tree/master/lingvo/core/gshard_builder.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/lingvo/lingvo/core/gshard_builder.py,BertTransformer,"def __init__(self, params):
    """"""The constructor of the model.""""""
    super().__init__(params)
    p = self.params
    if p.mlm_loss_weight > 0:
        p.masked_lm.vocab_size = p.vocab_size
        p.masked_lm.mask_token_id = p.mask_token_id
        self.CreateChild('masked_lm', p.masked_lm)
    if p.use_repeat_layer or p.num_spmd_pipeline_stages > 1:
        p.builder.deterministic_dropout = True
    assert p.num_transformer_layers % p.num_spmd_pipeline_stages == 0
    b = p.builder.Instantiate()
    if callable(p.gated_ffn_activation):
        gated_ffn_activation = p.gated_ffn_activation
    elif p.gated_ffn_activation == 'silu':
        gated_ffn_activation = tf.nn.silu
    elif p.gated_ffn_activation == 'gelu':
        gated_ffn_activation = lambda x: tf.nn.gelu(x, approximate=True)
    else:
        assert not p.gated_ffn_activation, p.gated_ffn_activation
        gated_ffn_activation = None
    enc_emb = b.Embedding('enc_emb', p.vocab_size)
    self.CreateChild('enc_emb', enc_emb)
    if p.positional_embedding:
        enc_pos_emb = b.Embedding('enc_pos_emb', p.max_length)
        self.CreateChild('enc_pos_emb', enc_pos_emb)
    if p.positional_embedding:
        atten_layer = b.SelfAttention('self_attention')
    else:
        atten_layer = b.SelfAttentionRelativeBias('dec_self_attention')
    if gated_ffn_activation is None:
        ffw_layer = b.DenseReluDense('dense_relu_dense', activation=p.activation)
    else:
        ffw_layer = b.DenseReluDenseGated('dense_relu_dense', gated_ffn_activation)
    if p.moe:
        if p.moe_gated_gelu:
            moe_layer = b.MoEGated('moe')
        else:
            moe_layer = b.MoE('moe')
        encoder_sub_layers = [atten_layer, moe_layer, atten_layer, ffw_layer]
        num_encoder_layers = p.num_transformer_layers // 2
    else:
        encoder_sub_layers = [atten_layer, ffw_layer]
        num_encoder_layers = p.num_transformer_layers
    enc = b.EncoderLayerStack('encoder', encoder_sub_layers, num_encoder_layers, use_repeat_layer=p.use_repeat_layer, spmd_pipeline_stages=p.num_spmd_pipeline_stages, spmd_pipeline_microbatches=p.num_spmd_pipeline_microbatches)
    enc.params_init = py_utils.WeightInit.Xavier(scale=1.0, seed=0)
    emb_w_split = b.MeshSplit('w_split', b.params.emb_w_split)
    enc_out_split = b.MeshSplit('enc_out_split', b._AdjustMSplit(b.params.blm_split[-3:], 2))
    logits_split = b.MeshSplit('logits_split', b.params.logits_split)
    self.CreateChild('enc', enc)
    self.CreateChild('emb_w_split', emb_w_split)
    self.CreateChild('enc_out_split', enc_out_split)
    self.CreateChild('logits_split', logits_split)",p.num_transformer_layers % p.num_spmd_pipeline_stages,f"{p.num_transformer_layers % p.num_spmd_pipeline_stages}",1,,,,,,,,,,
django-mysql,https://github.com/adamchainz/django-mysql/tree/master/src/django_mysql/models/fields/lists.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/django-mysql/src/django_mysql/models/fields/lists.py,ListFieldMixin,"def description(self) -> Any:
    return _('List of %(base_description)s') % {'base_description': self.base_field.description}",_('List of %(base_description)s') % {'base_description': self.base_field.description},f"List of {self.base_field.description}",1,,,,,,,,,,
pyqtgraph,https://github.com/pyqtgraph/pyqtgraph/tree/master/pyqtgraph/examples/ScatterPlotSpeedTest.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pyqtgraph/pyqtgraph/examples/ScatterPlotSpeedTest.py,,"def update():
    global ptr, lastTime, fps
    mode = param['mode']
    if mode == 'newItem':
        mkItem()
    elif mode == 'reuseItem':
        item.setData(**getData())
    elif mode == 'panZoom':
        item.viewTransformChanged()
        item.update()
    elif mode == 'hover':
        pts = item.points()
        old = pts[(ptr - 1) % len(pts)]
        new = pts[ptr % len(pts)]
        item.pointsAt(new.pos())
        old.resetBrush()
        new.setBrush(hoverBrush)
    ptr += 1
    now = perf_counter()
    dt = now - lastTime
    lastTime = now
    if fps is None:
        fps = 1.0 / dt
    else:
        s = np.clip(dt * 3.0, 0, 1)
        fps = fps * (1 - s) + 1.0 / dt * s
    p.setTitle('%0.2f fps' % fps)
    p.repaint()",'%0.2f fps' % fps,f"{fps:.2f} fps",1,,,,,,,,,,
oppia,https://github.com/oppia/oppia/tree/master/core/domain/rte_component_registry_test.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/oppia/core/domain/rte_component_registry_test.py,RteComponentUnitTests,"def test_image_thumbnails_for_rte_components(self) -> None:
    """"""Test the thumbnails for the RTE component icons.""""""
    rte_components = rte_component_registry.Registry.get_all_rte_components()
    for (component_name, component_specs) in rte_components.items():
        generated_image_filepath = os.path.join(os.getcwd(), feconf.RTE_EXTENSIONS_DIR, component_name, '%s.png' % component_name)
        relative_icon_data_url = component_specs['icon_data_url'][1:]
        defined_image_filepath = os.path.join(os.getcwd(), feconf.EXTENSIONS_DIR_PREFIX, 'extensions', relative_icon_data_url)
        self.assertEqual(generated_image_filepath, defined_image_filepath)
        with utils.open_file(generated_image_filepath, 'rb', encoding=None) as f:
            img_data = f.read()
            (width, height) = struct.unpack('>LL', img_data[16:24])
            self.assertEqual(int(width), RTE_THUMBNAIL_WIDTH_PX)
            self.assertEqual(int(height), RTE_THUMBNAIL_HEIGHT_PX)",'%s.png' % component_name,f"{component_name}.png",1,,,,,,,,,,
angr,https://github.com/angr/angr/tree/master/angr/knowledge_plugins/variables/variable_manager.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/angr/angr/knowledge_plugins/variables/variable_manager.py,VariableManagerInternal,"def assign_variable_names(self, labels=None, types=None):
    """"""
        Assign default names to all SSA variables.

        :param labels:  Known labels in the binary.
        :return:        None
        """"""
    for var in self._variables:
        if (types is None or SimStackVariable in types) and isinstance(var, SimStackVariable):
            if var.name is not None:
                continue
            if var.ident.startswith('iarg'):
                var.name = 'arg_%x' % var.offset
            else:
                var.name = 's_%x' % -var.offset
        elif (types is None or SimRegisterVariable in types) and isinstance(var, SimRegisterVariable):
            if var.name is not None:
                continue
            var.name = var.ident
        elif (types is None or SimMemoryVariable in types) and isinstance(var, SimMemoryVariable):
            if var.name is not None:
                continue
            if labels is not None and var.addr in labels:
                var.name = labels[var.addr]
                if '@@' in var.name:
                    var.name = var.name[:var.name.index('@@')]
            elif isinstance(var.addr, int):
                var.name = 'g_%x' % var.addr
            elif var.ident is not None:
                var.name = var.ident
            else:
                var.name = 'g_%s' % var.addr",'arg_%x' % var.offset,f"arg_{var.offset:x}",1,,,,,,,,,,
angr,https://github.com/angr/angr/tree/master/angr/knowledge_plugins/variables/variable_manager.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/angr/angr/knowledge_plugins/variables/variable_manager.py,VariableManagerInternal,"def assign_variable_names(self, labels=None, types=None):
    """"""
        Assign default names to all SSA variables.

        :param labels:  Known labels in the binary.
        :return:        None
        """"""
    for var in self._variables:
        if (types is None or SimStackVariable in types) and isinstance(var, SimStackVariable):
            if var.name is not None:
                continue
            if var.ident.startswith('iarg'):
                var.name = 'arg_%x' % var.offset
            else:
                var.name = 's_%x' % -var.offset
        elif (types is None or SimRegisterVariable in types) and isinstance(var, SimRegisterVariable):
            if var.name is not None:
                continue
            var.name = var.ident
        elif (types is None or SimMemoryVariable in types) and isinstance(var, SimMemoryVariable):
            if var.name is not None:
                continue
            if labels is not None and var.addr in labels:
                var.name = labels[var.addr]
                if '@@' in var.name:
                    var.name = var.name[:var.name.index('@@')]
            elif isinstance(var.addr, int):
                var.name = 'g_%x' % var.addr
            elif var.ident is not None:
                var.name = var.ident
            else:
                var.name = 'g_%s' % var.addr",'s_%x' % -var.offset,f"s_{-var.offset:x}",1,,,,,,,,,,
angr,https://github.com/angr/angr/tree/master/angr/knowledge_plugins/variables/variable_manager.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/angr/angr/knowledge_plugins/variables/variable_manager.py,VariableManagerInternal,"def assign_variable_names(self, labels=None, types=None):
    """"""
        Assign default names to all SSA variables.

        :param labels:  Known labels in the binary.
        :return:        None
        """"""
    for var in self._variables:
        if (types is None or SimStackVariable in types) and isinstance(var, SimStackVariable):
            if var.name is not None:
                continue
            if var.ident.startswith('iarg'):
                var.name = 'arg_%x' % var.offset
            else:
                var.name = 's_%x' % -var.offset
        elif (types is None or SimRegisterVariable in types) and isinstance(var, SimRegisterVariable):
            if var.name is not None:
                continue
            var.name = var.ident
        elif (types is None or SimMemoryVariable in types) and isinstance(var, SimMemoryVariable):
            if var.name is not None:
                continue
            if labels is not None and var.addr in labels:
                var.name = labels[var.addr]
                if '@@' in var.name:
                    var.name = var.name[:var.name.index('@@')]
            elif isinstance(var.addr, int):
                var.name = 'g_%x' % var.addr
            elif var.ident is not None:
                var.name = var.ident
            else:
                var.name = 'g_%s' % var.addr",'g_%x' % var.addr,f'g_{var.addr:x}',1,,,,,,,,,,
angr,https://github.com/angr/angr/tree/master/angr/knowledge_plugins/variables/variable_manager.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/angr/angr/knowledge_plugins/variables/variable_manager.py,VariableManagerInternal,"def assign_variable_names(self, labels=None, types=None):
    """"""
        Assign default names to all SSA variables.

        :param labels:  Known labels in the binary.
        :return:        None
        """"""
    for var in self._variables:
        if (types is None or SimStackVariable in types) and isinstance(var, SimStackVariable):
            if var.name is not None:
                continue
            if var.ident.startswith('iarg'):
                var.name = 'arg_%x' % var.offset
            else:
                var.name = 's_%x' % -var.offset
        elif (types is None or SimRegisterVariable in types) and isinstance(var, SimRegisterVariable):
            if var.name is not None:
                continue
            var.name = var.ident
        elif (types is None or SimMemoryVariable in types) and isinstance(var, SimMemoryVariable):
            if var.name is not None:
                continue
            if labels is not None and var.addr in labels:
                var.name = labels[var.addr]
                if '@@' in var.name:
                    var.name = var.name[:var.name.index('@@')]
            elif isinstance(var.addr, int):
                var.name = 'g_%x' % var.addr
            elif var.ident is not None:
                var.name = var.ident
            else:
                var.name = 'g_%s' % var.addr",'g_%s' % var.addr,f'g_{var.addr}',1,,,,,,,,,,
MeshCNN,https://github.com/ranahanocka/MeshCNN/tree/master/util/util.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/MeshCNN/util/util.py,,"def print_network(net):
    """"""Print the total number of parameters in the network
    Parameters:
        network
    """"""
    print('---------- Network initialized -------------')
    num_params = 0
    for param in net.parameters():
        num_params += param.numel()
    print('[Network] Total number of parameters : %.3f M' % (num_params / 1000000.0))
    print('-----------------------------------------------')",'[Network] Total number of parameters : %.3f M' % (num_params / 1000000.0),print(f"[Network] Total number of parameters : {num_params / 1000000.0:.3f} M"),1,,,,,,,,,,
fold,https://github.com/tensorflow/fold/tree/master/tensorflow_fold/blocks/plan.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/fold/tensorflow_fold/blocks/plan.py,TrainPlan,"def _run(self, supervisor, session):
    train_feed_dict = self.train_feeds.copy()
    train_fetches = {'train_op': self.train_op, 'loss': self.loss_total, 'step': self.global_step}
    if self.compute_summaries:
        train_fetches['summaries'] = self.summaries
    if self.examples:
        (epochs, train_size) = self._by_feed_dict(train_feed_dict)
    else:
        (epochs, train_size) = self._by_input_tensor(train_feed_dict)
    if self.dev_examples:
        gen_dev_batches = util.epochs(((len(batch), self.compiler.build_feed_dict(batch)) for batch in util.group_by_batches(self.dev_examples, self.batch_size)), shuffle=False)
        ckpt = tf.train.get_checkpoint_state(self.logdir)
        if ckpt and ckpt.model_checkpoint_path:
            (_, self._best_loss, _) = self._eval_batches(supervisor, session, next(gen_dev_batches), None, is_dev=True)
            if self._best_loss is None:
                return
    for (epoch, batches) in enumerate(epochs, 1):
        train_loss = 0.0
        for _ in batches:
            if self._should_stop(supervisor):
                return
            results = session.run(train_fetches, train_feed_dict)
            train_loss += results['loss']
            if self.compute_summaries:
                supervisor.summary_computed(session, results['summaries'], results['step'])
        if train_size == 0:
            raise ValueError('examples must be non-empty')
        if self.exact_batch_sizes and epoch == 1:
            if train_size < self.batch_size:
                raise ValueError('when exact_batch_sizes is true, examples must have at least batch_size items; %s vs. %s' % (train_size, self.batch_size))
            train_size -= train_size % self.batch_size
        train_loss /= train_size
        self.report_loss(results['step'], train_loss)
        log_str = 'epoch:%5d train[loss: %.3e]' % (epoch, train_loss)
        if self.dev_examples:
            (dev_size, dev_loss, dev_metrics) = self._eval_batches(supervisor, session, next(gen_dev_batches), results['step'], is_dev=True)
            if dev_size is None:
                return
            if epoch == 1:
                self.log_and_print('train_size: %d dev_size: %d' % (train_size, dev_size))
            log_str += ' dev[%s]' % _eval_str(dev_size, dev_loss, dev_metrics)
            self.log_and_print(log_str)
            self._save_best(session, supervisor.saver, dev_loss, results['step'])
        else:
            if epoch == 1:
                self.log_and_print('train_size: %d' % train_size)
            self.log_and_print(log_str)
    if not self.dev_examples and self.is_chief_trainer:
        save_path = os.path.join(self.logdir, 'model.ckpt')
        save_fname = supervisor.saver.save(session, save_path, global_step=results['step'])
        self.log_and_print('final model saved in file: %s' % save_fname)","'epoch:%5d train[loss: %.3e]' % (epoch, train_loss)",f'epoch:{epoch:5d} train[loss: {train_loss:.3e}]',1,,,,,,,,,,
fold,https://github.com/tensorflow/fold/tree/master/tensorflow_fold/blocks/plan.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/fold/tensorflow_fold/blocks/plan.py,TrainPlan,"def _run(self, supervisor, session):
    train_feed_dict = self.train_feeds.copy()
    train_fetches = {'train_op': self.train_op, 'loss': self.loss_total, 'step': self.global_step}
    if self.compute_summaries:
        train_fetches['summaries'] = self.summaries
    if self.examples:
        (epochs, train_size) = self._by_feed_dict(train_feed_dict)
    else:
        (epochs, train_size) = self._by_input_tensor(train_feed_dict)
    if self.dev_examples:
        gen_dev_batches = util.epochs(((len(batch), self.compiler.build_feed_dict(batch)) for batch in util.group_by_batches(self.dev_examples, self.batch_size)), shuffle=False)
        ckpt = tf.train.get_checkpoint_state(self.logdir)
        if ckpt and ckpt.model_checkpoint_path:
            (_, self._best_loss, _) = self._eval_batches(supervisor, session, next(gen_dev_batches), None, is_dev=True)
            if self._best_loss is None:
                return
    for (epoch, batches) in enumerate(epochs, 1):
        train_loss = 0.0
        for _ in batches:
            if self._should_stop(supervisor):
                return
            results = session.run(train_fetches, train_feed_dict)
            train_loss += results['loss']
            if self.compute_summaries:
                supervisor.summary_computed(session, results['summaries'], results['step'])
        if train_size == 0:
            raise ValueError('examples must be non-empty')
        if self.exact_batch_sizes and epoch == 1:
            if train_size < self.batch_size:
                raise ValueError('when exact_batch_sizes is true, examples must have at least batch_size items; %s vs. %s' % (train_size, self.batch_size))
            train_size -= train_size % self.batch_size
        train_loss /= train_size
        self.report_loss(results['step'], train_loss)
        log_str = 'epoch:%5d train[loss: %.3e]' % (epoch, train_loss)
        if self.dev_examples:
            (dev_size, dev_loss, dev_metrics) = self._eval_batches(supervisor, session, next(gen_dev_batches), results['step'], is_dev=True)
            if dev_size is None:
                return
            if epoch == 1:
                self.log_and_print('train_size: %d dev_size: %d' % (train_size, dev_size))
            log_str += ' dev[%s]' % _eval_str(dev_size, dev_loss, dev_metrics)
            self.log_and_print(log_str)
            self._save_best(session, supervisor.saver, dev_loss, results['step'])
        else:
            if epoch == 1:
                self.log_and_print('train_size: %d' % train_size)
            self.log_and_print(log_str)
    if not self.dev_examples and self.is_chief_trainer:
        save_path = os.path.join(self.logdir, 'model.ckpt')
        save_fname = supervisor.saver.save(session, save_path, global_step=results['step'])
        self.log_and_print('final model saved in file: %s' % save_fname)","' dev[%s]' % _eval_str(dev_size, dev_loss, dev_metrics)","f"" dev[{_eval_str(dev_size, dev_loss, dev_metrics)}]""",1,,,,,,,,,,
fold,https://github.com/tensorflow/fold/tree/master/tensorflow_fold/blocks/plan.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/fold/tensorflow_fold/blocks/plan.py,TrainPlan,"def _run(self, supervisor, session):
    train_feed_dict = self.train_feeds.copy()
    train_fetches = {'train_op': self.train_op, 'loss': self.loss_total, 'step': self.global_step}
    if self.compute_summaries:
        train_fetches['summaries'] = self.summaries
    if self.examples:
        (epochs, train_size) = self._by_feed_dict(train_feed_dict)
    else:
        (epochs, train_size) = self._by_input_tensor(train_feed_dict)
    if self.dev_examples:
        gen_dev_batches = util.epochs(((len(batch), self.compiler.build_feed_dict(batch)) for batch in util.group_by_batches(self.dev_examples, self.batch_size)), shuffle=False)
        ckpt = tf.train.get_checkpoint_state(self.logdir)
        if ckpt and ckpt.model_checkpoint_path:
            (_, self._best_loss, _) = self._eval_batches(supervisor, session, next(gen_dev_batches), None, is_dev=True)
            if self._best_loss is None:
                return
    for (epoch, batches) in enumerate(epochs, 1):
        train_loss = 0.0
        for _ in batches:
            if self._should_stop(supervisor):
                return
            results = session.run(train_fetches, train_feed_dict)
            train_loss += results['loss']
            if self.compute_summaries:
                supervisor.summary_computed(session, results['summaries'], results['step'])
        if train_size == 0:
            raise ValueError('examples must be non-empty')
        if self.exact_batch_sizes and epoch == 1:
            if train_size < self.batch_size:
                raise ValueError('when exact_batch_sizes is true, examples must have at least batch_size items; %s vs. %s' % (train_size, self.batch_size))
            train_size -= train_size % self.batch_size
        train_loss /= train_size
        self.report_loss(results['step'], train_loss)
        log_str = 'epoch:%5d train[loss: %.3e]' % (epoch, train_loss)
        if self.dev_examples:
            (dev_size, dev_loss, dev_metrics) = self._eval_batches(supervisor, session, next(gen_dev_batches), results['step'], is_dev=True)
            if dev_size is None:
                return
            if epoch == 1:
                self.log_and_print('train_size: %d dev_size: %d' % (train_size, dev_size))
            log_str += ' dev[%s]' % _eval_str(dev_size, dev_loss, dev_metrics)
            self.log_and_print(log_str)
            self._save_best(session, supervisor.saver, dev_loss, results['step'])
        else:
            if epoch == 1:
                self.log_and_print('train_size: %d' % train_size)
            self.log_and_print(log_str)
    if not self.dev_examples and self.is_chief_trainer:
        save_path = os.path.join(self.logdir, 'model.ckpt')
        save_fname = supervisor.saver.save(session, save_path, global_step=results['step'])
        self.log_and_print('final model saved in file: %s' % save_fname)",'final model saved in file: %s' % save_fname,f'final model saved in file: {save_fname}',1,,,,,,,,,,
fold,https://github.com/tensorflow/fold/tree/master/tensorflow_fold/blocks/plan.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/fold/tensorflow_fold/blocks/plan.py,TrainPlan,"def _run(self, supervisor, session):
    train_feed_dict = self.train_feeds.copy()
    train_fetches = {'train_op': self.train_op, 'loss': self.loss_total, 'step': self.global_step}
    if self.compute_summaries:
        train_fetches['summaries'] = self.summaries
    if self.examples:
        (epochs, train_size) = self._by_feed_dict(train_feed_dict)
    else:
        (epochs, train_size) = self._by_input_tensor(train_feed_dict)
    if self.dev_examples:
        gen_dev_batches = util.epochs(((len(batch), self.compiler.build_feed_dict(batch)) for batch in util.group_by_batches(self.dev_examples, self.batch_size)), shuffle=False)
        ckpt = tf.train.get_checkpoint_state(self.logdir)
        if ckpt and ckpt.model_checkpoint_path:
            (_, self._best_loss, _) = self._eval_batches(supervisor, session, next(gen_dev_batches), None, is_dev=True)
            if self._best_loss is None:
                return
    for (epoch, batches) in enumerate(epochs, 1):
        train_loss = 0.0
        for _ in batches:
            if self._should_stop(supervisor):
                return
            results = session.run(train_fetches, train_feed_dict)
            train_loss += results['loss']
            if self.compute_summaries:
                supervisor.summary_computed(session, results['summaries'], results['step'])
        if train_size == 0:
            raise ValueError('examples must be non-empty')
        if self.exact_batch_sizes and epoch == 1:
            if train_size < self.batch_size:
                raise ValueError('when exact_batch_sizes is true, examples must have at least batch_size items; %s vs. %s' % (train_size, self.batch_size))
            train_size -= train_size % self.batch_size
        train_loss /= train_size
        self.report_loss(results['step'], train_loss)
        log_str = 'epoch:%5d train[loss: %.3e]' % (epoch, train_loss)
        if self.dev_examples:
            (dev_size, dev_loss, dev_metrics) = self._eval_batches(supervisor, session, next(gen_dev_batches), results['step'], is_dev=True)
            if dev_size is None:
                return
            if epoch == 1:
                self.log_and_print('train_size: %d dev_size: %d' % (train_size, dev_size))
            log_str += ' dev[%s]' % _eval_str(dev_size, dev_loss, dev_metrics)
            self.log_and_print(log_str)
            self._save_best(session, supervisor.saver, dev_loss, results['step'])
        else:
            if epoch == 1:
                self.log_and_print('train_size: %d' % train_size)
            self.log_and_print(log_str)
    if not self.dev_examples and self.is_chief_trainer:
        save_path = os.path.join(self.logdir, 'model.ckpt')
        save_fname = supervisor.saver.save(session, save_path, global_step=results['step'])
        self.log_and_print('final model saved in file: %s' % save_fname)","'when exact_batch_sizes is true, examples must have at least batch_size items; %s vs. %s' % (train_size, self.batch_size)","f'when exact_batch_sizes is true, examples must have at least {self.batch_size} items; {train_size} vs. {self.batch_size}'",1,,,,,,,,,,
fold,https://github.com/tensorflow/fold/tree/master/tensorflow_fold/blocks/plan.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/fold/tensorflow_fold/blocks/plan.py,TrainPlan,"def _run(self, supervisor, session):
    train_feed_dict = self.train_feeds.copy()
    train_fetches = {'train_op': self.train_op, 'loss': self.loss_total, 'step': self.global_step}
    if self.compute_summaries:
        train_fetches['summaries'] = self.summaries
    if self.examples:
        (epochs, train_size) = self._by_feed_dict(train_feed_dict)
    else:
        (epochs, train_size) = self._by_input_tensor(train_feed_dict)
    if self.dev_examples:
        gen_dev_batches = util.epochs(((len(batch), self.compiler.build_feed_dict(batch)) for batch in util.group_by_batches(self.dev_examples, self.batch_size)), shuffle=False)
        ckpt = tf.train.get_checkpoint_state(self.logdir)
        if ckpt and ckpt.model_checkpoint_path:
            (_, self._best_loss, _) = self._eval_batches(supervisor, session, next(gen_dev_batches), None, is_dev=True)
            if self._best_loss is None:
                return
    for (epoch, batches) in enumerate(epochs, 1):
        train_loss = 0.0
        for _ in batches:
            if self._should_stop(supervisor):
                return
            results = session.run(train_fetches, train_feed_dict)
            train_loss += results['loss']
            if self.compute_summaries:
                supervisor.summary_computed(session, results['summaries'], results['step'])
        if train_size == 0:
            raise ValueError('examples must be non-empty')
        if self.exact_batch_sizes and epoch == 1:
            if train_size < self.batch_size:
                raise ValueError('when exact_batch_sizes is true, examples must have at least batch_size items; %s vs. %s' % (train_size, self.batch_size))
            train_size -= train_size % self.batch_size
        train_loss /= train_size
        self.report_loss(results['step'], train_loss)
        log_str = 'epoch:%5d train[loss: %.3e]' % (epoch, train_loss)
        if self.dev_examples:
            (dev_size, dev_loss, dev_metrics) = self._eval_batches(supervisor, session, next(gen_dev_batches), results['step'], is_dev=True)
            if dev_size is None:
                return
            if epoch == 1:
                self.log_and_print('train_size: %d dev_size: %d' % (train_size, dev_size))
            log_str += ' dev[%s]' % _eval_str(dev_size, dev_loss, dev_metrics)
            self.log_and_print(log_str)
            self._save_best(session, supervisor.saver, dev_loss, results['step'])
        else:
            if epoch == 1:
                self.log_and_print('train_size: %d' % train_size)
            self.log_and_print(log_str)
    if not self.dev_examples and self.is_chief_trainer:
        save_path = os.path.join(self.logdir, 'model.ckpt')
        save_fname = supervisor.saver.save(session, save_path, global_step=results['step'])
        self.log_and_print('final model saved in file: %s' % save_fname)","'train_size: %d dev_size: %d' % (train_size, dev_size)",f"train_size: {train_size} dev_size: {dev_size}",1,,,,,,,,,,
fold,https://github.com/tensorflow/fold/tree/master/tensorflow_fold/blocks/plan.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/fold/tensorflow_fold/blocks/plan.py,TrainPlan,"def _run(self, supervisor, session):
    train_feed_dict = self.train_feeds.copy()
    train_fetches = {'train_op': self.train_op, 'loss': self.loss_total, 'step': self.global_step}
    if self.compute_summaries:
        train_fetches['summaries'] = self.summaries
    if self.examples:
        (epochs, train_size) = self._by_feed_dict(train_feed_dict)
    else:
        (epochs, train_size) = self._by_input_tensor(train_feed_dict)
    if self.dev_examples:
        gen_dev_batches = util.epochs(((len(batch), self.compiler.build_feed_dict(batch)) for batch in util.group_by_batches(self.dev_examples, self.batch_size)), shuffle=False)
        ckpt = tf.train.get_checkpoint_state(self.logdir)
        if ckpt and ckpt.model_checkpoint_path:
            (_, self._best_loss, _) = self._eval_batches(supervisor, session, next(gen_dev_batches), None, is_dev=True)
            if self._best_loss is None:
                return
    for (epoch, batches) in enumerate(epochs, 1):
        train_loss = 0.0
        for _ in batches:
            if self._should_stop(supervisor):
                return
            results = session.run(train_fetches, train_feed_dict)
            train_loss += results['loss']
            if self.compute_summaries:
                supervisor.summary_computed(session, results['summaries'], results['step'])
        if train_size == 0:
            raise ValueError('examples must be non-empty')
        if self.exact_batch_sizes and epoch == 1:
            if train_size < self.batch_size:
                raise ValueError('when exact_batch_sizes is true, examples must have at least batch_size items; %s vs. %s' % (train_size, self.batch_size))
            train_size -= train_size % self.batch_size
        train_loss /= train_size
        self.report_loss(results['step'], train_loss)
        log_str = 'epoch:%5d train[loss: %.3e]' % (epoch, train_loss)
        if self.dev_examples:
            (dev_size, dev_loss, dev_metrics) = self._eval_batches(supervisor, session, next(gen_dev_batches), results['step'], is_dev=True)
            if dev_size is None:
                return
            if epoch == 1:
                self.log_and_print('train_size: %d dev_size: %d' % (train_size, dev_size))
            log_str += ' dev[%s]' % _eval_str(dev_size, dev_loss, dev_metrics)
            self.log_and_print(log_str)
            self._save_best(session, supervisor.saver, dev_loss, results['step'])
        else:
            if epoch == 1:
                self.log_and_print('train_size: %d' % train_size)
            self.log_and_print(log_str)
    if not self.dev_examples and self.is_chief_trainer:
        save_path = os.path.join(self.logdir, 'model.ckpt')
        save_fname = supervisor.saver.save(session, save_path, global_step=results['step'])
        self.log_and_print('final model saved in file: %s' % save_fname)",'train_size: %d' % train_size,f"train_size: {train_size}",1,,,,,,,,,,
not-youtube-dl,https://github.com/scastillo/not-youtube-dl/tree/master/youtube_dl/options.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/not-youtube-dl/youtube_dl/options.py,,"def parseOpts(overrideArguments=None):

    def _readOptions(filename_bytes, default=[]):
        try:
            optionf = open(filename_bytes)
        except IOError:
            return default
        try:
            contents = optionf.read()
            if sys.version_info < (3,):
                contents = contents.decode(preferredencoding())
            res = compat_shlex_split(contents, comments=True)
        finally:
            optionf.close()
        return res

    def _readUserConf():
        xdg_config_home = compat_getenv('XDG_CONFIG_HOME')
        if xdg_config_home:
            userConfFile = os.path.join(xdg_config_home, 'youtube-dl', 'config')
            if not os.path.isfile(userConfFile):
                userConfFile = os.path.join(xdg_config_home, 'youtube-dl.conf')
        else:
            userConfFile = os.path.join(compat_expanduser('~'), '.config', 'youtube-dl', 'config')
            if not os.path.isfile(userConfFile):
                userConfFile = os.path.join(compat_expanduser('~'), '.config', 'youtube-dl.conf')
        userConf = _readOptions(userConfFile, None)
        if userConf is None:
            appdata_dir = compat_getenv('appdata')
            if appdata_dir:
                userConf = _readOptions(os.path.join(appdata_dir, 'youtube-dl', 'config'), default=None)
                if userConf is None:
                    userConf = _readOptions(os.path.join(appdata_dir, 'youtube-dl', 'config.txt'), default=None)
        if userConf is None:
            userConf = _readOptions(os.path.join(compat_expanduser('~'), 'youtube-dl.conf'), default=None)
        if userConf is None:
            userConf = _readOptions(os.path.join(compat_expanduser('~'), 'youtube-dl.conf.txt'), default=None)
        if userConf is None:
            userConf = []
        return userConf

    def _format_option_string(option):
        """""" ('-o', '--option') -> -o, --format METAVAR""""""
        opts = []
        if option._short_opts:
            opts.append(option._short_opts[0])
        if option._long_opts:
            opts.append(option._long_opts[0])
        if len(opts) > 1:
            opts.insert(1, ', ')
        if option.takes_value():
            opts.append(' %s' % option.metavar)
        return ''.join(opts)

    def _comma_separated_values_options_callback(option, opt_str, value, parser):
        setattr(parser.values, option.dest, value.split(','))
    columns = compat_get_terminal_size().columns
    max_width = columns if columns else 80
    max_help_position = 80
    fmt = optparse.IndentedHelpFormatter(width=max_width, max_help_position=max_help_position)
    fmt.format_option_strings = _format_option_string
    kw = {'version': __version__, 'formatter': fmt, 'usage': '%prog [OPTIONS] URL [URL...]', 'conflict_handler': 'resolve'}
    parser = optparse.OptionParser(**compat_kwargs(kw))
    general = optparse.OptionGroup(parser, 'General Options')
    general.add_option('-h', '--help', action='help', help='Print this help text and exit')
    general.add_option('--version', action='version', help='Print program version and exit')
    general.add_option('-U', '--update', action='store_true', dest='update_self', help='Update this program to latest version. Make sure that you have sufficient permissions (run with sudo if needed)')
    general.add_option('-i', '--ignore-errors', action='store_true', dest='ignoreerrors', default=False, help='Continue on download errors, for example to skip unavailable videos in a playlist')
    general.add_option('--abort-on-error', action='store_false', dest='ignoreerrors', help='Abort downloading of further videos (in the playlist or the command line) if an error occurs')
    general.add_option('--dump-user-agent', action='store_true', dest='dump_user_agent', default=False, help='Display the current browser identification')
    general.add_option('--list-extractors', action='store_true', dest='list_extractors', default=False, help='List all supported extractors')
    general.add_option('--extractor-descriptions', action='store_true', dest='list_extractor_descriptions', default=False, help='Output descriptions of all supported extractors')
    general.add_option('--force-generic-extractor', action='store_true', dest='force_generic_extractor', default=False, help='Force extraction to use the generic extractor')
    general.add_option('--default-search', dest='default_search', metavar='PREFIX', help='Use this prefix for unqualified URLs. For example ""gvsearch2:"" downloads two videos from google videos for youtube-dl ""large apple"". Use the value ""auto"" to let youtube-dl guess (""auto_warning"" to emit a warning when guessing). ""error"" just throws an error. The default value ""fixup_error"" repairs broken URLs, but emits an error if this is not possible instead of searching.')
    general.add_option('--ignore-config', action='store_true', help='Do not read configuration files. When given in the global configuration file /etc/youtube-dl.conf: Do not read the user configuration in ~/.config/youtube-dl/config (%APPDATA%/youtube-dl/config.txt on Windows)')
    general.add_option('--config-location', dest='config_location', metavar='PATH', help='Location of the configuration file; either the path to the config or its containing directory.')
    general.add_option('--flat-playlist', action='store_const', dest='extract_flat', const='in_playlist', default=False, help='Do not extract the videos of a playlist, only list them.')
    general.add_option('--mark-watched', action='store_true', dest='mark_watched', default=False, help='Mark videos watched (YouTube only)')
    general.add_option('--no-mark-watched', action='store_false', dest='mark_watched', default=False, help='Do not mark videos watched (YouTube only)')
    general.add_option('--no-color', '--no-colors', action='store_true', dest='no_color', default=False, help='Do not emit color codes in output')
    network = optparse.OptionGroup(parser, 'Network Options')
    network.add_option('--proxy', dest='proxy', default=None, metavar='URL', help='Use the specified HTTP/HTTPS/SOCKS proxy. To enable SOCKS proxy, specify a proper scheme. For example socks5://127.0.0.1:1080/. Pass in an empty string (--proxy """") for direct connection')
    network.add_option('--socket-timeout', dest='socket_timeout', type=float, default=None, metavar='SECONDS', help='Time to wait before giving up, in seconds')
    network.add_option('--source-address', metavar='IP', dest='source_address', default=None, help='Client-side IP address to bind to')
    network.add_option('-4', '--force-ipv4', action='store_const', const='0.0.0.0', dest='source_address', help='Make all connections via IPv4')
    network.add_option('-6', '--force-ipv6', action='store_const', const='::', dest='source_address', help='Make all connections via IPv6')
    geo = optparse.OptionGroup(parser, 'Geo Restriction')
    geo.add_option('--geo-verification-proxy', dest='geo_verification_proxy', default=None, metavar='URL', help='Use this proxy to verify the IP address for some geo-restricted sites. The default proxy specified by --proxy (or none, if the option is not present) is used for the actual downloading.')
    geo.add_option('--cn-verification-proxy', dest='cn_verification_proxy', default=None, metavar='URL', help=optparse.SUPPRESS_HELP)
    geo.add_option('--geo-bypass', action='store_true', dest='geo_bypass', default=True, help='Bypass geographic restriction via faking X-Forwarded-For HTTP header')
    geo.add_option('--no-geo-bypass', action='store_false', dest='geo_bypass', default=True, help='Do not bypass geographic restriction via faking X-Forwarded-For HTTP header')
    geo.add_option('--geo-bypass-country', metavar='CODE', dest='geo_bypass_country', default=None, help='Force bypass geographic restriction with explicitly provided two-letter ISO 3166-2 country code')
    geo.add_option('--geo-bypass-ip-block', metavar='IP_BLOCK', dest='geo_bypass_ip_block', default=None, help='Force bypass geographic restriction with explicitly provided IP block in CIDR notation')
    selection = optparse.OptionGroup(parser, 'Video Selection')
    selection.add_option('--playlist-start', dest='playliststart', metavar='NUMBER', default=1, type=int, help='Playlist video to start at (default is %default)')
    selection.add_option('--playlist-end', dest='playlistend', metavar='NUMBER', default=None, type=int, help='Playlist video to end at (default is last)')
    selection.add_option('--playlist-items', dest='playlist_items', metavar='ITEM_SPEC', default=None, help='Playlist video items to download. Specify indices of the videos in the playlist separated by commas like: ""--playlist-items 1,2,5,8"" if you want to download videos indexed 1, 2, 5, 8 in the playlist. You can specify range: ""--playlist-items 1-3,7,10-13"", it will download the videos at index 1, 2, 3, 7, 10, 11, 12 and 13.')
    selection.add_option('--match-title', dest='matchtitle', metavar='REGEX', help='Download only matching titles (regex or caseless sub-string)')
    selection.add_option('--reject-title', dest='rejecttitle', metavar='REGEX', help='Skip download for matching titles (regex or caseless sub-string)')
    selection.add_option('--max-downloads', dest='max_downloads', metavar='NUMBER', type=int, default=None, help='Abort after downloading NUMBER files')
    selection.add_option('--min-filesize', metavar='SIZE', dest='min_filesize', default=None, help='Do not download any videos smaller than SIZE (e.g. 50k or 44.6m)')
    selection.add_option('--max-filesize', metavar='SIZE', dest='max_filesize', default=None, help='Do not download any videos larger than SIZE (e.g. 50k or 44.6m)')
    selection.add_option('--date', metavar='DATE', dest='date', default=None, help='Download only videos uploaded in this date')
    selection.add_option('--datebefore', metavar='DATE', dest='datebefore', default=None, help='Download only videos uploaded on or before this date (i.e. inclusive)')
    selection.add_option('--dateafter', metavar='DATE', dest='dateafter', default=None, help='Download only videos uploaded on or after this date (i.e. inclusive)')
    selection.add_option('--min-views', metavar='COUNT', dest='min_views', default=None, type=int, help='Do not download any videos with less than COUNT views')
    selection.add_option('--max-views', metavar='COUNT', dest='max_views', default=None, type=int, help='Do not download any videos with more than COUNT views')
    selection.add_option('--match-filter', metavar='FILTER', dest='match_filter', default=None, help='Generic video filter. Specify any key (see the ""OUTPUT TEMPLATE"" for a list of available keys) to match if the key is present, !key to check if the key is not present, key > NUMBER (like ""comment_count > 12"", also works with >=, <, <=, !=, =) to compare against a number, key = \'LITERAL\' (like ""uploader = \'Mike Smith\'"", also works with !=) to match against a string literal and & to require multiple matches. Values which are not known are excluded unless you put a question mark (?) after the operator. For example, to only match videos that have been liked more than 100 times and disliked less than 50 times (or the dislike functionality is not available at the given service), but who also have a description, use --match-filter ""like_count > 100 & dislike_count <? 50 & description"" .')
    selection.add_option('--no-playlist', action='store_true', dest='noplaylist', default=False, help='Download only the video, if the URL refers to a video and a playlist.')
    selection.add_option('--yes-playlist', action='store_false', dest='noplaylist', default=False, help='Download the playlist, if the URL refers to a video and a playlist.')
    selection.add_option('--age-limit', metavar='YEARS', dest='age_limit', default=None, type=int, help='Download only videos suitable for the given age')
    selection.add_option('--download-archive', metavar='FILE', dest='download_archive', help='Download only videos not listed in the archive file. Record the IDs of all downloaded videos in it.')
    selection.add_option('--include-ads', dest='include_ads', action='store_true', help='Download advertisements as well (experimental)')
    authentication = optparse.OptionGroup(parser, 'Authentication Options')
    authentication.add_option('-u', '--username', dest='username', metavar='USERNAME', help='Login with this account ID')
    authentication.add_option('-p', '--password', dest='password', metavar='PASSWORD', help='Account password. If this option is left out, youtube-dl will ask interactively.')
    authentication.add_option('-2', '--twofactor', dest='twofactor', metavar='TWOFACTOR', help='Two-factor authentication code')
    authentication.add_option('-n', '--netrc', action='store_true', dest='usenetrc', default=False, help='Use .netrc authentication data')
    authentication.add_option('--video-password', dest='videopassword', metavar='PASSWORD', help='Video password (vimeo, smotri, youku)')
    adobe_pass = optparse.OptionGroup(parser, 'Adobe Pass Options')
    adobe_pass.add_option('--ap-mso', dest='ap_mso', metavar='MSO', help='Adobe Pass multiple-system operator (TV provider) identifier, use --ap-list-mso for a list of available MSOs')
    adobe_pass.add_option('--ap-username', dest='ap_username', metavar='USERNAME', help='Multiple-system operator account login')
    adobe_pass.add_option('--ap-password', dest='ap_password', metavar='PASSWORD', help='Multiple-system operator account password. If this option is left out, youtube-dl will ask interactively.')
    adobe_pass.add_option('--ap-list-mso', action='store_true', dest='ap_list_mso', default=False, help='List all supported multiple-system operators')
    video_format = optparse.OptionGroup(parser, 'Video Format Options')
    video_format.add_option('-f', '--format', action='store', dest='format', metavar='FORMAT', default=None, help='Video format code, see the ""FORMAT SELECTION"" for all the info')
    video_format.add_option('--all-formats', action='store_const', dest='format', const='all', help='Download all available video formats')
    video_format.add_option('--prefer-free-formats', action='store_true', dest='prefer_free_formats', default=False, help='Prefer free video formats unless a specific one is requested')
    video_format.add_option('-F', '--list-formats', action='store_true', dest='listformats', help='List all available formats of requested videos')
    video_format.add_option('--youtube-include-dash-manifest', action='store_true', dest='youtube_include_dash_manifest', default=True, help=optparse.SUPPRESS_HELP)
    video_format.add_option('--youtube-skip-dash-manifest', action='store_false', dest='youtube_include_dash_manifest', help='Do not download the DASH manifests and related data on YouTube videos')
    video_format.add_option('--merge-output-format', action='store', dest='merge_output_format', metavar='FORMAT', default=None, help='If a merge is required (e.g. bestvideo+bestaudio), output to given container format. One of mkv, mp4, ogg, webm, flv. Ignored if no merge is required')
    subtitles = optparse.OptionGroup(parser, 'Subtitle Options')
    subtitles.add_option('--write-sub', '--write-srt', action='store_true', dest='writesubtitles', default=False, help='Write subtitle file')
    subtitles.add_option('--write-auto-sub', '--write-automatic-sub', action='store_true', dest='writeautomaticsub', default=False, help='Write automatically generated subtitle file (YouTube only)')
    subtitles.add_option('--all-subs', action='store_true', dest='allsubtitles', default=False, help='Download all the available subtitles of the video')
    subtitles.add_option('--list-subs', action='store_true', dest='listsubtitles', default=False, help='List all available subtitles for the video')
    subtitles.add_option('--sub-format', action='store', dest='subtitlesformat', metavar='FORMAT', default='best', help='Subtitle format, accepts formats preference, for example: ""srt"" or ""ass/srt/best""')
    subtitles.add_option('--sub-lang', '--sub-langs', '--srt-lang', action='callback', dest='subtitleslangs', metavar='LANGS', type='str', default=[], callback=_comma_separated_values_options_callback, help='Languages of the subtitles to download (optional) separated by commas, use --list-subs for available language tags')
    downloader = optparse.OptionGroup(parser, 'Download Options')
    downloader.add_option('-r', '--limit-rate', '--rate-limit', dest='ratelimit', metavar='RATE', help='Maximum download rate in bytes per second (e.g. 50K or 4.2M)')
    downloader.add_option('-R', '--retries', dest='retries', metavar='RETRIES', default=10, help='Number of retries (default is %default), or ""infinite"".')
    downloader.add_option('--fragment-retries', dest='fragment_retries', metavar='RETRIES', default=10, help='Number of retries for a fragment (default is %default), or ""infinite"" (DASH, hlsnative and ISM)')
    downloader.add_option('--skip-unavailable-fragments', action='store_true', dest='skip_unavailable_fragments', default=True, help='Skip unavailable fragments (DASH, hlsnative and ISM)')
    downloader.add_option('--abort-on-unavailable-fragment', action='store_false', dest='skip_unavailable_fragments', help='Abort downloading when some fragment is not available')
    downloader.add_option('--keep-fragments', action='store_true', dest='keep_fragments', default=False, help='Keep downloaded fragments on disk after downloading is finished; fragments are erased by default')
    downloader.add_option('--buffer-size', dest='buffersize', metavar='SIZE', default='1024', help='Size of download buffer (e.g. 1024 or 16K) (default is %default)')
    downloader.add_option('--no-resize-buffer', action='store_true', dest='noresizebuffer', default=False, help='Do not automatically adjust the buffer size. By default, the buffer size is automatically resized from an initial value of SIZE.')
    downloader.add_option('--http-chunk-size', dest='http_chunk_size', metavar='SIZE', default=None, help='Size of a chunk for chunk-based HTTP downloading (e.g. 10485760 or 10M) (default is disabled). May be useful for bypassing bandwidth throttling imposed by a webserver (experimental)')
    downloader.add_option('--test', action='store_true', dest='test', default=False, help=optparse.SUPPRESS_HELP)
    downloader.add_option('--playlist-reverse', action='store_true', help='Download playlist videos in reverse order')
    downloader.add_option('--playlist-random', action='store_true', help='Download playlist videos in random order')
    downloader.add_option('--xattr-set-filesize', dest='xattr_set_filesize', action='store_true', help='Set file xattribute ytdl.filesize with expected file size')
    downloader.add_option('--hls-prefer-native', dest='hls_prefer_native', action='store_true', default=None, help='Use the native HLS downloader instead of ffmpeg')
    downloader.add_option('--hls-prefer-ffmpeg', dest='hls_prefer_native', action='store_false', default=None, help='Use ffmpeg instead of the native HLS downloader')
    downloader.add_option('--hls-use-mpegts', dest='hls_use_mpegts', action='store_true', help='Use the mpegts container for HLS videos, allowing to play the video while downloading (some players may not be able to play it)')
    downloader.add_option('--external-downloader', dest='external_downloader', metavar='COMMAND', help='Use the specified external downloader. Currently supports %s' % ','.join(list_external_downloaders()))
    downloader.add_option('--external-downloader-args', dest='external_downloader_args', metavar='ARGS', help='Give these arguments to the external downloader')
    workarounds = optparse.OptionGroup(parser, 'Workarounds')
    workarounds.add_option('--encoding', dest='encoding', metavar='ENCODING', help='Force the specified encoding (experimental)')
    workarounds.add_option('--no-check-certificate', action='store_true', dest='no_check_certificate', default=False, help='Suppress HTTPS certificate validation')
    workarounds.add_option('--prefer-insecure', '--prefer-unsecure', action='store_true', dest='prefer_insecure', help='Use an unencrypted connection to retrieve information about the video. (Currently supported only for YouTube)')
    workarounds.add_option('--user-agent', metavar='UA', dest='user_agent', help='Specify a custom user agent')
    workarounds.add_option('--referer', metavar='URL', dest='referer', default=None, help='Specify a custom referer, use if the video access is restricted to one domain')
    workarounds.add_option('--add-header', metavar='FIELD:VALUE', dest='headers', action='append', help=""Specify a custom HTTP header and its value, separated by a colon ':'. You can use this option multiple times"")
    workarounds.add_option('--bidi-workaround', dest='bidi_workaround', action='store_true', help='Work around terminals that lack bidirectional text support. Requires bidiv or fribidi executable in PATH')
    workarounds.add_option('--sleep-interval', '--min-sleep-interval', metavar='SECONDS', dest='sleep_interval', type=float, help='Number of seconds to sleep before each download when used alone or a lower bound of a range for randomized sleep before each download (minimum possible number of seconds to sleep) when used along with --max-sleep-interval.')
    workarounds.add_option('--max-sleep-interval', metavar='SECONDS', dest='max_sleep_interval', type=float, help='Upper bound of a range for randomized sleep before each download (maximum possible number of seconds to sleep). Must only be used along with --min-sleep-interval.')
    verbosity = optparse.OptionGroup(parser, 'Verbosity / Simulation Options')
    verbosity.add_option('-q', '--quiet', action='store_true', dest='quiet', default=False, help='Activate quiet mode')
    verbosity.add_option('--no-warnings', dest='no_warnings', action='store_true', default=False, help='Ignore warnings')
    verbosity.add_option('-s', '--simulate', action='store_true', dest='simulate', default=False, help='Do not download the video and do not write anything to disk')
    verbosity.add_option('--skip-download', action='store_true', dest='skip_download', default=False, help='Do not download the video')
    verbosity.add_option('-g', '--get-url', action='store_true', dest='geturl', default=False, help='Simulate, quiet but print URL')
    verbosity.add_option('-e', '--get-title', action='store_true', dest='gettitle', default=False, help='Simulate, quiet but print title')
    verbosity.add_option('--get-id', action='store_true', dest='getid', default=False, help='Simulate, quiet but print id')
    verbosity.add_option('--get-thumbnail', action='store_true', dest='getthumbnail', default=False, help='Simulate, quiet but print thumbnail URL')
    verbosity.add_option('--get-description', action='store_true', dest='getdescription', default=False, help='Simulate, quiet but print video description')
    verbosity.add_option('--get-duration', action='store_true', dest='getduration', default=False, help='Simulate, quiet but print video length')
    verbosity.add_option('--get-filename', action='store_true', dest='getfilename', default=False, help='Simulate, quiet but print output filename')
    verbosity.add_option('--get-format', action='store_true', dest='getformat', default=False, help='Simulate, quiet but print output format')
    verbosity.add_option('-j', '--dump-json', action='store_true', dest='dumpjson', default=False, help='Simulate, quiet but print JSON information. See the ""OUTPUT TEMPLATE"" for a description of available keys.')
    verbosity.add_option('-J', '--dump-single-json', action='store_true', dest='dump_single_json', default=False, help='Simulate, quiet but print JSON information for each command-line argument. If the URL refers to a playlist, dump the whole playlist information in a single line.')
    verbosity.add_option('--print-json', action='store_true', dest='print_json', default=False, help='Be quiet and print the video information as JSON (video is still being downloaded).')
    verbosity.add_option('--newline', action='store_true', dest='progress_with_newline', default=False, help='Output progress bar as new lines')
    verbosity.add_option('--no-progress', action='store_true', dest='noprogress', default=False, help='Do not print progress bar')
    verbosity.add_option('--console-title', action='store_true', dest='consoletitle', default=False, help='Display progress in console titlebar')
    verbosity.add_option('-v', '--verbose', action='store_true', dest='verbose', default=False, help='Print various debugging information')
    verbosity.add_option('--dump-pages', '--dump-intermediate-pages', action='store_true', dest='dump_intermediate_pages', default=False, help='Print downloaded pages encoded using base64 to debug problems (very verbose)')
    verbosity.add_option('--write-pages', action='store_true', dest='write_pages', default=False, help='Write downloaded intermediary pages to files in the current directory to debug problems')
    verbosity.add_option('--youtube-print-sig-code', action='store_true', dest='youtube_print_sig_code', default=False, help=optparse.SUPPRESS_HELP)
    verbosity.add_option('--print-traffic', '--dump-headers', dest='debug_printtraffic', action='store_true', default=False, help='Display sent and read HTTP traffic')
    verbosity.add_option('-C', '--call-home', dest='call_home', action='store_true', default=False, help='Contact the youtube-dl server for debugging')
    verbosity.add_option('--no-call-home', dest='call_home', action='store_false', default=False, help='Do NOT contact the youtube-dl server for debugging')
    filesystem = optparse.OptionGroup(parser, 'Filesystem Options')
    filesystem.add_option('-a', '--batch-file', dest='batchfile', metavar='FILE', help=""File containing URLs to download ('-' for stdin), one URL per line. Lines starting with '#', ';' or ']' are considered as comments and ignored."")
    filesystem.add_option('--id', default=False, action='store_true', dest='useid', help='Use only video ID in file name')
    filesystem.add_option('-o', '--output', dest='outtmpl', metavar='TEMPLATE', help='Output filename template, see the ""OUTPUT TEMPLATE"" for all the info')
    filesystem.add_option('--autonumber-size', dest='autonumber_size', metavar='NUMBER', type=int, help=optparse.SUPPRESS_HELP)
    filesystem.add_option('--autonumber-start', dest='autonumber_start', metavar='NUMBER', default=1, type=int, help='Specify the start value for %(autonumber)s (default is %default)')
    filesystem.add_option('--restrict-filenames', action='store_true', dest='restrictfilenames', default=False, help='Restrict filenames to only ASCII characters, and avoid ""&"" and spaces in filenames')
    filesystem.add_option('-A', '--auto-number', action='store_true', dest='autonumber', default=False, help=optparse.SUPPRESS_HELP)
    filesystem.add_option('-t', '--title', action='store_true', dest='usetitle', default=False, help=optparse.SUPPRESS_HELP)
    filesystem.add_option('-l', '--literal', default=False, action='store_true', dest='usetitle', help=optparse.SUPPRESS_HELP)
    filesystem.add_option('-w', '--no-overwrites', action='store_true', dest='nooverwrites', default=False, help='Do not overwrite files')
    filesystem.add_option('-c', '--continue', action='store_true', dest='continue_dl', default=True, help='Force resume of partially downloaded files. By default, youtube-dl will resume downloads if possible.')
    filesystem.add_option('--no-continue', action='store_false', dest='continue_dl', help='Do not resume partially downloaded files (restart from beginning)')
    filesystem.add_option('--no-part', action='store_true', dest='nopart', default=False, help='Do not use .part files - write directly into output file')
    filesystem.add_option('--no-mtime', action='store_false', dest='updatetime', default=True, help='Do not use the Last-modified header to set the file modification time')
    filesystem.add_option('--write-description', action='store_true', dest='writedescription', default=False, help='Write video description to a .description file')
    filesystem.add_option('--write-info-json', action='store_true', dest='writeinfojson', default=False, help='Write video metadata to a .info.json file')
    filesystem.add_option('--write-annotations', action='store_true', dest='writeannotations', default=False, help='Write video annotations to a .annotations.xml file')
    filesystem.add_option('--load-info-json', '--load-info', dest='load_info_filename', metavar='FILE', help='JSON file containing the video information (created with the ""--write-info-json"" option)')
    filesystem.add_option('--cookies', dest='cookiefile', metavar='FILE', help='File to read cookies from and dump cookie jar in')
    filesystem.add_option('--cache-dir', dest='cachedir', default=None, metavar='DIR', help='Location in the filesystem where youtube-dl can store some downloaded information permanently. By default $XDG_CACHE_HOME/youtube-dl or ~/.cache/youtube-dl . At the moment, only YouTube player files (for videos with obfuscated signatures) are cached, but that may change.')
    filesystem.add_option('--no-cache-dir', action='store_const', const=False, dest='cachedir', help='Disable filesystem caching')
    filesystem.add_option('--rm-cache-dir', action='store_true', dest='rm_cachedir', help='Delete all filesystem cache files')
    thumbnail = optparse.OptionGroup(parser, 'Thumbnail images')
    thumbnail.add_option('--write-thumbnail', action='store_true', dest='writethumbnail', default=False, help='Write thumbnail image to disk')
    thumbnail.add_option('--write-all-thumbnails', action='store_true', dest='write_all_thumbnails', default=False, help='Write all thumbnail image formats to disk')
    thumbnail.add_option('--list-thumbnails', action='store_true', dest='list_thumbnails', default=False, help='Simulate and list all available thumbnail formats')
    postproc = optparse.OptionGroup(parser, 'Post-processing Options')
    postproc.add_option('-x', '--extract-audio', action='store_true', dest='extractaudio', default=False, help='Convert video files to audio-only files (requires ffmpeg or avconv and ffprobe or avprobe)')
    postproc.add_option('--audio-format', metavar='FORMAT', dest='audioformat', default='best', help='Specify audio format: ""best"", ""aac"", ""flac"", ""mp3"", ""m4a"", ""opus"", ""vorbis"", or ""wav""; ""%default"" by default; No effect without -x')
    postproc.add_option('--audio-quality', metavar='QUALITY', dest='audioquality', default='5', help='Specify ffmpeg/avconv audio quality, insert a value between 0 (better) and 9 (worse) for VBR or a specific bitrate like 128K (default %default)')
    postproc.add_option('--recode-video', metavar='FORMAT', dest='recodevideo', default=None, help='Encode the video to another format if necessary (currently supported: mp4|flv|ogg|webm|mkv|avi)')
    postproc.add_option('--postprocessor-args', dest='postprocessor_args', metavar='ARGS', help='Give these arguments to the postprocessor')
    postproc.add_option('-k', '--keep-video', action='store_true', dest='keepvideo', default=False, help='Keep the video file on disk after the post-processing; the video is erased by default')
    postproc.add_option('--no-post-overwrites', action='store_true', dest='nopostoverwrites', default=False, help='Do not overwrite post-processed files; the post-processed files are overwritten by default')
    postproc.add_option('--embed-subs', action='store_true', dest='embedsubtitles', default=False, help='Embed subtitles in the video (only for mp4, webm and mkv videos)')
    postproc.add_option('--embed-thumbnail', action='store_true', dest='embedthumbnail', default=False, help='Embed thumbnail in the audio as cover art')
    postproc.add_option('--add-metadata', action='store_true', dest='addmetadata', default=False, help='Write metadata to the video file')
    postproc.add_option('--metadata-from-title', metavar='FORMAT', dest='metafromtitle', help='Parse additional metadata like song title / artist from the video title. The format syntax is the same as --output. Regular expression with named capture groups may also be used. The parsed parameters replace existing values. Example: --metadata-from-title ""%(artist)s - %(title)s"" matches a title like ""Coldplay - Paradise"". Example (regex): --metadata-from-title ""(?P<artist>.+?) - (?P<title>.+)""')
    postproc.add_option('--xattrs', action='store_true', dest='xattrs', default=False, help=""Write metadata to the video file's xattrs (using dublin core and xdg standards)"")
    postproc.add_option('--fixup', metavar='POLICY', dest='fixup', default='detect_or_warn', help='Automatically correct known faults of the file. One of never (do nothing), warn (only emit a warning), detect_o","'Use the specified external downloader. Currently supports %s' % ','.join(list_external_downloaders())","f""Use the specified external downloader. Currently supports {','.join(list_external_downloaders())}""",1,,,,,,,,,,
not-youtube-dl,https://github.com/scastillo/not-youtube-dl/tree/master/youtube_dl/options.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/not-youtube-dl/youtube_dl/options.py,,"def parseOpts(overrideArguments=None):

    def _readOptions(filename_bytes, default=[]):
        try:
            optionf = open(filename_bytes)
        except IOError:
            return default
        try:
            contents = optionf.read()
            if sys.version_info < (3,):
                contents = contents.decode(preferredencoding())
            res = compat_shlex_split(contents, comments=True)
        finally:
            optionf.close()
        return res

    def _readUserConf():
        xdg_config_home = compat_getenv('XDG_CONFIG_HOME')
        if xdg_config_home:
            userConfFile = os.path.join(xdg_config_home, 'youtube-dl', 'config')
            if not os.path.isfile(userConfFile):
                userConfFile = os.path.join(xdg_config_home, 'youtube-dl.conf')
        else:
            userConfFile = os.path.join(compat_expanduser('~'), '.config', 'youtube-dl', 'config')
            if not os.path.isfile(userConfFile):
                userConfFile = os.path.join(compat_expanduser('~'), '.config', 'youtube-dl.conf')
        userConf = _readOptions(userConfFile, None)
        if userConf is None:
            appdata_dir = compat_getenv('appdata')
            if appdata_dir:
                userConf = _readOptions(os.path.join(appdata_dir, 'youtube-dl', 'config'), default=None)
                if userConf is None:
                    userConf = _readOptions(os.path.join(appdata_dir, 'youtube-dl', 'config.txt'), default=None)
        if userConf is None:
            userConf = _readOptions(os.path.join(compat_expanduser('~'), 'youtube-dl.conf'), default=None)
        if userConf is None:
            userConf = _readOptions(os.path.join(compat_expanduser('~'), 'youtube-dl.conf.txt'), default=None)
        if userConf is None:
            userConf = []
        return userConf

    def _format_option_string(option):
        """""" ('-o', '--option') -> -o, --format METAVAR""""""
        opts = []
        if option._short_opts:
            opts.append(option._short_opts[0])
        if option._long_opts:
            opts.append(option._long_opts[0])
        if len(opts) > 1:
            opts.insert(1, ', ')
        if option.takes_value():
            opts.append(' %s' % option.metavar)
        return ''.join(opts)

    def _comma_separated_values_options_callback(option, opt_str, value, parser):
        setattr(parser.values, option.dest, value.split(','))
    columns = compat_get_terminal_size().columns
    max_width = columns if columns else 80
    max_help_position = 80
    fmt = optparse.IndentedHelpFormatter(width=max_width, max_help_position=max_help_position)
    fmt.format_option_strings = _format_option_string
    kw = {'version': __version__, 'formatter': fmt, 'usage': '%prog [OPTIONS] URL [URL...]', 'conflict_handler': 'resolve'}
    parser = optparse.OptionParser(**compat_kwargs(kw))
    general = optparse.OptionGroup(parser, 'General Options')
    general.add_option('-h', '--help', action='help', help='Print this help text and exit')
    general.add_option('--version', action='version', help='Print program version and exit')
    general.add_option('-U', '--update', action='store_true', dest='update_self', help='Update this program to latest version. Make sure that you have sufficient permissions (run with sudo if needed)')
    general.add_option('-i', '--ignore-errors', action='store_true', dest='ignoreerrors', default=False, help='Continue on download errors, for example to skip unavailable videos in a playlist')
    general.add_option('--abort-on-error', action='store_false', dest='ignoreerrors', help='Abort downloading of further videos (in the playlist or the command line) if an error occurs')
    general.add_option('--dump-user-agent', action='store_true', dest='dump_user_agent', default=False, help='Display the current browser identification')
    general.add_option('--list-extractors', action='store_true', dest='list_extractors', default=False, help='List all supported extractors')
    general.add_option('--extractor-descriptions', action='store_true', dest='list_extractor_descriptions', default=False, help='Output descriptions of all supported extractors')
    general.add_option('--force-generic-extractor', action='store_true', dest='force_generic_extractor', default=False, help='Force extraction to use the generic extractor')
    general.add_option('--default-search', dest='default_search', metavar='PREFIX', help='Use this prefix for unqualified URLs. For example ""gvsearch2:"" downloads two videos from google videos for youtube-dl ""large apple"". Use the value ""auto"" to let youtube-dl guess (""auto_warning"" to emit a warning when guessing). ""error"" just throws an error. The default value ""fixup_error"" repairs broken URLs, but emits an error if this is not possible instead of searching.')
    general.add_option('--ignore-config', action='store_true', help='Do not read configuration files. When given in the global configuration file /etc/youtube-dl.conf: Do not read the user configuration in ~/.config/youtube-dl/config (%APPDATA%/youtube-dl/config.txt on Windows)')
    general.add_option('--config-location', dest='config_location', metavar='PATH', help='Location of the configuration file; either the path to the config or its containing directory.')
    general.add_option('--flat-playlist', action='store_const', dest='extract_flat', const='in_playlist', default=False, help='Do not extract the videos of a playlist, only list them.')
    general.add_option('--mark-watched', action='store_true', dest='mark_watched', default=False, help='Mark videos watched (YouTube only)')
    general.add_option('--no-mark-watched', action='store_false', dest='mark_watched', default=False, help='Do not mark videos watched (YouTube only)')
    general.add_option('--no-color', '--no-colors', action='store_true', dest='no_color', default=False, help='Do not emit color codes in output')
    network = optparse.OptionGroup(parser, 'Network Options')
    network.add_option('--proxy', dest='proxy', default=None, metavar='URL', help='Use the specified HTTP/HTTPS/SOCKS proxy. To enable SOCKS proxy, specify a proper scheme. For example socks5://127.0.0.1:1080/. Pass in an empty string (--proxy """") for direct connection')
    network.add_option('--socket-timeout', dest='socket_timeout', type=float, default=None, metavar='SECONDS', help='Time to wait before giving up, in seconds')
    network.add_option('--source-address', metavar='IP', dest='source_address', default=None, help='Client-side IP address to bind to')
    network.add_option('-4', '--force-ipv4', action='store_const', const='0.0.0.0', dest='source_address', help='Make all connections via IPv4')
    network.add_option('-6', '--force-ipv6', action='store_const', const='::', dest='source_address', help='Make all connections via IPv6')
    geo = optparse.OptionGroup(parser, 'Geo Restriction')
    geo.add_option('--geo-verification-proxy', dest='geo_verification_proxy', default=None, metavar='URL', help='Use this proxy to verify the IP address for some geo-restricted sites. The default proxy specified by --proxy (or none, if the option is not present) is used for the actual downloading.')
    geo.add_option('--cn-verification-proxy', dest='cn_verification_proxy', default=None, metavar='URL', help=optparse.SUPPRESS_HELP)
    geo.add_option('--geo-bypass', action='store_true', dest='geo_bypass', default=True, help='Bypass geographic restriction via faking X-Forwarded-For HTTP header')
    geo.add_option('--no-geo-bypass', action='store_false', dest='geo_bypass', default=True, help='Do not bypass geographic restriction via faking X-Forwarded-For HTTP header')
    geo.add_option('--geo-bypass-country', metavar='CODE', dest='geo_bypass_country', default=None, help='Force bypass geographic restriction with explicitly provided two-letter ISO 3166-2 country code')
    geo.add_option('--geo-bypass-ip-block', metavar='IP_BLOCK', dest='geo_bypass_ip_block', default=None, help='Force bypass geographic restriction with explicitly provided IP block in CIDR notation')
    selection = optparse.OptionGroup(parser, 'Video Selection')
    selection.add_option('--playlist-start', dest='playliststart', metavar='NUMBER', default=1, type=int, help='Playlist video to start at (default is %default)')
    selection.add_option('--playlist-end', dest='playlistend', metavar='NUMBER', default=None, type=int, help='Playlist video to end at (default is last)')
    selection.add_option('--playlist-items', dest='playlist_items', metavar='ITEM_SPEC', default=None, help='Playlist video items to download. Specify indices of the videos in the playlist separated by commas like: ""--playlist-items 1,2,5,8"" if you want to download videos indexed 1, 2, 5, 8 in the playlist. You can specify range: ""--playlist-items 1-3,7,10-13"", it will download the videos at index 1, 2, 3, 7, 10, 11, 12 and 13.')
    selection.add_option('--match-title', dest='matchtitle', metavar='REGEX', help='Download only matching titles (regex or caseless sub-string)')
    selection.add_option('--reject-title', dest='rejecttitle', metavar='REGEX', help='Skip download for matching titles (regex or caseless sub-string)')
    selection.add_option('--max-downloads', dest='max_downloads', metavar='NUMBER', type=int, default=None, help='Abort after downloading NUMBER files')
    selection.add_option('--min-filesize', metavar='SIZE', dest='min_filesize', default=None, help='Do not download any videos smaller than SIZE (e.g. 50k or 44.6m)')
    selection.add_option('--max-filesize', metavar='SIZE', dest='max_filesize', default=None, help='Do not download any videos larger than SIZE (e.g. 50k or 44.6m)')
    selection.add_option('--date', metavar='DATE', dest='date', default=None, help='Download only videos uploaded in this date')
    selection.add_option('--datebefore', metavar='DATE', dest='datebefore', default=None, help='Download only videos uploaded on or before this date (i.e. inclusive)')
    selection.add_option('--dateafter', metavar='DATE', dest='dateafter', default=None, help='Download only videos uploaded on or after this date (i.e. inclusive)')
    selection.add_option('--min-views', metavar='COUNT', dest='min_views', default=None, type=int, help='Do not download any videos with less than COUNT views')
    selection.add_option('--max-views', metavar='COUNT', dest='max_views', default=None, type=int, help='Do not download any videos with more than COUNT views')
    selection.add_option('--match-filter', metavar='FILTER', dest='match_filter', default=None, help='Generic video filter. Specify any key (see the ""OUTPUT TEMPLATE"" for a list of available keys) to match if the key is present, !key to check if the key is not present, key > NUMBER (like ""comment_count > 12"", also works with >=, <, <=, !=, =) to compare against a number, key = \'LITERAL\' (like ""uploader = \'Mike Smith\'"", also works with !=) to match against a string literal and & to require multiple matches. Values which are not known are excluded unless you put a question mark (?) after the operator. For example, to only match videos that have been liked more than 100 times and disliked less than 50 times (or the dislike functionality is not available at the given service), but who also have a description, use --match-filter ""like_count > 100 & dislike_count <? 50 & description"" .')
    selection.add_option('--no-playlist', action='store_true', dest='noplaylist', default=False, help='Download only the video, if the URL refers to a video and a playlist.')
    selection.add_option('--yes-playlist', action='store_false', dest='noplaylist', default=False, help='Download the playlist, if the URL refers to a video and a playlist.')
    selection.add_option('--age-limit', metavar='YEARS', dest='age_limit', default=None, type=int, help='Download only videos suitable for the given age')
    selection.add_option('--download-archive', metavar='FILE', dest='download_archive', help='Download only videos not listed in the archive file. Record the IDs of all downloaded videos in it.')
    selection.add_option('--include-ads', dest='include_ads', action='store_true', help='Download advertisements as well (experimental)')
    authentication = optparse.OptionGroup(parser, 'Authentication Options')
    authentication.add_option('-u', '--username', dest='username', metavar='USERNAME', help='Login with this account ID')
    authentication.add_option('-p', '--password', dest='password', metavar='PASSWORD', help='Account password. If this option is left out, youtube-dl will ask interactively.')
    authentication.add_option('-2', '--twofactor', dest='twofactor', metavar='TWOFACTOR', help='Two-factor authentication code')
    authentication.add_option('-n', '--netrc', action='store_true', dest='usenetrc', default=False, help='Use .netrc authentication data')
    authentication.add_option('--video-password', dest='videopassword', metavar='PASSWORD', help='Video password (vimeo, smotri, youku)')
    adobe_pass = optparse.OptionGroup(parser, 'Adobe Pass Options')
    adobe_pass.add_option('--ap-mso', dest='ap_mso', metavar='MSO', help='Adobe Pass multiple-system operator (TV provider) identifier, use --ap-list-mso for a list of available MSOs')
    adobe_pass.add_option('--ap-username', dest='ap_username', metavar='USERNAME', help='Multiple-system operator account login')
    adobe_pass.add_option('--ap-password', dest='ap_password', metavar='PASSWORD', help='Multiple-system operator account password. If this option is left out, youtube-dl will ask interactively.')
    adobe_pass.add_option('--ap-list-mso', action='store_true', dest='ap_list_mso', default=False, help='List all supported multiple-system operators')
    video_format = optparse.OptionGroup(parser, 'Video Format Options')
    video_format.add_option('-f', '--format', action='store', dest='format', metavar='FORMAT', default=None, help='Video format code, see the ""FORMAT SELECTION"" for all the info')
    video_format.add_option('--all-formats', action='store_const', dest='format', const='all', help='Download all available video formats')
    video_format.add_option('--prefer-free-formats', action='store_true', dest='prefer_free_formats', default=False, help='Prefer free video formats unless a specific one is requested')
    video_format.add_option('-F', '--list-formats', action='store_true', dest='listformats', help='List all available formats of requested videos')
    video_format.add_option('--youtube-include-dash-manifest', action='store_true', dest='youtube_include_dash_manifest', default=True, help=optparse.SUPPRESS_HELP)
    video_format.add_option('--youtube-skip-dash-manifest', action='store_false', dest='youtube_include_dash_manifest', help='Do not download the DASH manifests and related data on YouTube videos')
    video_format.add_option('--merge-output-format', action='store', dest='merge_output_format', metavar='FORMAT', default=None, help='If a merge is required (e.g. bestvideo+bestaudio), output to given container format. One of mkv, mp4, ogg, webm, flv. Ignored if no merge is required')
    subtitles = optparse.OptionGroup(parser, 'Subtitle Options')
    subtitles.add_option('--write-sub', '--write-srt', action='store_true', dest='writesubtitles', default=False, help='Write subtitle file')
    subtitles.add_option('--write-auto-sub', '--write-automatic-sub', action='store_true', dest='writeautomaticsub', default=False, help='Write automatically generated subtitle file (YouTube only)')
    subtitles.add_option('--all-subs', action='store_true', dest='allsubtitles', default=False, help='Download all the available subtitles of the video')
    subtitles.add_option('--list-subs', action='store_true', dest='listsubtitles', default=False, help='List all available subtitles for the video')
    subtitles.add_option('--sub-format', action='store', dest='subtitlesformat', metavar='FORMAT', default='best', help='Subtitle format, accepts formats preference, for example: ""srt"" or ""ass/srt/best""')
    subtitles.add_option('--sub-lang', '--sub-langs', '--srt-lang', action='callback', dest='subtitleslangs', metavar='LANGS', type='str', default=[], callback=_comma_separated_values_options_callback, help='Languages of the subtitles to download (optional) separated by commas, use --list-subs for available language tags')
    downloader = optparse.OptionGroup(parser, 'Download Options')
    downloader.add_option('-r', '--limit-rate', '--rate-limit', dest='ratelimit', metavar='RATE', help='Maximum download rate in bytes per second (e.g. 50K or 4.2M)')
    downloader.add_option('-R', '--retries', dest='retries', metavar='RETRIES', default=10, help='Number of retries (default is %default), or ""infinite"".')
    downloader.add_option('--fragment-retries', dest='fragment_retries', metavar='RETRIES', default=10, help='Number of retries for a fragment (default is %default), or ""infinite"" (DASH, hlsnative and ISM)')
    downloader.add_option('--skip-unavailable-fragments', action='store_true', dest='skip_unavailable_fragments', default=True, help='Skip unavailable fragments (DASH, hlsnative and ISM)')
    downloader.add_option('--abort-on-unavailable-fragment', action='store_false', dest='skip_unavailable_fragments', help='Abort downloading when some fragment is not available')
    downloader.add_option('--keep-fragments', action='store_true', dest='keep_fragments', default=False, help='Keep downloaded fragments on disk after downloading is finished; fragments are erased by default')
    downloader.add_option('--buffer-size', dest='buffersize', metavar='SIZE', default='1024', help='Size of download buffer (e.g. 1024 or 16K) (default is %default)')
    downloader.add_option('--no-resize-buffer', action='store_true', dest='noresizebuffer', default=False, help='Do not automatically adjust the buffer size. By default, the buffer size is automatically resized from an initial value of SIZE.')
    downloader.add_option('--http-chunk-size', dest='http_chunk_size', metavar='SIZE', default=None, help='Size of a chunk for chunk-based HTTP downloading (e.g. 10485760 or 10M) (default is disabled). May be useful for bypassing bandwidth throttling imposed by a webserver (experimental)')
    downloader.add_option('--test', action='store_true', dest='test', default=False, help=optparse.SUPPRESS_HELP)
    downloader.add_option('--playlist-reverse', action='store_true', help='Download playlist videos in reverse order')
    downloader.add_option('--playlist-random', action='store_true', help='Download playlist videos in random order')
    downloader.add_option('--xattr-set-filesize', dest='xattr_set_filesize', action='store_true', help='Set file xattribute ytdl.filesize with expected file size')
    downloader.add_option('--hls-prefer-native', dest='hls_prefer_native', action='store_true', default=None, help='Use the native HLS downloader instead of ffmpeg')
    downloader.add_option('--hls-prefer-ffmpeg', dest='hls_prefer_native', action='store_false', default=None, help='Use ffmpeg instead of the native HLS downloader')
    downloader.add_option('--hls-use-mpegts', dest='hls_use_mpegts', action='store_true', help='Use the mpegts container for HLS videos, allowing to play the video while downloading (some players may not be able to play it)')
    downloader.add_option('--external-downloader', dest='external_downloader', metavar='COMMAND', help='Use the specified external downloader. Currently supports %s' % ','.join(list_external_downloaders()))
    downloader.add_option('--external-downloader-args', dest='external_downloader_args', metavar='ARGS', help='Give these arguments to the external downloader')
    workarounds = optparse.OptionGroup(parser, 'Workarounds')
    workarounds.add_option('--encoding', dest='encoding', metavar='ENCODING', help='Force the specified encoding (experimental)')
    workarounds.add_option('--no-check-certificate', action='store_true', dest='no_check_certificate', default=False, help='Suppress HTTPS certificate validation')
    workarounds.add_option('--prefer-insecure', '--prefer-unsecure', action='store_true', dest='prefer_insecure', help='Use an unencrypted connection to retrieve information about the video. (Currently supported only for YouTube)')
    workarounds.add_option('--user-agent', metavar='UA', dest='user_agent', help='Specify a custom user agent')
    workarounds.add_option('--referer', metavar='URL', dest='referer', default=None, help='Specify a custom referer, use if the video access is restricted to one domain')
    workarounds.add_option('--add-header', metavar='FIELD:VALUE', dest='headers', action='append', help=""Specify a custom HTTP header and its value, separated by a colon ':'. You can use this option multiple times"")
    workarounds.add_option('--bidi-workaround', dest='bidi_workaround', action='store_true', help='Work around terminals that lack bidirectional text support. Requires bidiv or fribidi executable in PATH')
    workarounds.add_option('--sleep-interval', '--min-sleep-interval', metavar='SECONDS', dest='sleep_interval', type=float, help='Number of seconds to sleep before each download when used alone or a lower bound of a range for randomized sleep before each download (minimum possible number of seconds to sleep) when used along with --max-sleep-interval.')
    workarounds.add_option('--max-sleep-interval', metavar='SECONDS', dest='max_sleep_interval', type=float, help='Upper bound of a range for randomized sleep before each download (maximum possible number of seconds to sleep). Must only be used along with --min-sleep-interval.')
    verbosity = optparse.OptionGroup(parser, 'Verbosity / Simulation Options')
    verbosity.add_option('-q', '--quiet', action='store_true', dest='quiet', default=False, help='Activate quiet mode')
    verbosity.add_option('--no-warnings', dest='no_warnings', action='store_true', default=False, help='Ignore warnings')
    verbosity.add_option('-s', '--simulate', action='store_true', dest='simulate', default=False, help='Do not download the video and do not write anything to disk')
    verbosity.add_option('--skip-download', action='store_true', dest='skip_download', default=False, help='Do not download the video')
    verbosity.add_option('-g', '--get-url', action='store_true', dest='geturl', default=False, help='Simulate, quiet but print URL')
    verbosity.add_option('-e', '--get-title', action='store_true', dest='gettitle', default=False, help='Simulate, quiet but print title')
    verbosity.add_option('--get-id', action='store_true', dest='getid', default=False, help='Simulate, quiet but print id')
    verbosity.add_option('--get-thumbnail', action='store_true', dest='getthumbnail', default=False, help='Simulate, quiet but print thumbnail URL')
    verbosity.add_option('--get-description', action='store_true', dest='getdescription', default=False, help='Simulate, quiet but print video description')
    verbosity.add_option('--get-duration', action='store_true', dest='getduration', default=False, help='Simulate, quiet but print video length')
    verbosity.add_option('--get-filename', action='store_true', dest='getfilename', default=False, help='Simulate, quiet but print output filename')
    verbosity.add_option('--get-format', action='store_true', dest='getformat', default=False, help='Simulate, quiet but print output format')
    verbosity.add_option('-j', '--dump-json', action='store_true', dest='dumpjson', default=False, help='Simulate, quiet but print JSON information. See the ""OUTPUT TEMPLATE"" for a description of available keys.')
    verbosity.add_option('-J', '--dump-single-json', action='store_true', dest='dump_single_json', default=False, help='Simulate, quiet but print JSON information for each command-line argument. If the URL refers to a playlist, dump the whole playlist information in a single line.')
    verbosity.add_option('--print-json', action='store_true', dest='print_json', default=False, help='Be quiet and print the video information as JSON (video is still being downloaded).')
    verbosity.add_option('--newline', action='store_true', dest='progress_with_newline', default=False, help='Output progress bar as new lines')
    verbosity.add_option('--no-progress', action='store_true', dest='noprogress', default=False, help='Do not print progress bar')
    verbosity.add_option('--console-title', action='store_true', dest='consoletitle', default=False, help='Display progress in console titlebar')
    verbosity.add_option('-v', '--verbose', action='store_true', dest='verbose', default=False, help='Print various debugging information')
    verbosity.add_option('--dump-pages', '--dump-intermediate-pages', action='store_true', dest='dump_intermediate_pages', default=False, help='Print downloaded pages encoded using base64 to debug problems (very verbose)')
    verbosity.add_option('--write-pages', action='store_true', dest='write_pages', default=False, help='Write downloaded intermediary pages to files in the current directory to debug problems')
    verbosity.add_option('--youtube-print-sig-code', action='store_true', dest='youtube_print_sig_code', default=False, help=optparse.SUPPRESS_HELP)
    verbosity.add_option('--print-traffic', '--dump-headers', dest='debug_printtraffic', action='store_true', default=False, help='Display sent and read HTTP traffic')
    verbosity.add_option('-C', '--call-home', dest='call_home', action='store_true', default=False, help='Contact the youtube-dl server for debugging')
    verbosity.add_option('--no-call-home', dest='call_home', action='store_false', default=False, help='Do NOT contact the youtube-dl server for debugging')
    filesystem = optparse.OptionGroup(parser, 'Filesystem Options')
    filesystem.add_option('-a', '--batch-file', dest='batchfile', metavar='FILE', help=""File containing URLs to download ('-' for stdin), one URL per line. Lines starting with '#', ';' or ']' are considered as comments and ignored."")
    filesystem.add_option('--id', default=False, action='store_true', dest='useid', help='Use only video ID in file name')
    filesystem.add_option('-o', '--output', dest='outtmpl', metavar='TEMPLATE', help='Output filename template, see the ""OUTPUT TEMPLATE"" for all the info')
    filesystem.add_option('--autonumber-size', dest='autonumber_size', metavar='NUMBER', type=int, help=optparse.SUPPRESS_HELP)
    filesystem.add_option('--autonumber-start', dest='autonumber_start', metavar='NUMBER', default=1, type=int, help='Specify the start value for %(autonumber)s (default is %default)')
    filesystem.add_option('--restrict-filenames', action='store_true', dest='restrictfilenames', default=False, help='Restrict filenames to only ASCII characters, and avoid ""&"" and spaces in filenames')
    filesystem.add_option('-A', '--auto-number', action='store_true', dest='autonumber', default=False, help=optparse.SUPPRESS_HELP)
    filesystem.add_option('-t', '--title', action='store_true', dest='usetitle', default=False, help=optparse.SUPPRESS_HELP)
    filesystem.add_option('-l', '--literal', default=False, action='store_true', dest='usetitle', help=optparse.SUPPRESS_HELP)
    filesystem.add_option('-w', '--no-overwrites', action='store_true', dest='nooverwrites', default=False, help='Do not overwrite files')
    filesystem.add_option('-c', '--continue', action='store_true', dest='continue_dl', default=True, help='Force resume of partially downloaded files. By default, youtube-dl will resume downloads if possible.')
    filesystem.add_option('--no-continue', action='store_false', dest='continue_dl', help='Do not resume partially downloaded files (restart from beginning)')
    filesystem.add_option('--no-part', action='store_true', dest='nopart', default=False, help='Do not use .part files - write directly into output file')
    filesystem.add_option('--no-mtime', action='store_false', dest='updatetime', default=True, help='Do not use the Last-modified header to set the file modification time')
    filesystem.add_option('--write-description', action='store_true', dest='writedescription', default=False, help='Write video description to a .description file')
    filesystem.add_option('--write-info-json', action='store_true', dest='writeinfojson', default=False, help='Write video metadata to a .info.json file')
    filesystem.add_option('--write-annotations', action='store_true', dest='writeannotations', default=False, help='Write video annotations to a .annotations.xml file')
    filesystem.add_option('--load-info-json', '--load-info', dest='load_info_filename', metavar='FILE', help='JSON file containing the video information (created with the ""--write-info-json"" option)')
    filesystem.add_option('--cookies', dest='cookiefile', metavar='FILE', help='File to read cookies from and dump cookie jar in')
    filesystem.add_option('--cache-dir', dest='cachedir', default=None, metavar='DIR', help='Location in the filesystem where youtube-dl can store some downloaded information permanently. By default $XDG_CACHE_HOME/youtube-dl or ~/.cache/youtube-dl . At the moment, only YouTube player files (for videos with obfuscated signatures) are cached, but that may change.')
    filesystem.add_option('--no-cache-dir', action='store_const', const=False, dest='cachedir', help='Disable filesystem caching')
    filesystem.add_option('--rm-cache-dir', action='store_true', dest='rm_cachedir', help='Delete all filesystem cache files')
    thumbnail = optparse.OptionGroup(parser, 'Thumbnail images')
    thumbnail.add_option('--write-thumbnail', action='store_true', dest='writethumbnail', default=False, help='Write thumbnail image to disk')
    thumbnail.add_option('--write-all-thumbnails', action='store_true', dest='write_all_thumbnails', default=False, help='Write all thumbnail image formats to disk')
    thumbnail.add_option('--list-thumbnails', action='store_true', dest='list_thumbnails', default=False, help='Simulate and list all available thumbnail formats')
    postproc = optparse.OptionGroup(parser, 'Post-processing Options')
    postproc.add_option('-x', '--extract-audio', action='store_true', dest='extractaudio', default=False, help='Convert video files to audio-only files (requires ffmpeg or avconv and ffprobe or avprobe)')
    postproc.add_option('--audio-format', metavar='FORMAT', dest='audioformat', default='best', help='Specify audio format: ""best"", ""aac"", ""flac"", ""mp3"", ""m4a"", ""opus"", ""vorbis"", or ""wav""; ""%default"" by default; No effect without -x')
    postproc.add_option('--audio-quality', metavar='QUALITY', dest='audioquality', default='5', help='Specify ffmpeg/avconv audio quality, insert a value between 0 (better) and 9 (worse) for VBR or a specific bitrate like 128K (default %default)')
    postproc.add_option('--recode-video', metavar='FORMAT', dest='recodevideo', default=None, help='Encode the video to another format if necessary (currently supported: mp4|flv|ogg|webm|mkv|avi)')
    postproc.add_option('--postprocessor-args', dest='postprocessor_args', metavar='ARGS', help='Give these arguments to the postprocessor')
    postproc.add_option('-k', '--keep-video', action='store_true', dest='keepvideo', default=False, help='Keep the video file on disk after the post-processing; the video is erased by default')
    postproc.add_option('--no-post-overwrites', action='store_true', dest='nopostoverwrites', default=False, help='Do not overwrite post-processed files; the post-processed files are overwritten by default')
    postproc.add_option('--embed-subs', action='store_true', dest='embedsubtitles', default=False, help='Embed subtitles in the video (only for mp4, webm and mkv videos)')
    postproc.add_option('--embed-thumbnail', action='store_true', dest='embedthumbnail', default=False, help='Embed thumbnail in the audio as cover art')
    postproc.add_option('--add-metadata', action='store_true', dest='addmetadata', default=False, help='Write metadata to the video file')
    postproc.add_option('--metadata-from-title', metavar='FORMAT', dest='metafromtitle', help='Parse additional metadata like song title / artist from the video title. The format syntax is the same as --output. Regular expression with named capture groups may also be used. The parsed parameters replace existing values. Example: --metadata-from-title ""%(artist)s - %(title)s"" matches a title like ""Coldplay - Paradise"". Example (regex): --metadata-from-title ""(?P<artist>.+?) - (?P<title>.+)""')
    postproc.add_option('--xattrs', action='store_true', dest='xattrs', default=False, help=""Write metadata to the video file's xattrs (using dublin core and xdg standards)"")
    postproc.add_option('--fixup', metavar='POLICY', dest='fixup', default='detect_or_warn', help='Automatically correct known faults of the file. One of never (do nothing), warn (only emit a warning), detect_o",' %s' % option.metavar,f' {option.metavar}',1,,,,,,,,,,
not-youtube-dl,https://github.com/scastillo/not-youtube-dl/tree/master/youtube_dl/options.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/not-youtube-dl/youtube_dl/options.py,,"def parseOpts(overrideArguments=None):

    def _readOptions(filename_bytes, default=[]):
        try:
            optionf = open(filename_bytes)
        except IOError:
            return default
        try:
            contents = optionf.read()
            if sys.version_info < (3,):
                contents = contents.decode(preferredencoding())
            res = compat_shlex_split(contents, comments=True)
        finally:
            optionf.close()
        return res

    def _readUserConf():
        xdg_config_home = compat_getenv('XDG_CONFIG_HOME')
        if xdg_config_home:
            userConfFile = os.path.join(xdg_config_home, 'youtube-dl', 'config')
            if not os.path.isfile(userConfFile):
                userConfFile = os.path.join(xdg_config_home, 'youtube-dl.conf')
        else:
            userConfFile = os.path.join(compat_expanduser('~'), '.config', 'youtube-dl', 'config')
            if not os.path.isfile(userConfFile):
                userConfFile = os.path.join(compat_expanduser('~'), '.config', 'youtube-dl.conf')
        userConf = _readOptions(userConfFile, None)
        if userConf is None:
            appdata_dir = compat_getenv('appdata')
            if appdata_dir:
                userConf = _readOptions(os.path.join(appdata_dir, 'youtube-dl', 'config'), default=None)
                if userConf is None:
                    userConf = _readOptions(os.path.join(appdata_dir, 'youtube-dl', 'config.txt'), default=None)
        if userConf is None:
            userConf = _readOptions(os.path.join(compat_expanduser('~'), 'youtube-dl.conf'), default=None)
        if userConf is None:
            userConf = _readOptions(os.path.join(compat_expanduser('~'), 'youtube-dl.conf.txt'), default=None)
        if userConf is None:
            userConf = []
        return userConf

    def _format_option_string(option):
        """""" ('-o', '--option') -> -o, --format METAVAR""""""
        opts = []
        if option._short_opts:
            opts.append(option._short_opts[0])
        if option._long_opts:
            opts.append(option._long_opts[0])
        if len(opts) > 1:
            opts.insert(1, ', ')
        if option.takes_value():
            opts.append(' %s' % option.metavar)
        return ''.join(opts)

    def _comma_separated_values_options_callback(option, opt_str, value, parser):
        setattr(parser.values, option.dest, value.split(','))
    columns = compat_get_terminal_size().columns
    max_width = columns if columns else 80
    max_help_position = 80
    fmt = optparse.IndentedHelpFormatter(width=max_width, max_help_position=max_help_position)
    fmt.format_option_strings = _format_option_string
    kw = {'version': __version__, 'formatter': fmt, 'usage': '%prog [OPTIONS] URL [URL...]', 'conflict_handler': 'resolve'}
    parser = optparse.OptionParser(**compat_kwargs(kw))
    general = optparse.OptionGroup(parser, 'General Options')
    general.add_option('-h', '--help', action='help', help='Print this help text and exit')
    general.add_option('--version', action='version', help='Print program version and exit')
    general.add_option('-U', '--update', action='store_true', dest='update_self', help='Update this program to latest version. Make sure that you have sufficient permissions (run with sudo if needed)')
    general.add_option('-i', '--ignore-errors', action='store_true', dest='ignoreerrors', default=False, help='Continue on download errors, for example to skip unavailable videos in a playlist')
    general.add_option('--abort-on-error', action='store_false', dest='ignoreerrors', help='Abort downloading of further videos (in the playlist or the command line) if an error occurs')
    general.add_option('--dump-user-agent', action='store_true', dest='dump_user_agent', default=False, help='Display the current browser identification')
    general.add_option('--list-extractors', action='store_true', dest='list_extractors', default=False, help='List all supported extractors')
    general.add_option('--extractor-descriptions', action='store_true', dest='list_extractor_descriptions', default=False, help='Output descriptions of all supported extractors')
    general.add_option('--force-generic-extractor', action='store_true', dest='force_generic_extractor', default=False, help='Force extraction to use the generic extractor')
    general.add_option('--default-search', dest='default_search', metavar='PREFIX', help='Use this prefix for unqualified URLs. For example ""gvsearch2:"" downloads two videos from google videos for youtube-dl ""large apple"". Use the value ""auto"" to let youtube-dl guess (""auto_warning"" to emit a warning when guessing). ""error"" just throws an error. The default value ""fixup_error"" repairs broken URLs, but emits an error if this is not possible instead of searching.')
    general.add_option('--ignore-config', action='store_true', help='Do not read configuration files. When given in the global configuration file /etc/youtube-dl.conf: Do not read the user configuration in ~/.config/youtube-dl/config (%APPDATA%/youtube-dl/config.txt on Windows)')
    general.add_option('--config-location', dest='config_location', metavar='PATH', help='Location of the configuration file; either the path to the config or its containing directory.')
    general.add_option('--flat-playlist', action='store_const', dest='extract_flat', const='in_playlist', default=False, help='Do not extract the videos of a playlist, only list them.')
    general.add_option('--mark-watched', action='store_true', dest='mark_watched', default=False, help='Mark videos watched (YouTube only)')
    general.add_option('--no-mark-watched', action='store_false', dest='mark_watched', default=False, help='Do not mark videos watched (YouTube only)')
    general.add_option('--no-color', '--no-colors', action='store_true', dest='no_color', default=False, help='Do not emit color codes in output')
    network = optparse.OptionGroup(parser, 'Network Options')
    network.add_option('--proxy', dest='proxy', default=None, metavar='URL', help='Use the specified HTTP/HTTPS/SOCKS proxy. To enable SOCKS proxy, specify a proper scheme. For example socks5://127.0.0.1:1080/. Pass in an empty string (--proxy """") for direct connection')
    network.add_option('--socket-timeout', dest='socket_timeout', type=float, default=None, metavar='SECONDS', help='Time to wait before giving up, in seconds')
    network.add_option('--source-address', metavar='IP', dest='source_address', default=None, help='Client-side IP address to bind to')
    network.add_option('-4', '--force-ipv4', action='store_const', const='0.0.0.0', dest='source_address', help='Make all connections via IPv4')
    network.add_option('-6', '--force-ipv6', action='store_const', const='::', dest='source_address', help='Make all connections via IPv6')
    geo = optparse.OptionGroup(parser, 'Geo Restriction')
    geo.add_option('--geo-verification-proxy', dest='geo_verification_proxy', default=None, metavar='URL', help='Use this proxy to verify the IP address for some geo-restricted sites. The default proxy specified by --proxy (or none, if the option is not present) is used for the actual downloading.')
    geo.add_option('--cn-verification-proxy', dest='cn_verification_proxy', default=None, metavar='URL', help=optparse.SUPPRESS_HELP)
    geo.add_option('--geo-bypass', action='store_true', dest='geo_bypass', default=True, help='Bypass geographic restriction via faking X-Forwarded-For HTTP header')
    geo.add_option('--no-geo-bypass', action='store_false', dest='geo_bypass', default=True, help='Do not bypass geographic restriction via faking X-Forwarded-For HTTP header')
    geo.add_option('--geo-bypass-country', metavar='CODE', dest='geo_bypass_country', default=None, help='Force bypass geographic restriction with explicitly provided two-letter ISO 3166-2 country code')
    geo.add_option('--geo-bypass-ip-block', metavar='IP_BLOCK', dest='geo_bypass_ip_block', default=None, help='Force bypass geographic restriction with explicitly provided IP block in CIDR notation')
    selection = optparse.OptionGroup(parser, 'Video Selection')
    selection.add_option('--playlist-start', dest='playliststart', metavar='NUMBER', default=1, type=int, help='Playlist video to start at (default is %default)')
    selection.add_option('--playlist-end', dest='playlistend', metavar='NUMBER', default=None, type=int, help='Playlist video to end at (default is last)')
    selection.add_option('--playlist-items', dest='playlist_items', metavar='ITEM_SPEC', default=None, help='Playlist video items to download. Specify indices of the videos in the playlist separated by commas like: ""--playlist-items 1,2,5,8"" if you want to download videos indexed 1, 2, 5, 8 in the playlist. You can specify range: ""--playlist-items 1-3,7,10-13"", it will download the videos at index 1, 2, 3, 7, 10, 11, 12 and 13.')
    selection.add_option('--match-title', dest='matchtitle', metavar='REGEX', help='Download only matching titles (regex or caseless sub-string)')
    selection.add_option('--reject-title', dest='rejecttitle', metavar='REGEX', help='Skip download for matching titles (regex or caseless sub-string)')
    selection.add_option('--max-downloads', dest='max_downloads', metavar='NUMBER', type=int, default=None, help='Abort after downloading NUMBER files')
    selection.add_option('--min-filesize', metavar='SIZE', dest='min_filesize', default=None, help='Do not download any videos smaller than SIZE (e.g. 50k or 44.6m)')
    selection.add_option('--max-filesize', metavar='SIZE', dest='max_filesize', default=None, help='Do not download any videos larger than SIZE (e.g. 50k or 44.6m)')
    selection.add_option('--date', metavar='DATE', dest='date', default=None, help='Download only videos uploaded in this date')
    selection.add_option('--datebefore', metavar='DATE', dest='datebefore', default=None, help='Download only videos uploaded on or before this date (i.e. inclusive)')
    selection.add_option('--dateafter', metavar='DATE', dest='dateafter', default=None, help='Download only videos uploaded on or after this date (i.e. inclusive)')
    selection.add_option('--min-views', metavar='COUNT', dest='min_views', default=None, type=int, help='Do not download any videos with less than COUNT views')
    selection.add_option('--max-views', metavar='COUNT', dest='max_views', default=None, type=int, help='Do not download any videos with more than COUNT views')
    selection.add_option('--match-filter', metavar='FILTER', dest='match_filter', default=None, help='Generic video filter. Specify any key (see the ""OUTPUT TEMPLATE"" for a list of available keys) to match if the key is present, !key to check if the key is not present, key > NUMBER (like ""comment_count > 12"", also works with >=, <, <=, !=, =) to compare against a number, key = \'LITERAL\' (like ""uploader = \'Mike Smith\'"", also works with !=) to match against a string literal and & to require multiple matches. Values which are not known are excluded unless you put a question mark (?) after the operator. For example, to only match videos that have been liked more than 100 times and disliked less than 50 times (or the dislike functionality is not available at the given service), but who also have a description, use --match-filter ""like_count > 100 & dislike_count <? 50 & description"" .')
    selection.add_option('--no-playlist', action='store_true', dest='noplaylist', default=False, help='Download only the video, if the URL refers to a video and a playlist.')
    selection.add_option('--yes-playlist', action='store_false', dest='noplaylist', default=False, help='Download the playlist, if the URL refers to a video and a playlist.')
    selection.add_option('--age-limit', metavar='YEARS', dest='age_limit', default=None, type=int, help='Download only videos suitable for the given age')
    selection.add_option('--download-archive', metavar='FILE', dest='download_archive', help='Download only videos not listed in the archive file. Record the IDs of all downloaded videos in it.')
    selection.add_option('--include-ads', dest='include_ads', action='store_true', help='Download advertisements as well (experimental)')
    authentication = optparse.OptionGroup(parser, 'Authentication Options')
    authentication.add_option('-u', '--username', dest='username', metavar='USERNAME', help='Login with this account ID')
    authentication.add_option('-p', '--password', dest='password', metavar='PASSWORD', help='Account password. If this option is left out, youtube-dl will ask interactively.')
    authentication.add_option('-2', '--twofactor', dest='twofactor', metavar='TWOFACTOR', help='Two-factor authentication code')
    authentication.add_option('-n', '--netrc', action='store_true', dest='usenetrc', default=False, help='Use .netrc authentication data')
    authentication.add_option('--video-password', dest='videopassword', metavar='PASSWORD', help='Video password (vimeo, smotri, youku)')
    adobe_pass = optparse.OptionGroup(parser, 'Adobe Pass Options')
    adobe_pass.add_option('--ap-mso', dest='ap_mso', metavar='MSO', help='Adobe Pass multiple-system operator (TV provider) identifier, use --ap-list-mso for a list of available MSOs')
    adobe_pass.add_option('--ap-username', dest='ap_username', metavar='USERNAME', help='Multiple-system operator account login')
    adobe_pass.add_option('--ap-password', dest='ap_password', metavar='PASSWORD', help='Multiple-system operator account password. If this option is left out, youtube-dl will ask interactively.')
    adobe_pass.add_option('--ap-list-mso', action='store_true', dest='ap_list_mso', default=False, help='List all supported multiple-system operators')
    video_format = optparse.OptionGroup(parser, 'Video Format Options')
    video_format.add_option('-f', '--format', action='store', dest='format', metavar='FORMAT', default=None, help='Video format code, see the ""FORMAT SELECTION"" for all the info')
    video_format.add_option('--all-formats', action='store_const', dest='format', const='all', help='Download all available video formats')
    video_format.add_option('--prefer-free-formats', action='store_true', dest='prefer_free_formats', default=False, help='Prefer free video formats unless a specific one is requested')
    video_format.add_option('-F', '--list-formats', action='store_true', dest='listformats', help='List all available formats of requested videos')
    video_format.add_option('--youtube-include-dash-manifest', action='store_true', dest='youtube_include_dash_manifest', default=True, help=optparse.SUPPRESS_HELP)
    video_format.add_option('--youtube-skip-dash-manifest', action='store_false', dest='youtube_include_dash_manifest', help='Do not download the DASH manifests and related data on YouTube videos')
    video_format.add_option('--merge-output-format', action='store', dest='merge_output_format', metavar='FORMAT', default=None, help='If a merge is required (e.g. bestvideo+bestaudio), output to given container format. One of mkv, mp4, ogg, webm, flv. Ignored if no merge is required')
    subtitles = optparse.OptionGroup(parser, 'Subtitle Options')
    subtitles.add_option('--write-sub', '--write-srt', action='store_true', dest='writesubtitles', default=False, help='Write subtitle file')
    subtitles.add_option('--write-auto-sub', '--write-automatic-sub', action='store_true', dest='writeautomaticsub', default=False, help='Write automatically generated subtitle file (YouTube only)')
    subtitles.add_option('--all-subs', action='store_true', dest='allsubtitles', default=False, help='Download all the available subtitles of the video')
    subtitles.add_option('--list-subs', action='store_true', dest='listsubtitles', default=False, help='List all available subtitles for the video')
    subtitles.add_option('--sub-format', action='store', dest='subtitlesformat', metavar='FORMAT', default='best', help='Subtitle format, accepts formats preference, for example: ""srt"" or ""ass/srt/best""')
    subtitles.add_option('--sub-lang', '--sub-langs', '--srt-lang', action='callback', dest='subtitleslangs', metavar='LANGS', type='str', default=[], callback=_comma_separated_values_options_callback, help='Languages of the subtitles to download (optional) separated by commas, use --list-subs for available language tags')
    downloader = optparse.OptionGroup(parser, 'Download Options')
    downloader.add_option('-r', '--limit-rate', '--rate-limit', dest='ratelimit', metavar='RATE', help='Maximum download rate in bytes per second (e.g. 50K or 4.2M)')
    downloader.add_option('-R', '--retries', dest='retries', metavar='RETRIES', default=10, help='Number of retries (default is %default), or ""infinite"".')
    downloader.add_option('--fragment-retries', dest='fragment_retries', metavar='RETRIES', default=10, help='Number of retries for a fragment (default is %default), or ""infinite"" (DASH, hlsnative and ISM)')
    downloader.add_option('--skip-unavailable-fragments', action='store_true', dest='skip_unavailable_fragments', default=True, help='Skip unavailable fragments (DASH, hlsnative and ISM)')
    downloader.add_option('--abort-on-unavailable-fragment', action='store_false', dest='skip_unavailable_fragments', help='Abort downloading when some fragment is not available')
    downloader.add_option('--keep-fragments', action='store_true', dest='keep_fragments', default=False, help='Keep downloaded fragments on disk after downloading is finished; fragments are erased by default')
    downloader.add_option('--buffer-size', dest='buffersize', metavar='SIZE', default='1024', help='Size of download buffer (e.g. 1024 or 16K) (default is %default)')
    downloader.add_option('--no-resize-buffer', action='store_true', dest='noresizebuffer', default=False, help='Do not automatically adjust the buffer size. By default, the buffer size is automatically resized from an initial value of SIZE.')
    downloader.add_option('--http-chunk-size', dest='http_chunk_size', metavar='SIZE', default=None, help='Size of a chunk for chunk-based HTTP downloading (e.g. 10485760 or 10M) (default is disabled). May be useful for bypassing bandwidth throttling imposed by a webserver (experimental)')
    downloader.add_option('--test', action='store_true', dest='test', default=False, help=optparse.SUPPRESS_HELP)
    downloader.add_option('--playlist-reverse', action='store_true', help='Download playlist videos in reverse order')
    downloader.add_option('--playlist-random', action='store_true', help='Download playlist videos in random order')
    downloader.add_option('--xattr-set-filesize', dest='xattr_set_filesize', action='store_true', help='Set file xattribute ytdl.filesize with expected file size')
    downloader.add_option('--hls-prefer-native', dest='hls_prefer_native', action='store_true', default=None, help='Use the native HLS downloader instead of ffmpeg')
    downloader.add_option('--hls-prefer-ffmpeg', dest='hls_prefer_native', action='store_false', default=None, help='Use ffmpeg instead of the native HLS downloader')
    downloader.add_option('--hls-use-mpegts', dest='hls_use_mpegts', action='store_true', help='Use the mpegts container for HLS videos, allowing to play the video while downloading (some players may not be able to play it)')
    downloader.add_option('--external-downloader', dest='external_downloader', metavar='COMMAND', help='Use the specified external downloader. Currently supports %s' % ','.join(list_external_downloaders()))
    downloader.add_option('--external-downloader-args', dest='external_downloader_args', metavar='ARGS', help='Give these arguments to the external downloader')
    workarounds = optparse.OptionGroup(parser, 'Workarounds')
    workarounds.add_option('--encoding', dest='encoding', metavar='ENCODING', help='Force the specified encoding (experimental)')
    workarounds.add_option('--no-check-certificate', action='store_true', dest='no_check_certificate', default=False, help='Suppress HTTPS certificate validation')
    workarounds.add_option('--prefer-insecure', '--prefer-unsecure', action='store_true', dest='prefer_insecure', help='Use an unencrypted connection to retrieve information about the video. (Currently supported only for YouTube)')
    workarounds.add_option('--user-agent', metavar='UA', dest='user_agent', help='Specify a custom user agent')
    workarounds.add_option('--referer', metavar='URL', dest='referer', default=None, help='Specify a custom referer, use if the video access is restricted to one domain')
    workarounds.add_option('--add-header', metavar='FIELD:VALUE', dest='headers', action='append', help=""Specify a custom HTTP header and its value, separated by a colon ':'. You can use this option multiple times"")
    workarounds.add_option('--bidi-workaround', dest='bidi_workaround', action='store_true', help='Work around terminals that lack bidirectional text support. Requires bidiv or fribidi executable in PATH')
    workarounds.add_option('--sleep-interval', '--min-sleep-interval', metavar='SECONDS', dest='sleep_interval', type=float, help='Number of seconds to sleep before each download when used alone or a lower bound of a range for randomized sleep before each download (minimum possible number of seconds to sleep) when used along with --max-sleep-interval.')
    workarounds.add_option('--max-sleep-interval', metavar='SECONDS', dest='max_sleep_interval', type=float, help='Upper bound of a range for randomized sleep before each download (maximum possible number of seconds to sleep). Must only be used along with --min-sleep-interval.')
    verbosity = optparse.OptionGroup(parser, 'Verbosity / Simulation Options')
    verbosity.add_option('-q', '--quiet', action='store_true', dest='quiet', default=False, help='Activate quiet mode')
    verbosity.add_option('--no-warnings', dest='no_warnings', action='store_true', default=False, help='Ignore warnings')
    verbosity.add_option('-s', '--simulate', action='store_true', dest='simulate', default=False, help='Do not download the video and do not write anything to disk')
    verbosity.add_option('--skip-download', action='store_true', dest='skip_download', default=False, help='Do not download the video')
    verbosity.add_option('-g', '--get-url', action='store_true', dest='geturl', default=False, help='Simulate, quiet but print URL')
    verbosity.add_option('-e', '--get-title', action='store_true', dest='gettitle', default=False, help='Simulate, quiet but print title')
    verbosity.add_option('--get-id', action='store_true', dest='getid', default=False, help='Simulate, quiet but print id')
    verbosity.add_option('--get-thumbnail', action='store_true', dest='getthumbnail', default=False, help='Simulate, quiet but print thumbnail URL')
    verbosity.add_option('--get-description', action='store_true', dest='getdescription', default=False, help='Simulate, quiet but print video description')
    verbosity.add_option('--get-duration', action='store_true', dest='getduration', default=False, help='Simulate, quiet but print video length')
    verbosity.add_option('--get-filename', action='store_true', dest='getfilename', default=False, help='Simulate, quiet but print output filename')
    verbosity.add_option('--get-format', action='store_true', dest='getformat', default=False, help='Simulate, quiet but print output format')
    verbosity.add_option('-j', '--dump-json', action='store_true', dest='dumpjson', default=False, help='Simulate, quiet but print JSON information. See the ""OUTPUT TEMPLATE"" for a description of available keys.')
    verbosity.add_option('-J', '--dump-single-json', action='store_true', dest='dump_single_json', default=False, help='Simulate, quiet but print JSON information for each command-line argument. If the URL refers to a playlist, dump the whole playlist information in a single line.')
    verbosity.add_option('--print-json', action='store_true', dest='print_json', default=False, help='Be quiet and print the video information as JSON (video is still being downloaded).')
    verbosity.add_option('--newline', action='store_true', dest='progress_with_newline', default=False, help='Output progress bar as new lines')
    verbosity.add_option('--no-progress', action='store_true', dest='noprogress', default=False, help='Do not print progress bar')
    verbosity.add_option('--console-title', action='store_true', dest='consoletitle', default=False, help='Display progress in console titlebar')
    verbosity.add_option('-v', '--verbose', action='store_true', dest='verbose', default=False, help='Print various debugging information')
    verbosity.add_option('--dump-pages', '--dump-intermediate-pages', action='store_true', dest='dump_intermediate_pages', default=False, help='Print downloaded pages encoded using base64 to debug problems (very verbose)')
    verbosity.add_option('--write-pages', action='store_true', dest='write_pages', default=False, help='Write downloaded intermediary pages to files in the current directory to debug problems')
    verbosity.add_option('--youtube-print-sig-code', action='store_true', dest='youtube_print_sig_code', default=False, help=optparse.SUPPRESS_HELP)
    verbosity.add_option('--print-traffic', '--dump-headers', dest='debug_printtraffic', action='store_true', default=False, help='Display sent and read HTTP traffic')
    verbosity.add_option('-C', '--call-home', dest='call_home', action='store_true', default=False, help='Contact the youtube-dl server for debugging')
    verbosity.add_option('--no-call-home', dest='call_home', action='store_false', default=False, help='Do NOT contact the youtube-dl server for debugging')
    filesystem = optparse.OptionGroup(parser, 'Filesystem Options')
    filesystem.add_option('-a', '--batch-file', dest='batchfile', metavar='FILE', help=""File containing URLs to download ('-' for stdin), one URL per line. Lines starting with '#', ';' or ']' are considered as comments and ignored."")
    filesystem.add_option('--id', default=False, action='store_true', dest='useid', help='Use only video ID in file name')
    filesystem.add_option('-o', '--output', dest='outtmpl', metavar='TEMPLATE', help='Output filename template, see the ""OUTPUT TEMPLATE"" for all the info')
    filesystem.add_option('--autonumber-size', dest='autonumber_size', metavar='NUMBER', type=int, help=optparse.SUPPRESS_HELP)
    filesystem.add_option('--autonumber-start', dest='autonumber_start', metavar='NUMBER', default=1, type=int, help='Specify the start value for %(autonumber)s (default is %default)')
    filesystem.add_option('--restrict-filenames', action='store_true', dest='restrictfilenames', default=False, help='Restrict filenames to only ASCII characters, and avoid ""&"" and spaces in filenames')
    filesystem.add_option('-A', '--auto-number', action='store_true', dest='autonumber', default=False, help=optparse.SUPPRESS_HELP)
    filesystem.add_option('-t', '--title', action='store_true', dest='usetitle', default=False, help=optparse.SUPPRESS_HELP)
    filesystem.add_option('-l', '--literal', default=False, action='store_true', dest='usetitle', help=optparse.SUPPRESS_HELP)
    filesystem.add_option('-w', '--no-overwrites', action='store_true', dest='nooverwrites', default=False, help='Do not overwrite files')
    filesystem.add_option('-c', '--continue', action='store_true', dest='continue_dl', default=True, help='Force resume of partially downloaded files. By default, youtube-dl will resume downloads if possible.')
    filesystem.add_option('--no-continue', action='store_false', dest='continue_dl', help='Do not resume partially downloaded files (restart from beginning)')
    filesystem.add_option('--no-part', action='store_true', dest='nopart', default=False, help='Do not use .part files - write directly into output file')
    filesystem.add_option('--no-mtime', action='store_false', dest='updatetime', default=True, help='Do not use the Last-modified header to set the file modification time')
    filesystem.add_option('--write-description', action='store_true', dest='writedescription', default=False, help='Write video description to a .description file')
    filesystem.add_option('--write-info-json', action='store_true', dest='writeinfojson', default=False, help='Write video metadata to a .info.json file')
    filesystem.add_option('--write-annotations', action='store_true', dest='writeannotations', default=False, help='Write video annotations to a .annotations.xml file')
    filesystem.add_option('--load-info-json', '--load-info', dest='load_info_filename', metavar='FILE', help='JSON file containing the video information (created with the ""--write-info-json"" option)')
    filesystem.add_option('--cookies', dest='cookiefile', metavar='FILE', help='File to read cookies from and dump cookie jar in')
    filesystem.add_option('--cache-dir', dest='cachedir', default=None, metavar='DIR', help='Location in the filesystem where youtube-dl can store some downloaded information permanently. By default $XDG_CACHE_HOME/youtube-dl or ~/.cache/youtube-dl . At the moment, only YouTube player files (for videos with obfuscated signatures) are cached, but that may change.')
    filesystem.add_option('--no-cache-dir', action='store_const', const=False, dest='cachedir', help='Disable filesystem caching')
    filesystem.add_option('--rm-cache-dir', action='store_true', dest='rm_cachedir', help='Delete all filesystem cache files')
    thumbnail = optparse.OptionGroup(parser, 'Thumbnail images')
    thumbnail.add_option('--write-thumbnail', action='store_true', dest='writethumbnail', default=False, help='Write thumbnail image to disk')
    thumbnail.add_option('--write-all-thumbnails', action='store_true', dest='write_all_thumbnails', default=False, help='Write all thumbnail image formats to disk')
    thumbnail.add_option('--list-thumbnails', action='store_true', dest='list_thumbnails', default=False, help='Simulate and list all available thumbnail formats')
    postproc = optparse.OptionGroup(parser, 'Post-processing Options')
    postproc.add_option('-x', '--extract-audio', action='store_true', dest='extractaudio', default=False, help='Convert video files to audio-only files (requires ffmpeg or avconv and ffprobe or avprobe)')
    postproc.add_option('--audio-format', metavar='FORMAT', dest='audioformat', default='best', help='Specify audio format: ""best"", ""aac"", ""flac"", ""mp3"", ""m4a"", ""opus"", ""vorbis"", or ""wav""; ""%default"" by default; No effect without -x')
    postproc.add_option('--audio-quality', metavar='QUALITY', dest='audioquality', default='5', help='Specify ffmpeg/avconv audio quality, insert a value between 0 (better) and 9 (worse) for VBR or a specific bitrate like 128K (default %default)')
    postproc.add_option('--recode-video', metavar='FORMAT', dest='recodevideo', default=None, help='Encode the video to another format if necessary (currently supported: mp4|flv|ogg|webm|mkv|avi)')
    postproc.add_option('--postprocessor-args', dest='postprocessor_args', metavar='ARGS', help='Give these arguments to the postprocessor')
    postproc.add_option('-k', '--keep-video', action='store_true', dest='keepvideo', default=False, help='Keep the video file on disk after the post-processing; the video is erased by default')
    postproc.add_option('--no-post-overwrites', action='store_true', dest='nopostoverwrites', default=False, help='Do not overwrite post-processed files; the post-processed files are overwritten by default')
    postproc.add_option('--embed-subs', action='store_true', dest='embedsubtitles', default=False, help='Embed subtitles in the video (only for mp4, webm and mkv videos)')
    postproc.add_option('--embed-thumbnail', action='store_true', dest='embedthumbnail', default=False, help='Embed thumbnail in the audio as cover art')
    postproc.add_option('--add-metadata', action='store_true', dest='addmetadata', default=False, help='Write metadata to the video file')
    postproc.add_option('--metadata-from-title', metavar='FORMAT', dest='metafromtitle', help='Parse additional metadata like song title / artist from the video title. The format syntax is the same as --output. Regular expression with named capture groups may also be used. The parsed parameters replace existing values. Example: --metadata-from-title ""%(artist)s - %(title)s"" matches a title like ""Coldplay - Paradise"". Example (regex): --metadata-from-title ""(?P<artist>.+?) - (?P<title>.+)""')
    postproc.add_option('--xattrs', action='store_true', dest='xattrs', default=False, help=""Write metadata to the video file's xattrs (using dublin core and xdg standards)"")
    postproc.add_option('--fixup', metavar='POLICY', dest='fixup', default='detect_or_warn', help='Automatically correct known faults of the file. One of never (do nothing), warn (only emit a warning), detect_o",'config-location %s does not exist.' % location,f"config-location {location} does not exist.",1,,,,,,,,,,
not-youtube-dl,https://github.com/scastillo/not-youtube-dl/tree/master/youtube_dl/options.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/not-youtube-dl/youtube_dl/options.py,,"def parseOpts(overrideArguments=None):

    def _readOptions(filename_bytes, default=[]):
        try:
            optionf = open(filename_bytes)
        except IOError:
            return default
        try:
            contents = optionf.read()
            if sys.version_info < (3,):
                contents = contents.decode(preferredencoding())
            res = compat_shlex_split(contents, comments=True)
        finally:
            optionf.close()
        return res

    def _readUserConf():
        xdg_config_home = compat_getenv('XDG_CONFIG_HOME')
        if xdg_config_home:
            userConfFile = os.path.join(xdg_config_home, 'youtube-dl', 'config')
            if not os.path.isfile(userConfFile):
                userConfFile = os.path.join(xdg_config_home, 'youtube-dl.conf')
        else:
            userConfFile = os.path.join(compat_expanduser('~'), '.config', 'youtube-dl', 'config')
            if not os.path.isfile(userConfFile):
                userConfFile = os.path.join(compat_expanduser('~'), '.config', 'youtube-dl.conf')
        userConf = _readOptions(userConfFile, None)
        if userConf is None:
            appdata_dir = compat_getenv('appdata')
            if appdata_dir:
                userConf = _readOptions(os.path.join(appdata_dir, 'youtube-dl', 'config'), default=None)
                if userConf is None:
                    userConf = _readOptions(os.path.join(appdata_dir, 'youtube-dl', 'config.txt'), default=None)
        if userConf is None:
            userConf = _readOptions(os.path.join(compat_expanduser('~'), 'youtube-dl.conf'), default=None)
        if userConf is None:
            userConf = _readOptions(os.path.join(compat_expanduser('~'), 'youtube-dl.conf.txt'), default=None)
        if userConf is None:
            userConf = []
        return userConf

    def _format_option_string(option):
        """""" ('-o', '--option') -> -o, --format METAVAR""""""
        opts = []
        if option._short_opts:
            opts.append(option._short_opts[0])
        if option._long_opts:
            opts.append(option._long_opts[0])
        if len(opts) > 1:
            opts.insert(1, ', ')
        if option.takes_value():
            opts.append(' %s' % option.metavar)
        return ''.join(opts)

    def _comma_separated_values_options_callback(option, opt_str, value, parser):
        setattr(parser.values, option.dest, value.split(','))
    columns = compat_get_terminal_size().columns
    max_width = columns if columns else 80
    max_help_position = 80
    fmt = optparse.IndentedHelpFormatter(width=max_width, max_help_position=max_help_position)
    fmt.format_option_strings = _format_option_string
    kw = {'version': __version__, 'formatter': fmt, 'usage': '%prog [OPTIONS] URL [URL...]', 'conflict_handler': 'resolve'}
    parser = optparse.OptionParser(**compat_kwargs(kw))
    general = optparse.OptionGroup(parser, 'General Options')
    general.add_option('-h', '--help', action='help', help='Print this help text and exit')
    general.add_option('--version', action='version', help='Print program version and exit')
    general.add_option('-U', '--update', action='store_true', dest='update_self', help='Update this program to latest version. Make sure that you have sufficient permissions (run with sudo if needed)')
    general.add_option('-i', '--ignore-errors', action='store_true', dest='ignoreerrors', default=False, help='Continue on download errors, for example to skip unavailable videos in a playlist')
    general.add_option('--abort-on-error', action='store_false', dest='ignoreerrors', help='Abort downloading of further videos (in the playlist or the command line) if an error occurs')
    general.add_option('--dump-user-agent', action='store_true', dest='dump_user_agent', default=False, help='Display the current browser identification')
    general.add_option('--list-extractors', action='store_true', dest='list_extractors', default=False, help='List all supported extractors')
    general.add_option('--extractor-descriptions', action='store_true', dest='list_extractor_descriptions', default=False, help='Output descriptions of all supported extractors')
    general.add_option('--force-generic-extractor', action='store_true', dest='force_generic_extractor', default=False, help='Force extraction to use the generic extractor')
    general.add_option('--default-search', dest='default_search', metavar='PREFIX', help='Use this prefix for unqualified URLs. For example ""gvsearch2:"" downloads two videos from google videos for youtube-dl ""large apple"". Use the value ""auto"" to let youtube-dl guess (""auto_warning"" to emit a warning when guessing). ""error"" just throws an error. The default value ""fixup_error"" repairs broken URLs, but emits an error if this is not possible instead of searching.')
    general.add_option('--ignore-config', action='store_true', help='Do not read configuration files. When given in the global configuration file /etc/youtube-dl.conf: Do not read the user configuration in ~/.config/youtube-dl/config (%APPDATA%/youtube-dl/config.txt on Windows)')
    general.add_option('--config-location', dest='config_location', metavar='PATH', help='Location of the configuration file; either the path to the config or its containing directory.')
    general.add_option('--flat-playlist', action='store_const', dest='extract_flat', const='in_playlist', default=False, help='Do not extract the videos of a playlist, only list them.')
    general.add_option('--mark-watched', action='store_true', dest='mark_watched', default=False, help='Mark videos watched (YouTube only)')
    general.add_option('--no-mark-watched', action='store_false', dest='mark_watched', default=False, help='Do not mark videos watched (YouTube only)')
    general.add_option('--no-color', '--no-colors', action='store_true', dest='no_color', default=False, help='Do not emit color codes in output')
    network = optparse.OptionGroup(parser, 'Network Options')
    network.add_option('--proxy', dest='proxy', default=None, metavar='URL', help='Use the specified HTTP/HTTPS/SOCKS proxy. To enable SOCKS proxy, specify a proper scheme. For example socks5://127.0.0.1:1080/. Pass in an empty string (--proxy """") for direct connection')
    network.add_option('--socket-timeout', dest='socket_timeout', type=float, default=None, metavar='SECONDS', help='Time to wait before giving up, in seconds')
    network.add_option('--source-address', metavar='IP', dest='source_address', default=None, help='Client-side IP address to bind to')
    network.add_option('-4', '--force-ipv4', action='store_const', const='0.0.0.0', dest='source_address', help='Make all connections via IPv4')
    network.add_option('-6', '--force-ipv6', action='store_const', const='::', dest='source_address', help='Make all connections via IPv6')
    geo = optparse.OptionGroup(parser, 'Geo Restriction')
    geo.add_option('--geo-verification-proxy', dest='geo_verification_proxy', default=None, metavar='URL', help='Use this proxy to verify the IP address for some geo-restricted sites. The default proxy specified by --proxy (or none, if the option is not present) is used for the actual downloading.')
    geo.add_option('--cn-verification-proxy', dest='cn_verification_proxy', default=None, metavar='URL', help=optparse.SUPPRESS_HELP)
    geo.add_option('--geo-bypass', action='store_true', dest='geo_bypass', default=True, help='Bypass geographic restriction via faking X-Forwarded-For HTTP header')
    geo.add_option('--no-geo-bypass', action='store_false', dest='geo_bypass', default=True, help='Do not bypass geographic restriction via faking X-Forwarded-For HTTP header')
    geo.add_option('--geo-bypass-country', metavar='CODE', dest='geo_bypass_country', default=None, help='Force bypass geographic restriction with explicitly provided two-letter ISO 3166-2 country code')
    geo.add_option('--geo-bypass-ip-block', metavar='IP_BLOCK', dest='geo_bypass_ip_block', default=None, help='Force bypass geographic restriction with explicitly provided IP block in CIDR notation')
    selection = optparse.OptionGroup(parser, 'Video Selection')
    selection.add_option('--playlist-start', dest='playliststart', metavar='NUMBER', default=1, type=int, help='Playlist video to start at (default is %default)')
    selection.add_option('--playlist-end', dest='playlistend', metavar='NUMBER', default=None, type=int, help='Playlist video to end at (default is last)')
    selection.add_option('--playlist-items', dest='playlist_items', metavar='ITEM_SPEC', default=None, help='Playlist video items to download. Specify indices of the videos in the playlist separated by commas like: ""--playlist-items 1,2,5,8"" if you want to download videos indexed 1, 2, 5, 8 in the playlist. You can specify range: ""--playlist-items 1-3,7,10-13"", it will download the videos at index 1, 2, 3, 7, 10, 11, 12 and 13.')
    selection.add_option('--match-title', dest='matchtitle', metavar='REGEX', help='Download only matching titles (regex or caseless sub-string)')
    selection.add_option('--reject-title', dest='rejecttitle', metavar='REGEX', help='Skip download for matching titles (regex or caseless sub-string)')
    selection.add_option('--max-downloads', dest='max_downloads', metavar='NUMBER', type=int, default=None, help='Abort after downloading NUMBER files')
    selection.add_option('--min-filesize', metavar='SIZE', dest='min_filesize', default=None, help='Do not download any videos smaller than SIZE (e.g. 50k or 44.6m)')
    selection.add_option('--max-filesize', metavar='SIZE', dest='max_filesize', default=None, help='Do not download any videos larger than SIZE (e.g. 50k or 44.6m)')
    selection.add_option('--date', metavar='DATE', dest='date', default=None, help='Download only videos uploaded in this date')
    selection.add_option('--datebefore', metavar='DATE', dest='datebefore', default=None, help='Download only videos uploaded on or before this date (i.e. inclusive)')
    selection.add_option('--dateafter', metavar='DATE', dest='dateafter', default=None, help='Download only videos uploaded on or after this date (i.e. inclusive)')
    selection.add_option('--min-views', metavar='COUNT', dest='min_views', default=None, type=int, help='Do not download any videos with less than COUNT views')
    selection.add_option('--max-views', metavar='COUNT', dest='max_views', default=None, type=int, help='Do not download any videos with more than COUNT views')
    selection.add_option('--match-filter', metavar='FILTER', dest='match_filter', default=None, help='Generic video filter. Specify any key (see the ""OUTPUT TEMPLATE"" for a list of available keys) to match if the key is present, !key to check if the key is not present, key > NUMBER (like ""comment_count > 12"", also works with >=, <, <=, !=, =) to compare against a number, key = \'LITERAL\' (like ""uploader = \'Mike Smith\'"", also works with !=) to match against a string literal and & to require multiple matches. Values which are not known are excluded unless you put a question mark (?) after the operator. For example, to only match videos that have been liked more than 100 times and disliked less than 50 times (or the dislike functionality is not available at the given service), but who also have a description, use --match-filter ""like_count > 100 & dislike_count <? 50 & description"" .')
    selection.add_option('--no-playlist', action='store_true', dest='noplaylist', default=False, help='Download only the video, if the URL refers to a video and a playlist.')
    selection.add_option('--yes-playlist', action='store_false', dest='noplaylist', default=False, help='Download the playlist, if the URL refers to a video and a playlist.')
    selection.add_option('--age-limit', metavar='YEARS', dest='age_limit', default=None, type=int, help='Download only videos suitable for the given age')
    selection.add_option('--download-archive', metavar='FILE', dest='download_archive', help='Download only videos not listed in the archive file. Record the IDs of all downloaded videos in it.')
    selection.add_option('--include-ads', dest='include_ads', action='store_true', help='Download advertisements as well (experimental)')
    authentication = optparse.OptionGroup(parser, 'Authentication Options')
    authentication.add_option('-u', '--username', dest='username', metavar='USERNAME', help='Login with this account ID')
    authentication.add_option('-p', '--password', dest='password', metavar='PASSWORD', help='Account password. If this option is left out, youtube-dl will ask interactively.')
    authentication.add_option('-2', '--twofactor', dest='twofactor', metavar='TWOFACTOR', help='Two-factor authentication code')
    authentication.add_option('-n', '--netrc', action='store_true', dest='usenetrc', default=False, help='Use .netrc authentication data')
    authentication.add_option('--video-password', dest='videopassword', metavar='PASSWORD', help='Video password (vimeo, smotri, youku)')
    adobe_pass = optparse.OptionGroup(parser, 'Adobe Pass Options')
    adobe_pass.add_option('--ap-mso', dest='ap_mso', metavar='MSO', help='Adobe Pass multiple-system operator (TV provider) identifier, use --ap-list-mso for a list of available MSOs')
    adobe_pass.add_option('--ap-username', dest='ap_username', metavar='USERNAME', help='Multiple-system operator account login')
    adobe_pass.add_option('--ap-password', dest='ap_password', metavar='PASSWORD', help='Multiple-system operator account password. If this option is left out, youtube-dl will ask interactively.')
    adobe_pass.add_option('--ap-list-mso', action='store_true', dest='ap_list_mso', default=False, help='List all supported multiple-system operators')
    video_format = optparse.OptionGroup(parser, 'Video Format Options')
    video_format.add_option('-f', '--format', action='store', dest='format', metavar='FORMAT', default=None, help='Video format code, see the ""FORMAT SELECTION"" for all the info')
    video_format.add_option('--all-formats', action='store_const', dest='format', const='all', help='Download all available video formats')
    video_format.add_option('--prefer-free-formats', action='store_true', dest='prefer_free_formats', default=False, help='Prefer free video formats unless a specific one is requested')
    video_format.add_option('-F', '--list-formats', action='store_true', dest='listformats', help='List all available formats of requested videos')
    video_format.add_option('--youtube-include-dash-manifest', action='store_true', dest='youtube_include_dash_manifest', default=True, help=optparse.SUPPRESS_HELP)
    video_format.add_option('--youtube-skip-dash-manifest', action='store_false', dest='youtube_include_dash_manifest', help='Do not download the DASH manifests and related data on YouTube videos')
    video_format.add_option('--merge-output-format', action='store', dest='merge_output_format', metavar='FORMAT', default=None, help='If a merge is required (e.g. bestvideo+bestaudio), output to given container format. One of mkv, mp4, ogg, webm, flv. Ignored if no merge is required')
    subtitles = optparse.OptionGroup(parser, 'Subtitle Options')
    subtitles.add_option('--write-sub', '--write-srt', action='store_true', dest='writesubtitles', default=False, help='Write subtitle file')
    subtitles.add_option('--write-auto-sub', '--write-automatic-sub', action='store_true', dest='writeautomaticsub', default=False, help='Write automatically generated subtitle file (YouTube only)')
    subtitles.add_option('--all-subs', action='store_true', dest='allsubtitles', default=False, help='Download all the available subtitles of the video')
    subtitles.add_option('--list-subs', action='store_true', dest='listsubtitles', default=False, help='List all available subtitles for the video')
    subtitles.add_option('--sub-format', action='store', dest='subtitlesformat', metavar='FORMAT', default='best', help='Subtitle format, accepts formats preference, for example: ""srt"" or ""ass/srt/best""')
    subtitles.add_option('--sub-lang', '--sub-langs', '--srt-lang', action='callback', dest='subtitleslangs', metavar='LANGS', type='str', default=[], callback=_comma_separated_values_options_callback, help='Languages of the subtitles to download (optional) separated by commas, use --list-subs for available language tags')
    downloader = optparse.OptionGroup(parser, 'Download Options')
    downloader.add_option('-r', '--limit-rate', '--rate-limit', dest='ratelimit', metavar='RATE', help='Maximum download rate in bytes per second (e.g. 50K or 4.2M)')
    downloader.add_option('-R', '--retries', dest='retries', metavar='RETRIES', default=10, help='Number of retries (default is %default), or ""infinite"".')
    downloader.add_option('--fragment-retries', dest='fragment_retries', metavar='RETRIES', default=10, help='Number of retries for a fragment (default is %default), or ""infinite"" (DASH, hlsnative and ISM)')
    downloader.add_option('--skip-unavailable-fragments', action='store_true', dest='skip_unavailable_fragments', default=True, help='Skip unavailable fragments (DASH, hlsnative and ISM)')
    downloader.add_option('--abort-on-unavailable-fragment', action='store_false', dest='skip_unavailable_fragments', help='Abort downloading when some fragment is not available')
    downloader.add_option('--keep-fragments', action='store_true', dest='keep_fragments', default=False, help='Keep downloaded fragments on disk after downloading is finished; fragments are erased by default')
    downloader.add_option('--buffer-size', dest='buffersize', metavar='SIZE', default='1024', help='Size of download buffer (e.g. 1024 or 16K) (default is %default)')
    downloader.add_option('--no-resize-buffer', action='store_true', dest='noresizebuffer', default=False, help='Do not automatically adjust the buffer size. By default, the buffer size is automatically resized from an initial value of SIZE.')
    downloader.add_option('--http-chunk-size', dest='http_chunk_size', metavar='SIZE', default=None, help='Size of a chunk for chunk-based HTTP downloading (e.g. 10485760 or 10M) (default is disabled). May be useful for bypassing bandwidth throttling imposed by a webserver (experimental)')
    downloader.add_option('--test', action='store_true', dest='test', default=False, help=optparse.SUPPRESS_HELP)
    downloader.add_option('--playlist-reverse', action='store_true', help='Download playlist videos in reverse order')
    downloader.add_option('--playlist-random', action='store_true', help='Download playlist videos in random order')
    downloader.add_option('--xattr-set-filesize', dest='xattr_set_filesize', action='store_true', help='Set file xattribute ytdl.filesize with expected file size')
    downloader.add_option('--hls-prefer-native', dest='hls_prefer_native', action='store_true', default=None, help='Use the native HLS downloader instead of ffmpeg')
    downloader.add_option('--hls-prefer-ffmpeg', dest='hls_prefer_native', action='store_false', default=None, help='Use ffmpeg instead of the native HLS downloader')
    downloader.add_option('--hls-use-mpegts', dest='hls_use_mpegts', action='store_true', help='Use the mpegts container for HLS videos, allowing to play the video while downloading (some players may not be able to play it)')
    downloader.add_option('--external-downloader', dest='external_downloader', metavar='COMMAND', help='Use the specified external downloader. Currently supports %s' % ','.join(list_external_downloaders()))
    downloader.add_option('--external-downloader-args', dest='external_downloader_args', metavar='ARGS', help='Give these arguments to the external downloader')
    workarounds = optparse.OptionGroup(parser, 'Workarounds')
    workarounds.add_option('--encoding', dest='encoding', metavar='ENCODING', help='Force the specified encoding (experimental)')
    workarounds.add_option('--no-check-certificate', action='store_true', dest='no_check_certificate', default=False, help='Suppress HTTPS certificate validation')
    workarounds.add_option('--prefer-insecure', '--prefer-unsecure', action='store_true', dest='prefer_insecure', help='Use an unencrypted connection to retrieve information about the video. (Currently supported only for YouTube)')
    workarounds.add_option('--user-agent', metavar='UA', dest='user_agent', help='Specify a custom user agent')
    workarounds.add_option('--referer', metavar='URL', dest='referer', default=None, help='Specify a custom referer, use if the video access is restricted to one domain')
    workarounds.add_option('--add-header', metavar='FIELD:VALUE', dest='headers', action='append', help=""Specify a custom HTTP header and its value, separated by a colon ':'. You can use this option multiple times"")
    workarounds.add_option('--bidi-workaround', dest='bidi_workaround', action='store_true', help='Work around terminals that lack bidirectional text support. Requires bidiv or fribidi executable in PATH')
    workarounds.add_option('--sleep-interval', '--min-sleep-interval', metavar='SECONDS', dest='sleep_interval', type=float, help='Number of seconds to sleep before each download when used alone or a lower bound of a range for randomized sleep before each download (minimum possible number of seconds to sleep) when used along with --max-sleep-interval.')
    workarounds.add_option('--max-sleep-interval', metavar='SECONDS', dest='max_sleep_interval', type=float, help='Upper bound of a range for randomized sleep before each download (maximum possible number of seconds to sleep). Must only be used along with --min-sleep-interval.')
    verbosity = optparse.OptionGroup(parser, 'Verbosity / Simulation Options')
    verbosity.add_option('-q', '--quiet', action='store_true', dest='quiet', default=False, help='Activate quiet mode')
    verbosity.add_option('--no-warnings', dest='no_warnings', action='store_true', default=False, help='Ignore warnings')
    verbosity.add_option('-s', '--simulate', action='store_true', dest='simulate', default=False, help='Do not download the video and do not write anything to disk')
    verbosity.add_option('--skip-download', action='store_true', dest='skip_download', default=False, help='Do not download the video')
    verbosity.add_option('-g', '--get-url', action='store_true', dest='geturl', default=False, help='Simulate, quiet but print URL')
    verbosity.add_option('-e', '--get-title', action='store_true', dest='gettitle', default=False, help='Simulate, quiet but print title')
    verbosity.add_option('--get-id', action='store_true', dest='getid', default=False, help='Simulate, quiet but print id')
    verbosity.add_option('--get-thumbnail', action='store_true', dest='getthumbnail', default=False, help='Simulate, quiet but print thumbnail URL')
    verbosity.add_option('--get-description', action='store_true', dest='getdescription', default=False, help='Simulate, quiet but print video description')
    verbosity.add_option('--get-duration', action='store_true', dest='getduration', default=False, help='Simulate, quiet but print video length')
    verbosity.add_option('--get-filename', action='store_true', dest='getfilename', default=False, help='Simulate, quiet but print output filename')
    verbosity.add_option('--get-format', action='store_true', dest='getformat', default=False, help='Simulate, quiet but print output format')
    verbosity.add_option('-j', '--dump-json', action='store_true', dest='dumpjson', default=False, help='Simulate, quiet but print JSON information. See the ""OUTPUT TEMPLATE"" for a description of available keys.')
    verbosity.add_option('-J', '--dump-single-json', action='store_true', dest='dump_single_json', default=False, help='Simulate, quiet but print JSON information for each command-line argument. If the URL refers to a playlist, dump the whole playlist information in a single line.')
    verbosity.add_option('--print-json', action='store_true', dest='print_json', default=False, help='Be quiet and print the video information as JSON (video is still being downloaded).')
    verbosity.add_option('--newline', action='store_true', dest='progress_with_newline', default=False, help='Output progress bar as new lines')
    verbosity.add_option('--no-progress', action='store_true', dest='noprogress', default=False, help='Do not print progress bar')
    verbosity.add_option('--console-title', action='store_true', dest='consoletitle', default=False, help='Display progress in console titlebar')
    verbosity.add_option('-v', '--verbose', action='store_true', dest='verbose', default=False, help='Print various debugging information')
    verbosity.add_option('--dump-pages', '--dump-intermediate-pages', action='store_true', dest='dump_intermediate_pages', default=False, help='Print downloaded pages encoded using base64 to debug problems (very verbose)')
    verbosity.add_option('--write-pages', action='store_true', dest='write_pages', default=False, help='Write downloaded intermediary pages to files in the current directory to debug problems')
    verbosity.add_option('--youtube-print-sig-code', action='store_true', dest='youtube_print_sig_code', default=False, help=optparse.SUPPRESS_HELP)
    verbosity.add_option('--print-traffic', '--dump-headers', dest='debug_printtraffic', action='store_true', default=False, help='Display sent and read HTTP traffic')
    verbosity.add_option('-C', '--call-home', dest='call_home', action='store_true', default=False, help='Contact the youtube-dl server for debugging')
    verbosity.add_option('--no-call-home', dest='call_home', action='store_false', default=False, help='Do NOT contact the youtube-dl server for debugging')
    filesystem = optparse.OptionGroup(parser, 'Filesystem Options')
    filesystem.add_option('-a', '--batch-file', dest='batchfile', metavar='FILE', help=""File containing URLs to download ('-' for stdin), one URL per line. Lines starting with '#', ';' or ']' are considered as comments and ignored."")
    filesystem.add_option('--id', default=False, action='store_true', dest='useid', help='Use only video ID in file name')
    filesystem.add_option('-o', '--output', dest='outtmpl', metavar='TEMPLATE', help='Output filename template, see the ""OUTPUT TEMPLATE"" for all the info')
    filesystem.add_option('--autonumber-size', dest='autonumber_size', metavar='NUMBER', type=int, help=optparse.SUPPRESS_HELP)
    filesystem.add_option('--autonumber-start', dest='autonumber_start', metavar='NUMBER', default=1, type=int, help='Specify the start value for %(autonumber)s (default is %default)')
    filesystem.add_option('--restrict-filenames', action='store_true', dest='restrictfilenames', default=False, help='Restrict filenames to only ASCII characters, and avoid ""&"" and spaces in filenames')
    filesystem.add_option('-A', '--auto-number', action='store_true', dest='autonumber', default=False, help=optparse.SUPPRESS_HELP)
    filesystem.add_option('-t', '--title', action='store_true', dest='usetitle', default=False, help=optparse.SUPPRESS_HELP)
    filesystem.add_option('-l', '--literal', default=False, action='store_true', dest='usetitle', help=optparse.SUPPRESS_HELP)
    filesystem.add_option('-w', '--no-overwrites', action='store_true', dest='nooverwrites', default=False, help='Do not overwrite files')
    filesystem.add_option('-c', '--continue', action='store_true', dest='continue_dl', default=True, help='Force resume of partially downloaded files. By default, youtube-dl will resume downloads if possible.')
    filesystem.add_option('--no-continue', action='store_false', dest='continue_dl', help='Do not resume partially downloaded files (restart from beginning)')
    filesystem.add_option('--no-part', action='store_true', dest='nopart', default=False, help='Do not use .part files - write directly into output file')
    filesystem.add_option('--no-mtime', action='store_false', dest='updatetime', default=True, help='Do not use the Last-modified header to set the file modification time')
    filesystem.add_option('--write-description', action='store_true', dest='writedescription', default=False, help='Write video description to a .description file')
    filesystem.add_option('--write-info-json', action='store_true', dest='writeinfojson', default=False, help='Write video metadata to a .info.json file')
    filesystem.add_option('--write-annotations', action='store_true', dest='writeannotations', default=False, help='Write video annotations to a .annotations.xml file')
    filesystem.add_option('--load-info-json', '--load-info', dest='load_info_filename', metavar='FILE', help='JSON file containing the video information (created with the ""--write-info-json"" option)')
    filesystem.add_option('--cookies', dest='cookiefile', metavar='FILE', help='File to read cookies from and dump cookie jar in')
    filesystem.add_option('--cache-dir', dest='cachedir', default=None, metavar='DIR', help='Location in the filesystem where youtube-dl can store some downloaded information permanently. By default $XDG_CACHE_HOME/youtube-dl or ~/.cache/youtube-dl . At the moment, only YouTube player files (for videos with obfuscated signatures) are cached, but that may change.')
    filesystem.add_option('--no-cache-dir', action='store_const', const=False, dest='cachedir', help='Disable filesystem caching')
    filesystem.add_option('--rm-cache-dir', action='store_true', dest='rm_cachedir', help='Delete all filesystem cache files')
    thumbnail = optparse.OptionGroup(parser, 'Thumbnail images')
    thumbnail.add_option('--write-thumbnail', action='store_true', dest='writethumbnail', default=False, help='Write thumbnail image to disk')
    thumbnail.add_option('--write-all-thumbnails', action='store_true', dest='write_all_thumbnails', default=False, help='Write all thumbnail image formats to disk')
    thumbnail.add_option('--list-thumbnails', action='store_true', dest='list_thumbnails', default=False, help='Simulate and list all available thumbnail formats')
    postproc = optparse.OptionGroup(parser, 'Post-processing Options')
    postproc.add_option('-x', '--extract-audio', action='store_true', dest='extractaudio', default=False, help='Convert video files to audio-only files (requires ffmpeg or avconv and ffprobe or avprobe)')
    postproc.add_option('--audio-format', metavar='FORMAT', dest='audioformat', default='best', help='Specify audio format: ""best"", ""aac"", ""flac"", ""mp3"", ""m4a"", ""opus"", ""vorbis"", or ""wav""; ""%default"" by default; No effect without -x')
    postproc.add_option('--audio-quality', metavar='QUALITY', dest='audioquality', default='5', help='Specify ffmpeg/avconv audio quality, insert a value between 0 (better) and 9 (worse) for VBR or a specific bitrate like 128K (default %default)')
    postproc.add_option('--recode-video', metavar='FORMAT', dest='recodevideo', default=None, help='Encode the video to another format if necessary (currently supported: mp4|flv|ogg|webm|mkv|avi)')
    postproc.add_option('--postprocessor-args', dest='postprocessor_args', metavar='ARGS', help='Give these arguments to the postprocessor')
    postproc.add_option('-k', '--keep-video', action='store_true', dest='keepvideo', default=False, help='Keep the video file on disk after the post-processing; the video is erased by default')
    postproc.add_option('--no-post-overwrites', action='store_true', dest='nopostoverwrites', default=False, help='Do not overwrite post-processed files; the post-processed files are overwritten by default')
    postproc.add_option('--embed-subs', action='store_true', dest='embedsubtitles', default=False, help='Embed subtitles in the video (only for mp4, webm and mkv videos)')
    postproc.add_option('--embed-thumbnail', action='store_true', dest='embedthumbnail', default=False, help='Embed thumbnail in the audio as cover art')
    postproc.add_option('--add-metadata', action='store_true', dest='addmetadata', default=False, help='Write metadata to the video file')
    postproc.add_option('--metadata-from-title', metavar='FORMAT', dest='metafromtitle', help='Parse additional metadata like song title / artist from the video title. The format syntax is the same as --output. Regular expression with named capture groups may also be used. The parsed parameters replace existing values. Example: --metadata-from-title ""%(artist)s - %(title)s"" matches a title like ""Coldplay - Paradise"". Example (regex): --metadata-from-title ""(?P<artist>.+?) - (?P<title>.+)""')
    postproc.add_option('--xattrs', action='store_true', dest='xattrs', default=False, help=""Write metadata to the video file's xattrs (using dublin core and xdg standards)"")
    postproc.add_option('--fixup', metavar='POLICY', dest='fixup', default='detect_or_warn', help='Automatically correct known faults of the file. One of never (do nothing), warn (only emit a warning), detect_o","'[debug] %s: %s\n' % (conf_label, repr(_hide_login_info(conf)))",f'[debug] {conf_label}: {repr(_hide_login_info(conf))}\n',1,,,,,,,,,,
wig,https://github.com/jekyc/wig/tree/master/wig/classes/request2.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/wig/wig/classes/request2.py,Response,"def __repr__(self):

    def get_string(r):
        string = r.url + '\n'
        string += '%s %s\n' % (r.status['code'], r.status['text'])
        string += '\n'.join([header + ': ' + r.headers[header] for header in r.headers])
        string += '\n\n'
        string += 'MD5:            ' + self.md5 + '\n'
        string += 'MD5 Error page: ' + self.md5_404 + '\n'
        return string
    return get_string(self)","'%s %s\n' % (r.status['code'], r.status['text'])",f"{r.status['code']} {r.status['text']}\n",1,,,,,,,,,,
pony,https://github.com/ponyorm/pony/tree/master/pony/orm/tests/testutils.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pony/pony/orm/tests/testutils.py,,"def decorator(func):

    def wrapper(test_case, *args, **kwargs):
        try:
            func(test_case, *args, **kwargs)
            test_case.fail(""Expected exception %s wasn't raised"" % exc_class.__name__)
        except exc_class as e:
            if not e.args:
                test_case.assertEqual(test_msg, None)
            else:
                test_exception_msg(test_case, str(e), test_msg)
    wrapper.__name__ = func.__name__
    return wrapper","""Expected exception %s wasn't raised"" % exc_class.__name__",f"Expected exception {exc_class.__name__} wasn't raised",1,,,,,,,,,,
mypy,https://github.com/python/mypy/tree/master/mypy/suggestions.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/mypy/mypy/suggestions.py,SuggestionEngine,"def find_node(self, key: str) -> Tuple[str, str, FuncDef]:
    """"""From a target name, return module/target names and the func def.

        The 'key' argument can be in one of two formats:
        * As the function full name, e.g., package.module.Cls.method
        * As the function location as file and line separated by column,
          e.g., path/to/file.py:42
        """"""
    node: Optional[SymbolNode] = None
    if ':' in key:
        if key.count(':') > 1:
            raise SuggestionFailure('Malformed location for function: {}. Must be either package.module.Class.method or path/to/file.py:line'.format(key))
        (file, line) = key.split(':')
        if not line.isdigit():
            raise SuggestionFailure('Line number must be a number. Got {}'.format(line))
        line_number = int(line)
        (modname, node) = self.find_node_by_file_and_line(file, line_number)
        tail = node.fullname[len(modname) + 1:]
    else:
        target = split_target(self.fgmanager.graph, key)
        if not target:
            raise SuggestionFailure('Cannot find module for %s' % (key,))
        (modname, tail) = target
        node = self.find_node_by_module_and_name(modname, tail)
    if isinstance(node, Decorator):
        node = self.extract_from_decorator(node)
        if not node:
            raise SuggestionFailure(""Object %s is a decorator we can't handle"" % key)
    if not isinstance(node, FuncDef):
        raise SuggestionFailure('Object %s is not a function' % key)
    return (modname, tail, node)",'Object %s is not a function' % key,f'Object {key} is not a function',1,,,,,,,,,,
mypy,https://github.com/python/mypy/tree/master/mypy/suggestions.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/mypy/mypy/suggestions.py,SuggestionEngine,"def find_node(self, key: str) -> Tuple[str, str, FuncDef]:
    """"""From a target name, return module/target names and the func def.

        The 'key' argument can be in one of two formats:
        * As the function full name, e.g., package.module.Cls.method
        * As the function location as file and line separated by column,
          e.g., path/to/file.py:42
        """"""
    node: Optional[SymbolNode] = None
    if ':' in key:
        if key.count(':') > 1:
            raise SuggestionFailure('Malformed location for function: {}. Must be either package.module.Class.method or path/to/file.py:line'.format(key))
        (file, line) = key.split(':')
        if not line.isdigit():
            raise SuggestionFailure('Line number must be a number. Got {}'.format(line))
        line_number = int(line)
        (modname, node) = self.find_node_by_file_and_line(file, line_number)
        tail = node.fullname[len(modname) + 1:]
    else:
        target = split_target(self.fgmanager.graph, key)
        if not target:
            raise SuggestionFailure('Cannot find module for %s' % (key,))
        (modname, tail) = target
        node = self.find_node_by_module_and_name(modname, tail)
    if isinstance(node, Decorator):
        node = self.extract_from_decorator(node)
        if not node:
            raise SuggestionFailure(""Object %s is a decorator we can't handle"" % key)
    if not isinstance(node, FuncDef):
        raise SuggestionFailure('Object %s is not a function' % key)
    return (modname, tail, node)","'Cannot find module for %s' % (key,)",f"Cannot find module for {key}",1,,,,,,,,,,
mypy,https://github.com/python/mypy/tree/master/mypy/suggestions.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/mypy/mypy/suggestions.py,SuggestionEngine,"def find_node(self, key: str) -> Tuple[str, str, FuncDef]:
    """"""From a target name, return module/target names and the func def.

        The 'key' argument can be in one of two formats:
        * As the function full name, e.g., package.module.Cls.method
        * As the function location as file and line separated by column,
          e.g., path/to/file.py:42
        """"""
    node: Optional[SymbolNode] = None
    if ':' in key:
        if key.count(':') > 1:
            raise SuggestionFailure('Malformed location for function: {}. Must be either package.module.Class.method or path/to/file.py:line'.format(key))
        (file, line) = key.split(':')
        if not line.isdigit():
            raise SuggestionFailure('Line number must be a number. Got {}'.format(line))
        line_number = int(line)
        (modname, node) = self.find_node_by_file_and_line(file, line_number)
        tail = node.fullname[len(modname) + 1:]
    else:
        target = split_target(self.fgmanager.graph, key)
        if not target:
            raise SuggestionFailure('Cannot find module for %s' % (key,))
        (modname, tail) = target
        node = self.find_node_by_module_and_name(modname, tail)
    if isinstance(node, Decorator):
        node = self.extract_from_decorator(node)
        if not node:
            raise SuggestionFailure(""Object %s is a decorator we can't handle"" % key)
    if not isinstance(node, FuncDef):
        raise SuggestionFailure('Object %s is not a function' % key)
    return (modname, tail, node)","""Object %s is a decorator we can't handle"" % key",f"Object {key} is a decorator we can't handle",1,,,,,,,,,,
capa,https://github.com/mandiant/capa/tree/master/scripts/profile-time.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/capa/scripts/profile-time.py,,"def main(argv=None):
    if argv is None:
        argv = sys.argv[1:]
    label = subprocess.run('git show --pretty=oneline --abbrev-commit | head -n 1', shell=True, capture_output=True, text=True).stdout.strip()
    is_dirty = subprocess.run(""git status | grep 'modified: ' | grep -v 'rules' | grep -v 'tests/data'"", shell=True, capture_output=True, text=True).stdout != ''
    if is_dirty:
        label += ' (dirty)'
    parser = argparse.ArgumentParser(description='Profile capa performance')
    capa.main.install_common_args(parser, wanted={'format', 'sample', 'signatures', 'rules'})
    parser.add_argument('--number', type=int, default=3, help='batch size of profile collection')
    parser.add_argument('--repeat', type=int, default=30, help='batch count of profile collection')
    parser.add_argument('--label', type=str, default=label, help='description of the profile collection')
    args = parser.parse_args(args=argv)
    capa.main.handle_common_args(args)
    try:
        taste = capa.helpers.get_file_taste(args.sample)
    except IOError as e:
        logger.error('%s', str(e))
        return -1
    try:
        with capa.main.timing('load rules'):
            rules = capa.rules.RuleSet(capa.main.get_rules(args.rules, disable_progress=True))
    except IOError as e:
        logger.error('%s', str(e))
        return -1
    try:
        sig_paths = capa.main.get_signatures(args.signatures)
    except IOError as e:
        logger.error('%s', str(e))
        return -1
    if args.format == 'freeze' or (args.format == 'auto' and capa.features.freeze.is_freeze(taste)):
        with open(args.sample, 'rb') as f:
            extractor = capa.features.freeze.load(f.read())
    else:
        extractor = capa.main.get_extractor(args.sample, args.format, capa.main.BACKEND_VIV, sig_paths, should_save_workspace=False)
    with tqdm.tqdm(total=args.number * args.repeat) as pbar:

        def do_iteration():
            capa.perf.reset()
            capa.main.find_capabilities(rules, extractor, disable_progress=True)
            pbar.update(1)
        samples = timeit.repeat(do_iteration, number=args.number, repeat=args.repeat)
    logger.debug('perf: find capabilities: min: %0.2fs' % (min(samples) / float(args.number)))
    logger.debug('perf: find capabilities: avg: %0.2fs' % (sum(samples) / float(args.repeat) / float(args.number)))
    logger.debug('perf: find capabilities: max: %0.2fs' % (max(samples) / float(args.number)))
    for (counter, count) in capa.perf.counters.most_common():
        logger.debug('perf: counter: {:}: {:,}'.format(counter, count))
    print(tabulate.tabulate([(args.label, '{:,}'.format(capa.perf.counters['evaluate.feature']), '%0.2fs' % (min(samples) / float(args.number)), '%0.2fs' % (sum(samples) / float(args.repeat) / float(args.number)), '%0.2fs' % (max(samples) / float(args.number)))], headers=['label', 'count(evaluations)', 'min(time)', 'avg(time)', 'max(time)'], tablefmt='github'))
    return 0",'perf: find capabilities: min: %0.2fs' % (min(samples) / float(args.number)),f"perf: find capabilities: min: {min(samples) / float(args.number):0.2f}s",1,,,,,,,,,,
capa,https://github.com/mandiant/capa/tree/master/scripts/profile-time.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/capa/scripts/profile-time.py,,"def main(argv=None):
    if argv is None:
        argv = sys.argv[1:]
    label = subprocess.run('git show --pretty=oneline --abbrev-commit | head -n 1', shell=True, capture_output=True, text=True).stdout.strip()
    is_dirty = subprocess.run(""git status | grep 'modified: ' | grep -v 'rules' | grep -v 'tests/data'"", shell=True, capture_output=True, text=True).stdout != ''
    if is_dirty:
        label += ' (dirty)'
    parser = argparse.ArgumentParser(description='Profile capa performance')
    capa.main.install_common_args(parser, wanted={'format', 'sample', 'signatures', 'rules'})
    parser.add_argument('--number', type=int, default=3, help='batch size of profile collection')
    parser.add_argument('--repeat', type=int, default=30, help='batch count of profile collection')
    parser.add_argument('--label', type=str, default=label, help='description of the profile collection')
    args = parser.parse_args(args=argv)
    capa.main.handle_common_args(args)
    try:
        taste = capa.helpers.get_file_taste(args.sample)
    except IOError as e:
        logger.error('%s', str(e))
        return -1
    try:
        with capa.main.timing('load rules'):
            rules = capa.rules.RuleSet(capa.main.get_rules(args.rules, disable_progress=True))
    except IOError as e:
        logger.error('%s', str(e))
        return -1
    try:
        sig_paths = capa.main.get_signatures(args.signatures)
    except IOError as e:
        logger.error('%s', str(e))
        return -1
    if args.format == 'freeze' or (args.format == 'auto' and capa.features.freeze.is_freeze(taste)):
        with open(args.sample, 'rb') as f:
            extractor = capa.features.freeze.load(f.read())
    else:
        extractor = capa.main.get_extractor(args.sample, args.format, capa.main.BACKEND_VIV, sig_paths, should_save_workspace=False)
    with tqdm.tqdm(total=args.number * args.repeat) as pbar:

        def do_iteration():
            capa.perf.reset()
            capa.main.find_capabilities(rules, extractor, disable_progress=True)
            pbar.update(1)
        samples = timeit.repeat(do_iteration, number=args.number, repeat=args.repeat)
    logger.debug('perf: find capabilities: min: %0.2fs' % (min(samples) / float(args.number)))
    logger.debug('perf: find capabilities: avg: %0.2fs' % (sum(samples) / float(args.repeat) / float(args.number)))
    logger.debug('perf: find capabilities: max: %0.2fs' % (max(samples) / float(args.number)))
    for (counter, count) in capa.perf.counters.most_common():
        logger.debug('perf: counter: {:}: {:,}'.format(counter, count))
    print(tabulate.tabulate([(args.label, '{:,}'.format(capa.perf.counters['evaluate.feature']), '%0.2fs' % (min(samples) / float(args.number)), '%0.2fs' % (sum(samples) / float(args.repeat) / float(args.number)), '%0.2fs' % (max(samples) / float(args.number)))], headers=['label', 'count(evaluations)', 'min(time)', 'avg(time)', 'max(time)'], tablefmt='github'))
    return 0",'perf: find capabilities: avg: %0.2fs' % (sum(samples) / float(args.repeat) / float(args.number)),f"perf: find capabilities: avg: {sum(samples) / float(args.repeat) / float(args.number):.2f}s",1,,,,,,,,,,
capa,https://github.com/mandiant/capa/tree/master/scripts/profile-time.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/capa/scripts/profile-time.py,,"def main(argv=None):
    if argv is None:
        argv = sys.argv[1:]
    label = subprocess.run('git show --pretty=oneline --abbrev-commit | head -n 1', shell=True, capture_output=True, text=True).stdout.strip()
    is_dirty = subprocess.run(""git status | grep 'modified: ' | grep -v 'rules' | grep -v 'tests/data'"", shell=True, capture_output=True, text=True).stdout != ''
    if is_dirty:
        label += ' (dirty)'
    parser = argparse.ArgumentParser(description='Profile capa performance')
    capa.main.install_common_args(parser, wanted={'format', 'sample', 'signatures', 'rules'})
    parser.add_argument('--number', type=int, default=3, help='batch size of profile collection')
    parser.add_argument('--repeat', type=int, default=30, help='batch count of profile collection')
    parser.add_argument('--label', type=str, default=label, help='description of the profile collection')
    args = parser.parse_args(args=argv)
    capa.main.handle_common_args(args)
    try:
        taste = capa.helpers.get_file_taste(args.sample)
    except IOError as e:
        logger.error('%s', str(e))
        return -1
    try:
        with capa.main.timing('load rules'):
            rules = capa.rules.RuleSet(capa.main.get_rules(args.rules, disable_progress=True))
    except IOError as e:
        logger.error('%s', str(e))
        return -1
    try:
        sig_paths = capa.main.get_signatures(args.signatures)
    except IOError as e:
        logger.error('%s', str(e))
        return -1
    if args.format == 'freeze' or (args.format == 'auto' and capa.features.freeze.is_freeze(taste)):
        with open(args.sample, 'rb') as f:
            extractor = capa.features.freeze.load(f.read())
    else:
        extractor = capa.main.get_extractor(args.sample, args.format, capa.main.BACKEND_VIV, sig_paths, should_save_workspace=False)
    with tqdm.tqdm(total=args.number * args.repeat) as pbar:

        def do_iteration():
            capa.perf.reset()
            capa.main.find_capabilities(rules, extractor, disable_progress=True)
            pbar.update(1)
        samples = timeit.repeat(do_iteration, number=args.number, repeat=args.repeat)
    logger.debug('perf: find capabilities: min: %0.2fs' % (min(samples) / float(args.number)))
    logger.debug('perf: find capabilities: avg: %0.2fs' % (sum(samples) / float(args.repeat) / float(args.number)))
    logger.debug('perf: find capabilities: max: %0.2fs' % (max(samples) / float(args.number)))
    for (counter, count) in capa.perf.counters.most_common():
        logger.debug('perf: counter: {:}: {:,}'.format(counter, count))
    print(tabulate.tabulate([(args.label, '{:,}'.format(capa.perf.counters['evaluate.feature']), '%0.2fs' % (min(samples) / float(args.number)), '%0.2fs' % (sum(samples) / float(args.repeat) / float(args.number)), '%0.2fs' % (max(samples) / float(args.number)))], headers=['label', 'count(evaluations)', 'min(time)', 'avg(time)', 'max(time)'], tablefmt='github'))
    return 0",'perf: find capabilities: max: %0.2fs' % (max(samples) / float(args.number)),f"perf: find capabilities: max: {max(samples) / float(args.number):.2f}s",1,,,,,,,,,,
capa,https://github.com/mandiant/capa/tree/master/scripts/profile-time.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/capa/scripts/profile-time.py,,"def main(argv=None):
    if argv is None:
        argv = sys.argv[1:]
    label = subprocess.run('git show --pretty=oneline --abbrev-commit | head -n 1', shell=True, capture_output=True, text=True).stdout.strip()
    is_dirty = subprocess.run(""git status | grep 'modified: ' | grep -v 'rules' | grep -v 'tests/data'"", shell=True, capture_output=True, text=True).stdout != ''
    if is_dirty:
        label += ' (dirty)'
    parser = argparse.ArgumentParser(description='Profile capa performance')
    capa.main.install_common_args(parser, wanted={'format', 'sample', 'signatures', 'rules'})
    parser.add_argument('--number', type=int, default=3, help='batch size of profile collection')
    parser.add_argument('--repeat', type=int, default=30, help='batch count of profile collection')
    parser.add_argument('--label', type=str, default=label, help='description of the profile collection')
    args = parser.parse_args(args=argv)
    capa.main.handle_common_args(args)
    try:
        taste = capa.helpers.get_file_taste(args.sample)
    except IOError as e:
        logger.error('%s', str(e))
        return -1
    try:
        with capa.main.timing('load rules'):
            rules = capa.rules.RuleSet(capa.main.get_rules(args.rules, disable_progress=True))
    except IOError as e:
        logger.error('%s', str(e))
        return -1
    try:
        sig_paths = capa.main.get_signatures(args.signatures)
    except IOError as e:
        logger.error('%s', str(e))
        return -1
    if args.format == 'freeze' or (args.format == 'auto' and capa.features.freeze.is_freeze(taste)):
        with open(args.sample, 'rb') as f:
            extractor = capa.features.freeze.load(f.read())
    else:
        extractor = capa.main.get_extractor(args.sample, args.format, capa.main.BACKEND_VIV, sig_paths, should_save_workspace=False)
    with tqdm.tqdm(total=args.number * args.repeat) as pbar:

        def do_iteration():
            capa.perf.reset()
            capa.main.find_capabilities(rules, extractor, disable_progress=True)
            pbar.update(1)
        samples = timeit.repeat(do_iteration, number=args.number, repeat=args.repeat)
    logger.debug('perf: find capabilities: min: %0.2fs' % (min(samples) / float(args.number)))
    logger.debug('perf: find capabilities: avg: %0.2fs' % (sum(samples) / float(args.repeat) / float(args.number)))
    logger.debug('perf: find capabilities: max: %0.2fs' % (max(samples) / float(args.number)))
    for (counter, count) in capa.perf.counters.most_common():
        logger.debug('perf: counter: {:}: {:,}'.format(counter, count))
    print(tabulate.tabulate([(args.label, '{:,}'.format(capa.perf.counters['evaluate.feature']), '%0.2fs' % (min(samples) / float(args.number)), '%0.2fs' % (sum(samples) / float(args.repeat) / float(args.number)), '%0.2fs' % (max(samples) / float(args.number)))], headers=['label', 'count(evaluations)', 'min(time)', 'avg(time)', 'max(time)'], tablefmt='github'))
    return 0",'%0.2fs' % (min(samples) / float(args.number)),f"{min(samples) / float(args.number):.2f}s",1,,,,,,,,,,
capa,https://github.com/mandiant/capa/tree/master/scripts/profile-time.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/capa/scripts/profile-time.py,,"def main(argv=None):
    if argv is None:
        argv = sys.argv[1:]
    label = subprocess.run('git show --pretty=oneline --abbrev-commit | head -n 1', shell=True, capture_output=True, text=True).stdout.strip()
    is_dirty = subprocess.run(""git status | grep 'modified: ' | grep -v 'rules' | grep -v 'tests/data'"", shell=True, capture_output=True, text=True).stdout != ''
    if is_dirty:
        label += ' (dirty)'
    parser = argparse.ArgumentParser(description='Profile capa performance')
    capa.main.install_common_args(parser, wanted={'format', 'sample', 'signatures', 'rules'})
    parser.add_argument('--number', type=int, default=3, help='batch size of profile collection')
    parser.add_argument('--repeat', type=int, default=30, help='batch count of profile collection')
    parser.add_argument('--label', type=str, default=label, help='description of the profile collection')
    args = parser.parse_args(args=argv)
    capa.main.handle_common_args(args)
    try:
        taste = capa.helpers.get_file_taste(args.sample)
    except IOError as e:
        logger.error('%s', str(e))
        return -1
    try:
        with capa.main.timing('load rules'):
            rules = capa.rules.RuleSet(capa.main.get_rules(args.rules, disable_progress=True))
    except IOError as e:
        logger.error('%s', str(e))
        return -1
    try:
        sig_paths = capa.main.get_signatures(args.signatures)
    except IOError as e:
        logger.error('%s', str(e))
        return -1
    if args.format == 'freeze' or (args.format == 'auto' and capa.features.freeze.is_freeze(taste)):
        with open(args.sample, 'rb') as f:
            extractor = capa.features.freeze.load(f.read())
    else:
        extractor = capa.main.get_extractor(args.sample, args.format, capa.main.BACKEND_VIV, sig_paths, should_save_workspace=False)
    with tqdm.tqdm(total=args.number * args.repeat) as pbar:

        def do_iteration():
            capa.perf.reset()
            capa.main.find_capabilities(rules, extractor, disable_progress=True)
            pbar.update(1)
        samples = timeit.repeat(do_iteration, number=args.number, repeat=args.repeat)
    logger.debug('perf: find capabilities: min: %0.2fs' % (min(samples) / float(args.number)))
    logger.debug('perf: find capabilities: avg: %0.2fs' % (sum(samples) / float(args.repeat) / float(args.number)))
    logger.debug('perf: find capabilities: max: %0.2fs' % (max(samples) / float(args.number)))
    for (counter, count) in capa.perf.counters.most_common():
        logger.debug('perf: counter: {:}: {:,}'.format(counter, count))
    print(tabulate.tabulate([(args.label, '{:,}'.format(capa.perf.counters['evaluate.feature']), '%0.2fs' % (min(samples) / float(args.number)), '%0.2fs' % (sum(samples) / float(args.repeat) / float(args.number)), '%0.2fs' % (max(samples) / float(args.number)))], headers=['label', 'count(evaluations)', 'min(time)', 'avg(time)', 'max(time)'], tablefmt='github'))
    return 0",'%0.2fs' % (sum(samples) / float(args.repeat) / float(args.number)),f"{sum(samples) / float(args.repeat) / float(args.number):.2f}s",1,,,,,,,,,,
capa,https://github.com/mandiant/capa/tree/master/scripts/profile-time.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/capa/scripts/profile-time.py,,"def main(argv=None):
    if argv is None:
        argv = sys.argv[1:]
    label = subprocess.run('git show --pretty=oneline --abbrev-commit | head -n 1', shell=True, capture_output=True, text=True).stdout.strip()
    is_dirty = subprocess.run(""git status | grep 'modified: ' | grep -v 'rules' | grep -v 'tests/data'"", shell=True, capture_output=True, text=True).stdout != ''
    if is_dirty:
        label += ' (dirty)'
    parser = argparse.ArgumentParser(description='Profile capa performance')
    capa.main.install_common_args(parser, wanted={'format', 'sample', 'signatures', 'rules'})
    parser.add_argument('--number', type=int, default=3, help='batch size of profile collection')
    parser.add_argument('--repeat', type=int, default=30, help='batch count of profile collection')
    parser.add_argument('--label', type=str, default=label, help='description of the profile collection')
    args = parser.parse_args(args=argv)
    capa.main.handle_common_args(args)
    try:
        taste = capa.helpers.get_file_taste(args.sample)
    except IOError as e:
        logger.error('%s', str(e))
        return -1
    try:
        with capa.main.timing('load rules'):
            rules = capa.rules.RuleSet(capa.main.get_rules(args.rules, disable_progress=True))
    except IOError as e:
        logger.error('%s', str(e))
        return -1
    try:
        sig_paths = capa.main.get_signatures(args.signatures)
    except IOError as e:
        logger.error('%s', str(e))
        return -1
    if args.format == 'freeze' or (args.format == 'auto' and capa.features.freeze.is_freeze(taste)):
        with open(args.sample, 'rb') as f:
            extractor = capa.features.freeze.load(f.read())
    else:
        extractor = capa.main.get_extractor(args.sample, args.format, capa.main.BACKEND_VIV, sig_paths, should_save_workspace=False)
    with tqdm.tqdm(total=args.number * args.repeat) as pbar:

        def do_iteration():
            capa.perf.reset()
            capa.main.find_capabilities(rules, extractor, disable_progress=True)
            pbar.update(1)
        samples = timeit.repeat(do_iteration, number=args.number, repeat=args.repeat)
    logger.debug('perf: find capabilities: min: %0.2fs' % (min(samples) / float(args.number)))
    logger.debug('perf: find capabilities: avg: %0.2fs' % (sum(samples) / float(args.repeat) / float(args.number)))
    logger.debug('perf: find capabilities: max: %0.2fs' % (max(samples) / float(args.number)))
    for (counter, count) in capa.perf.counters.most_common():
        logger.debug('perf: counter: {:}: {:,}'.format(counter, count))
    print(tabulate.tabulate([(args.label, '{:,}'.format(capa.perf.counters['evaluate.feature']), '%0.2fs' % (min(samples) / float(args.number)), '%0.2fs' % (sum(samples) / float(args.repeat) / float(args.number)), '%0.2fs' % (max(samples) / float(args.number)))], headers=['label', 'count(evaluations)', 'min(time)', 'avg(time)', 'max(time)'], tablefmt='github'))
    return 0",'%0.2fs' % (max(samples) / float(args.number)),f"{max(samples) / float(args.number):.2f}s",1,,,,,,,,,,
pandapower,https://github.com/e2nIEE/pandapower/tree/master/pandapower/test/api/test_create.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pandapower/pandapower/test/api/test_create.py,,"def test_create_switches_raise_except():
    net = pp.create_empty_network()
    b1 = pp.create_bus(net, 110)
    b2 = pp.create_bus(net, 110)
    b3 = pp.create_bus(net, 15)
    b4 = pp.create_bus(net, 15)
    b5 = pp.create_bus(net, 0.9)
    b6 = pp.create_bus(net, 0.4)
    l1 = pp.create_line(net, b1, b2, length_km=1, std_type='48-AL1/8-ST1A 10.0')
    t1 = pp.create_transformer(net, b2, b3, std_type='160 MVA 380/110 kV')
    t3w1 = pp.create_transformer3w_from_parameters(net, hv_bus=b4, mv_bus=b5, lv_bus=b6, vn_hv_kv=15.0, vn_mv_kv=0.9, vn_lv_kv=0.45, sn_hv_mva=0.6, sn_mv_mva=0.5, sn_lv_mva=0.4, vk_hv_percent=1.0, vk_mv_percent=1.0, vk_lv_percent=1.0, vkr_hv_percent=0.3, vkr_mv_percent=0.3, vkr_lv_percent=0.3, pfe_kw=0.2, i0_percent=0.3, tap_neutral=0.0)
    sw = pp.create_switch(net, bus=b1, element=l1, et='l', z_ohm=0.0)
    with pytest.raises(UserWarning, match='Switches with indexes \\[0\\] already exist.'):
        pp.create_switches(net, buses=[b1, b2, b3], elements=[l1, t1, b4], et=['l', 't', 'b'], z_ohm=0.0, index=[sw, 1, 2])
    with pytest.raises(UserWarning, match='Cannot attach to buses \\{6\\}, they do not exist'):
        pp.create_switches(net, buses=[6, b2, b3], elements=[l1, t1, b4], et=['l', 't', 'b'], z_ohm=0.0)
    with pytest.raises(UserWarning, match='Line 1 does not exist'):
        pp.create_switches(net, buses=[b1, b2, b3], elements=[1, t1, b4], et=['l', 't', 'b'], z_ohm=0.0)
    with pytest.raises(UserWarning, match='Line %s not connected to bus %s' % (l1, b3)):
        pp.create_switches(net, buses=[b3, b2, b3], elements=[l1, t1, b4], et=['l', 't', 'b'], z_ohm=0.0)
    with pytest.raises(UserWarning, match='Trafo 1 does not exist'):
        pp.create_switches(net, buses=[b1, b2, b3], elements=[l1, 1, b4], et=['l', 't', 'b'], z_ohm=0.0)
    with pytest.raises(UserWarning, match='Trafo %s not connected to bus %s' % (t1, b1)):
        pp.create_switches(net, buses=[b1, b1, b3], elements=[l1, t1, b4], et=['l', 't', 'b'], z_ohm=0.0)
    with pytest.raises(UserWarning, match='Cannot attach to bus 6, bus does not exist'):
        pp.create_switches(net, buses=[b1, b2, b3], elements=[l1, t1, 6], et=['l', 't', 'b'], z_ohm=0.0)
    with pytest.raises(UserWarning, match='Trafo3w 1 does not exist'):
        pp.create_switches(net, buses=[b1, b2, b3], elements=[l1, t1, 1], et=['l', 't', 't3'], z_ohm=0.0)
    with pytest.raises(UserWarning, match='Trafo3w %s not connected to bus %s' % (t3w1, b3)):
        pp.create_switches(net, buses=[b1, b2, b3], elements=[l1, t1, t3w1], et=['l', 't', 't3'], z_ohm=0.0)","'Line %s not connected to bus %s' % (l1, b3)",f'Line {l1} not connected to bus {b3}',1,,,,,,,,,,
pandapower,https://github.com/e2nIEE/pandapower/tree/master/pandapower/test/api/test_create.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pandapower/pandapower/test/api/test_create.py,,"def test_create_switches_raise_except():
    net = pp.create_empty_network()
    b1 = pp.create_bus(net, 110)
    b2 = pp.create_bus(net, 110)
    b3 = pp.create_bus(net, 15)
    b4 = pp.create_bus(net, 15)
    b5 = pp.create_bus(net, 0.9)
    b6 = pp.create_bus(net, 0.4)
    l1 = pp.create_line(net, b1, b2, length_km=1, std_type='48-AL1/8-ST1A 10.0')
    t1 = pp.create_transformer(net, b2, b3, std_type='160 MVA 380/110 kV')
    t3w1 = pp.create_transformer3w_from_parameters(net, hv_bus=b4, mv_bus=b5, lv_bus=b6, vn_hv_kv=15.0, vn_mv_kv=0.9, vn_lv_kv=0.45, sn_hv_mva=0.6, sn_mv_mva=0.5, sn_lv_mva=0.4, vk_hv_percent=1.0, vk_mv_percent=1.0, vk_lv_percent=1.0, vkr_hv_percent=0.3, vkr_mv_percent=0.3, vkr_lv_percent=0.3, pfe_kw=0.2, i0_percent=0.3, tap_neutral=0.0)
    sw = pp.create_switch(net, bus=b1, element=l1, et='l', z_ohm=0.0)
    with pytest.raises(UserWarning, match='Switches with indexes \\[0\\] already exist.'):
        pp.create_switches(net, buses=[b1, b2, b3], elements=[l1, t1, b4], et=['l', 't', 'b'], z_ohm=0.0, index=[sw, 1, 2])
    with pytest.raises(UserWarning, match='Cannot attach to buses \\{6\\}, they do not exist'):
        pp.create_switches(net, buses=[6, b2, b3], elements=[l1, t1, b4], et=['l', 't', 'b'], z_ohm=0.0)
    with pytest.raises(UserWarning, match='Line 1 does not exist'):
        pp.create_switches(net, buses=[b1, b2, b3], elements=[1, t1, b4], et=['l', 't', 'b'], z_ohm=0.0)
    with pytest.raises(UserWarning, match='Line %s not connected to bus %s' % (l1, b3)):
        pp.create_switches(net, buses=[b3, b2, b3], elements=[l1, t1, b4], et=['l', 't', 'b'], z_ohm=0.0)
    with pytest.raises(UserWarning, match='Trafo 1 does not exist'):
        pp.create_switches(net, buses=[b1, b2, b3], elements=[l1, 1, b4], et=['l', 't', 'b'], z_ohm=0.0)
    with pytest.raises(UserWarning, match='Trafo %s not connected to bus %s' % (t1, b1)):
        pp.create_switches(net, buses=[b1, b1, b3], elements=[l1, t1, b4], et=['l', 't', 'b'], z_ohm=0.0)
    with pytest.raises(UserWarning, match='Cannot attach to bus 6, bus does not exist'):
        pp.create_switches(net, buses=[b1, b2, b3], elements=[l1, t1, 6], et=['l', 't', 'b'], z_ohm=0.0)
    with pytest.raises(UserWarning, match='Trafo3w 1 does not exist'):
        pp.create_switches(net, buses=[b1, b2, b3], elements=[l1, t1, 1], et=['l', 't', 't3'], z_ohm=0.0)
    with pytest.raises(UserWarning, match='Trafo3w %s not connected to bus %s' % (t3w1, b3)):
        pp.create_switches(net, buses=[b1, b2, b3], elements=[l1, t1, t3w1], et=['l', 't', 't3'], z_ohm=0.0)","'Trafo %s not connected to bus %s' % (t1, b1)",f"Trafo {t1} not connected to bus {b1}",1,,,,,,,,,,
pandapower,https://github.com/e2nIEE/pandapower/tree/master/pandapower/test/api/test_create.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pandapower/pandapower/test/api/test_create.py,,"def test_create_switches_raise_except():
    net = pp.create_empty_network()
    b1 = pp.create_bus(net, 110)
    b2 = pp.create_bus(net, 110)
    b3 = pp.create_bus(net, 15)
    b4 = pp.create_bus(net, 15)
    b5 = pp.create_bus(net, 0.9)
    b6 = pp.create_bus(net, 0.4)
    l1 = pp.create_line(net, b1, b2, length_km=1, std_type='48-AL1/8-ST1A 10.0')
    t1 = pp.create_transformer(net, b2, b3, std_type='160 MVA 380/110 kV')
    t3w1 = pp.create_transformer3w_from_parameters(net, hv_bus=b4, mv_bus=b5, lv_bus=b6, vn_hv_kv=15.0, vn_mv_kv=0.9, vn_lv_kv=0.45, sn_hv_mva=0.6, sn_mv_mva=0.5, sn_lv_mva=0.4, vk_hv_percent=1.0, vk_mv_percent=1.0, vk_lv_percent=1.0, vkr_hv_percent=0.3, vkr_mv_percent=0.3, vkr_lv_percent=0.3, pfe_kw=0.2, i0_percent=0.3, tap_neutral=0.0)
    sw = pp.create_switch(net, bus=b1, element=l1, et='l', z_ohm=0.0)
    with pytest.raises(UserWarning, match='Switches with indexes \\[0\\] already exist.'):
        pp.create_switches(net, buses=[b1, b2, b3], elements=[l1, t1, b4], et=['l', 't', 'b'], z_ohm=0.0, index=[sw, 1, 2])
    with pytest.raises(UserWarning, match='Cannot attach to buses \\{6\\}, they do not exist'):
        pp.create_switches(net, buses=[6, b2, b3], elements=[l1, t1, b4], et=['l', 't', 'b'], z_ohm=0.0)
    with pytest.raises(UserWarning, match='Line 1 does not exist'):
        pp.create_switches(net, buses=[b1, b2, b3], elements=[1, t1, b4], et=['l', 't', 'b'], z_ohm=0.0)
    with pytest.raises(UserWarning, match='Line %s not connected to bus %s' % (l1, b3)):
        pp.create_switches(net, buses=[b3, b2, b3], elements=[l1, t1, b4], et=['l', 't', 'b'], z_ohm=0.0)
    with pytest.raises(UserWarning, match='Trafo 1 does not exist'):
        pp.create_switches(net, buses=[b1, b2, b3], elements=[l1, 1, b4], et=['l', 't', 'b'], z_ohm=0.0)
    with pytest.raises(UserWarning, match='Trafo %s not connected to bus %s' % (t1, b1)):
        pp.create_switches(net, buses=[b1, b1, b3], elements=[l1, t1, b4], et=['l', 't', 'b'], z_ohm=0.0)
    with pytest.raises(UserWarning, match='Cannot attach to bus 6, bus does not exist'):
        pp.create_switches(net, buses=[b1, b2, b3], elements=[l1, t1, 6], et=['l', 't', 'b'], z_ohm=0.0)
    with pytest.raises(UserWarning, match='Trafo3w 1 does not exist'):
        pp.create_switches(net, buses=[b1, b2, b3], elements=[l1, t1, 1], et=['l', 't', 't3'], z_ohm=0.0)
    with pytest.raises(UserWarning, match='Trafo3w %s not connected to bus %s' % (t3w1, b3)):
        pp.create_switches(net, buses=[b1, b2, b3], elements=[l1, t1, t3w1], et=['l', 't', 't3'], z_ohm=0.0)","'Trafo3w %s not connected to bus %s' % (t3w1, b3)",f"Trafo3w {t3w1} not connected to bus {b3}",1,,,,,,,,,,
Paddle,https://github.com/PaddlePaddle/Paddle/tree/master/python/paddle/fluid/tests/unittests/test_dist_base.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/Paddle/python/paddle/fluid/tests/unittests/test_dist_base.py,TestDistRunnerBase,"def run_use_fleet_api_trainer(self, args):
    assert args.update_method == 'nccl2' or 'bkcl'
    self.lr = args.lr
    exec_strategy = fluid.ExecutionStrategy()
    exec_strategy.num_threads = 1
    dist_strategy = DistributedStrategy()
    dist_strategy.exec_strategy = exec_strategy
    dist_strategy.fuse_memory_size = 1
    dist_strategy.fuse_laryer_size = 1
    if args.use_local_sgd:
        dist_strategy.use_local_sgd = True
    if args.ut4grad_allreduce:
        dist_strategy._ut4grad_allreduce = True
    if args.sync_batch_norm:
        dist_strategy.sync_batch_norm = True
    role = role_maker.PaddleCloudRoleMaker(is_collective=True)
    fleet.init(role)
    print_to_err('use_fleet', 'fleet.node_num:')
    (test_program, avg_cost, train_reader, test_reader, batch_acc, predict) = self.get_model(batch_size=args.batch_size, dist_strategy=dist_strategy)
    trainer_prog = fleet._origin_program
    dist_prog = fleet.main_program
    if fluid.core.is_compiled_with_cuda():
        device_id = int(os.getenv('FLAGS_selected_gpus', '0'))
        place = fluid.CUDAPlace(device_id)
    elif fluid.core.is_compiled_with_xpu():
        device_id = int(os.getenv('FLAGS_selected_xpus', '0'))
        place = fluid.XPUPlace(device_id)
    else:
        raise ValueError('fleet dygraph api must in paddlepaddle-xpu or paddlepaddle-gpu.')
    exe = fluid.Executor(place)
    exe.run(fluid.default_startup_program())
    eprint(type(self).__name__, 'run worker startup program done.')
    feed_var_list = [var for var in trainer_prog.global_block().vars.values() if var.is_data]
    eprint('feed_var_list:', feed_var_list)
    if feed_var_list[0].name == 'label':
        feed_var_list = feed_var_list[::-1]
    feeder = fluid.DataFeeder(feed_var_list, place)
    reader_generator = train_reader()

    def get_data():
        origin_batch = next(reader_generator)
        if args.update_method != 'local' and args.use_reader_alloc:
            new_batch = []
            for (offset, item) in enumerate(origin_batch):
                if offset % 2 == args.trainer_id:
                    new_batch.append(item)
            return new_batch
        else:
            return origin_batch
    print_to_err(type(self).__name__, 'begin to train on trainer')
    out_losses = []
    for i in range(RUN_STEP):
        (loss,) = exe.run(dist_prog, fetch_list=[avg_cost.name], feed=feeder.feed(get_data()))
        out_losses.append(loss[0])
        print_to_err(type(self).__name__, 'run step %d finished' % i)
    print_to_err(type(self).__name__, 'trainer run finished')
    sys.stdout.buffer.write(pickle.dumps(out_losses))
    if args.save_model:
        model_save_dir = '/tmp'
        if fleet.worker_index() == 0:
            model_save_dir_fluid = os.path.join(model_save_dir, 'fluid_persistables')
            model_save_dir_fleet = os.path.join(model_save_dir, 'fleet_persistables')
            infer_save_dir_fluid = os.path.join(model_save_dir, 'fluid_infer')
            infer_save_dir_fleet = os.path.join(model_save_dir, 'fleet_infer')
        else:
            model_save_dir_fluid = os.path.join(model_save_dir, 'fluid_persistables_2')
            model_save_dir_fleet = os.path.join(model_save_dir, 'fleet_persistables_2')
            infer_save_dir_fluid = os.path.join(model_save_dir, 'fluid_infer_2')
            infer_save_dir_fleet = os.path.join(model_save_dir, 'fleet_infer_2')
        paddle.distributed.io.save_persistables(exe, model_save_dir_fluid, fleet._origin_program)
        fleet.save_persistables(executor=exe, dirname=model_save_dir_fleet)
        feeded_var_names = [var.name for var in feed_var_list]
        fluid.io.save_inference_model(infer_save_dir_fluid, feeded_var_names, [avg_cost], exe, fleet._origin_program)
        fleet.save_inference_model(exe, infer_save_dir_fleet, feeded_var_names, [avg_cost])",'run step %d finished' % i,f'run step {i} finished',1,,,,,,,,,,
pgadmin4,https://github.com/postgres/pgadmin4/tree/master/web/pgadmin/browser/server_groups/servers/databases/schemas/tables/indexes/tests/test_indexes_get_nodes.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pgadmin4/web/pgadmin/browser/server_groups/servers/databases/schemas/tables/indexes/tests/test_indexes_get_nodes.py,IndexesGetTestCase,"def setUp(self):
    """""" Creating index required in further steps""""""
    self.db_name = parent_node_dict['database'][-1]['db_name']
    schema_info = parent_node_dict['schema'][-1]
    self.server_id = schema_info['server_id']
    self.db_id = schema_info['db_id']
    db_con = database_utils.connect_database(self, utils.SERVER_GROUP, self.server_id, self.db_id)
    if not db_con['data']['connected']:
        raise Exception('Could not connect to database to add a table.')
    self.schema_id = schema_info['schema_id']
    self.schema_name = schema_info['schema_name']
    schema_response = schema_utils.verify_schemas(self.server, self.db_name, self.schema_name)
    if not schema_response:
        raise Exception('Could not find the schema to add a table.')
    self.table_name = 'table_column_%s' % str(uuid.uuid4())[1:8]
    self.table_id = tables_utils.create_table(self.server, self.db_name, self.schema_name, self.table_name)
    self.column_name = 'test_column_delete_%s' % str(uuid.uuid4())[1:8]
    self.column_id = columns_utils.create_column(self.server, self.db_name, self.schema_name, self.table_name, self.column_name)
    self.index_name = 'test_index_delete_%s' % str(uuid.uuid4())[1:8]
    self.index_id = indexes_utils.create_index(self.server, self.db_name, self.schema_name, self.table_name, self.index_name, self.column_name)
    if self.is_list:
        self.index_name_1 = 'test_index_delete_%s' % str(uuid.uuid4())[1:8]
        self.index_ids = [self.index_id, indexes_utils.create_index(self.server, self.db_name, self.schema_name, self.table_name, self.index_name_1, self.column_name)]",'table_column_%s' % str(uuid.uuid4())[1:8],f"table_column_{str(uuid.uuid4())[1:8]}",1,,,,,,,,,,
pgadmin4,https://github.com/postgres/pgadmin4/tree/master/web/pgadmin/browser/server_groups/servers/databases/schemas/tables/indexes/tests/test_indexes_get_nodes.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pgadmin4/web/pgadmin/browser/server_groups/servers/databases/schemas/tables/indexes/tests/test_indexes_get_nodes.py,IndexesGetTestCase,"def setUp(self):
    """""" Creating index required in further steps""""""
    self.db_name = parent_node_dict['database'][-1]['db_name']
    schema_info = parent_node_dict['schema'][-1]
    self.server_id = schema_info['server_id']
    self.db_id = schema_info['db_id']
    db_con = database_utils.connect_database(self, utils.SERVER_GROUP, self.server_id, self.db_id)
    if not db_con['data']['connected']:
        raise Exception('Could not connect to database to add a table.')
    self.schema_id = schema_info['schema_id']
    self.schema_name = schema_info['schema_name']
    schema_response = schema_utils.verify_schemas(self.server, self.db_name, self.schema_name)
    if not schema_response:
        raise Exception('Could not find the schema to add a table.')
    self.table_name = 'table_column_%s' % str(uuid.uuid4())[1:8]
    self.table_id = tables_utils.create_table(self.server, self.db_name, self.schema_name, self.table_name)
    self.column_name = 'test_column_delete_%s' % str(uuid.uuid4())[1:8]
    self.column_id = columns_utils.create_column(self.server, self.db_name, self.schema_name, self.table_name, self.column_name)
    self.index_name = 'test_index_delete_%s' % str(uuid.uuid4())[1:8]
    self.index_id = indexes_utils.create_index(self.server, self.db_name, self.schema_name, self.table_name, self.index_name, self.column_name)
    if self.is_list:
        self.index_name_1 = 'test_index_delete_%s' % str(uuid.uuid4())[1:8]
        self.index_ids = [self.index_id, indexes_utils.create_index(self.server, self.db_name, self.schema_name, self.table_name, self.index_name_1, self.column_name)]",'test_column_delete_%s' % str(uuid.uuid4())[1:8],f"test_column_delete_{str(uuid.uuid4())[1:8]}",1,,,,,,,,,,
pgadmin4,https://github.com/postgres/pgadmin4/tree/master/web/pgadmin/browser/server_groups/servers/databases/schemas/tables/indexes/tests/test_indexes_get_nodes.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pgadmin4/web/pgadmin/browser/server_groups/servers/databases/schemas/tables/indexes/tests/test_indexes_get_nodes.py,IndexesGetTestCase,"def setUp(self):
    """""" Creating index required in further steps""""""
    self.db_name = parent_node_dict['database'][-1]['db_name']
    schema_info = parent_node_dict['schema'][-1]
    self.server_id = schema_info['server_id']
    self.db_id = schema_info['db_id']
    db_con = database_utils.connect_database(self, utils.SERVER_GROUP, self.server_id, self.db_id)
    if not db_con['data']['connected']:
        raise Exception('Could not connect to database to add a table.')
    self.schema_id = schema_info['schema_id']
    self.schema_name = schema_info['schema_name']
    schema_response = schema_utils.verify_schemas(self.server, self.db_name, self.schema_name)
    if not schema_response:
        raise Exception('Could not find the schema to add a table.')
    self.table_name = 'table_column_%s' % str(uuid.uuid4())[1:8]
    self.table_id = tables_utils.create_table(self.server, self.db_name, self.schema_name, self.table_name)
    self.column_name = 'test_column_delete_%s' % str(uuid.uuid4())[1:8]
    self.column_id = columns_utils.create_column(self.server, self.db_name, self.schema_name, self.table_name, self.column_name)
    self.index_name = 'test_index_delete_%s' % str(uuid.uuid4())[1:8]
    self.index_id = indexes_utils.create_index(self.server, self.db_name, self.schema_name, self.table_name, self.index_name, self.column_name)
    if self.is_list:
        self.index_name_1 = 'test_index_delete_%s' % str(uuid.uuid4())[1:8]
        self.index_ids = [self.index_id, indexes_utils.create_index(self.server, self.db_name, self.schema_name, self.table_name, self.index_name_1, self.column_name)]",'test_index_delete_%s' % str(uuid.uuid4())[1:8],f"test_index_delete_{str(uuid.uuid4())[1:8]}",1,,,,,,,,,,
pgadmin4,https://github.com/postgres/pgadmin4/tree/master/web/pgadmin/browser/server_groups/servers/databases/schemas/tables/indexes/tests/test_indexes_get_nodes.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pgadmin4/web/pgadmin/browser/server_groups/servers/databases/schemas/tables/indexes/tests/test_indexes_get_nodes.py,IndexesGetTestCase,"def setUp(self):
    """""" Creating index required in further steps""""""
    self.db_name = parent_node_dict['database'][-1]['db_name']
    schema_info = parent_node_dict['schema'][-1]
    self.server_id = schema_info['server_id']
    self.db_id = schema_info['db_id']
    db_con = database_utils.connect_database(self, utils.SERVER_GROUP, self.server_id, self.db_id)
    if not db_con['data']['connected']:
        raise Exception('Could not connect to database to add a table.')
    self.schema_id = schema_info['schema_id']
    self.schema_name = schema_info['schema_name']
    schema_response = schema_utils.verify_schemas(self.server, self.db_name, self.schema_name)
    if not schema_response:
        raise Exception('Could not find the schema to add a table.')
    self.table_name = 'table_column_%s' % str(uuid.uuid4())[1:8]
    self.table_id = tables_utils.create_table(self.server, self.db_name, self.schema_name, self.table_name)
    self.column_name = 'test_column_delete_%s' % str(uuid.uuid4())[1:8]
    self.column_id = columns_utils.create_column(self.server, self.db_name, self.schema_name, self.table_name, self.column_name)
    self.index_name = 'test_index_delete_%s' % str(uuid.uuid4())[1:8]
    self.index_id = indexes_utils.create_index(self.server, self.db_name, self.schema_name, self.table_name, self.index_name, self.column_name)
    if self.is_list:
        self.index_name_1 = 'test_index_delete_%s' % str(uuid.uuid4())[1:8]
        self.index_ids = [self.index_id, indexes_utils.create_index(self.server, self.db_name, self.schema_name, self.table_name, self.index_name_1, self.column_name)]",'test_index_delete_%s' % str(uuid.uuid4())[1:8],f"test_index_delete_{str(uuid.uuid4())[1:8]}",1,,,,,,,,,,
FedML,https://github.com/FedML-AI/FedML/tree/master/fedml_api/model/cv/efficientnet_utils.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/FedML/fedml_api/model/cv/efficientnet_utils.py,BlockDecoder,"def _encode_block_string(block):
    """"""Encode a block to a string.
        Args:
            block (namedtuple): A BlockArgs type argument.
        Returns:
            block_string: A String form of BlockArgs.
        """"""
    args = ['r%d' % block.num_repeat, 'k%d' % block.kernel_size, 's%d%d' % (block.strides[0], block.strides[1]), 'e%s' % block.expand_ratio, 'i%d' % block.input_filters, 'o%d' % block.output_filters]
    if 0 < block.se_ratio <= 1:
        args.append('se%s' % block.se_ratio)
    if block.id_skip is False:
        args.append('noskip')
    return '_'.join(args)",'r%d' % block.num_repeat,f'r{block.num_repeat}',1,,,,,,,,,,
FedML,https://github.com/FedML-AI/FedML/tree/master/fedml_api/model/cv/efficientnet_utils.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/FedML/fedml_api/model/cv/efficientnet_utils.py,BlockDecoder,"def _encode_block_string(block):
    """"""Encode a block to a string.
        Args:
            block (namedtuple): A BlockArgs type argument.
        Returns:
            block_string: A String form of BlockArgs.
        """"""
    args = ['r%d' % block.num_repeat, 'k%d' % block.kernel_size, 's%d%d' % (block.strides[0], block.strides[1]), 'e%s' % block.expand_ratio, 'i%d' % block.input_filters, 'o%d' % block.output_filters]
    if 0 < block.se_ratio <= 1:
        args.append('se%s' % block.se_ratio)
    if block.id_skip is False:
        args.append('noskip')
    return '_'.join(args)",'k%d' % block.kernel_size,f'k{block.kernel_size}',1,,,,,,,,,,
FedML,https://github.com/FedML-AI/FedML/tree/master/fedml_api/model/cv/efficientnet_utils.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/FedML/fedml_api/model/cv/efficientnet_utils.py,BlockDecoder,"def _encode_block_string(block):
    """"""Encode a block to a string.
        Args:
            block (namedtuple): A BlockArgs type argument.
        Returns:
            block_string: A String form of BlockArgs.
        """"""
    args = ['r%d' % block.num_repeat, 'k%d' % block.kernel_size, 's%d%d' % (block.strides[0], block.strides[1]), 'e%s' % block.expand_ratio, 'i%d' % block.input_filters, 'o%d' % block.output_filters]
    if 0 < block.se_ratio <= 1:
        args.append('se%s' % block.se_ratio)
    if block.id_skip is False:
        args.append('noskip')
    return '_'.join(args)","'s%d%d' % (block.strides[0], block.strides[1])",f's{block.strides[0]}{block.strides[1]}',1,,,,,,,,,,
FedML,https://github.com/FedML-AI/FedML/tree/master/fedml_api/model/cv/efficientnet_utils.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/FedML/fedml_api/model/cv/efficientnet_utils.py,BlockDecoder,"def _encode_block_string(block):
    """"""Encode a block to a string.
        Args:
            block (namedtuple): A BlockArgs type argument.
        Returns:
            block_string: A String form of BlockArgs.
        """"""
    args = ['r%d' % block.num_repeat, 'k%d' % block.kernel_size, 's%d%d' % (block.strides[0], block.strides[1]), 'e%s' % block.expand_ratio, 'i%d' % block.input_filters, 'o%d' % block.output_filters]
    if 0 < block.se_ratio <= 1:
        args.append('se%s' % block.se_ratio)
    if block.id_skip is False:
        args.append('noskip')
    return '_'.join(args)",'e%s' % block.expand_ratio,f"e{block.expand_ratio}",1,,,,,,,,,,
FedML,https://github.com/FedML-AI/FedML/tree/master/fedml_api/model/cv/efficientnet_utils.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/FedML/fedml_api/model/cv/efficientnet_utils.py,BlockDecoder,"def _encode_block_string(block):
    """"""Encode a block to a string.
        Args:
            block (namedtuple): A BlockArgs type argument.
        Returns:
            block_string: A String form of BlockArgs.
        """"""
    args = ['r%d' % block.num_repeat, 'k%d' % block.kernel_size, 's%d%d' % (block.strides[0], block.strides[1]), 'e%s' % block.expand_ratio, 'i%d' % block.input_filters, 'o%d' % block.output_filters]
    if 0 < block.se_ratio <= 1:
        args.append('se%s' % block.se_ratio)
    if block.id_skip is False:
        args.append('noskip')
    return '_'.join(args)",'i%d' % block.input_filters,f"i{block.input_filters}",1,,,,,,,,,,
FedML,https://github.com/FedML-AI/FedML/tree/master/fedml_api/model/cv/efficientnet_utils.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/FedML/fedml_api/model/cv/efficientnet_utils.py,BlockDecoder,"def _encode_block_string(block):
    """"""Encode a block to a string.
        Args:
            block (namedtuple): A BlockArgs type argument.
        Returns:
            block_string: A String form of BlockArgs.
        """"""
    args = ['r%d' % block.num_repeat, 'k%d' % block.kernel_size, 's%d%d' % (block.strides[0], block.strides[1]), 'e%s' % block.expand_ratio, 'i%d' % block.input_filters, 'o%d' % block.output_filters]
    if 0 < block.se_ratio <= 1:
        args.append('se%s' % block.se_ratio)
    if block.id_skip is False:
        args.append('noskip')
    return '_'.join(args)",'o%d' % block.output_filters,f"o{block.output_filters}",1,,,,,,,,,,
FedML,https://github.com/FedML-AI/FedML/tree/master/fedml_api/model/cv/efficientnet_utils.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/FedML/fedml_api/model/cv/efficientnet_utils.py,BlockDecoder,"def _encode_block_string(block):
    """"""Encode a block to a string.
        Args:
            block (namedtuple): A BlockArgs type argument.
        Returns:
            block_string: A String form of BlockArgs.
        """"""
    args = ['r%d' % block.num_repeat, 'k%d' % block.kernel_size, 's%d%d' % (block.strides[0], block.strides[1]), 'e%s' % block.expand_ratio, 'i%d' % block.input_filters, 'o%d' % block.output_filters]
    if 0 < block.se_ratio <= 1:
        args.append('se%s' % block.se_ratio)
    if block.id_skip is False:
        args.append('noskip')
    return '_'.join(args)",'se%s' % block.se_ratio,f"se{block.se_ratio}",1,,,,,,,,,,
anaconda,https://github.com/DamnWidget/anaconda/tree/master/anaconda_lib/parso/pgen2/generator.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/anaconda/anaconda_lib/parso/pgen2/generator.py,,"def _calculate_tree_traversal(nonterminal_to_dfas):
    """"""
    By this point we know how dfas can move around within a stack node, but we
    don't know how we can add a new stack node (nonterminal transitions).
    """"""
    first_plans = {}
    nonterminals = list(nonterminal_to_dfas.keys())
    nonterminals.sort()
    for nonterminal in nonterminals:
        if nonterminal not in first_plans:
            _calculate_first_plans(nonterminal_to_dfas, first_plans, nonterminal)
    for dfas in nonterminal_to_dfas.values():
        for dfa_state in dfas:
            transitions = dfa_state.transitions
            for (nonterminal, next_dfa) in dfa_state.nonterminal_arcs.items():
                for (transition, pushes) in first_plans[nonterminal].items():
                    if transition in transitions:
                        prev_plan = transitions[transition]
                        choices = sorted([prev_plan.dfa_pushes[0].from_rule if prev_plan.dfa_pushes else prev_plan.next_dfa.from_rule, pushes[0].from_rule if pushes else next_dfa.from_rule])
                        raise ValueError(""Rule %s is ambiguous; given a %s token, we can't determine if we should evaluate %s or %s."" % ((dfa_state.from_rule, transition) + tuple(choices)))
                    transitions[transition] = DFAPlan(next_dfa, pushes)","""Rule %s is ambiguous; given a %s token, we can't determine if we should evaluate %s or %s."" % ((dfa_state.from_rule, transition) + tuple(choices))","f""Rule {dfa_state.from_rule} is ambiguous; given a {transition} token, we can't determine if we should evaluate {choices[0]} or {choices[1]}.""",1,,,,,,,,,,
geneva,https://github.com/Kkevsterrr/geneva/tree/master/actions/trace.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/geneva/actions/trace.py,TraceAction,"def __str__(self):
    """"""
        Returns a string representation.
        """"""
    s = Action.__str__(self)
    s += '{%d:%d}' % (self.start_ttl, self.end_ttl)
    return s","'{%d:%d}' % (self.start_ttl, self.end_ttl)",f'{{{self.start_ttl}:{self.end_ttl}}}',1,,,,,,,,,,
geopy,https://github.com/geopy/geopy/tree/master/geopy/geocoders/smartystreets.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/geopy/geopy/geocoders/smartystreets.py,LiveAddress,"def __init__(self, auth_id, auth_token, *, timeout=DEFAULT_SENTINEL, proxies=DEFAULT_SENTINEL, user_agent=None, ssl_context=DEFAULT_SENTINEL, adapter_factory=None):
    """"""

        :param str auth_id: Valid `Auth ID` from SmartyStreets.

        :param str auth_token: Valid `Auth Token` from SmartyStreets.

        :param int timeout:
            See :attr:`geopy.geocoders.options.default_timeout`.

        :param dict proxies:
            See :attr:`geopy.geocoders.options.default_proxies`.

        :param str user_agent:
            See :attr:`geopy.geocoders.options.default_user_agent`.

        :type ssl_context: :class:`ssl.SSLContext`
        :param ssl_context:
            See :attr:`geopy.geocoders.options.default_ssl_context`.

        :param callable adapter_factory:
            See :attr:`geopy.geocoders.options.default_adapter_factory`.

            .. versionadded:: 2.0
        """"""
    super().__init__(scheme='https', timeout=timeout, proxies=proxies, user_agent=user_agent, ssl_context=ssl_context, adapter_factory=adapter_factory)
    self.auth_id = auth_id
    self.auth_token = auth_token
    domain = 'api.smartystreets.com'
    self.api = '%s://%s%s' % (self.scheme, domain, self.geocode_path)","'%s://%s%s' % (self.scheme, domain, self.geocode_path)",f"{self.scheme}://{domain}{self.geocode_path}",1,,,,,,,,,,
holoviews,https://github.com/holoviz/holoviews/tree/master/holoviews/tests/test_streams.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/holoviews/holoviews/tests/test_streams.py,,"def test_all_linked_stream_parameters_owners():
    """"""Test to ensure operations can accept parameters in streams dictionary""""""
    stream_classes = param.concrete_descendents(LinkedStream)
    for stream_class in stream_classes.values():
        for (name, p) in stream_class.param.params().items():
            if name != 'name' and p.owner != stream_class:
                msg = 'Linked stream %r has parameter %r which is inherited from %s. Parameter needs to be redeclared in the class definition of this linked stream.'
                raise Exception(msg % (stream_class, name, p.owner))","msg % (stream_class, name, p.owner)","f""{msg} {stream_class}, {name}, {p.owner}""",1,,,,,,,,,,
circus,https://github.com/circus-tent/circus/tree/master/circus/plugins/statsd.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/circus/circus/plugins/statsd.py,StatsdClient,"def timed(self, bucket, value):
    self.send(bucket, '%s|ms' % value)",'%s|ms' % value,f"{value}|ms",1,,,,,,,,,,
shuup,https://github.com/shuup/shuup/tree/master/shuup/admin/modules/products/views/edit_media.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/shuup/shuup/admin/modules/products/views/edit_media.py,ProductMediaBulkAdderView,"def post(self, *args, **kwargs):
    ids = self.request.POST.getlist('file_ids')
    shop_product_id = kwargs.pop('pk')
    kind = self.request.POST.get('kind')
    shop = self.request.shop
    shop_id = self.request.POST.get('shop_id', shop.pk)
    if not ids or not shop_product_id:
        return JsonResponse({'response': 'error', 'message': 'Error! Bad request.'}, status=400)
    if not Shop.objects.filter(pk=shop_id).exists():
        return JsonResponse({'response': 'error', 'message': 'Error! Invalid shop id `%s`.' % shop_id}, status=400)
    shop_product = ShopProduct.objects.filter(pk=shop_product_id, shop_id=shop_id).first()
    if not shop_product:
        return JsonResponse({'response': 'error', 'message': 'Error! Invalid shop product id `%s`.' % shop_product_id}, status=400)
    if kind == 'images':
        kind = ProductMediaKind.IMAGE
    elif kind == 'media':
        kind = ProductMediaKind.GENERIC_FILE
    else:
        return JsonResponse({'response': 'error', 'message': 'Error! Invalid file kind `%s`.' % kind}, status=400)
    for file_id in ids:
        if not File.objects.filter(id=file_id).exists():
            return JsonResponse({'response': 'error', 'message': 'Error! Invalid file id `%s`.' % file_id}, status=400)
    added = []
    for file_id in ids:
        if not ProductMedia.objects.filter(product_id=shop_product.product_id, file_id=file_id, kind=kind, shops__in=[shop_id]).exists():
            image = ProductMedia.objects.create(product_id=shop_product.product_id, file_id=file_id, kind=kind)
            image.shops.add(shop_id)
            added.append({'product': image.product_id, 'file': int(file_id), 'kind': kind.value, 'product_media': image.pk})
    return JsonResponse({'response': 'success', 'added': added, 'message': force_text(_('Files added to the product.'))})",'Error! Invalid shop id `%s`.' % shop_id,f"Error! Invalid shop id `{shop_id}`.",1,,,,,,,,,,
shuup,https://github.com/shuup/shuup/tree/master/shuup/admin/modules/products/views/edit_media.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/shuup/shuup/admin/modules/products/views/edit_media.py,ProductMediaBulkAdderView,"def post(self, *args, **kwargs):
    ids = self.request.POST.getlist('file_ids')
    shop_product_id = kwargs.pop('pk')
    kind = self.request.POST.get('kind')
    shop = self.request.shop
    shop_id = self.request.POST.get('shop_id', shop.pk)
    if not ids or not shop_product_id:
        return JsonResponse({'response': 'error', 'message': 'Error! Bad request.'}, status=400)
    if not Shop.objects.filter(pk=shop_id).exists():
        return JsonResponse({'response': 'error', 'message': 'Error! Invalid shop id `%s`.' % shop_id}, status=400)
    shop_product = ShopProduct.objects.filter(pk=shop_product_id, shop_id=shop_id).first()
    if not shop_product:
        return JsonResponse({'response': 'error', 'message': 'Error! Invalid shop product id `%s`.' % shop_product_id}, status=400)
    if kind == 'images':
        kind = ProductMediaKind.IMAGE
    elif kind == 'media':
        kind = ProductMediaKind.GENERIC_FILE
    else:
        return JsonResponse({'response': 'error', 'message': 'Error! Invalid file kind `%s`.' % kind}, status=400)
    for file_id in ids:
        if not File.objects.filter(id=file_id).exists():
            return JsonResponse({'response': 'error', 'message': 'Error! Invalid file id `%s`.' % file_id}, status=400)
    added = []
    for file_id in ids:
        if not ProductMedia.objects.filter(product_id=shop_product.product_id, file_id=file_id, kind=kind, shops__in=[shop_id]).exists():
            image = ProductMedia.objects.create(product_id=shop_product.product_id, file_id=file_id, kind=kind)
            image.shops.add(shop_id)
            added.append({'product': image.product_id, 'file': int(file_id), 'kind': kind.value, 'product_media': image.pk})
    return JsonResponse({'response': 'success', 'added': added, 'message': force_text(_('Files added to the product.'))})",'Error! Invalid shop product id `%s`.' % shop_product_id,f'Error! Invalid shop product id `{shop_product_id}`.',1,,,,,,,,,,
shuup,https://github.com/shuup/shuup/tree/master/shuup/admin/modules/products/views/edit_media.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/shuup/shuup/admin/modules/products/views/edit_media.py,ProductMediaBulkAdderView,"def post(self, *args, **kwargs):
    ids = self.request.POST.getlist('file_ids')
    shop_product_id = kwargs.pop('pk')
    kind = self.request.POST.get('kind')
    shop = self.request.shop
    shop_id = self.request.POST.get('shop_id', shop.pk)
    if not ids or not shop_product_id:
        return JsonResponse({'response': 'error', 'message': 'Error! Bad request.'}, status=400)
    if not Shop.objects.filter(pk=shop_id).exists():
        return JsonResponse({'response': 'error', 'message': 'Error! Invalid shop id `%s`.' % shop_id}, status=400)
    shop_product = ShopProduct.objects.filter(pk=shop_product_id, shop_id=shop_id).first()
    if not shop_product:
        return JsonResponse({'response': 'error', 'message': 'Error! Invalid shop product id `%s`.' % shop_product_id}, status=400)
    if kind == 'images':
        kind = ProductMediaKind.IMAGE
    elif kind == 'media':
        kind = ProductMediaKind.GENERIC_FILE
    else:
        return JsonResponse({'response': 'error', 'message': 'Error! Invalid file kind `%s`.' % kind}, status=400)
    for file_id in ids:
        if not File.objects.filter(id=file_id).exists():
            return JsonResponse({'response': 'error', 'message': 'Error! Invalid file id `%s`.' % file_id}, status=400)
    added = []
    for file_id in ids:
        if not ProductMedia.objects.filter(product_id=shop_product.product_id, file_id=file_id, kind=kind, shops__in=[shop_id]).exists():
            image = ProductMedia.objects.create(product_id=shop_product.product_id, file_id=file_id, kind=kind)
            image.shops.add(shop_id)
            added.append({'product': image.product_id, 'file': int(file_id), 'kind': kind.value, 'product_media': image.pk})
    return JsonResponse({'response': 'success', 'added': added, 'message': force_text(_('Files added to the product.'))})",'Error! Invalid file kind `%s`.' % kind,f"Error! Invalid file kind `{kind}`.",1,,,,,,,,,,
shuup,https://github.com/shuup/shuup/tree/master/shuup/admin/modules/products/views/edit_media.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/shuup/shuup/admin/modules/products/views/edit_media.py,ProductMediaBulkAdderView,"def post(self, *args, **kwargs):
    ids = self.request.POST.getlist('file_ids')
    shop_product_id = kwargs.pop('pk')
    kind = self.request.POST.get('kind')
    shop = self.request.shop
    shop_id = self.request.POST.get('shop_id', shop.pk)
    if not ids or not shop_product_id:
        return JsonResponse({'response': 'error', 'message': 'Error! Bad request.'}, status=400)
    if not Shop.objects.filter(pk=shop_id).exists():
        return JsonResponse({'response': 'error', 'message': 'Error! Invalid shop id `%s`.' % shop_id}, status=400)
    shop_product = ShopProduct.objects.filter(pk=shop_product_id, shop_id=shop_id).first()
    if not shop_product:
        return JsonResponse({'response': 'error', 'message': 'Error! Invalid shop product id `%s`.' % shop_product_id}, status=400)
    if kind == 'images':
        kind = ProductMediaKind.IMAGE
    elif kind == 'media':
        kind = ProductMediaKind.GENERIC_FILE
    else:
        return JsonResponse({'response': 'error', 'message': 'Error! Invalid file kind `%s`.' % kind}, status=400)
    for file_id in ids:
        if not File.objects.filter(id=file_id).exists():
            return JsonResponse({'response': 'error', 'message': 'Error! Invalid file id `%s`.' % file_id}, status=400)
    added = []
    for file_id in ids:
        if not ProductMedia.objects.filter(product_id=shop_product.product_id, file_id=file_id, kind=kind, shops__in=[shop_id]).exists():
            image = ProductMedia.objects.create(product_id=shop_product.product_id, file_id=file_id, kind=kind)
            image.shops.add(shop_id)
            added.append({'product': image.product_id, 'file': int(file_id), 'kind': kind.value, 'product_media': image.pk})
    return JsonResponse({'response': 'success', 'added': added, 'message': force_text(_('Files added to the product.'))})",'Error! Invalid file id `%s`.' % file_id,f"Error! Invalid file id `{file_id}`.",1,,,,,,,,,,
ansible,https://github.com/ansible/ansible/tree/master/test/support/integration/plugins/inventory/foreman.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/ansible/test/support/integration/plugins/inventory/foreman.py,InventoryModule,"def _get_facts_by_id(self, hid):
    url = '%s/api/v2/hosts/%s/facts' % (self.foreman_url, hid)
    return self._get_json(url)","'%s/api/v2/hosts/%s/facts' % (self.foreman_url, hid)",f"{self.foreman_url}/api/v2/hosts/{hid}/facts",1,,,,,,,,,,
clusterfuzz,https://github.com/google/clusterfuzz/tree/master/src/appengine/handlers/jobs.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/clusterfuzz/src/appengine/handlers/jobs.py,DeleteJobHandler,"def post(self):
    """"""Handle a post request.""""""
    key = helpers.get_integer_key(request)
    job = ndb.Key(data_types.Job, key).get()
    if not job:
        raise helpers.EarlyExitException('Job not found.', 400)
    for fuzzer in ndb_utils.get_all_from_model(data_types.Fuzzer):
        if job.name in fuzzer.jobs:
            fuzzer.jobs.remove(job.name)
            fuzzer.put()
    query = data_types.FuzzerJob.query()
    query = query.filter(data_types.FuzzerJob.job == job.name)
    for mapping in ndb_utils.get_all_from_query(query):
        mapping.key.delete()
    job.key.delete()
    helpers.log('Deleted job %s' % job.name, helpers.MODIFY_OPERATION)
    return self.redirect('/jobs')",'Deleted job %s' % job.name,f"Deleted job {job.name}",1,,,,,,,,,,
Transformer-TTS,https://github.com/soobinseo/Transformer-TTS/tree/master//train_transformer.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/Transformer-TTS//train_transformer.py,,"def main():
    dataset = get_dataset()
    global_step = 0
    m = nn.DataParallel(Model().cuda())
    m.train()
    optimizer = t.optim.Adam(m.parameters(), lr=hp.lr)
    pos_weight = t.FloatTensor([5.0]).cuda()
    writer = SummaryWriter()
    for epoch in range(hp.epochs):
        dataloader = DataLoader(dataset, batch_size=hp.batch_size, shuffle=True, collate_fn=collate_fn_transformer, drop_last=True, num_workers=16)
        pbar = tqdm(dataloader)
        for (i, data) in enumerate(pbar):
            pbar.set_description('Processing at epoch %d' % epoch)
            global_step += 1
            if global_step < 400000:
                adjust_learning_rate(optimizer, global_step)
            (character, mel, mel_input, pos_text, pos_mel, _) = data
            stop_tokens = t.abs(pos_mel.ne(0).type(t.float) - 1)
            character = character.cuda()
            mel = mel.cuda()
            mel_input = mel_input.cuda()
            pos_text = pos_text.cuda()
            pos_mel = pos_mel.cuda()
            (mel_pred, postnet_pred, attn_probs, stop_preds, attns_enc, attns_dec) = m.forward(character, mel_input, pos_text, pos_mel)
            mel_loss = nn.L1Loss()(mel_pred, mel)
            post_mel_loss = nn.L1Loss()(postnet_pred, mel)
            loss = mel_loss + post_mel_loss
            writer.add_scalars('training_loss', {'mel_loss': mel_loss, 'post_mel_loss': post_mel_loss}, global_step)
            writer.add_scalars('alphas', {'encoder_alpha': m.module.encoder.alpha.data, 'decoder_alpha': m.module.decoder.alpha.data}, global_step)
            if global_step % hp.image_step == 1:
                for (i, prob) in enumerate(attn_probs):
                    num_h = prob.size(0)
                    for j in range(4):
                        x = vutils.make_grid(prob[j * 16] * 255)
                        writer.add_image('Attention_%d_0' % global_step, x, i * 4 + j)
                for (i, prob) in enumerate(attns_enc):
                    num_h = prob.size(0)
                    for j in range(4):
                        x = vutils.make_grid(prob[j * 16] * 255)
                        writer.add_image('Attention_enc_%d_0' % global_step, x, i * 4 + j)
                for (i, prob) in enumerate(attns_dec):
                    num_h = prob.size(0)
                    for j in range(4):
                        x = vutils.make_grid(prob[j * 16] * 255)
                        writer.add_image('Attention_dec_%d_0' % global_step, x, i * 4 + j)
            optimizer.zero_grad()
            loss.backward()
            nn.utils.clip_grad_norm_(m.parameters(), 1.0)
            optimizer.step()
            if global_step % hp.save_step == 0:
                t.save({'model': m.state_dict(), 'optimizer': optimizer.state_dict()}, os.path.join(hp.checkpoint_path, 'checkpoint_transformer_%d.pth.tar' % global_step))",'Processing at epoch %d' % epoch,f'Processing at epoch {epoch}',1,,,,,,,,,,
Transformer-TTS,https://github.com/soobinseo/Transformer-TTS/tree/master//train_transformer.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/Transformer-TTS//train_transformer.py,,"def main():
    dataset = get_dataset()
    global_step = 0
    m = nn.DataParallel(Model().cuda())
    m.train()
    optimizer = t.optim.Adam(m.parameters(), lr=hp.lr)
    pos_weight = t.FloatTensor([5.0]).cuda()
    writer = SummaryWriter()
    for epoch in range(hp.epochs):
        dataloader = DataLoader(dataset, batch_size=hp.batch_size, shuffle=True, collate_fn=collate_fn_transformer, drop_last=True, num_workers=16)
        pbar = tqdm(dataloader)
        for (i, data) in enumerate(pbar):
            pbar.set_description('Processing at epoch %d' % epoch)
            global_step += 1
            if global_step < 400000:
                adjust_learning_rate(optimizer, global_step)
            (character, mel, mel_input, pos_text, pos_mel, _) = data
            stop_tokens = t.abs(pos_mel.ne(0).type(t.float) - 1)
            character = character.cuda()
            mel = mel.cuda()
            mel_input = mel_input.cuda()
            pos_text = pos_text.cuda()
            pos_mel = pos_mel.cuda()
            (mel_pred, postnet_pred, attn_probs, stop_preds, attns_enc, attns_dec) = m.forward(character, mel_input, pos_text, pos_mel)
            mel_loss = nn.L1Loss()(mel_pred, mel)
            post_mel_loss = nn.L1Loss()(postnet_pred, mel)
            loss = mel_loss + post_mel_loss
            writer.add_scalars('training_loss', {'mel_loss': mel_loss, 'post_mel_loss': post_mel_loss}, global_step)
            writer.add_scalars('alphas', {'encoder_alpha': m.module.encoder.alpha.data, 'decoder_alpha': m.module.decoder.alpha.data}, global_step)
            if global_step % hp.image_step == 1:
                for (i, prob) in enumerate(attn_probs):
                    num_h = prob.size(0)
                    for j in range(4):
                        x = vutils.make_grid(prob[j * 16] * 255)
                        writer.add_image('Attention_%d_0' % global_step, x, i * 4 + j)
                for (i, prob) in enumerate(attns_enc):
                    num_h = prob.size(0)
                    for j in range(4):
                        x = vutils.make_grid(prob[j * 16] * 255)
                        writer.add_image('Attention_enc_%d_0' % global_step, x, i * 4 + j)
                for (i, prob) in enumerate(attns_dec):
                    num_h = prob.size(0)
                    for j in range(4):
                        x = vutils.make_grid(prob[j * 16] * 255)
                        writer.add_image('Attention_dec_%d_0' % global_step, x, i * 4 + j)
            optimizer.zero_grad()
            loss.backward()
            nn.utils.clip_grad_norm_(m.parameters(), 1.0)
            optimizer.step()
            if global_step % hp.save_step == 0:
                t.save({'model': m.state_dict(), 'optimizer': optimizer.state_dict()}, os.path.join(hp.checkpoint_path, 'checkpoint_transformer_%d.pth.tar' % global_step))",'checkpoint_transformer_%d.pth.tar' % global_step,f'checkpoint_transformer_{global_step}.pth.tar',1,,,,,,,,,,
Transformer-TTS,https://github.com/soobinseo/Transformer-TTS/tree/master//train_transformer.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/Transformer-TTS//train_transformer.py,,"def main():
    dataset = get_dataset()
    global_step = 0
    m = nn.DataParallel(Model().cuda())
    m.train()
    optimizer = t.optim.Adam(m.parameters(), lr=hp.lr)
    pos_weight = t.FloatTensor([5.0]).cuda()
    writer = SummaryWriter()
    for epoch in range(hp.epochs):
        dataloader = DataLoader(dataset, batch_size=hp.batch_size, shuffle=True, collate_fn=collate_fn_transformer, drop_last=True, num_workers=16)
        pbar = tqdm(dataloader)
        for (i, data) in enumerate(pbar):
            pbar.set_description('Processing at epoch %d' % epoch)
            global_step += 1
            if global_step < 400000:
                adjust_learning_rate(optimizer, global_step)
            (character, mel, mel_input, pos_text, pos_mel, _) = data
            stop_tokens = t.abs(pos_mel.ne(0).type(t.float) - 1)
            character = character.cuda()
            mel = mel.cuda()
            mel_input = mel_input.cuda()
            pos_text = pos_text.cuda()
            pos_mel = pos_mel.cuda()
            (mel_pred, postnet_pred, attn_probs, stop_preds, attns_enc, attns_dec) = m.forward(character, mel_input, pos_text, pos_mel)
            mel_loss = nn.L1Loss()(mel_pred, mel)
            post_mel_loss = nn.L1Loss()(postnet_pred, mel)
            loss = mel_loss + post_mel_loss
            writer.add_scalars('training_loss', {'mel_loss': mel_loss, 'post_mel_loss': post_mel_loss}, global_step)
            writer.add_scalars('alphas', {'encoder_alpha': m.module.encoder.alpha.data, 'decoder_alpha': m.module.decoder.alpha.data}, global_step)
            if global_step % hp.image_step == 1:
                for (i, prob) in enumerate(attn_probs):
                    num_h = prob.size(0)
                    for j in range(4):
                        x = vutils.make_grid(prob[j * 16] * 255)
                        writer.add_image('Attention_%d_0' % global_step, x, i * 4 + j)
                for (i, prob) in enumerate(attns_enc):
                    num_h = prob.size(0)
                    for j in range(4):
                        x = vutils.make_grid(prob[j * 16] * 255)
                        writer.add_image('Attention_enc_%d_0' % global_step, x, i * 4 + j)
                for (i, prob) in enumerate(attns_dec):
                    num_h = prob.size(0)
                    for j in range(4):
                        x = vutils.make_grid(prob[j * 16] * 255)
                        writer.add_image('Attention_dec_%d_0' % global_step, x, i * 4 + j)
            optimizer.zero_grad()
            loss.backward()
            nn.utils.clip_grad_norm_(m.parameters(), 1.0)
            optimizer.step()
            if global_step % hp.save_step == 0:
                t.save({'model': m.state_dict(), 'optimizer': optimizer.state_dict()}, os.path.join(hp.checkpoint_path, 'checkpoint_transformer_%d.pth.tar' % global_step))",'Attention_%d_0' % global_step,f'Attention_{global_step}_0',1,,,,,,,,,,
Transformer-TTS,https://github.com/soobinseo/Transformer-TTS/tree/master//train_transformer.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/Transformer-TTS//train_transformer.py,,"def main():
    dataset = get_dataset()
    global_step = 0
    m = nn.DataParallel(Model().cuda())
    m.train()
    optimizer = t.optim.Adam(m.parameters(), lr=hp.lr)
    pos_weight = t.FloatTensor([5.0]).cuda()
    writer = SummaryWriter()
    for epoch in range(hp.epochs):
        dataloader = DataLoader(dataset, batch_size=hp.batch_size, shuffle=True, collate_fn=collate_fn_transformer, drop_last=True, num_workers=16)
        pbar = tqdm(dataloader)
        for (i, data) in enumerate(pbar):
            pbar.set_description('Processing at epoch %d' % epoch)
            global_step += 1
            if global_step < 400000:
                adjust_learning_rate(optimizer, global_step)
            (character, mel, mel_input, pos_text, pos_mel, _) = data
            stop_tokens = t.abs(pos_mel.ne(0).type(t.float) - 1)
            character = character.cuda()
            mel = mel.cuda()
            mel_input = mel_input.cuda()
            pos_text = pos_text.cuda()
            pos_mel = pos_mel.cuda()
            (mel_pred, postnet_pred, attn_probs, stop_preds, attns_enc, attns_dec) = m.forward(character, mel_input, pos_text, pos_mel)
            mel_loss = nn.L1Loss()(mel_pred, mel)
            post_mel_loss = nn.L1Loss()(postnet_pred, mel)
            loss = mel_loss + post_mel_loss
            writer.add_scalars('training_loss', {'mel_loss': mel_loss, 'post_mel_loss': post_mel_loss}, global_step)
            writer.add_scalars('alphas', {'encoder_alpha': m.module.encoder.alpha.data, 'decoder_alpha': m.module.decoder.alpha.data}, global_step)
            if global_step % hp.image_step == 1:
                for (i, prob) in enumerate(attn_probs):
                    num_h = prob.size(0)
                    for j in range(4):
                        x = vutils.make_grid(prob[j * 16] * 255)
                        writer.add_image('Attention_%d_0' % global_step, x, i * 4 + j)
                for (i, prob) in enumerate(attns_enc):
                    num_h = prob.size(0)
                    for j in range(4):
                        x = vutils.make_grid(prob[j * 16] * 255)
                        writer.add_image('Attention_enc_%d_0' % global_step, x, i * 4 + j)
                for (i, prob) in enumerate(attns_dec):
                    num_h = prob.size(0)
                    for j in range(4):
                        x = vutils.make_grid(prob[j * 16] * 255)
                        writer.add_image('Attention_dec_%d_0' % global_step, x, i * 4 + j)
            optimizer.zero_grad()
            loss.backward()
            nn.utils.clip_grad_norm_(m.parameters(), 1.0)
            optimizer.step()
            if global_step % hp.save_step == 0:
                t.save({'model': m.state_dict(), 'optimizer': optimizer.state_dict()}, os.path.join(hp.checkpoint_path, 'checkpoint_transformer_%d.pth.tar' % global_step))",'Attention_enc_%d_0' % global_step,f'Attention_enc_{global_step}_0',1,,,,,,,,,,
Transformer-TTS,https://github.com/soobinseo/Transformer-TTS/tree/master//train_transformer.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/Transformer-TTS//train_transformer.py,,"def main():
    dataset = get_dataset()
    global_step = 0
    m = nn.DataParallel(Model().cuda())
    m.train()
    optimizer = t.optim.Adam(m.parameters(), lr=hp.lr)
    pos_weight = t.FloatTensor([5.0]).cuda()
    writer = SummaryWriter()
    for epoch in range(hp.epochs):
        dataloader = DataLoader(dataset, batch_size=hp.batch_size, shuffle=True, collate_fn=collate_fn_transformer, drop_last=True, num_workers=16)
        pbar = tqdm(dataloader)
        for (i, data) in enumerate(pbar):
            pbar.set_description('Processing at epoch %d' % epoch)
            global_step += 1
            if global_step < 400000:
                adjust_learning_rate(optimizer, global_step)
            (character, mel, mel_input, pos_text, pos_mel, _) = data
            stop_tokens = t.abs(pos_mel.ne(0).type(t.float) - 1)
            character = character.cuda()
            mel = mel.cuda()
            mel_input = mel_input.cuda()
            pos_text = pos_text.cuda()
            pos_mel = pos_mel.cuda()
            (mel_pred, postnet_pred, attn_probs, stop_preds, attns_enc, attns_dec) = m.forward(character, mel_input, pos_text, pos_mel)
            mel_loss = nn.L1Loss()(mel_pred, mel)
            post_mel_loss = nn.L1Loss()(postnet_pred, mel)
            loss = mel_loss + post_mel_loss
            writer.add_scalars('training_loss', {'mel_loss': mel_loss, 'post_mel_loss': post_mel_loss}, global_step)
            writer.add_scalars('alphas', {'encoder_alpha': m.module.encoder.alpha.data, 'decoder_alpha': m.module.decoder.alpha.data}, global_step)
            if global_step % hp.image_step == 1:
                for (i, prob) in enumerate(attn_probs):
                    num_h = prob.size(0)
                    for j in range(4):
                        x = vutils.make_grid(prob[j * 16] * 255)
                        writer.add_image('Attention_%d_0' % global_step, x, i * 4 + j)
                for (i, prob) in enumerate(attns_enc):
                    num_h = prob.size(0)
                    for j in range(4):
                        x = vutils.make_grid(prob[j * 16] * 255)
                        writer.add_image('Attention_enc_%d_0' % global_step, x, i * 4 + j)
                for (i, prob) in enumerate(attns_dec):
                    num_h = prob.size(0)
                    for j in range(4):
                        x = vutils.make_grid(prob[j * 16] * 255)
                        writer.add_image('Attention_dec_%d_0' % global_step, x, i * 4 + j)
            optimizer.zero_grad()
            loss.backward()
            nn.utils.clip_grad_norm_(m.parameters(), 1.0)
            optimizer.step()
            if global_step % hp.save_step == 0:
                t.save({'model': m.state_dict(), 'optimizer': optimizer.state_dict()}, os.path.join(hp.checkpoint_path, 'checkpoint_transformer_%d.pth.tar' % global_step))",'Attention_dec_%d_0' % global_step,f'Attention_dec_{global_step}_0',1,,,,,,,,,,
PyDrive,https://github.com/googlearchive/PyDrive/tree/master/pydrive/auth.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/PyDrive/pydrive/auth.py,GoogleAuth,"def Refresh(self):
    """"""Refreshes the access_token.

    :raises: RefreshError
    """"""
    if self.credentials is None:
        raise RefreshError('No credential to refresh.')
    if self.credentials.refresh_token is None:
        raise RefreshError('No refresh_token found.Please set access_type of OAuth to offline.')
    if self.http is None:
        self.http = httplib2.Http(timeout=self.http_timeout)
    try:
        self.credentials.refresh(self.http)
    except AccessTokenRefreshError as error:
        raise RefreshError('Access token refresh failed: %s' % error)",'Access token refresh failed: %s' % error,f"Access token refresh failed: {error}",1,,,,,,,,,,
oppia,https://github.com/oppia/oppia/tree/master/core/controllers/blog_homepage_test.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/oppia/core/controllers/blog_homepage_test.py,BlogPostDataHandlerTest,"def test_raise_exception_if_blog_post_does_not_exists(self) -> None:
    self.login(self.user_email)
    blog_post = blog_services.get_blog_post_by_id(self.blog_post_one.id)
    self.get_json('%s/%s' % (feconf.BLOG_HOMEPAGE_DATA_URL, blog_post.url_fragment))
    blog_services.delete_blog_post(blog_post.id)
    self.get_json('%s/%s' % (feconf.BLOG_HOMEPAGE_DATA_URL, blog_post.url_fragment), expected_status_int=404)","'%s/%s' % (feconf.BLOG_HOMEPAGE_DATA_URL, blog_post.url_fragment)",f"{feconf.BLOG_HOMEPAGE_DATA_URL}/{blog_post.url_fragment}",1,,,,,,,,,,
oppia,https://github.com/oppia/oppia/tree/master/core/controllers/blog_homepage_test.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/oppia/core/controllers/blog_homepage_test.py,BlogPostDataHandlerTest,"def test_raise_exception_if_blog_post_does_not_exists(self) -> None:
    self.login(self.user_email)
    blog_post = blog_services.get_blog_post_by_id(self.blog_post_one.id)
    self.get_json('%s/%s' % (feconf.BLOG_HOMEPAGE_DATA_URL, blog_post.url_fragment))
    blog_services.delete_blog_post(blog_post.id)
    self.get_json('%s/%s' % (feconf.BLOG_HOMEPAGE_DATA_URL, blog_post.url_fragment), expected_status_int=404)","'%s/%s' % (feconf.BLOG_HOMEPAGE_DATA_URL, blog_post.url_fragment)",f"{feconf.BLOG_HOMEPAGE_DATA_URL}/{blog_post.url_fragment}",1,,,,,,,,,,
trackma,https://github.com/z411/trackma/tree/master/trackma/ui/qt/accounts.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/trackma/trackma/ui/qt/accounts.py,AccountAddDialog,"def s_request_pin(self):
    auth_url = self.adding_api[3]
    if self.adding_api[2] == utils.LOGIN_OAUTH_PKCE:
        self.adding_extra = {'code_verifier': utils.oauth_generate_pkce()}
        auth_url = auth_url % self.adding_extra['code_verifier']
    self.adding_allow = True
    QtGui.QDesktopServices.openUrl(QtCore.QUrl(auth_url))",auth_url % self.adding_extra['code_verifier'],f"{auth_url}{self.adding_extra['code_verifier']}",1,,,,,,,,,,
pychess,https://github.com/pychess/pychess/tree/master/lib/pychess/Utils/GameModel.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pychess/lib/pychess/Utils/GameModel.py,GameModel,"def acceptReceived(self, player, offer):
    log.debug('GameModel.acceptReceived: accepter=%s %s' % (repr(player), offer))
    if player == self.players[WHITE]:
        opPlayer = self.players[BLACK]
    else:
        opPlayer = self.players[WHITE]
    if offer in self.offers and self.offers[offer] == opPlayer:
        if offer.type == DRAW_OFFER:
            self.end(DRAW, DRAW_AGREE)
        elif offer.type == TAKEBACK_OFFER:
            log.debug('GameModel.acceptReceived: undoMoves(%s)' % offer.param)
            self.undoMoves(offer.param)
        elif offer.type == ADJOURN_OFFER:
            self.end(ADJOURNED, ADJOURNED_AGREEMENT)
        elif offer.type == ABORT_OFFER:
            self.end(ABORTED, ABORTED_AGREEMENT)
        elif offer.type == PAUSE_OFFER:
            self.pause()
        elif offer.type == RESUME_OFFER:
            self.resume()
        del self.offers[offer]
    else:
        player.offerError(offer, ACTION_ERROR_NONE_TO_ACCEPT)","'GameModel.acceptReceived: accepter=%s %s' % (repr(player), offer)",f"GameModel.acceptReceived: accepter={repr(player)} {offer}",1,,,,,,,,,,
pychess,https://github.com/pychess/pychess/tree/master/lib/pychess/Utils/GameModel.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pychess/lib/pychess/Utils/GameModel.py,GameModel,"def acceptReceived(self, player, offer):
    log.debug('GameModel.acceptReceived: accepter=%s %s' % (repr(player), offer))
    if player == self.players[WHITE]:
        opPlayer = self.players[BLACK]
    else:
        opPlayer = self.players[WHITE]
    if offer in self.offers and self.offers[offer] == opPlayer:
        if offer.type == DRAW_OFFER:
            self.end(DRAW, DRAW_AGREE)
        elif offer.type == TAKEBACK_OFFER:
            log.debug('GameModel.acceptReceived: undoMoves(%s)' % offer.param)
            self.undoMoves(offer.param)
        elif offer.type == ADJOURN_OFFER:
            self.end(ADJOURNED, ADJOURNED_AGREEMENT)
        elif offer.type == ABORT_OFFER:
            self.end(ABORTED, ABORTED_AGREEMENT)
        elif offer.type == PAUSE_OFFER:
            self.pause()
        elif offer.type == RESUME_OFFER:
            self.resume()
        del self.offers[offer]
    else:
        player.offerError(offer, ACTION_ERROR_NONE_TO_ACCEPT)",'GameModel.acceptReceived: undoMoves(%s)' % offer.param,f'GameModel.acceptReceived: undoMoves({offer.param})',1,,,,,,,,,,
barman,https://github.com/EnterpriseDB/barman/tree/master/barman/server.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/barman/barman/server.py,Server,"def check_backup_validity(self, check_strategy):
    """"""
        Check if backup validity requirements are satisfied

        :param CheckStrategy check_strategy: the strategy for the management
             of the results of the various checks
        """"""
    check_strategy.init_check('backup maximum age')
    if self.config.last_backup_maximum_age is not None:
        backup_age = self.backup_manager.validate_last_backup_maximum_age(self.config.last_backup_maximum_age)
        check_strategy.result(self.config.name, backup_age[0], hint='interval provided: %s, latest backup age: %s' % (human_readable_timedelta(self.config.last_backup_maximum_age), backup_age[1]))
    else:
        check_strategy.result(self.config.name, True, hint='no last_backup_maximum_age provided')
    check_strategy.init_check('backup minimum size')
    if self.config.last_backup_minimum_size is not None:
        backup_size = self.backup_manager.validate_last_backup_min_size(self.config.last_backup_minimum_size)
        gtlt = '>' if backup_size[0] else '<'
        check_strategy.result(self.config.name, backup_size[0], hint='last backup size %s %s %s minimum' % (pretty_size(backup_size[1]), gtlt, pretty_size(self.config.last_backup_minimum_size)), perfdata=backup_size[1])
    else:
        backup_size = self.backup_manager.validate_last_backup_min_size(0)
        check_strategy.result(self.config.name, True, hint=pretty_size(backup_size[1]), perfdata=backup_size[1])","'interval provided: %s, latest backup age: %s' % (human_readable_timedelta(self.config.last_backup_maximum_age), backup_age[1])","f""interval provided: {human_readable_timedelta(self.config.last_backup_maximum_age)}, latest backup age: {backup_age[1]}""",1,,,,,,,,,,
barman,https://github.com/EnterpriseDB/barman/tree/master/barman/server.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/barman/barman/server.py,Server,"def check_backup_validity(self, check_strategy):
    """"""
        Check if backup validity requirements are satisfied

        :param CheckStrategy check_strategy: the strategy for the management
             of the results of the various checks
        """"""
    check_strategy.init_check('backup maximum age')
    if self.config.last_backup_maximum_age is not None:
        backup_age = self.backup_manager.validate_last_backup_maximum_age(self.config.last_backup_maximum_age)
        check_strategy.result(self.config.name, backup_age[0], hint='interval provided: %s, latest backup age: %s' % (human_readable_timedelta(self.config.last_backup_maximum_age), backup_age[1]))
    else:
        check_strategy.result(self.config.name, True, hint='no last_backup_maximum_age provided')
    check_strategy.init_check('backup minimum size')
    if self.config.last_backup_minimum_size is not None:
        backup_size = self.backup_manager.validate_last_backup_min_size(self.config.last_backup_minimum_size)
        gtlt = '>' if backup_size[0] else '<'
        check_strategy.result(self.config.name, backup_size[0], hint='last backup size %s %s %s minimum' % (pretty_size(backup_size[1]), gtlt, pretty_size(self.config.last_backup_minimum_size)), perfdata=backup_size[1])
    else:
        backup_size = self.backup_manager.validate_last_backup_min_size(0)
        check_strategy.result(self.config.name, True, hint=pretty_size(backup_size[1]), perfdata=backup_size[1])","'last backup size %s %s %s minimum' % (pretty_size(backup_size[1]), gtlt, pretty_size(self.config.last_backup_minimum_size))",f"last backup size {pretty_size(backup_size[1])} {gtlt} {pretty_size(self.config.last_backup_minimum_size)} minimum",1,,,,,,,,,,
bt-speaker,https://github.com/lukasjapan/bt-speaker/tree/master/bt_manager/audio.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/bt-speaker/bt_manager/audio.py,SBCAudioSink,"def _notify_media_transport_available(self, path, transport):
    """"""
        Called by the endpoint when a new media transport is
        available
        """"""
    print('Transport available! transport=%s' % transport)
    self.source = BTMediaTransport(transport)
    self.state = 'idle'
    self.source.add_signal_receiver(self._property_change_event_handler, BTAudioSource.SIGNAL_PROPERTY_CHANGED, transport)",'Transport available! transport=%s' % transport,f'Transport available! transport={transport}',1,,,,,,,,,,
keystone,https://github.com/openstack/keystone/tree/master/keystone/tests/unit/test_v3_resource.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/keystone/keystone/tests/unit/test_v3_resource.py,ResourceTestCase,"def test_get_project_with_subtree_as_list_and_subtree_as_ids(self):
    """"""Attempt to get a project subtree as both a list and as IDs.

        This uses ``GET /projects/{project_id}?subtree_as_list&subtree_as_ids``
        which should fail with a bad request due to the conflicting query
        strings.

        """"""
    projects = self._create_projects_hierarchy(hierarchy_size=2)
    self.get('/projects/%(project_id)s?subtree_as_list&subtree_as_ids' % {'project_id': projects[1]['project']['id']}, expected_status=http.client.BAD_REQUEST)",'/projects/%(project_id)s?subtree_as_list&subtree_as_ids' % {'project_id': projects[1]['project']['id']},f"/projects/{projects[1]['project']['id']}?subtree_as_list&subtree_as_ids",1,,,,,,,,,,
aws-cli,https://github.com/aws/aws-cli/tree/master/awscli/customizations/cloudtrail/validation.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/aws-cli/awscli/customizations/cloudtrail/validation.py,CloudTrailValidateLogs,"def _write_summary_text(self):
    if not self._is_last_status_double_space:
        sys.stdout.write('\n')
    sys.stdout.write('Results requested for %s to %s\n' % (format_display_date(self.start_time), format_display_date(self.end_time)))
    if not self._valid_digests and (not self._invalid_digests):
        sys.stdout.write('No digests found\n')
        return
    if not self._found_start_time or not self._found_end_time:
        sys.stdout.write('No valid digests found in range\n')
    else:
        sys.stdout.write('Results found for %s to %s:\n' % (format_display_date(self._found_start_time), format_display_date(self._found_end_time)))
    self._write_ratio(self._valid_digests, self._invalid_digests, 'digest')
    self._write_ratio(self._valid_logs, self._invalid_logs, 'log')
    sys.stdout.write('\n')","'Results requested for %s to %s\n' % (format_display_date(self.start_time), format_display_date(self.end_time))",f'Results requested for {format_display_date(self.start_time)} to {format_display_date(self.end_time)}\n',1,,,,,,,,,,
aws-cli,https://github.com/aws/aws-cli/tree/master/awscli/customizations/cloudtrail/validation.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/aws-cli/awscli/customizations/cloudtrail/validation.py,CloudTrailValidateLogs,"def _write_summary_text(self):
    if not self._is_last_status_double_space:
        sys.stdout.write('\n')
    sys.stdout.write('Results requested for %s to %s\n' % (format_display_date(self.start_time), format_display_date(self.end_time)))
    if not self._valid_digests and (not self._invalid_digests):
        sys.stdout.write('No digests found\n')
        return
    if not self._found_start_time or not self._found_end_time:
        sys.stdout.write('No valid digests found in range\n')
    else:
        sys.stdout.write('Results found for %s to %s:\n' % (format_display_date(self._found_start_time), format_display_date(self._found_end_time)))
    self._write_ratio(self._valid_digests, self._invalid_digests, 'digest')
    self._write_ratio(self._valid_logs, self._invalid_logs, 'log')
    sys.stdout.write('\n')","'Results found for %s to %s:\n' % (format_display_date(self._found_start_time), format_display_date(self._found_end_time))",f"Results found for {format_display_date(self._found_start_time)} to {format_display_date(self._found_end_time)}:\n",1,,,,,,,,,,
synapse,https://github.com/matrix-org/synapse/tree/master/tests/rest/admin/test_device.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/synapse/tests/rest/admin/test_device.py,DeviceRestTestCase,"def test_user_is_not_local(self, method: str) -> None:
    """"""
        Tests that a lookup for a user that is not a local returns a 400
        """"""
    url = '/_synapse/admin/v2/users/@unknown_person:unknown_domain/devices/%s' % self.other_user_device_id
    channel = self.make_request(method, url, access_token=self.admin_user_tok)
    self.assertEqual(400, channel.code, msg=channel.json_body)
    self.assertEqual('Can only lookup local users', channel.json_body['error'])",'/_synapse/admin/v2/users/@unknown_person:unknown_domain/devices/%s' % self.other_user_device_id,f"/_synapse/admin/v2/users/@unknown_person:unknown_domain/devices/{self.other_user_device_id}",1,,,,,,,,,,
aliyun-openapi-python-sdk,https://github.com/aliyun/aliyun-openapi-python-sdk/tree/master/aliyun-python-sdk-core-v3/aliyunsdkcore/acs_exception/exceptions.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/aliyun-openapi-python-sdk/aliyun-python-sdk-core-v3/aliyunsdkcore/acs_exception/exceptions.py,ServerException,"def __str__(self):
    return 'HTTP Status: %s Error:%s %s RequestID: %s' % (str(self.http_status), self.error_code, self.message, self.request_id)","'HTTP Status: %s Error:%s %s RequestID: %s' % (str(self.http_status), self.error_code, self.message, self.request_id)",f'HTTP Status: {str(self.http_status)} Error:{self.error_code} {self.message} RequestID: {self.request_id}',1,,,,,,,,,,
neutron,https://github.com/openstack/neutron/tree/master/neutron/tests/unit/common/ovn/test_utils.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/neutron/neutron/tests/unit/common/ovn/test_utils.py,TestOvsdbClientCommand,"def test_run_northbound_with_ssl(self):
    private_key = 'north_pk'
    certificate = 'north_cert'
    ca_auth = 'north_ca_auth'
    ovn_conf.cfg.CONF.set_default('ovn_nb_private_key', private_key, group='ovn')
    ovn_conf.cfg.CONF.set_default('ovn_nb_certificate', certificate, group='ovn')
    ovn_conf.cfg.CONF.set_default('ovn_nb_ca_cert', ca_auth, group='ovn')
    expected = 'ovsdb-client %s %s --timeout 180 -p %s -c %s -C %s \'[""OVN_Northbound"", ""foo""]\'' % (self.OvsdbClientTestCommand.COMMAND, self.nb_connection, private_key, certificate, ca_auth)
    self.OvsdbClientTestCommand.run(['OVN_Northbound', 'foo'])
    self.assert_exec_call(expected)","'ovsdb-client %s %s --timeout 180 -p %s -c %s -C %s \'[""OVN_Northbound"", ""foo""]\'' % (self.OvsdbClientTestCommand.COMMAND, self.nb_connection, private_key, certificate, ca_auth)","f'ovsdb-client {self.OvsdbClientTestCommand.COMMAND} {self.nb_connection} --timeout 180 -p {private_key} -c {certificate} -C {ca_auth} \'[""OVN_Northbound"", ""foo""]\''",1,,,,,,,,,,
cloud-custodian,https://github.com/cloud-custodian/cloud-custodian/tree/master/tests/test_policy.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/cloud-custodian/tests/test_policy.py,PolicyMetaLint,"def test_deprecation_dates(self):

    def check_deprecations(source):
        issues = set()
        for dep in getattr(source, 'deprecations', ()):
            when = dep.removed_after
            if when is not None:
                name = f'{source.__module__}.{source.__name__}'
                if not isinstance(when, str):
                    issues.add(f'{name}: ""{dep}"", removed_after attribute must be a string')
                    continue
                try:
                    datetime.strptime(when, '%Y-%m-%d')
                except ValueError:
                    issues.add(f""""""{name}: ""{dep}"", removed_after must be a valid date in the format 'YYYY-MM-DD', got '{when}'"""""")
        return issues
    issues = check_deprecations(Policy)
    for (name, cloud) in clouds.items():
        for (resource_name, resource) in cloud.resources.items():
            issues = issues.union(check_deprecations(resource))
            for (fname, f) in resource.filter_registry.items():
                if fname in ('and', 'or', 'not'):
                    continue
                issues = issues.union(check_deprecations(f))
            for (aname, a) in resource.action_registry.items():
                issues = issues.union(check_deprecations(a))
    for (name, mode) in execution.items():
        issues = issues.union(check_deprecations(mode))
    if issues:
        self.fail('Deprecation validation issues with \n\t%s' % '\n\t'.join(sorted(issues)))",'Deprecation validation issues with \n\t%s' % '\n\t'.join(sorted(issues)),f"Deprecation validation issues with \n\t{'\n\t'.join(sorted(issues))}",1,,,,,,,,,,
numpy,https://github.com/numpy/numpy/tree/master/numpy/distutils/command/install.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/numpy/numpy/distutils/command/install.py,install,"def run(self):
    if not have_setuptools:
        r = old_install.run(self)
    else:
        r = self.setuptools_run()
    if self.record:
        with open(self.record, 'r') as f:
            lines = []
            need_rewrite = False
            for l in f:
                l = l.rstrip()
                if ' ' in l:
                    need_rewrite = True
                    l = '""%s""' % l
                lines.append(l)
        if need_rewrite:
            self.execute(write_file, (self.record, lines), ""re-writing list of installed files to '%s'"" % self.record)
    return r","""re-writing list of installed files to '%s'"" % self.record",f"re-writing list of installed files to '{self.record}'",1,,,,,,,,,,
numpy,https://github.com/numpy/numpy/tree/master/numpy/distutils/command/install.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/numpy/numpy/distutils/command/install.py,install,"def run(self):
    if not have_setuptools:
        r = old_install.run(self)
    else:
        r = self.setuptools_run()
    if self.record:
        with open(self.record, 'r') as f:
            lines = []
            need_rewrite = False
            for l in f:
                l = l.rstrip()
                if ' ' in l:
                    need_rewrite = True
                    l = '""%s""' % l
                lines.append(l)
        if need_rewrite:
            self.execute(write_file, (self.record, lines), ""re-writing list of installed files to '%s'"" % self.record)
    return r",'"%s"' % l,f'"{l}"',1,,,,,,,,,,
RedditDownloader,https://github.com/shadowmoose/RedditDownloader/tree/master/redditdownloader/tools/win_file_fixer.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/RedditDownloader/redditdownloader/tools/win_file_fixer.py,,"if __name__ == '__main__':
    if os.name != 'nt':
        print('This is only for Windows, as it is the only platform to experience the bug this fixes.')
        import sys
        sys.exit(1)
    print('\nThis is a mini program to (attempt to) repair buggy Windows directories.')
    print('It scans all the subdirectories in the directory you specify,\nincluding the selected directory, and attempts to rename them to valid Windows names.')
    print(""This should ONLY be run if you're stuck with some directories that can't be removed or renamed."")
    print('\nAdditionally, this only works on Windows platforms, and has only been tested on Win10.')
    print(""\tIf you're having issues with directories on other Operating Systems, it's not a bug this can fix."")
    print()
    if 'y' in input('Are you sure you want to run this? (y/n): ').lower():
        targ = input('Enter the EXACT PATH to the base directory you want scanned: ')
        targ = os.path.abspath(targ)
        if 'y' in input('Is the path ""%s"" correct? (y/n): ' % targ).lower():
            repair_subdirs(targ)
        else:
            print('Aborted run.')
        print('Finished.')
    else:
        print('Not running.')",'Is the path "%s" correct? (y/n): ' % targ,f'Is the path "{targ}" correct? (y/n): ',1,,,,,,,,,,
not-youtube-dl,https://github.com/scastillo/not-youtube-dl/tree/master/youtube_dl/extractor/once.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/not-youtube-dl/youtube_dl/extractor/once.py,OnceIE,"def _extract_once_formats(self, url, http_formats_preference=None):
    (domain_id, application_id, media_item_id) = re.match(OnceIE._VALID_URL, url).groups()
    formats = self._extract_m3u8_formats(self.ADAPTIVE_URL_TEMPLATE % (domain_id, application_id, media_item_id), media_item_id, 'mp4', m3u8_id='hls', fatal=False)
    progressive_formats = []
    for adaptive_format in formats:
        adaptive_format['url'] = re.sub('\\badsegmentlength=\\d+', 'adsegmentlength=0', adaptive_format['url'])
        rendition_id = self._search_regex('/now/media/playlist/[^/]+/[^/]+/([^/]+)', adaptive_format['url'], 'redition id', default=None)
        if rendition_id:
            progressive_format = adaptive_format.copy()
            progressive_format.update({'url': self.PROGRESSIVE_URL_TEMPLATE % (domain_id, application_id, rendition_id, media_item_id), 'format_id': adaptive_format['format_id'].replace('hls', 'http'), 'protocol': 'http', 'preference': http_formats_preference})
            progressive_formats.append(progressive_format)
    self._check_formats(progressive_formats, media_item_id)
    formats.extend(progressive_formats)
    return formats","self.ADAPTIVE_URL_TEMPLATE % (domain_id, application_id, media_item_id)",f"{self.ADAPTIVE_URL_TEMPLATE}{domain_id}/{application_id}/{media_item_id}",1,,,,,,,,,,
not-youtube-dl,https://github.com/scastillo/not-youtube-dl/tree/master/youtube_dl/extractor/once.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/not-youtube-dl/youtube_dl/extractor/once.py,OnceIE,"def _extract_once_formats(self, url, http_formats_preference=None):
    (domain_id, application_id, media_item_id) = re.match(OnceIE._VALID_URL, url).groups()
    formats = self._extract_m3u8_formats(self.ADAPTIVE_URL_TEMPLATE % (domain_id, application_id, media_item_id), media_item_id, 'mp4', m3u8_id='hls', fatal=False)
    progressive_formats = []
    for adaptive_format in formats:
        adaptive_format['url'] = re.sub('\\badsegmentlength=\\d+', 'adsegmentlength=0', adaptive_format['url'])
        rendition_id = self._search_regex('/now/media/playlist/[^/]+/[^/]+/([^/]+)', adaptive_format['url'], 'redition id', default=None)
        if rendition_id:
            progressive_format = adaptive_format.copy()
            progressive_format.update({'url': self.PROGRESSIVE_URL_TEMPLATE % (domain_id, application_id, rendition_id, media_item_id), 'format_id': adaptive_format['format_id'].replace('hls', 'http'), 'protocol': 'http', 'preference': http_formats_preference})
            progressive_formats.append(progressive_format)
    self._check_formats(progressive_formats, media_item_id)
    formats.extend(progressive_formats)
    return formats","self.PROGRESSIVE_URL_TEMPLATE % (domain_id, application_id, rendition_id, media_item_id)",f"{self.PROGRESSIVE_URL_TEMPLATE}{domain_id}/{application_id}/{rendition_id}/{media_item_id}",1,,,,,,,,,,
pyannote-audio,https://github.com/pyannote/pyannote-audio/tree/master/pyannote/audio/_version.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pyannote-audio/pyannote/audio/_version.py,,"def git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):
    if not os.path.exists(os.path.join(root, '.git')):
        if verbose:
            print('no .git in %s' % root)
        raise NotThisMethod('no .git directory')
    GITS = ['git']
    if sys.platform == 'win32':
        GITS = ['git.cmd', 'git.exe']
    describe_out = run_command(GITS, ['describe', '--tags', '--dirty', '--always', '--long'], cwd=root)
    if describe_out is None:
        raise NotThisMethod(""'git describe' failed"")
    describe_out = describe_out.strip()
    full_out = run_command(GITS, ['rev-parse', 'HEAD'], cwd=root)
    if full_out is None:
        raise NotThisMethod(""'git rev-parse' failed"")
    full_out = full_out.strip()
    pieces = {}
    pieces['long'] = full_out
    pieces['short'] = full_out[:7]
    pieces['error'] = None
    git_describe = describe_out
    dirty = git_describe.endswith('-dirty')
    pieces['dirty'] = dirty
    if dirty:
        git_describe = git_describe[:git_describe.rindex('-dirty')]
    if '-' in git_describe:
        mo = re.search('^(.+)-(\\d+)-g([0-9a-f]+)$', git_describe)
        if not mo:
            pieces['error'] = ""unable to parse git-describe output: '%s'"" % describe_out
            return pieces
        full_tag = mo.group(1)
        if not full_tag.startswith(tag_prefix):
            if verbose:
                fmt = ""tag '%s' doesn't start with prefix '%s'""
                print(fmt % (full_tag, tag_prefix))
            pieces['error'] = ""tag '%s' doesn't start with prefix '%s'"" % (full_tag, tag_prefix)
            return pieces
        pieces['closest-tag'] = full_tag[len(tag_prefix):]
        pieces['distance'] = int(mo.group(2))
        pieces['short'] = mo.group(3)
    else:
        pieces['closest-tag'] = None
        count_out = run_command(GITS, ['rev-list', 'HEAD', '--count'], cwd=root)
        pieces['distance'] = int(count_out)
    return pieces","""unable to parse git-describe output: '%s'"" % describe_out",f"unable to parse git-describe output: '{describe_out}'",1,,,,,,,,,,
pyannote-audio,https://github.com/pyannote/pyannote-audio/tree/master/pyannote/audio/_version.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pyannote-audio/pyannote/audio/_version.py,,"def git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):
    if not os.path.exists(os.path.join(root, '.git')):
        if verbose:
            print('no .git in %s' % root)
        raise NotThisMethod('no .git directory')
    GITS = ['git']
    if sys.platform == 'win32':
        GITS = ['git.cmd', 'git.exe']
    describe_out = run_command(GITS, ['describe', '--tags', '--dirty', '--always', '--long'], cwd=root)
    if describe_out is None:
        raise NotThisMethod(""'git describe' failed"")
    describe_out = describe_out.strip()
    full_out = run_command(GITS, ['rev-parse', 'HEAD'], cwd=root)
    if full_out is None:
        raise NotThisMethod(""'git rev-parse' failed"")
    full_out = full_out.strip()
    pieces = {}
    pieces['long'] = full_out
    pieces['short'] = full_out[:7]
    pieces['error'] = None
    git_describe = describe_out
    dirty = git_describe.endswith('-dirty')
    pieces['dirty'] = dirty
    if dirty:
        git_describe = git_describe[:git_describe.rindex('-dirty')]
    if '-' in git_describe:
        mo = re.search('^(.+)-(\\d+)-g([0-9a-f]+)$', git_describe)
        if not mo:
            pieces['error'] = ""unable to parse git-describe output: '%s'"" % describe_out
            return pieces
        full_tag = mo.group(1)
        if not full_tag.startswith(tag_prefix):
            if verbose:
                fmt = ""tag '%s' doesn't start with prefix '%s'""
                print(fmt % (full_tag, tag_prefix))
            pieces['error'] = ""tag '%s' doesn't start with prefix '%s'"" % (full_tag, tag_prefix)
            return pieces
        pieces['closest-tag'] = full_tag[len(tag_prefix):]
        pieces['distance'] = int(mo.group(2))
        pieces['short'] = mo.group(3)
    else:
        pieces['closest-tag'] = None
        count_out = run_command(GITS, ['rev-list', 'HEAD', '--count'], cwd=root)
        pieces['distance'] = int(count_out)
    return pieces","""tag '%s' doesn't start with prefix '%s'"" % (full_tag, tag_prefix)",f"tag '{full_tag}' doesn't start with prefix '{tag_prefix}'",1,,,,,,,,,,
pyannote-audio,https://github.com/pyannote/pyannote-audio/tree/master/pyannote/audio/_version.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pyannote-audio/pyannote/audio/_version.py,,"def git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):
    if not os.path.exists(os.path.join(root, '.git')):
        if verbose:
            print('no .git in %s' % root)
        raise NotThisMethod('no .git directory')
    GITS = ['git']
    if sys.platform == 'win32':
        GITS = ['git.cmd', 'git.exe']
    describe_out = run_command(GITS, ['describe', '--tags', '--dirty', '--always', '--long'], cwd=root)
    if describe_out is None:
        raise NotThisMethod(""'git describe' failed"")
    describe_out = describe_out.strip()
    full_out = run_command(GITS, ['rev-parse', 'HEAD'], cwd=root)
    if full_out is None:
        raise NotThisMethod(""'git rev-parse' failed"")
    full_out = full_out.strip()
    pieces = {}
    pieces['long'] = full_out
    pieces['short'] = full_out[:7]
    pieces['error'] = None
    git_describe = describe_out
    dirty = git_describe.endswith('-dirty')
    pieces['dirty'] = dirty
    if dirty:
        git_describe = git_describe[:git_describe.rindex('-dirty')]
    if '-' in git_describe:
        mo = re.search('^(.+)-(\\d+)-g([0-9a-f]+)$', git_describe)
        if not mo:
            pieces['error'] = ""unable to parse git-describe output: '%s'"" % describe_out
            return pieces
        full_tag = mo.group(1)
        if not full_tag.startswith(tag_prefix):
            if verbose:
                fmt = ""tag '%s' doesn't start with prefix '%s'""
                print(fmt % (full_tag, tag_prefix))
            pieces['error'] = ""tag '%s' doesn't start with prefix '%s'"" % (full_tag, tag_prefix)
            return pieces
        pieces['closest-tag'] = full_tag[len(tag_prefix):]
        pieces['distance'] = int(mo.group(2))
        pieces['short'] = mo.group(3)
    else:
        pieces['closest-tag'] = None
        count_out = run_command(GITS, ['rev-list', 'HEAD', '--count'], cwd=root)
        pieces['distance'] = int(count_out)
    return pieces",'no .git in %s' % root,f'no .git in {root}',1,,,,,,,,,,
sprutio,https://github.com/LTD-Beget/sprutio/tree/master/app/classes/core/FMAuth.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/sprutio/app/classes/core/FMAuth.py,FMAuth,"def authenticate_by_token(request, token):
    redis = request.redis.get(threading.currentThread())
    ':type : connectors.RedisConnector.RedisConnector'
    if redis.exists(str(token)):
        try:
            params = redis.get(token)
            params = json.loads(str(params))
            redis.set(token, json.dumps(params))
            request.set_secure_cookie(DEFAULT_COOKIE_TOKEN_NAME, token, COOKIE_EXPIRE)
            return token
        except Exception as e:
            request.application.logger.error('Error in FMAuth: %s, traceback = %s' % (str(e), traceback.format_exc()))
            return False
    return False","'Error in FMAuth: %s, traceback = %s' % (str(e), traceback.format_exc())","f""Error in FMAuth: {str(e)}, traceback = {traceback.format_exc()}""",1,,,,,,,,,,
lingvo,https://github.com/tensorflow/lingvo/tree/master/lingvo/core/batch_major_attention.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/lingvo/lingvo/core/batch_major_attention.py,FunnelUpsampleLayer,"def FProp(self, theta, x, all_hiddens=None):
    """"""Upsample to the inputs.

    Args:
      theta: weights defined in this layer.
      x: input tensor, [batch, time, dim] upsampling is applied to the time dim.
      all_hiddens: None or the list of hiddens states from all encoder layers,
        where each hidden state is a NestedMap with 'vec' and 'padding' keys.
        See the Builder class below for more details.

    Returns:
      Upsampled tensor, with the upsampling applied to the second dim in x.
    """"""
    p = self.params
    if x.shape.ndims is not None and x.shape.ndims != 3:
        raise ValueError('FunnelUpsampleLayer expects input to be rank 3, but got %d' % x.shape.ndims)
    if p.upsample_type not in ['REPEAT', 'DECONV']:
        raise ValueError('Only supports upsample_type REPEAT and DECONV, but got %s' % p.upsample_type)
    assert isinstance(p.upsample_rate, int)
    if p.upsample_rate == 1:
        return x
    if p.begin_intact > 0:
        intact = x[:, :p.begin_intact]
        hid = x[:, p.begin_intact:]
    else:
        hid = x
    if p.upsample_type == 'REPEAT':
        upsampled = tf.repeat(hid, repeats=p.upsample_rate, axis=1)
    elif p.upsample_type == 'DECONV':
        upsampled = tf.einsum('BLD,DNH->BLNH', hid, theta.weight)
        (bsz, seq_len) = py_utils.GetShape(hid, 3)[:2]
        upsampled = tf.reshape(upsampled, [bsz, p.upsample_rate * seq_len, p.hidden_dim])
    if p.begin_intact > 0:
        sep_len = 1
        if p.trunc_seq:
            num_pad = p.begin_intact * p.upsample_rate - p.begin_intact
            upsampled = tf.pad(upsampled, [[0, 0], [0, num_pad], [0, 0]])
        else:
            upsampled = upsampled[:, :-sep_len]
        upsampled = tf.concat([intact, upsampled], axis=1, name='concat_upsampled')
    if p.shortcut_index is not None:
        assert all_hiddens, 'all_hiddens must be provided for shortcut.'
        upsampled_shape = tf.shape(upsampled)
        shortcut_shape = tf.shape(all_hiddens[p.shortcut_index].vec)
        upsampled = py_utils.with_dependencies([py_utils.assert_shape_match(upsampled_shape, shortcut_shape)], upsampled + all_hiddens[p.shortcut_index].vec)
        if p.decoder_stack is not None:
            decoder_input = py_utils.NestedMap(vec=upsampled, paddings=all_hiddens[p.shortcut_index].paddings)
            upsampled = self.decoder_stack(decoder_input).vec
    return upsampled","'FunnelUpsampleLayer expects input to be rank 3, but got %d' % x.shape.ndims","'FunnelUpsampleLayer expects input to be rank 3, but got {x.shape.ndims}'",1,,,,,,,,,,
lingvo,https://github.com/tensorflow/lingvo/tree/master/lingvo/core/batch_major_attention.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/lingvo/lingvo/core/batch_major_attention.py,FunnelUpsampleLayer,"def FProp(self, theta, x, all_hiddens=None):
    """"""Upsample to the inputs.

    Args:
      theta: weights defined in this layer.
      x: input tensor, [batch, time, dim] upsampling is applied to the time dim.
      all_hiddens: None or the list of hiddens states from all encoder layers,
        where each hidden state is a NestedMap with 'vec' and 'padding' keys.
        See the Builder class below for more details.

    Returns:
      Upsampled tensor, with the upsampling applied to the second dim in x.
    """"""
    p = self.params
    if x.shape.ndims is not None and x.shape.ndims != 3:
        raise ValueError('FunnelUpsampleLayer expects input to be rank 3, but got %d' % x.shape.ndims)
    if p.upsample_type not in ['REPEAT', 'DECONV']:
        raise ValueError('Only supports upsample_type REPEAT and DECONV, but got %s' % p.upsample_type)
    assert isinstance(p.upsample_rate, int)
    if p.upsample_rate == 1:
        return x
    if p.begin_intact > 0:
        intact = x[:, :p.begin_intact]
        hid = x[:, p.begin_intact:]
    else:
        hid = x
    if p.upsample_type == 'REPEAT':
        upsampled = tf.repeat(hid, repeats=p.upsample_rate, axis=1)
    elif p.upsample_type == 'DECONV':
        upsampled = tf.einsum('BLD,DNH->BLNH', hid, theta.weight)
        (bsz, seq_len) = py_utils.GetShape(hid, 3)[:2]
        upsampled = tf.reshape(upsampled, [bsz, p.upsample_rate * seq_len, p.hidden_dim])
    if p.begin_intact > 0:
        sep_len = 1
        if p.trunc_seq:
            num_pad = p.begin_intact * p.upsample_rate - p.begin_intact
            upsampled = tf.pad(upsampled, [[0, 0], [0, num_pad], [0, 0]])
        else:
            upsampled = upsampled[:, :-sep_len]
        upsampled = tf.concat([intact, upsampled], axis=1, name='concat_upsampled')
    if p.shortcut_index is not None:
        assert all_hiddens, 'all_hiddens must be provided for shortcut.'
        upsampled_shape = tf.shape(upsampled)
        shortcut_shape = tf.shape(all_hiddens[p.shortcut_index].vec)
        upsampled = py_utils.with_dependencies([py_utils.assert_shape_match(upsampled_shape, shortcut_shape)], upsampled + all_hiddens[p.shortcut_index].vec)
        if p.decoder_stack is not None:
            decoder_input = py_utils.NestedMap(vec=upsampled, paddings=all_hiddens[p.shortcut_index].paddings)
            upsampled = self.decoder_stack(decoder_input).vec
    return upsampled","'Only supports upsample_type REPEAT and DECONV, but got %s' % p.upsample_type","f""Only supports upsample_type REPEAT and DECONV, but got {p.upsample_type}""",1,,,,,,,,,,
django,https://github.com/django/django/tree/master/tests/gis_tests/test_geoip2.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/django/tests/gis_tests/test_geoip2.py,GeoIPTest,"def test_repr(self):
    path = settings.GEOIP_PATH
    g = GeoIP2(path=path)
    meta = g._reader.metadata()
    version = '%s.%s' % (meta.binary_format_major_version, meta.binary_format_minor_version)
    country_path = g._country_file
    city_path = g._city_file
    expected = '<GeoIP2 [v%(version)s] _country_file=""%(country)s"", _city_file=""%(city)s"">' % {'version': version, 'country': country_path, 'city': city_path}
    self.assertEqual(repr(g), expected)","'%s.%s' % (meta.binary_format_major_version, meta.binary_format_minor_version)",f"{meta.binary_format_major_version}.{meta.binary_format_minor_version}",1,,,,,,,,,,
django,https://github.com/django/django/tree/master/tests/gis_tests/test_geoip2.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/django/tests/gis_tests/test_geoip2.py,GeoIPTest,"def test_repr(self):
    path = settings.GEOIP_PATH
    g = GeoIP2(path=path)
    meta = g._reader.metadata()
    version = '%s.%s' % (meta.binary_format_major_version, meta.binary_format_minor_version)
    country_path = g._country_file
    city_path = g._city_file
    expected = '<GeoIP2 [v%(version)s] _country_file=""%(country)s"", _city_file=""%(city)s"">' % {'version': version, 'country': country_path, 'city': city_path}
    self.assertEqual(repr(g), expected)","'<GeoIP2 [v%(version)s] _country_file=""%(country)s"", _city_file=""%(city)s"">' % {'version': version, 'country': country_path, 'city': city_path}","f'<GeoIP2 [v{version}] _country_file=""{country_path}"", _city_file=""{city_path}"">'",1,,,,,,,,,,
NeoVintageous,https://github.com/NeoVintageous/NeoVintageous/tree/master/nv/shell_windows.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/NeoVintageous/nv/shell_windows.py,,"def filter_region(view, txt: str, cmd: str) -> str:
    try:
        contents = tempfile.NamedTemporaryFile(suffix='.txt', delete=False)
        contents.write(txt.encode('utf-8'))
        contents.close()
        script = tempfile.NamedTemporaryFile(suffix='.bat', delete=False)
        script.write(('@echo off\ntype %s | %s' % (contents.name, cmd)).encode('utf-8'))
        script.close()
        p = subprocess.Popen([script.name], stdout=subprocess.PIPE, stderr=subprocess.PIPE, startupinfo=_get_startup_info())
        (out, err) = p.communicate()
        if out:
            return _translate_newlines(out.decode(_get_encoding()))
        if err:
            return _translate_newlines(err.decode(_get_encoding()))
        return ''
    finally:
        os.remove(script.name)
        os.remove(contents.name)","'@echo off\ntype %s | %s' % (contents.name, cmd)",f'@echo off\ntype {contents.name} | {cmd}',1,,,,,,,,,,
gentle,https://github.com/lowerquality/gentle/tree/master/gentle/rpc.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/gentle/gentle/rpc.py,RPCError,"def __str__(self):
    return 'standard_kaldi: error %d: %s' % (self.status, self.why)","'standard_kaldi: error %d: %s' % (self.status, self.why)",f'standard_kaldi: error {self.status}: {self.why}',1,,,,,,,,,,
jetson_stats,https://github.com/rbonghi/jetson_stats/tree/master/jtop/tests/test_fan.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/jetson_stats/jtop/tests/test_fan.py,,"def copyDirectory(src, dest):
    try:
        shutil.copytree(src, dest)
    except shutil.Error as e:
        print('Directory not copied. Error: %s' % e)
    except OSError as e:
        print('Directory not copied. Error: %s' % e)",'Directory not copied. Error: %s' % e,f"Directory not copied. Error: {e}",1,,,,,,,,,,
jetson_stats,https://github.com/rbonghi/jetson_stats/tree/master/jtop/tests/test_fan.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/jetson_stats/jtop/tests/test_fan.py,,"def copyDirectory(src, dest):
    try:
        shutil.copytree(src, dest)
    except shutil.Error as e:
        print('Directory not copied. Error: %s' % e)
    except OSError as e:
        print('Directory not copied. Error: %s' % e)",'Directory not copied. Error: %s' % e,f"Directory not copied. Error: {e}",1,,,,,,,,,,
mitmproxy,https://github.com/mitmproxy/mitmproxy/tree/master/mitmproxy/addons/core.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/mitmproxy/mitmproxy/addons/core.py,Core,"def revert(self, flows: typing.Sequence[flow.Flow]) -> None:
    """"""
            Revert flow changes.
        """"""
    updated = []
    for f in flows:
        if f.modified():
            f.revert()
            updated.append(f)
    ctx.log.alert('Reverted %s flows.' % len(updated))
    ctx.master.addons.trigger(hooks.UpdateHook(updated))",'Reverted %s flows.' % len(updated),f"Reverted {len(updated)} flows.",1,,,,,,,,,,
WeasyPrint,https://github.com/Kozea/WeasyPrint/tree/master/tests/layout/test_block.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/WeasyPrint/tests/layout/test_block.py,,"def test_vertical_space_6(margin_1, margin_2, result):
    (page,) = render_pages('\n      <style>\n        p { font: 20px/1 serif } /* block height == 20px */\n        #div1 { margin-top: %s; overflow: hidden }\n        #div2 { margin-top: %s }\n      </style>\n      <p>Lorem ipsum\n      <div id=div1>\n        <div id=div2>\n          <p id=p2>dolor sit amet\n        </div>\n      </div>\n    ' % (margin_1, margin_2))
    (html,) = page.children
    (body,) = html.children
    (p1, div1) = body.children
    (div2,) = div1.children
    (p2,) = div2.children
    p1_bottom = p1.content_box_y() + p1.height
    p2_top = p2.content_box_y()
    assert p2_top - p1_bottom == result","'\n      <style>\n        p { font: 20px/1 serif } /* block height == 20px */\n        #div1 { margin-top: %s; overflow: hidden }\n        #div2 { margin-top: %s }\n      </style>\n      <p>Lorem ipsum\n      <div id=div1>\n        <div id=div2>\n          <p id=p2>dolor sit amet\n        </div>\n      </div>\n    ' % (margin_1, margin_2)",f'''\n      <style>\n        p {{ font: 20px/1 serif }} /* block height == 20px */\n        #div1 {{ margin-top: {margin_1}; overflow: hidden }}\n        #div2 {{ margin-top: {margin_2} }}\n      </style>\n      <p>Lorem ipsum\n      <div id=div1>\n        <div id=div2>\n          <p id=p2>dolor sit amet\n        </div>\n      </div>\n    ''',1,,,,,,,,,,
conan,https://github.com/conan-io/conan/tree/master/conans/client/build/meson.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/conan/conans/client/build/meson.py,Meson,"def _run_meson_targets(self, args=None, build_dir=None, targets=None):
    args = args or []
    build_dir = build_dir or self.build_dir or self._conanfile.build_folder
    arg_list = join_arguments(['-C ""%s""' % build_dir, args_to_string(args), args_to_string(targets)])
    command = 'ninja' if self.backend == 'ninja' else 'meson compile'
    self._run('%s %s' % (command, arg_list))","'%s %s' % (command, arg_list)",f"{command} {arg_list}",1,,,,,,,,,,
conan,https://github.com/conan-io/conan/tree/master/conans/client/build/meson.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/conan/conans/client/build/meson.py,Meson,"def _run_meson_targets(self, args=None, build_dir=None, targets=None):
    args = args or []
    build_dir = build_dir or self.build_dir or self._conanfile.build_folder
    arg_list = join_arguments(['-C ""%s""' % build_dir, args_to_string(args), args_to_string(targets)])
    command = 'ninja' if self.backend == 'ninja' else 'meson compile'
    self._run('%s %s' % (command, arg_list))",'-C "%s"' % build_dir,f'-C "{build_dir}"',1,,,,,,,,,,
TensorFlow-and-DeepLearning-Tutorial,https://github.com/CreatCodeBuild/TensorFlow-and-DeepLearning-Tutorial/tree/master/Season1_Tensorflow1.1_Python3.5/12-15/dp_refined_api.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/TensorFlow-and-DeepLearning-Tutorial/Season1_Tensorflow1.1_Python3.5/12-15/dp_refined_api.py,Network,"def run(self, data_iterator, train_samples, train_labels, test_samples, test_labels):
    """"""
        Session
        :data_iterator: a function that yields chuck of data
        """"""

    def print_confusion_matrix(confusionMatrix):
        print('Confusion    Matrix:')
        for (i, line) in enumerate(confusionMatrix):
            print(line, line[i] / np.sum(line))
        a = 0
        for (i, column) in enumerate(np.transpose(confusionMatrix, (1, 0))):
            a += column[i] / np.sum(column) * (np.sum(column) / 26000)
            print(column[i] / np.sum(column))
        print('\n', np.sum(confusionMatrix), a)
    self.writer = tf.summary.FileWriter('./board', tf.get_default_graph())
    with tf.Session(graph=tf.get_default_graph()) as session:
        tf.initialize_all_variables().run()
        print('Start Training')
        for (i, samples, labels) in data_iterator(train_samples, train_labels, self.train_batch_size):
            (_, l, predictions, summary) = session.run([self.optimizer, self.loss, self.train_prediction, self.merged_train_summary], feed_dict={self.tf_train_samples: samples, self.tf_train_labels: labels})
            self.writer.add_summary(summary, i)
            (accuracy, _) = self.accuracy(predictions, labels)
            if i % 50 == 0:
                print('Minibatch loss at step %d: %f' % (i, l))
                print('Minibatch accuracy: %.1f%%' % accuracy)
        accuracies = []
        confusionMatrices = []
        for (i, samples, labels) in data_iterator(test_samples, test_labels, self.test_batch_size):
            print('samples shape', samples.shape)
            (result, summary) = session.run([self.test_prediction, self.merged_test_summary], feed_dict={self.tf_test_samples: samples})
            self.writer.add_summary(summary, i)
            (accuracy, cm) = self.accuracy(result, labels, need_confusion_matrix=True)
            accuracies.append(accuracy)
            confusionMatrices.append(cm)
            print('Test Accuracy: %.1f%%' % accuracy)
        print(' Average  Accuracy:', np.average(accuracies))
        print('Standard Deviation:', np.std(accuracies))
        print_confusion_matrix(np.add.reduce(confusionMatrices))",'Test Accuracy: %.1f%%' % accuracy,print(f"Test Accuracy: {accuracy:.1f}%"),1,,,,,,,,,,
TensorFlow-and-DeepLearning-Tutorial,https://github.com/CreatCodeBuild/TensorFlow-and-DeepLearning-Tutorial/tree/master/Season1_Tensorflow1.1_Python3.5/12-15/dp_refined_api.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/TensorFlow-and-DeepLearning-Tutorial/Season1_Tensorflow1.1_Python3.5/12-15/dp_refined_api.py,Network,"def run(self, data_iterator, train_samples, train_labels, test_samples, test_labels):
    """"""
        Session
        :data_iterator: a function that yields chuck of data
        """"""

    def print_confusion_matrix(confusionMatrix):
        print('Confusion    Matrix:')
        for (i, line) in enumerate(confusionMatrix):
            print(line, line[i] / np.sum(line))
        a = 0
        for (i, column) in enumerate(np.transpose(confusionMatrix, (1, 0))):
            a += column[i] / np.sum(column) * (np.sum(column) / 26000)
            print(column[i] / np.sum(column))
        print('\n', np.sum(confusionMatrix), a)
    self.writer = tf.summary.FileWriter('./board', tf.get_default_graph())
    with tf.Session(graph=tf.get_default_graph()) as session:
        tf.initialize_all_variables().run()
        print('Start Training')
        for (i, samples, labels) in data_iterator(train_samples, train_labels, self.train_batch_size):
            (_, l, predictions, summary) = session.run([self.optimizer, self.loss, self.train_prediction, self.merged_train_summary], feed_dict={self.tf_train_samples: samples, self.tf_train_labels: labels})
            self.writer.add_summary(summary, i)
            (accuracy, _) = self.accuracy(predictions, labels)
            if i % 50 == 0:
                print('Minibatch loss at step %d: %f' % (i, l))
                print('Minibatch accuracy: %.1f%%' % accuracy)
        accuracies = []
        confusionMatrices = []
        for (i, samples, labels) in data_iterator(test_samples, test_labels, self.test_batch_size):
            print('samples shape', samples.shape)
            (result, summary) = session.run([self.test_prediction, self.merged_test_summary], feed_dict={self.tf_test_samples: samples})
            self.writer.add_summary(summary, i)
            (accuracy, cm) = self.accuracy(result, labels, need_confusion_matrix=True)
            accuracies.append(accuracy)
            confusionMatrices.append(cm)
            print('Test Accuracy: %.1f%%' % accuracy)
        print(' Average  Accuracy:', np.average(accuracies))
        print('Standard Deviation:', np.std(accuracies))
        print_confusion_matrix(np.add.reduce(confusionMatrices))","'Minibatch loss at step %d: %f' % (i, l)",f"Minibatch loss at step {i}: {l}",1,,,,,,,,,,
TensorFlow-and-DeepLearning-Tutorial,https://github.com/CreatCodeBuild/TensorFlow-and-DeepLearning-Tutorial/tree/master/Season1_Tensorflow1.1_Python3.5/12-15/dp_refined_api.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/TensorFlow-and-DeepLearning-Tutorial/Season1_Tensorflow1.1_Python3.5/12-15/dp_refined_api.py,Network,"def run(self, data_iterator, train_samples, train_labels, test_samples, test_labels):
    """"""
        Session
        :data_iterator: a function that yields chuck of data
        """"""

    def print_confusion_matrix(confusionMatrix):
        print('Confusion    Matrix:')
        for (i, line) in enumerate(confusionMatrix):
            print(line, line[i] / np.sum(line))
        a = 0
        for (i, column) in enumerate(np.transpose(confusionMatrix, (1, 0))):
            a += column[i] / np.sum(column) * (np.sum(column) / 26000)
            print(column[i] / np.sum(column))
        print('\n', np.sum(confusionMatrix), a)
    self.writer = tf.summary.FileWriter('./board', tf.get_default_graph())
    with tf.Session(graph=tf.get_default_graph()) as session:
        tf.initialize_all_variables().run()
        print('Start Training')
        for (i, samples, labels) in data_iterator(train_samples, train_labels, self.train_batch_size):
            (_, l, predictions, summary) = session.run([self.optimizer, self.loss, self.train_prediction, self.merged_train_summary], feed_dict={self.tf_train_samples: samples, self.tf_train_labels: labels})
            self.writer.add_summary(summary, i)
            (accuracy, _) = self.accuracy(predictions, labels)
            if i % 50 == 0:
                print('Minibatch loss at step %d: %f' % (i, l))
                print('Minibatch accuracy: %.1f%%' % accuracy)
        accuracies = []
        confusionMatrices = []
        for (i, samples, labels) in data_iterator(test_samples, test_labels, self.test_batch_size):
            print('samples shape', samples.shape)
            (result, summary) = session.run([self.test_prediction, self.merged_test_summary], feed_dict={self.tf_test_samples: samples})
            self.writer.add_summary(summary, i)
            (accuracy, cm) = self.accuracy(result, labels, need_confusion_matrix=True)
            accuracies.append(accuracy)
            confusionMatrices.append(cm)
            print('Test Accuracy: %.1f%%' % accuracy)
        print(' Average  Accuracy:', np.average(accuracies))
        print('Standard Deviation:', np.std(accuracies))
        print_confusion_matrix(np.add.reduce(confusionMatrices))",'Minibatch accuracy: %.1f%%' % accuracy,f"Minibatch accuracy: {accuracy:.1f}%",1,,,,,,,,,,
pychess,https://github.com/pychess/pychess/tree/master/lib/pychess/Players/PyChess.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pychess/lib/pychess/Players/PyChess.py,PyChess,"def __remainingMovesA(self):
    ply_count = self.board.plyCount
    remaining = -1.71086e-12 * ply_count ** 6 + 1.69103e-09 * ply_count ** 5 - 6.00801e-07 * ply_count ** 4 + 8.17741e-05 * ply_count ** 3 + 0.000291858 * ply_count ** 2 - 0.94497 * ply_count + 78.8979
    self.print('# remaining moves estimate=%s' % remaining)
    return remaining",'# remaining moves estimate=%s' % remaining,f"# remaining moves estimate={remaining}",1,,,,,,,,,,
ansible-modules-extras,https://github.com/ansible/ansible-modules-extras/tree/master/database/mssql/mssql_db.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/ansible-modules-extras/database/mssql/mssql_db.py,,"def db_import(conn, cursor, module, db, target):
    if os.path.isfile(target):
        backup = open(target, 'r')
        try:
            sqlQuery = 'USE [%s]\n' % db
            for line in backup:
                if line is None:
                    break
                elif line.startswith('GO'):
                    cursor.execute(sqlQuery)
                    sqlQuery = 'USE [%s]\n' % db
                else:
                    sqlQuery += line
            cursor.execute(sqlQuery)
            conn.commit()
        finally:
            backup.close()
        return (0, 'import successful', '')
    else:
        return (1, 'cannot find target file', 'cannot find target file')",'USE [%s]\n' % db,f"USE [{db}]\n",1,,,,,,,,,,
ansible-modules-extras,https://github.com/ansible/ansible-modules-extras/tree/master/database/mssql/mssql_db.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/ansible-modules-extras/database/mssql/mssql_db.py,,"def db_import(conn, cursor, module, db, target):
    if os.path.isfile(target):
        backup = open(target, 'r')
        try:
            sqlQuery = 'USE [%s]\n' % db
            for line in backup:
                if line is None:
                    break
                elif line.startswith('GO'):
                    cursor.execute(sqlQuery)
                    sqlQuery = 'USE [%s]\n' % db
                else:
                    sqlQuery += line
            cursor.execute(sqlQuery)
            conn.commit()
        finally:
            backup.close()
        return (0, 'import successful', '')
    else:
        return (1, 'cannot find target file', 'cannot find target file')",'USE [%s]\n' % db,f"USE [{db}]\n",1,,,,,,,,,,
pylearn2,https://github.com/lisa-lab/pylearn2/tree/master/pylearn2/models/dbm/ising.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pylearn2/pylearn2/models/dbm/ising.py,IsingHidden,"def mf_update(self, state_below, state_above, layer_above=None, double_weights=False, iter_name=None):
    """"""
        .. todo::

            WRITEME
        """"""
    self.input_space.validate(state_below)
    if self.requires_reformat:
        if not isinstance(state_below, tuple):
            for sb in get_debug_values(state_below):
                if sb.shape[0] != self.dbm.batch_size:
                    raise ValueError('self.dbm.batch_size is %d but got ' + 'shape of %d' % (self.dbm.batch_size, sb.shape[0]))
                assert reduce(operator.mul, sb.shape[1:]) == self.input_dim
        state_below = self.input_space.format_as(state_below, self.desired_space)
    if iter_name is None:
        iter_name = 'anon'
    if state_above is not None:
        assert layer_above is not None
        msg = layer_above.downward_message(state_above)
        msg.name = 'msg_from_' + layer_above.layer_name + '_to_' + self.layer_name + '[' + iter_name + ']'
    else:
        msg = None
    if double_weights:
        state_below = 2.0 * state_below
        state_below.name = self.layer_name + '_' + iter_name + '_2state'
    z = self.transformer.lmul(state_below) + self.b
    if self.layer_name is not None and iter_name is not None:
        z.name = self.layer_name + '_' + iter_name + '_z'
    if msg is not None:
        z = z + msg
    h = T.tanh(self.beta * z)
    return h","'shape of %d' % (self.dbm.batch_size, sb.shape[0])","f'shape of {self.dbm.batch_size}, {sb.shape[0]}'",1,,,,,,,,,,
dirbot,https://github.com/scrapy/dirbot/tree/master/dirbot/pipelines.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/dirbot/dirbot/pipelines.py,FilterWordsPipeline,"def process_item(self, item, spider):
    for word in self.words_to_filter:
        if word in item['description'].lower():
            raise DropItem('Contains forbidden word: %s' % word)
    else:
        return item",'Contains forbidden word: %s' % word,f"Contains forbidden word: {word}",1,,,,,,,,,,
LightNet,https://github.com/linksense/LightNet/tree/master/scripts/model_measure.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/LightNet/scripts/model_measure.py,,"def measure_layer(layer, x):
    global count_ops, count_params
    delta_ops = 0
    delta_params = 0
    multi_add = 1
    type_name = get_layer_info(layer)
    if type_name in ['Conv2d']:
        out_h = int((x.size()[2] + 2 * layer.padding[0] - layer.kernel_size[0]) / layer.stride[0] + 1)
        out_w = int((x.size()[3] + 2 * layer.padding[1] - layer.kernel_size[1]) / layer.stride[1] + 1)
        delta_ops = layer.in_channels * layer.out_channels * layer.kernel_size[0] * layer.kernel_size[1] * out_h * out_w / layer.groups * multi_add
        delta_params = get_layer_param(layer)
    elif type_name in ['ReLU', 'ReLU6', 'LeakyReLU', 'Sigmoid']:
        delta_ops = x.numel()
        delta_params = get_layer_param(layer)
    elif type_name in ['AvgPool2d']:
        in_w = x.size()[2]
        kernel_ops = layer.kernel_size * layer.kernel_size
        out_w = int((in_w + 2 * layer.padding - layer.kernel_size) / layer.stride + 1)
        out_h = int((in_w + 2 * layer.padding - layer.kernel_size) / layer.stride + 1)
        delta_ops = x.size()[0] * x.size()[1] * out_w * out_h * kernel_ops
        delta_params = get_layer_param(layer)
    elif type_name in ['AdaptiveAvgPool2d']:
        delta_ops = x.size()[0] * x.size()[1] * x.size()[2] * x.size()[3]
        delta_params = get_layer_param(layer)
    elif type_name in ['Linear']:
        weight_ops = layer.weight.numel() * multi_add
        bias_ops = layer.bias.numel()
        delta_ops = x.size()[0] * (weight_ops + bias_ops)
        delta_params = get_layer_param(layer)
    elif type_name in ['BatchNorm2d', 'Dropout2d', 'DropChannel', 'Dropout', 'InPlaceABN', 'InPlaceABNSync', 'Upsample', 'MaxPool2d']:
        delta_params = get_layer_param(layer)
    else:
        raise TypeError('unknown layer type: %s' % type_name)
    count_ops += delta_ops
    count_params += delta_params
    return",'unknown layer type: %s' % type_name,f"unknown layer type: {type_name}",1,,,,,,,,,,
hyper,https://github.com/python-hyper/hyper/tree/master/test/test_integration.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/hyper/test/test_integration.py,TestRequestsAdapter,"def test_adapter_close_context_manager(self):
    self.set_up(secure=False)

    def socket_handler(listener):
        sock = listener.accept()[0]
        data = b''
        while not data.endswith(b'\r\n\r\n'):
            data += sock.recv(65535)
        resp = b'HTTP/1.1 201 No Content\r\nServer: socket-level-server\r\nContent-Length: 0\r\nConnection: close\r\n\r\n'
        sock.send(resp)
        sock.close()
    self._start_server(socket_handler)
    with requests.Session() as s:
        a = HTTP20Adapter()
        s.mount('http://', a)
        r = s.get('http://%s:%s' % (self.host, self.port))
        connections_before_close = list(a.connections.values())
        assert connections_before_close
    assert not a.connections
    assert all((conn._sock is None for conn in connections_before_close))
    assert r.status_code == 201
    assert len(r.headers) == 3
    assert r.headers['server'] == 'socket-level-server'
    assert r.headers['content-length'] == '0'
    assert r.headers['connection'] == 'close'
    assert r.content == b''
    self.tear_down()","'http://%s:%s' % (self.host, self.port)",f'http://{self.host}:{self.port}',1,,,,,,,,,,
kale,https://github.com/kubeflow-kale/kale/tree/master/backend/kale/kfserving/transformer.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/kale/backend/kale/kfserving/transformer.py,KaleTransformer,"def _load_transformer_assets(self):
    marshal.set_data_dir(serveutils.TRANSFORMER_ASSETS_DIR)
    log.info('Loading transformer function...')
    _fn = marshal.load(serveutils.TRANSFORMER_FN_ASSET_NAME)
    self.fn = types.FunctionType(_fn.__code__, globals(), _fn.__name__, _fn.__defaults__, _fn.__closure__)
    log.info('Processing source notebook for imports and functions...')
    processor = NotebookProcessor(nb_path=os.path.join(serveutils.TRANSFORMER_ASSETS_DIR, serveutils.TRANSFORMER_SRC_NOTEBOOK_NAME), skip_validation=True)
    self.init_code = processor.get_imports_and_functions()
    log.info('Initialization code:\n%s' % self.init_code)
    log.info('Running initialization code...')
    exec(self.init_code, globals())
    log.info(""Loading transformer's assets..."")
    for file in os.listdir(serveutils.TRANSFORMER_ASSETS_DIR):
        if file in [serveutils.TRANSFORMER_SRC_NOTEBOOK_NAME, serveutils.TRANSFORMER_FN_ASSET_NAME]:
            continue
        basename = os.path.splitext(file)[0]
        self.assets[basename] = marshal.load(basename)
    log.info('Assets successfully loaded: %s' % self.assets.keys())
    log.info('Initializing assets...')
    for (asset_name, asset_value) in self.assets.items():
        globals()[asset_name] = asset_value",'Initialization code:\n%s' % self.init_code,f'Initialization code:\n{self.init_code}',1,,,,,,,,,,
kale,https://github.com/kubeflow-kale/kale/tree/master/backend/kale/kfserving/transformer.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/kale/backend/kale/kfserving/transformer.py,KaleTransformer,"def _load_transformer_assets(self):
    marshal.set_data_dir(serveutils.TRANSFORMER_ASSETS_DIR)
    log.info('Loading transformer function...')
    _fn = marshal.load(serveutils.TRANSFORMER_FN_ASSET_NAME)
    self.fn = types.FunctionType(_fn.__code__, globals(), _fn.__name__, _fn.__defaults__, _fn.__closure__)
    log.info('Processing source notebook for imports and functions...')
    processor = NotebookProcessor(nb_path=os.path.join(serveutils.TRANSFORMER_ASSETS_DIR, serveutils.TRANSFORMER_SRC_NOTEBOOK_NAME), skip_validation=True)
    self.init_code = processor.get_imports_and_functions()
    log.info('Initialization code:\n%s' % self.init_code)
    log.info('Running initialization code...')
    exec(self.init_code, globals())
    log.info(""Loading transformer's assets..."")
    for file in os.listdir(serveutils.TRANSFORMER_ASSETS_DIR):
        if file in [serveutils.TRANSFORMER_SRC_NOTEBOOK_NAME, serveutils.TRANSFORMER_FN_ASSET_NAME]:
            continue
        basename = os.path.splitext(file)[0]
        self.assets[basename] = marshal.load(basename)
    log.info('Assets successfully loaded: %s' % self.assets.keys())
    log.info('Initializing assets...')
    for (asset_name, asset_value) in self.assets.items():
        globals()[asset_name] = asset_value",'Assets successfully loaded: %s' % self.assets.keys(),f'Assets successfully loaded: {list(self.assets.keys())}',1,,,,,,,,,,
brave,https://github.com/bbc/brave/tree/master/brave/connections/connection_to_mixer.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/brave/brave/connections/connection_to_mixer.py,ConnectionToMixer,"def _remove_from_mix(self, audio_or_video):
    if not self._mix_request_pad[audio_or_video].is_linked():
        self.logger.info('Attempted to remove from %s mix but not currently mixed' % audio_or_video)
        return
    if audio_or_video in self._mix_request_pad:
        self._mix_request_pad[audio_or_video].get_peer().unlink(self._mix_request_pad[audio_or_video])
        self.dest.mixer_element[audio_or_video].release_request_pad(self._mix_request_pad[audio_or_video])
        del self._mix_request_pad[audio_or_video]",'Attempted to remove from %s mix but not currently mixed' % audio_or_video,f"Attempted to remove from {audio_or_video} mix but not currently mixed",1,,,,,,,,,,
dcc,https://github.com/amimo/dcc/tree/master/androguard/decompiler/dad/instruction.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/dcc/androguard/decompiler/dad/instruction.py,CastExpression,"def __str__(self):
    return 'CAST_%s(%s)' % (self.op, self.var_map[self.arg])","'CAST_%s(%s)' % (self.op, self.var_map[self.arg])",f"CAST_{self.op}({self.var_map[self.arg]})",1,,,,,,,,,,
magenta,https://github.com/magenta/magenta/tree/master/magenta/models/image_stylization/image_stylization_convert_tflite.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/magenta/magenta/models/image_stylization/image_stylization_convert_tflite.py,,"def _convert_to_tflite(saved_model_dir, num_styles, image_size, quantize, output_model):
    """"""Convert a image stylization saved model to TensorFlow Lite format.""""""
    if tf.io.gfile.isdir(output_model):
        if quantize:
            filename = 'stylize_quantized.tflite'
        else:
            filename = 'stylize.tflite'
        output_model = os.path.join(output_model, filename)
    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir=saved_model_dir, input_shapes={'input_image': [None, image_size, image_size, 3], 'style_weights': num_styles})
    if quantize:
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
    tflite_model = converter.convert()
    with tf.io.gfile.GFile(output_model, 'wb') as f:
        f.write(tflite_model)
    tf.logging.info('Converted to TF Lite model: %s; Size: %d KB.' % (output_model, len(tflite_model) / 1024))","'Converted to TF Lite model: %s; Size: %d KB.' % (output_model, len(tflite_model) / 1024)",print(f"Converted to TF Lite model: {output_model}; Size: {len(tflite_model) / 1024} KB."),1,,,,,,,,,,
pootle,https://github.com/translate/pootle/tree/master/tests/views/admin.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pootle/tests/views/admin.py,,"def test_admin_view_project_delete_tp(english, client, admin):
    user = admin
    project = Project.objects.get(code='project0')
    tp = TranslationProject.objects.create(language=english, project=project)
    project.config['pootle.core.lang_mapping'] = {tp.language.code: 'foo'}
    client.login(username=user.username, password=TEST_USERS['admin']['password'])
    get_response = _admin_view_get(client, project)
    post_data = {}
    formset = get_response.context['formset']
    forms = formset.forms + formset.extra_forms + [formset.management_form]
    for form in forms:
        for field in form.fields:
            post_data['%s-%s' % (form.prefix, field)] = form.fields[field].initial or form.initial.get(field, '')
    tp_pk = post_data['form-0-id']
    post_data['form-0-DELETE'] = 'true'
    response = _admin_view_post(client, project, **post_data)
    assert tp_pk not in project.translationproject_set.values_list('pk', flat=True)
    _test_admin_view(response, project)
    assert project.config['pootle.core.lang_mapping'] == {}","'%s-%s' % (form.prefix, field)",f"{form.prefix}-{field}",1,,,,,,,,,,
pytorch3d,https://github.com/facebookresearch/pytorch3d/tree/master/projects/nerf/nerf/stats.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pytorch3d/projects/nerf/nerf/stats.py,Stats,"def reset(self) -> None:
    """"""
        Called before an epoch to clear current epoch buffers.
        """"""
    stat_sets = list(self.stats.keys())
    if self.verbose:
        print('stats: epoch %d - reset' % self.epoch)
    self.it = {k: -1 for k in stat_sets}
    for stat_set in stat_sets:
        for stat in self.stats[stat_set]:
            self.stats[stat_set][stat].reset()
    self._epoch_start = time.time()",'stats: epoch %d - reset' % self.epoch,f"stats: epoch {self.epoch} - reset",1,,,,,,,,,,
q,https://github.com/zestyping/q/tree/master/test/test_suite.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/q/test/test_suite.py,ParsingModeTests,"def test_strict_mode_too_small_specific_column_count(self):
    tmpfile = self.create_file_with_data(sample_data_no_header)
    cmd = Q_EXECUTABLE + ' -d , -m strict -c 2 ""select count(*) from %s""' % tmpfile.name
    (retcode, o, e) = run_command(cmd)
    self.assertNotEqual(retcode, 0)
    self.assertEqual(len(o), 0)
    self.assertEqual(len(e), 1)
    self.assertEqual(e[0], six.b('Strict mode. Column count is expected to be 2 but is 3'))
    self.cleanup(tmpfile)","' -d , -m strict -c 2 ""select count(*) from %s""' % tmpfile.name","f' -d , -m strict -c 2 ""select count(*) from {tmpfile.name}""'",1,,,,,,,,,,
ansible-modules-extras,https://github.com/ansible/ansible-modules-extras/tree/master/cloud/cloudstack/cs_firewall.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/ansible-modules-extras/cloud/cloudstack/cs_firewall.py,AnsibleCloudStackFirewall,"def create_firewall_rule(self):
    firewall_rule = self.get_firewall_rule()
    if not firewall_rule:
        self.result['changed'] = True
        args = {}
        args['cidrlist'] = self.module.params.get('cidr')
        args['protocol'] = self.module.params.get('protocol')
        args['startport'] = self.module.params.get('start_port')
        args['endport'] = self.get_or_fallback('end_port', 'start_port')
        args['icmptype'] = self.module.params.get('icmp_type')
        args['icmpcode'] = self.module.params.get('icmp_code')
        fw_type = self.module.params.get('type')
        if not self.module.check_mode:
            if fw_type == 'egress':
                args['networkid'] = self.get_network(key='id')
                res = self.cs.createEgressFirewallRule(**args)
            else:
                args['ipaddressid'] = self.get_ip_address('id')
                res = self.cs.createFirewallRule(**args)
            if 'errortext' in res:
                self.module.fail_json(msg=""Failed: '%s'"" % res['errortext'])
            poll_async = self.module.params.get('poll_async')
            if poll_async:
                firewall_rule = self.poll_job(res, 'firewallrule')
    return firewall_rule","""Failed: '%s'"" % res['errortext']",f"Failed: '{res['errortext']}'",1,,,,,,,,,,
lore,https://github.com/instacart/lore/tree/master/lore/encoders.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/lore/lore/encoders.py,NestedUnique,"def unnest(self, data, fit=False):
    """"""
        :param data: a dataframe containing a column to be unnested
        :param fit: if True, self.sequence_length will exactly accomodate the largest sequence length
        :return: 1D array of values with length = rows * sequence_length
        """"""
    with timer('unnest %s' % self.name, logging.DEBUG):
        raw = self.series(data)
        lengths = [0 if x is None or (isinstance(x, float) and numpy.isnan(x)) else len(x) for x in raw.values]
        if fit and self.sequence_length is None:
            self.sequence_length = numpy.max(lengths)

        def fill_x(x, length):
            x_new = numpy.empty(length, dtype='O')
            if x is None or (isinstance(x, float) and numpy.isnan(x)):
                return x_new
            fill_length = min(len(x), length)
            x_new[0:fill_length] = x[0:fill_length]
            return x_new
        same_size = [fill_x(x, self.sequence_length) for x in raw.values]
        flattened = [item for sublist in same_size for item in sublist]
        return pandas.DataFrame({self.column: flattened})",'unnest %s' % self.name,f"unnest {self.name}",1,,,,,,,,,,
glance,https://github.com/openstack/glance/tree/master/glance/tests/functional/db/base.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/glance/glance/tests/functional/db/base.py,DriverTests,"def test_image_member_create(self, mock_utcnow):
    mock_utcnow.return_value = datetime.datetime.utcnow()
    memberships = self.db_api.image_member_find(self.context)
    self.assertEqual([], memberships)
    TENANT1 = str(uuid.uuid4())
    self.context.auth_token = 'user:%s:user' % TENANT1
    self.db_api.image_member_create(self.context, {'member': TENANT1, 'image_id': UUID1})
    memberships = self.db_api.image_member_find(self.context)
    self.assertEqual(1, len(memberships))
    actual = memberships[0]
    self.assertIsNotNone(actual['created_at'])
    self.assertIsNotNone(actual['updated_at'])
    actual.pop('id')
    actual.pop('created_at')
    actual.pop('updated_at')
    expected = {'member': TENANT1, 'image_id': UUID1, 'can_share': False, 'status': 'pending', 'deleted': False}
    self.assertEqual(expected, actual)",'user:%s:user' % TENANT1,f'user:{TENANT1}:user',1,,,,,,,,,,
python-jose,https://github.com/mpdavis/python-jose/tree/master/jose/backends/cryptography_backend.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/python-jose/jose/backends/cryptography_backend.py,CryptographyECKey,"def sign(self, msg):
    if self.hash_alg.digest_size * 8 > self.prepared_key.curve.key_size:
        raise TypeError('this curve (%s) is too short for your digest (%d)' % (self.prepared_key.curve.name, 8 * self.hash_alg.digest_size))
    signature = self.prepared_key.sign(msg, ec.ECDSA(self.hash_alg()))
    return self._der_to_raw(signature)","'this curve (%s) is too short for your digest (%d)' % (self.prepared_key.curve.name, 8 * self.hash_alg.digest_size)",f"this curve ({self.prepared_key.curve.name}) is too short for your digest ({8 * self.hash_alg.digest_size})",1,,,,,,,,,,
swift,https://github.com/openstack/swift/tree/master/test/unit/common/middleware/test_keystoneauth.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/swift/test/unit/common/middleware/test_keystoneauth.py,TestAuthorizeReaderSystem,"def test_reader_put_elsewhere_fails(self):
    roles = operator_roles(self.test_auth) + [self.system_reader_role_1]
    identity = self._get_identity(roles=roles)
    account = '%s%s' % (self._get_account(identity), '2')
    self._check_authenticate(exception=HTTP_FORBIDDEN, identity=identity, account=account, env={'REQUEST_METHOD': 'PUT'})","'%s%s' % (self._get_account(identity), '2')",f"{self._get_account(identity)}2",1,,,,,,,,,,
django-wiki,https://github.com/django-wiki/django-wiki/tree/master/tests/plugins/images/test_markdown.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/django-wiki/tests/plugins/images/test_markdown.py,ImageMarkdownTests,"def check_escape(self, text_to_escape):
    md = markdown.ArticleMarkdown(article=self.root_article)
    md_text = md.convert('`%s`' % text_to_escape)
    self.assertNotIn('<figure', md_text)
    self.assertIn(text_to_escape, md_text)",'`%s`' % text_to_escape,f'`{text_to_escape}`',1,,,,,,,,,,
PGL,https://github.com/PaddlePaddle/PGL/tree/master/apps/Graph4Rec/env_run/src/datasets/ego_graph.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/PGL/apps/Graph4Rec/env_run/src/datasets/ego_graph.py,EgoGraphGenerator,"def __init__(self, config, graph, **kwargs):
    self.config = config
    self.graph = graph
    self.rank = kwargs.get('rank', 0)
    self.nrank = kwargs.get('nrank', 1)
    self.kwargs = kwargs
    self.edge_types = self.graph.get_edge_types()
    self.sample_num_list = kwargs.get('sample_list', self.config.sample_num_list)
    log.info('sample_num_list is %s' % repr(self.sample_num_list))",'sample_num_list is %s' % repr(self.sample_num_list),f"sample_num_list is {repr(self.sample_num_list)}",1,,,,,,,,,,
sympy,https://github.com/sympy/sympy/tree/master/sympy/printing/c.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/sympy/sympy/printing/c.py,C89CodePrinter,"def _print_Min(self, expr):
    if 'Min' in self.known_functions:
        return self._print_Function(expr)

    def inner_print_min(args):
        if len(args) == 1:
            return self._print(args[0])
        half = len(args) // 2
        return '((%(a)s < %(b)s) ? %(a)s : %(b)s)' % {'a': inner_print_min(args[:half]), 'b': inner_print_min(args[half:])}
    return inner_print_min(expr.args)","'((%(a)s < %(b)s) ? %(a)s : %(b)s)' % {'a': inner_print_min(args[:half]), 'b': inner_print_min(args[half:])}",f"(({inner_print_min(args[:half])} < {inner_print_min(args[half:])}) ? {inner_print_min(args[:half])} : {inner_print_min(args[half:])})",1,,,,,,,,,,
flask-peewee,https://github.com/coleifer/flask-peewee/tree/master/flask_peewee/tests/rest.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/flask-peewee/flask_peewee/tests/rest.py,RestApiOwnerAuthTestCase,"def test_detail_get(self):
    resp = self.app.get('/api/message/1/')
    self.assertEqual(resp.status_code, 404)
    self.create_messages()
    resp = self.app.get('/api/message/%s/' % self.normal_message.id)
    resp_json = self.response_json(resp)
    self.assertAPIMessage(resp_json, self.normal_message)",'/api/message/%s/' % self.normal_message.id,f"/api/message/{self.normal_message.id}/",1,,,,,,,,,,
vispy,https://github.com/vispy/vispy/tree/master/codegen/createglapi.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/vispy/codegen/createglapi.py,ProxyApiGenerator,"def _add_function(self, des):
    ret = self._returns(des)
    prefix = 'return ' if ret else ''
    argstr = ', '.join(des.args)
    self.lines.append('    def %s(self, %s):' % (des.apiname, argstr))
    self.lines.append('        %sself(""%s"", %r, %s)' % (prefix, apiname(des.name), ret, argstr))","'    def %s(self, %s):' % (des.apiname, argstr)","f""    def {des.apiname}(self, {argstr}):""",1,,,,,,,,,,
vispy,https://github.com/vispy/vispy/tree/master/codegen/createglapi.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/vispy/codegen/createglapi.py,ProxyApiGenerator,"def _add_function(self, des):
    ret = self._returns(des)
    prefix = 'return ' if ret else ''
    argstr = ', '.join(des.args)
    self.lines.append('    def %s(self, %s):' % (des.apiname, argstr))
    self.lines.append('        %sself(""%s"", %r, %s)' % (prefix, apiname(des.name), ret, argstr))","'        %sself(""%s"", %r, %s)' % (prefix, apiname(des.name), ret, argstr)","f'        {prefix}self(""{apiname(des.name)}"", {ret}, {argstr})'",1,,,,,,,,,,
yamllint,https://github.com/adrienverge/yamllint/tree/master/yamllint/cli.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/yamllint/yamllint/cli.py,Format,"def standard_color(problem, filename):
    line = '  \x1b[2m%d:%d\x1b[0m' % (problem.line, problem.column)
    line += max(20 - len(line), 0) * ' '
    if problem.level == 'warning':
        line += '\x1b[33m%s\x1b[0m' % problem.level
    else:
        line += '\x1b[31m%s\x1b[0m' % problem.level
    line += max(38 - len(line), 0) * ' '
    line += problem.desc
    if problem.rule:
        line += '  \x1b[2m(%s)\x1b[0m' % problem.rule
    return line","'  \x1b[2m%d:%d\x1b[0m' % (problem.line, problem.column)",f'  \x1b[2m{problem.line}:{problem.column}\x1b[0m',1,,,,,,,,,,
yamllint,https://github.com/adrienverge/yamllint/tree/master/yamllint/cli.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/yamllint/yamllint/cli.py,Format,"def standard_color(problem, filename):
    line = '  \x1b[2m%d:%d\x1b[0m' % (problem.line, problem.column)
    line += max(20 - len(line), 0) * ' '
    if problem.level == 'warning':
        line += '\x1b[33m%s\x1b[0m' % problem.level
    else:
        line += '\x1b[31m%s\x1b[0m' % problem.level
    line += max(38 - len(line), 0) * ' '
    line += problem.desc
    if problem.rule:
        line += '  \x1b[2m(%s)\x1b[0m' % problem.rule
    return line",'\x1b[33m%s\x1b[0m' % problem.level,f'\x1b[33m{problem.level}\x1b[0m',1,,,,,,,,,,
yamllint,https://github.com/adrienverge/yamllint/tree/master/yamllint/cli.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/yamllint/yamllint/cli.py,Format,"def standard_color(problem, filename):
    line = '  \x1b[2m%d:%d\x1b[0m' % (problem.line, problem.column)
    line += max(20 - len(line), 0) * ' '
    if problem.level == 'warning':
        line += '\x1b[33m%s\x1b[0m' % problem.level
    else:
        line += '\x1b[31m%s\x1b[0m' % problem.level
    line += max(38 - len(line), 0) * ' '
    line += problem.desc
    if problem.rule:
        line += '  \x1b[2m(%s)\x1b[0m' % problem.rule
    return line",'\x1b[31m%s\x1b[0m' % problem.level,f"\x1b[31m{problem.level}\x1b[0m",1,,,,,,,,,,
yamllint,https://github.com/adrienverge/yamllint/tree/master/yamllint/cli.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/yamllint/yamllint/cli.py,Format,"def standard_color(problem, filename):
    line = '  \x1b[2m%d:%d\x1b[0m' % (problem.line, problem.column)
    line += max(20 - len(line), 0) * ' '
    if problem.level == 'warning':
        line += '\x1b[33m%s\x1b[0m' % problem.level
    else:
        line += '\x1b[31m%s\x1b[0m' % problem.level
    line += max(38 - len(line), 0) * ' '
    line += problem.desc
    if problem.rule:
        line += '  \x1b[2m(%s)\x1b[0m' % problem.rule
    return line",'  \x1b[2m(%s)\x1b[0m' % problem.rule,f'  \x1b[2m({problem.rule})\x1b[0m',1,,,,,,,,,,
pi-timolo,https://github.com/pageauc/pi-timolo/tree/master/source/pi-timolo-67/pi-timolo.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pi-timolo/source/pi-timolo-67/pi-timolo.py,,"def subDirCreate(directory, prefix):
    now = datetime.datetime.now()
    subDirName = '%s%d-%02d-%02d-%02d:%02d' % (prefix, now.year, now.month, now.day, now.hour, now.minute)
    subDirPath = os.path.join(directory, subDirName)
    if not os.path.exists(subDirPath):
        try:
            os.makedirs(subDirPath)
        except OSError as err:
            logging.error('Cannot Create Directory %s - %s, using default location.', subDirPath, err)
            subDirPath = directory
        else:
            logging.info('Created %s', subDirPath)
    else:
        subDirPath = directory
    return subDirPath","'%s%d-%02d-%02d-%02d:%02d' % (prefix, now.year, now.month, now.day, now.hour, now.minute)",f"{prefix}{now.year}{now.month:02d}{now.day:02d}-{now.hour:02d}:{now.minute:02d}",1,,,,,,,,,,
youtube-dl,https://github.com/lrvick/youtube-dl/tree/master/youtube_dl/extractor/rtve.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/youtube-dl/youtube_dl/extractor/rtve.py,RTVEALaCartaIE,"def _extract_png_formats(self, video_id):
    png = self._download_webpage('http://www.rtve.es/ztnr/movil/thumbnail/%s/videos/%s.png' % (self._manager, video_id), video_id, 'Downloading url information', query={'q': 'v2'})
    q = qualities(['Media', 'Alta', 'HQ', 'HD_READY', 'HD_FULL'])
    formats = []
    for (quality, video_url) in self._decrypt_url(png):
        ext = determine_ext(video_url)
        if ext == 'm3u8':
            formats.extend(self._extract_m3u8_formats(video_url, video_id, 'mp4', 'm3u8_native', m3u8_id='hls', fatal=False))
        elif ext == 'mpd':
            formats.extend(self._extract_mpd_formats(video_url, video_id, 'dash', fatal=False))
        else:
            formats.append({'format_id': quality, 'quality': q(quality), 'url': video_url})
    self._sort_formats(formats)
    return formats","'http://www.rtve.es/ztnr/movil/thumbnail/%s/videos/%s.png' % (self._manager, video_id)",f'http://www.rtve.es/ztnr/movil/thumbnail/{self._manager}/videos/{video_id}.png',1,,,,,,,,,,
pyquil,https://github.com/rigetti/pyquil/tree/master/pyquil/paulis.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pyquil/pyquil/paulis.py,PauliTerm,"def __repr__(self) -> str:
    term_strs = []
    for index in self._ops.keys():
        term_strs.append('%s%s' % (self[index], index))
    if len(term_strs) == 0:
        term_strs.append('I')
    out = '%s*%s' % (self.coefficient, '*'.join(term_strs))
    return out","'%s*%s' % (self.coefficient, '*'.join(term_strs))",f"{self.coefficient}*{'*'.join(term_strs)}",1,,,,,,,,,,
pyquil,https://github.com/rigetti/pyquil/tree/master/pyquil/paulis.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pyquil/pyquil/paulis.py,PauliTerm,"def __repr__(self) -> str:
    term_strs = []
    for index in self._ops.keys():
        term_strs.append('%s%s' % (self[index], index))
    if len(term_strs) == 0:
        term_strs.append('I')
    out = '%s*%s' % (self.coefficient, '*'.join(term_strs))
    return out","'%s%s' % (self[index], index)",f"{self[index]}{index}",1,,,,,,,,,,
recordlinkage,https://github.com/J535D165/recordlinkage/tree/master//versioneer.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/recordlinkage//versioneer.py,cmd_version,"def run(self):
    vers = get_versions(verbose=True)
    print('Version: %s' % vers['version'])
    print(' full-revisionid: %s' % vers.get('full-revisionid'))
    print(' dirty: %s' % vers.get('dirty'))
    if vers['error']:
        print(' error: %s' % vers['error'])",'Version: %s' % vers['version'],f"Version: {vers['version']}",1,,,,,,,,,,
recordlinkage,https://github.com/J535D165/recordlinkage/tree/master//versioneer.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/recordlinkage//versioneer.py,cmd_version,"def run(self):
    vers = get_versions(verbose=True)
    print('Version: %s' % vers['version'])
    print(' full-revisionid: %s' % vers.get('full-revisionid'))
    print(' dirty: %s' % vers.get('dirty'))
    if vers['error']:
        print(' error: %s' % vers['error'])",' full-revisionid: %s' % vers.get('full-revisionid'),f" full-revisionid: {vers.get('full-revisionid')}",1,,,,,,,,,,
recordlinkage,https://github.com/J535D165/recordlinkage/tree/master//versioneer.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/recordlinkage//versioneer.py,cmd_version,"def run(self):
    vers = get_versions(verbose=True)
    print('Version: %s' % vers['version'])
    print(' full-revisionid: %s' % vers.get('full-revisionid'))
    print(' dirty: %s' % vers.get('dirty'))
    if vers['error']:
        print(' error: %s' % vers['error'])",' dirty: %s' % vers.get('dirty'),f" dirty: {vers.get('dirty')}",1,,,,,,,,,,
recordlinkage,https://github.com/J535D165/recordlinkage/tree/master//versioneer.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/recordlinkage//versioneer.py,cmd_version,"def run(self):
    vers = get_versions(verbose=True)
    print('Version: %s' % vers['version'])
    print(' full-revisionid: %s' % vers.get('full-revisionid'))
    print(' dirty: %s' % vers.get('dirty'))
    if vers['error']:
        print(' error: %s' % vers['error'])",' error: %s' % vers['error'],f" error: {vers['error']}",1,,,,,,,,,,
doit,https://github.com/pydoit/doit/tree/master/doit/task.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/doit/doit/task.py,Task,"def clean(self, outstream, dryrun):
    """"""Execute task's clean
        @ivar outstream: 'write' output into this stream
        @ivar dryrun (bool): if True clean tasks are not executed
                             (just print out what would be executed)
        """"""
    self.init_options()
    if self._remove_targets is True:
        clean_targets(self, dryrun)
    else:
        for action in self.clean_actions:
            msg = ""%s - executing '%s'\n""
            outstream.write(msg % (self.name, action))
            execute_on_dryrun = False
            if isinstance(action, PythonAction):
                action_sig = inspect.signature(action.py_callable)
                if 'dryrun' in action_sig.parameters:
                    execute_on_dryrun = True
                    action.kwargs['dryrun'] = dryrun
            if not dryrun or execute_on_dryrun:
                result = action.execute(out=outstream)
                if isinstance(result, CatchedException):
                    sys.stderr.write(str(result))","msg % (self.name, action)","f""{msg} {self.name}, {action}""",1,,,,,,,,,,
deep_gcns,https://github.com/lightaime/deep_gcns/tree/master/sem_seg/indoor3d_util.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/deep_gcns/sem_seg/indoor3d_util.py,,"def bbox_label_to_obj_room(input_filename, out_filename_prefix, easy_view=False, permute=None, center=False, exclude_table=False):
    """""" Visualization of bounding boxes.

  Args:
    input_filename: each line is x1 y1 z1 x2 y2 z2 label
    out_filename_prefix: OBJ filename prefix,
      visualize object by g_label2color
    easy_view: if True, only visualize furniture and floor
    permute: if not None, permute XYZ for rendering, e.g. [0 2 1]
    center: if True, move obj to have zero origin
  Returns:
    output a list of OBJ file and MTL files with the same prefix
  """"""
    bbox_label = np.loadtxt(input_filename)
    bbox = bbox_label[:, 0:6]
    if permute is not None:
        assert len(permute) == 3
        permute = np.array(permute)
        bbox[:, 0:3] = bbox[:, permute]
        bbox[:, 3:6] = bbox[:, permute + 3]
    if center:
        xyz_max = np.amax(bbox[:, 3:6], 0)
        bbox[:, 0:3] -= xyz_max / 2.0
        bbox[:, 3:6] -= xyz_max / 2.0
        bbox /= np.max(xyz_max / 2.0)
    label = bbox_label[:, -1].astype(int)
    obj_filename = out_filename_prefix + '.obj'
    mtl_filename = out_filename_prefix + '.mtl'
    fout_obj = open(obj_filename, 'w')
    fout_mtl = open(mtl_filename, 'w')
    fout_obj.write('mtllib %s\n' % os.path.basename(mtl_filename))
    v_cnt = 0
    ins_cnt = 0
    for i in range(bbox.shape[0]):
        if easy_view and label[i] not in g_easy_view_labels:
            continue
        if exclude_table and label[i] == g_classes.index('table'):
            continue
        length = bbox[i, 3:6] - bbox[i, 0:3]
        a = length[0]
        b = length[1]
        c = length[2]
        x = bbox[i, 0]
        y = bbox[i, 1]
        z = bbox[i, 2]
        color = np.array(g_label2color[label[i]], dtype=float) / 255.0
        material = 'material%d' % ins_cnt
        fout_obj.write('usemtl %s\n' % material)
        fout_obj.write('v %f %f %f\n' % (x, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y, z))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z))
        fout_obj.write('g default\n')
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 3 + v_cnt, 2 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (1 + v_cnt, 2 + v_cnt, 6 + v_cnt, 5 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (7 + v_cnt, 6 + v_cnt, 2 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 8 + v_cnt, 7 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 8 + v_cnt, 4 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 6 + v_cnt, 7 + v_cnt, 8 + v_cnt))
        fout_obj.write('\n')
        fout_mtl.write('newmtl %s\n' % material)
        fout_mtl.write('Kd %f %f %f\n' % (color[0], color[1], color[2]))
        fout_mtl.write('\n')
        v_cnt += 8
        ins_cnt += 1
    fout_obj.close()
    fout_mtl.close()",'mtllib %s\n' % os.path.basename(mtl_filename),f"mtllib {os.path.basename(mtl_filename)}\n",1,,,,,,,,,,
deep_gcns,https://github.com/lightaime/deep_gcns/tree/master/sem_seg/indoor3d_util.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/deep_gcns/sem_seg/indoor3d_util.py,,"def bbox_label_to_obj_room(input_filename, out_filename_prefix, easy_view=False, permute=None, center=False, exclude_table=False):
    """""" Visualization of bounding boxes.

  Args:
    input_filename: each line is x1 y1 z1 x2 y2 z2 label
    out_filename_prefix: OBJ filename prefix,
      visualize object by g_label2color
    easy_view: if True, only visualize furniture and floor
    permute: if not None, permute XYZ for rendering, e.g. [0 2 1]
    center: if True, move obj to have zero origin
  Returns:
    output a list of OBJ file and MTL files with the same prefix
  """"""
    bbox_label = np.loadtxt(input_filename)
    bbox = bbox_label[:, 0:6]
    if permute is not None:
        assert len(permute) == 3
        permute = np.array(permute)
        bbox[:, 0:3] = bbox[:, permute]
        bbox[:, 3:6] = bbox[:, permute + 3]
    if center:
        xyz_max = np.amax(bbox[:, 3:6], 0)
        bbox[:, 0:3] -= xyz_max / 2.0
        bbox[:, 3:6] -= xyz_max / 2.0
        bbox /= np.max(xyz_max / 2.0)
    label = bbox_label[:, -1].astype(int)
    obj_filename = out_filename_prefix + '.obj'
    mtl_filename = out_filename_prefix + '.mtl'
    fout_obj = open(obj_filename, 'w')
    fout_mtl = open(mtl_filename, 'w')
    fout_obj.write('mtllib %s\n' % os.path.basename(mtl_filename))
    v_cnt = 0
    ins_cnt = 0
    for i in range(bbox.shape[0]):
        if easy_view and label[i] not in g_easy_view_labels:
            continue
        if exclude_table and label[i] == g_classes.index('table'):
            continue
        length = bbox[i, 3:6] - bbox[i, 0:3]
        a = length[0]
        b = length[1]
        c = length[2]
        x = bbox[i, 0]
        y = bbox[i, 1]
        z = bbox[i, 2]
        color = np.array(g_label2color[label[i]], dtype=float) / 255.0
        material = 'material%d' % ins_cnt
        fout_obj.write('usemtl %s\n' % material)
        fout_obj.write('v %f %f %f\n' % (x, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y, z))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z))
        fout_obj.write('g default\n')
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 3 + v_cnt, 2 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (1 + v_cnt, 2 + v_cnt, 6 + v_cnt, 5 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (7 + v_cnt, 6 + v_cnt, 2 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 8 + v_cnt, 7 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 8 + v_cnt, 4 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 6 + v_cnt, 7 + v_cnt, 8 + v_cnt))
        fout_obj.write('\n')
        fout_mtl.write('newmtl %s\n' % material)
        fout_mtl.write('Kd %f %f %f\n' % (color[0], color[1], color[2]))
        fout_mtl.write('\n')
        v_cnt += 8
        ins_cnt += 1
    fout_obj.close()
    fout_mtl.close()",'material%d' % ins_cnt,f"material{ins_cnt}",1,,,,,,,,,,
deep_gcns,https://github.com/lightaime/deep_gcns/tree/master/sem_seg/indoor3d_util.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/deep_gcns/sem_seg/indoor3d_util.py,,"def bbox_label_to_obj_room(input_filename, out_filename_prefix, easy_view=False, permute=None, center=False, exclude_table=False):
    """""" Visualization of bounding boxes.

  Args:
    input_filename: each line is x1 y1 z1 x2 y2 z2 label
    out_filename_prefix: OBJ filename prefix,
      visualize object by g_label2color
    easy_view: if True, only visualize furniture and floor
    permute: if not None, permute XYZ for rendering, e.g. [0 2 1]
    center: if True, move obj to have zero origin
  Returns:
    output a list of OBJ file and MTL files with the same prefix
  """"""
    bbox_label = np.loadtxt(input_filename)
    bbox = bbox_label[:, 0:6]
    if permute is not None:
        assert len(permute) == 3
        permute = np.array(permute)
        bbox[:, 0:3] = bbox[:, permute]
        bbox[:, 3:6] = bbox[:, permute + 3]
    if center:
        xyz_max = np.amax(bbox[:, 3:6], 0)
        bbox[:, 0:3] -= xyz_max / 2.0
        bbox[:, 3:6] -= xyz_max / 2.0
        bbox /= np.max(xyz_max / 2.0)
    label = bbox_label[:, -1].astype(int)
    obj_filename = out_filename_prefix + '.obj'
    mtl_filename = out_filename_prefix + '.mtl'
    fout_obj = open(obj_filename, 'w')
    fout_mtl = open(mtl_filename, 'w')
    fout_obj.write('mtllib %s\n' % os.path.basename(mtl_filename))
    v_cnt = 0
    ins_cnt = 0
    for i in range(bbox.shape[0]):
        if easy_view and label[i] not in g_easy_view_labels:
            continue
        if exclude_table and label[i] == g_classes.index('table'):
            continue
        length = bbox[i, 3:6] - bbox[i, 0:3]
        a = length[0]
        b = length[1]
        c = length[2]
        x = bbox[i, 0]
        y = bbox[i, 1]
        z = bbox[i, 2]
        color = np.array(g_label2color[label[i]], dtype=float) / 255.0
        material = 'material%d' % ins_cnt
        fout_obj.write('usemtl %s\n' % material)
        fout_obj.write('v %f %f %f\n' % (x, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y, z))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z))
        fout_obj.write('g default\n')
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 3 + v_cnt, 2 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (1 + v_cnt, 2 + v_cnt, 6 + v_cnt, 5 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (7 + v_cnt, 6 + v_cnt, 2 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 8 + v_cnt, 7 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 8 + v_cnt, 4 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 6 + v_cnt, 7 + v_cnt, 8 + v_cnt))
        fout_obj.write('\n')
        fout_mtl.write('newmtl %s\n' % material)
        fout_mtl.write('Kd %f %f %f\n' % (color[0], color[1], color[2]))
        fout_mtl.write('\n')
        v_cnt += 8
        ins_cnt += 1
    fout_obj.close()
    fout_mtl.close()",'usemtl %s\n' % material,f'usemtl {material}\n',1,,,,,,,,,,
deep_gcns,https://github.com/lightaime/deep_gcns/tree/master/sem_seg/indoor3d_util.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/deep_gcns/sem_seg/indoor3d_util.py,,"def bbox_label_to_obj_room(input_filename, out_filename_prefix, easy_view=False, permute=None, center=False, exclude_table=False):
    """""" Visualization of bounding boxes.

  Args:
    input_filename: each line is x1 y1 z1 x2 y2 z2 label
    out_filename_prefix: OBJ filename prefix,
      visualize object by g_label2color
    easy_view: if True, only visualize furniture and floor
    permute: if not None, permute XYZ for rendering, e.g. [0 2 1]
    center: if True, move obj to have zero origin
  Returns:
    output a list of OBJ file and MTL files with the same prefix
  """"""
    bbox_label = np.loadtxt(input_filename)
    bbox = bbox_label[:, 0:6]
    if permute is not None:
        assert len(permute) == 3
        permute = np.array(permute)
        bbox[:, 0:3] = bbox[:, permute]
        bbox[:, 3:6] = bbox[:, permute + 3]
    if center:
        xyz_max = np.amax(bbox[:, 3:6], 0)
        bbox[:, 0:3] -= xyz_max / 2.0
        bbox[:, 3:6] -= xyz_max / 2.0
        bbox /= np.max(xyz_max / 2.0)
    label = bbox_label[:, -1].astype(int)
    obj_filename = out_filename_prefix + '.obj'
    mtl_filename = out_filename_prefix + '.mtl'
    fout_obj = open(obj_filename, 'w')
    fout_mtl = open(mtl_filename, 'w')
    fout_obj.write('mtllib %s\n' % os.path.basename(mtl_filename))
    v_cnt = 0
    ins_cnt = 0
    for i in range(bbox.shape[0]):
        if easy_view and label[i] not in g_easy_view_labels:
            continue
        if exclude_table and label[i] == g_classes.index('table'):
            continue
        length = bbox[i, 3:6] - bbox[i, 0:3]
        a = length[0]
        b = length[1]
        c = length[2]
        x = bbox[i, 0]
        y = bbox[i, 1]
        z = bbox[i, 2]
        color = np.array(g_label2color[label[i]], dtype=float) / 255.0
        material = 'material%d' % ins_cnt
        fout_obj.write('usemtl %s\n' % material)
        fout_obj.write('v %f %f %f\n' % (x, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y, z))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z))
        fout_obj.write('g default\n')
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 3 + v_cnt, 2 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (1 + v_cnt, 2 + v_cnt, 6 + v_cnt, 5 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (7 + v_cnt, 6 + v_cnt, 2 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 8 + v_cnt, 7 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 8 + v_cnt, 4 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 6 + v_cnt, 7 + v_cnt, 8 + v_cnt))
        fout_obj.write('\n')
        fout_mtl.write('newmtl %s\n' % material)
        fout_mtl.write('Kd %f %f %f\n' % (color[0], color[1], color[2]))
        fout_mtl.write('\n')
        v_cnt += 8
        ins_cnt += 1
    fout_obj.close()
    fout_mtl.close()","'v %f %f %f\n' % (x, y, z + c)",'v {x} {y} {z+c}\n',1,,,,,,,,,,
deep_gcns,https://github.com/lightaime/deep_gcns/tree/master/sem_seg/indoor3d_util.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/deep_gcns/sem_seg/indoor3d_util.py,,"def bbox_label_to_obj_room(input_filename, out_filename_prefix, easy_view=False, permute=None, center=False, exclude_table=False):
    """""" Visualization of bounding boxes.

  Args:
    input_filename: each line is x1 y1 z1 x2 y2 z2 label
    out_filename_prefix: OBJ filename prefix,
      visualize object by g_label2color
    easy_view: if True, only visualize furniture and floor
    permute: if not None, permute XYZ for rendering, e.g. [0 2 1]
    center: if True, move obj to have zero origin
  Returns:
    output a list of OBJ file and MTL files with the same prefix
  """"""
    bbox_label = np.loadtxt(input_filename)
    bbox = bbox_label[:, 0:6]
    if permute is not None:
        assert len(permute) == 3
        permute = np.array(permute)
        bbox[:, 0:3] = bbox[:, permute]
        bbox[:, 3:6] = bbox[:, permute + 3]
    if center:
        xyz_max = np.amax(bbox[:, 3:6], 0)
        bbox[:, 0:3] -= xyz_max / 2.0
        bbox[:, 3:6] -= xyz_max / 2.0
        bbox /= np.max(xyz_max / 2.0)
    label = bbox_label[:, -1].astype(int)
    obj_filename = out_filename_prefix + '.obj'
    mtl_filename = out_filename_prefix + '.mtl'
    fout_obj = open(obj_filename, 'w')
    fout_mtl = open(mtl_filename, 'w')
    fout_obj.write('mtllib %s\n' % os.path.basename(mtl_filename))
    v_cnt = 0
    ins_cnt = 0
    for i in range(bbox.shape[0]):
        if easy_view and label[i] not in g_easy_view_labels:
            continue
        if exclude_table and label[i] == g_classes.index('table'):
            continue
        length = bbox[i, 3:6] - bbox[i, 0:3]
        a = length[0]
        b = length[1]
        c = length[2]
        x = bbox[i, 0]
        y = bbox[i, 1]
        z = bbox[i, 2]
        color = np.array(g_label2color[label[i]], dtype=float) / 255.0
        material = 'material%d' % ins_cnt
        fout_obj.write('usemtl %s\n' % material)
        fout_obj.write('v %f %f %f\n' % (x, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y, z))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z))
        fout_obj.write('g default\n')
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 3 + v_cnt, 2 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (1 + v_cnt, 2 + v_cnt, 6 + v_cnt, 5 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (7 + v_cnt, 6 + v_cnt, 2 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 8 + v_cnt, 7 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 8 + v_cnt, 4 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 6 + v_cnt, 7 + v_cnt, 8 + v_cnt))
        fout_obj.write('\n')
        fout_mtl.write('newmtl %s\n' % material)
        fout_mtl.write('Kd %f %f %f\n' % (color[0], color[1], color[2]))
        fout_mtl.write('\n')
        v_cnt += 8
        ins_cnt += 1
    fout_obj.close()
    fout_mtl.close()","'v %f %f %f\n' % (x, y + b, z + c)",f'v {x} {y+b} {z+c}\n',1,,,,,,,,,,
deep_gcns,https://github.com/lightaime/deep_gcns/tree/master/sem_seg/indoor3d_util.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/deep_gcns/sem_seg/indoor3d_util.py,,"def bbox_label_to_obj_room(input_filename, out_filename_prefix, easy_view=False, permute=None, center=False, exclude_table=False):
    """""" Visualization of bounding boxes.

  Args:
    input_filename: each line is x1 y1 z1 x2 y2 z2 label
    out_filename_prefix: OBJ filename prefix,
      visualize object by g_label2color
    easy_view: if True, only visualize furniture and floor
    permute: if not None, permute XYZ for rendering, e.g. [0 2 1]
    center: if True, move obj to have zero origin
  Returns:
    output a list of OBJ file and MTL files with the same prefix
  """"""
    bbox_label = np.loadtxt(input_filename)
    bbox = bbox_label[:, 0:6]
    if permute is not None:
        assert len(permute) == 3
        permute = np.array(permute)
        bbox[:, 0:3] = bbox[:, permute]
        bbox[:, 3:6] = bbox[:, permute + 3]
    if center:
        xyz_max = np.amax(bbox[:, 3:6], 0)
        bbox[:, 0:3] -= xyz_max / 2.0
        bbox[:, 3:6] -= xyz_max / 2.0
        bbox /= np.max(xyz_max / 2.0)
    label = bbox_label[:, -1].astype(int)
    obj_filename = out_filename_prefix + '.obj'
    mtl_filename = out_filename_prefix + '.mtl'
    fout_obj = open(obj_filename, 'w')
    fout_mtl = open(mtl_filename, 'w')
    fout_obj.write('mtllib %s\n' % os.path.basename(mtl_filename))
    v_cnt = 0
    ins_cnt = 0
    for i in range(bbox.shape[0]):
        if easy_view and label[i] not in g_easy_view_labels:
            continue
        if exclude_table and label[i] == g_classes.index('table'):
            continue
        length = bbox[i, 3:6] - bbox[i, 0:3]
        a = length[0]
        b = length[1]
        c = length[2]
        x = bbox[i, 0]
        y = bbox[i, 1]
        z = bbox[i, 2]
        color = np.array(g_label2color[label[i]], dtype=float) / 255.0
        material = 'material%d' % ins_cnt
        fout_obj.write('usemtl %s\n' % material)
        fout_obj.write('v %f %f %f\n' % (x, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y, z))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z))
        fout_obj.write('g default\n')
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 3 + v_cnt, 2 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (1 + v_cnt, 2 + v_cnt, 6 + v_cnt, 5 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (7 + v_cnt, 6 + v_cnt, 2 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 8 + v_cnt, 7 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 8 + v_cnt, 4 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 6 + v_cnt, 7 + v_cnt, 8 + v_cnt))
        fout_obj.write('\n')
        fout_mtl.write('newmtl %s\n' % material)
        fout_mtl.write('Kd %f %f %f\n' % (color[0], color[1], color[2]))
        fout_mtl.write('\n')
        v_cnt += 8
        ins_cnt += 1
    fout_obj.close()
    fout_mtl.close()","'v %f %f %f\n' % (x + a, y + b, z + c)",f'v {x+a} {y+b} {z+c}\n',1,,,,,,,,,,
deep_gcns,https://github.com/lightaime/deep_gcns/tree/master/sem_seg/indoor3d_util.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/deep_gcns/sem_seg/indoor3d_util.py,,"def bbox_label_to_obj_room(input_filename, out_filename_prefix, easy_view=False, permute=None, center=False, exclude_table=False):
    """""" Visualization of bounding boxes.

  Args:
    input_filename: each line is x1 y1 z1 x2 y2 z2 label
    out_filename_prefix: OBJ filename prefix,
      visualize object by g_label2color
    easy_view: if True, only visualize furniture and floor
    permute: if not None, permute XYZ for rendering, e.g. [0 2 1]
    center: if True, move obj to have zero origin
  Returns:
    output a list of OBJ file and MTL files with the same prefix
  """"""
    bbox_label = np.loadtxt(input_filename)
    bbox = bbox_label[:, 0:6]
    if permute is not None:
        assert len(permute) == 3
        permute = np.array(permute)
        bbox[:, 0:3] = bbox[:, permute]
        bbox[:, 3:6] = bbox[:, permute + 3]
    if center:
        xyz_max = np.amax(bbox[:, 3:6], 0)
        bbox[:, 0:3] -= xyz_max / 2.0
        bbox[:, 3:6] -= xyz_max / 2.0
        bbox /= np.max(xyz_max / 2.0)
    label = bbox_label[:, -1].astype(int)
    obj_filename = out_filename_prefix + '.obj'
    mtl_filename = out_filename_prefix + '.mtl'
    fout_obj = open(obj_filename, 'w')
    fout_mtl = open(mtl_filename, 'w')
    fout_obj.write('mtllib %s\n' % os.path.basename(mtl_filename))
    v_cnt = 0
    ins_cnt = 0
    for i in range(bbox.shape[0]):
        if easy_view and label[i] not in g_easy_view_labels:
            continue
        if exclude_table and label[i] == g_classes.index('table'):
            continue
        length = bbox[i, 3:6] - bbox[i, 0:3]
        a = length[0]
        b = length[1]
        c = length[2]
        x = bbox[i, 0]
        y = bbox[i, 1]
        z = bbox[i, 2]
        color = np.array(g_label2color[label[i]], dtype=float) / 255.0
        material = 'material%d' % ins_cnt
        fout_obj.write('usemtl %s\n' % material)
        fout_obj.write('v %f %f %f\n' % (x, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y, z))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z))
        fout_obj.write('g default\n')
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 3 + v_cnt, 2 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (1 + v_cnt, 2 + v_cnt, 6 + v_cnt, 5 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (7 + v_cnt, 6 + v_cnt, 2 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 8 + v_cnt, 7 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 8 + v_cnt, 4 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 6 + v_cnt, 7 + v_cnt, 8 + v_cnt))
        fout_obj.write('\n')
        fout_mtl.write('newmtl %s\n' % material)
        fout_mtl.write('Kd %f %f %f\n' % (color[0], color[1], color[2]))
        fout_mtl.write('\n')
        v_cnt += 8
        ins_cnt += 1
    fout_obj.close()
    fout_mtl.close()","'v %f %f %f\n' % (x + a, y, z + c)",f'v {x+a} {y} {z+c}\n',1,,,,,,,,,,
deep_gcns,https://github.com/lightaime/deep_gcns/tree/master/sem_seg/indoor3d_util.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/deep_gcns/sem_seg/indoor3d_util.py,,"def bbox_label_to_obj_room(input_filename, out_filename_prefix, easy_view=False, permute=None, center=False, exclude_table=False):
    """""" Visualization of bounding boxes.

  Args:
    input_filename: each line is x1 y1 z1 x2 y2 z2 label
    out_filename_prefix: OBJ filename prefix,
      visualize object by g_label2color
    easy_view: if True, only visualize furniture and floor
    permute: if not None, permute XYZ for rendering, e.g. [0 2 1]
    center: if True, move obj to have zero origin
  Returns:
    output a list of OBJ file and MTL files with the same prefix
  """"""
    bbox_label = np.loadtxt(input_filename)
    bbox = bbox_label[:, 0:6]
    if permute is not None:
        assert len(permute) == 3
        permute = np.array(permute)
        bbox[:, 0:3] = bbox[:, permute]
        bbox[:, 3:6] = bbox[:, permute + 3]
    if center:
        xyz_max = np.amax(bbox[:, 3:6], 0)
        bbox[:, 0:3] -= xyz_max / 2.0
        bbox[:, 3:6] -= xyz_max / 2.0
        bbox /= np.max(xyz_max / 2.0)
    label = bbox_label[:, -1].astype(int)
    obj_filename = out_filename_prefix + '.obj'
    mtl_filename = out_filename_prefix + '.mtl'
    fout_obj = open(obj_filename, 'w')
    fout_mtl = open(mtl_filename, 'w')
    fout_obj.write('mtllib %s\n' % os.path.basename(mtl_filename))
    v_cnt = 0
    ins_cnt = 0
    for i in range(bbox.shape[0]):
        if easy_view and label[i] not in g_easy_view_labels:
            continue
        if exclude_table and label[i] == g_classes.index('table'):
            continue
        length = bbox[i, 3:6] - bbox[i, 0:3]
        a = length[0]
        b = length[1]
        c = length[2]
        x = bbox[i, 0]
        y = bbox[i, 1]
        z = bbox[i, 2]
        color = np.array(g_label2color[label[i]], dtype=float) / 255.0
        material = 'material%d' % ins_cnt
        fout_obj.write('usemtl %s\n' % material)
        fout_obj.write('v %f %f %f\n' % (x, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y, z))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z))
        fout_obj.write('g default\n')
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 3 + v_cnt, 2 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (1 + v_cnt, 2 + v_cnt, 6 + v_cnt, 5 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (7 + v_cnt, 6 + v_cnt, 2 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 8 + v_cnt, 7 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 8 + v_cnt, 4 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 6 + v_cnt, 7 + v_cnt, 8 + v_cnt))
        fout_obj.write('\n')
        fout_mtl.write('newmtl %s\n' % material)
        fout_mtl.write('Kd %f %f %f\n' % (color[0], color[1], color[2]))
        fout_mtl.write('\n')
        v_cnt += 8
        ins_cnt += 1
    fout_obj.close()
    fout_mtl.close()","'v %f %f %f\n' % (x, y, z)",'v {x} {y} {z}\n',1,,,,,,,,,,
deep_gcns,https://github.com/lightaime/deep_gcns/tree/master/sem_seg/indoor3d_util.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/deep_gcns/sem_seg/indoor3d_util.py,,"def bbox_label_to_obj_room(input_filename, out_filename_prefix, easy_view=False, permute=None, center=False, exclude_table=False):
    """""" Visualization of bounding boxes.

  Args:
    input_filename: each line is x1 y1 z1 x2 y2 z2 label
    out_filename_prefix: OBJ filename prefix,
      visualize object by g_label2color
    easy_view: if True, only visualize furniture and floor
    permute: if not None, permute XYZ for rendering, e.g. [0 2 1]
    center: if True, move obj to have zero origin
  Returns:
    output a list of OBJ file and MTL files with the same prefix
  """"""
    bbox_label = np.loadtxt(input_filename)
    bbox = bbox_label[:, 0:6]
    if permute is not None:
        assert len(permute) == 3
        permute = np.array(permute)
        bbox[:, 0:3] = bbox[:, permute]
        bbox[:, 3:6] = bbox[:, permute + 3]
    if center:
        xyz_max = np.amax(bbox[:, 3:6], 0)
        bbox[:, 0:3] -= xyz_max / 2.0
        bbox[:, 3:6] -= xyz_max / 2.0
        bbox /= np.max(xyz_max / 2.0)
    label = bbox_label[:, -1].astype(int)
    obj_filename = out_filename_prefix + '.obj'
    mtl_filename = out_filename_prefix + '.mtl'
    fout_obj = open(obj_filename, 'w')
    fout_mtl = open(mtl_filename, 'w')
    fout_obj.write('mtllib %s\n' % os.path.basename(mtl_filename))
    v_cnt = 0
    ins_cnt = 0
    for i in range(bbox.shape[0]):
        if easy_view and label[i] not in g_easy_view_labels:
            continue
        if exclude_table and label[i] == g_classes.index('table'):
            continue
        length = bbox[i, 3:6] - bbox[i, 0:3]
        a = length[0]
        b = length[1]
        c = length[2]
        x = bbox[i, 0]
        y = bbox[i, 1]
        z = bbox[i, 2]
        color = np.array(g_label2color[label[i]], dtype=float) / 255.0
        material = 'material%d' % ins_cnt
        fout_obj.write('usemtl %s\n' % material)
        fout_obj.write('v %f %f %f\n' % (x, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y, z))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z))
        fout_obj.write('g default\n')
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 3 + v_cnt, 2 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (1 + v_cnt, 2 + v_cnt, 6 + v_cnt, 5 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (7 + v_cnt, 6 + v_cnt, 2 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 8 + v_cnt, 7 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 8 + v_cnt, 4 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 6 + v_cnt, 7 + v_cnt, 8 + v_cnt))
        fout_obj.write('\n')
        fout_mtl.write('newmtl %s\n' % material)
        fout_mtl.write('Kd %f %f %f\n' % (color[0], color[1], color[2]))
        fout_mtl.write('\n')
        v_cnt += 8
        ins_cnt += 1
    fout_obj.close()
    fout_mtl.close()","'v %f %f %f\n' % (x, y + b, z)",f'v {x} {y+b} {z}\n',1,,,,,,,,,,
deep_gcns,https://github.com/lightaime/deep_gcns/tree/master/sem_seg/indoor3d_util.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/deep_gcns/sem_seg/indoor3d_util.py,,"def bbox_label_to_obj_room(input_filename, out_filename_prefix, easy_view=False, permute=None, center=False, exclude_table=False):
    """""" Visualization of bounding boxes.

  Args:
    input_filename: each line is x1 y1 z1 x2 y2 z2 label
    out_filename_prefix: OBJ filename prefix,
      visualize object by g_label2color
    easy_view: if True, only visualize furniture and floor
    permute: if not None, permute XYZ for rendering, e.g. [0 2 1]
    center: if True, move obj to have zero origin
  Returns:
    output a list of OBJ file and MTL files with the same prefix
  """"""
    bbox_label = np.loadtxt(input_filename)
    bbox = bbox_label[:, 0:6]
    if permute is not None:
        assert len(permute) == 3
        permute = np.array(permute)
        bbox[:, 0:3] = bbox[:, permute]
        bbox[:, 3:6] = bbox[:, permute + 3]
    if center:
        xyz_max = np.amax(bbox[:, 3:6], 0)
        bbox[:, 0:3] -= xyz_max / 2.0
        bbox[:, 3:6] -= xyz_max / 2.0
        bbox /= np.max(xyz_max / 2.0)
    label = bbox_label[:, -1].astype(int)
    obj_filename = out_filename_prefix + '.obj'
    mtl_filename = out_filename_prefix + '.mtl'
    fout_obj = open(obj_filename, 'w')
    fout_mtl = open(mtl_filename, 'w')
    fout_obj.write('mtllib %s\n' % os.path.basename(mtl_filename))
    v_cnt = 0
    ins_cnt = 0
    for i in range(bbox.shape[0]):
        if easy_view and label[i] not in g_easy_view_labels:
            continue
        if exclude_table and label[i] == g_classes.index('table'):
            continue
        length = bbox[i, 3:6] - bbox[i, 0:3]
        a = length[0]
        b = length[1]
        c = length[2]
        x = bbox[i, 0]
        y = bbox[i, 1]
        z = bbox[i, 2]
        color = np.array(g_label2color[label[i]], dtype=float) / 255.0
        material = 'material%d' % ins_cnt
        fout_obj.write('usemtl %s\n' % material)
        fout_obj.write('v %f %f %f\n' % (x, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y, z))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z))
        fout_obj.write('g default\n')
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 3 + v_cnt, 2 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (1 + v_cnt, 2 + v_cnt, 6 + v_cnt, 5 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (7 + v_cnt, 6 + v_cnt, 2 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 8 + v_cnt, 7 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 8 + v_cnt, 4 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 6 + v_cnt, 7 + v_cnt, 8 + v_cnt))
        fout_obj.write('\n')
        fout_mtl.write('newmtl %s\n' % material)
        fout_mtl.write('Kd %f %f %f\n' % (color[0], color[1], color[2]))
        fout_mtl.write('\n')
        v_cnt += 8
        ins_cnt += 1
    fout_obj.close()
    fout_mtl.close()","'v %f %f %f\n' % (x + a, y + b, z)",f"v {x+a} {y+b} {z}\n",1,,,,,,,,,,
deep_gcns,https://github.com/lightaime/deep_gcns/tree/master/sem_seg/indoor3d_util.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/deep_gcns/sem_seg/indoor3d_util.py,,"def bbox_label_to_obj_room(input_filename, out_filename_prefix, easy_view=False, permute=None, center=False, exclude_table=False):
    """""" Visualization of bounding boxes.

  Args:
    input_filename: each line is x1 y1 z1 x2 y2 z2 label
    out_filename_prefix: OBJ filename prefix,
      visualize object by g_label2color
    easy_view: if True, only visualize furniture and floor
    permute: if not None, permute XYZ for rendering, e.g. [0 2 1]
    center: if True, move obj to have zero origin
  Returns:
    output a list of OBJ file and MTL files with the same prefix
  """"""
    bbox_label = np.loadtxt(input_filename)
    bbox = bbox_label[:, 0:6]
    if permute is not None:
        assert len(permute) == 3
        permute = np.array(permute)
        bbox[:, 0:3] = bbox[:, permute]
        bbox[:, 3:6] = bbox[:, permute + 3]
    if center:
        xyz_max = np.amax(bbox[:, 3:6], 0)
        bbox[:, 0:3] -= xyz_max / 2.0
        bbox[:, 3:6] -= xyz_max / 2.0
        bbox /= np.max(xyz_max / 2.0)
    label = bbox_label[:, -1].astype(int)
    obj_filename = out_filename_prefix + '.obj'
    mtl_filename = out_filename_prefix + '.mtl'
    fout_obj = open(obj_filename, 'w')
    fout_mtl = open(mtl_filename, 'w')
    fout_obj.write('mtllib %s\n' % os.path.basename(mtl_filename))
    v_cnt = 0
    ins_cnt = 0
    for i in range(bbox.shape[0]):
        if easy_view and label[i] not in g_easy_view_labels:
            continue
        if exclude_table and label[i] == g_classes.index('table'):
            continue
        length = bbox[i, 3:6] - bbox[i, 0:3]
        a = length[0]
        b = length[1]
        c = length[2]
        x = bbox[i, 0]
        y = bbox[i, 1]
        z = bbox[i, 2]
        color = np.array(g_label2color[label[i]], dtype=float) / 255.0
        material = 'material%d' % ins_cnt
        fout_obj.write('usemtl %s\n' % material)
        fout_obj.write('v %f %f %f\n' % (x, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y, z))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z))
        fout_obj.write('g default\n')
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 3 + v_cnt, 2 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (1 + v_cnt, 2 + v_cnt, 6 + v_cnt, 5 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (7 + v_cnt, 6 + v_cnt, 2 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 8 + v_cnt, 7 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 8 + v_cnt, 4 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 6 + v_cnt, 7 + v_cnt, 8 + v_cnt))
        fout_obj.write('\n')
        fout_mtl.write('newmtl %s\n' % material)
        fout_mtl.write('Kd %f %f %f\n' % (color[0], color[1], color[2]))
        fout_mtl.write('\n')
        v_cnt += 8
        ins_cnt += 1
    fout_obj.close()
    fout_mtl.close()","'v %f %f %f\n' % (x + a, y, z)",f"v {x+a} {y} {z}\n",1,,,,,,,,,,
deep_gcns,https://github.com/lightaime/deep_gcns/tree/master/sem_seg/indoor3d_util.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/deep_gcns/sem_seg/indoor3d_util.py,,"def bbox_label_to_obj_room(input_filename, out_filename_prefix, easy_view=False, permute=None, center=False, exclude_table=False):
    """""" Visualization of bounding boxes.

  Args:
    input_filename: each line is x1 y1 z1 x2 y2 z2 label
    out_filename_prefix: OBJ filename prefix,
      visualize object by g_label2color
    easy_view: if True, only visualize furniture and floor
    permute: if not None, permute XYZ for rendering, e.g. [0 2 1]
    center: if True, move obj to have zero origin
  Returns:
    output a list of OBJ file and MTL files with the same prefix
  """"""
    bbox_label = np.loadtxt(input_filename)
    bbox = bbox_label[:, 0:6]
    if permute is not None:
        assert len(permute) == 3
        permute = np.array(permute)
        bbox[:, 0:3] = bbox[:, permute]
        bbox[:, 3:6] = bbox[:, permute + 3]
    if center:
        xyz_max = np.amax(bbox[:, 3:6], 0)
        bbox[:, 0:3] -= xyz_max / 2.0
        bbox[:, 3:6] -= xyz_max / 2.0
        bbox /= np.max(xyz_max / 2.0)
    label = bbox_label[:, -1].astype(int)
    obj_filename = out_filename_prefix + '.obj'
    mtl_filename = out_filename_prefix + '.mtl'
    fout_obj = open(obj_filename, 'w')
    fout_mtl = open(mtl_filename, 'w')
    fout_obj.write('mtllib %s\n' % os.path.basename(mtl_filename))
    v_cnt = 0
    ins_cnt = 0
    for i in range(bbox.shape[0]):
        if easy_view and label[i] not in g_easy_view_labels:
            continue
        if exclude_table and label[i] == g_classes.index('table'):
            continue
        length = bbox[i, 3:6] - bbox[i, 0:3]
        a = length[0]
        b = length[1]
        c = length[2]
        x = bbox[i, 0]
        y = bbox[i, 1]
        z = bbox[i, 2]
        color = np.array(g_label2color[label[i]], dtype=float) / 255.0
        material = 'material%d' % ins_cnt
        fout_obj.write('usemtl %s\n' % material)
        fout_obj.write('v %f %f %f\n' % (x, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y, z))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z))
        fout_obj.write('g default\n')
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 3 + v_cnt, 2 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (1 + v_cnt, 2 + v_cnt, 6 + v_cnt, 5 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (7 + v_cnt, 6 + v_cnt, 2 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 8 + v_cnt, 7 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 8 + v_cnt, 4 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 6 + v_cnt, 7 + v_cnt, 8 + v_cnt))
        fout_obj.write('\n')
        fout_mtl.write('newmtl %s\n' % material)
        fout_mtl.write('Kd %f %f %f\n' % (color[0], color[1], color[2]))
        fout_mtl.write('\n')
        v_cnt += 8
        ins_cnt += 1
    fout_obj.close()
    fout_mtl.close()","'f %d %d %d %d\n' % (4 + v_cnt, 3 + v_cnt, 2 + v_cnt, 1 + v_cnt)",f'f {4 + v_cnt} {3 + v_cnt} {2 + v_cnt} {1 + v_cnt}\n',1,,,,,,,,,,
deep_gcns,https://github.com/lightaime/deep_gcns/tree/master/sem_seg/indoor3d_util.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/deep_gcns/sem_seg/indoor3d_util.py,,"def bbox_label_to_obj_room(input_filename, out_filename_prefix, easy_view=False, permute=None, center=False, exclude_table=False):
    """""" Visualization of bounding boxes.

  Args:
    input_filename: each line is x1 y1 z1 x2 y2 z2 label
    out_filename_prefix: OBJ filename prefix,
      visualize object by g_label2color
    easy_view: if True, only visualize furniture and floor
    permute: if not None, permute XYZ for rendering, e.g. [0 2 1]
    center: if True, move obj to have zero origin
  Returns:
    output a list of OBJ file and MTL files with the same prefix
  """"""
    bbox_label = np.loadtxt(input_filename)
    bbox = bbox_label[:, 0:6]
    if permute is not None:
        assert len(permute) == 3
        permute = np.array(permute)
        bbox[:, 0:3] = bbox[:, permute]
        bbox[:, 3:6] = bbox[:, permute + 3]
    if center:
        xyz_max = np.amax(bbox[:, 3:6], 0)
        bbox[:, 0:3] -= xyz_max / 2.0
        bbox[:, 3:6] -= xyz_max / 2.0
        bbox /= np.max(xyz_max / 2.0)
    label = bbox_label[:, -1].astype(int)
    obj_filename = out_filename_prefix + '.obj'
    mtl_filename = out_filename_prefix + '.mtl'
    fout_obj = open(obj_filename, 'w')
    fout_mtl = open(mtl_filename, 'w')
    fout_obj.write('mtllib %s\n' % os.path.basename(mtl_filename))
    v_cnt = 0
    ins_cnt = 0
    for i in range(bbox.shape[0]):
        if easy_view and label[i] not in g_easy_view_labels:
            continue
        if exclude_table and label[i] == g_classes.index('table'):
            continue
        length = bbox[i, 3:6] - bbox[i, 0:3]
        a = length[0]
        b = length[1]
        c = length[2]
        x = bbox[i, 0]
        y = bbox[i, 1]
        z = bbox[i, 2]
        color = np.array(g_label2color[label[i]], dtype=float) / 255.0
        material = 'material%d' % ins_cnt
        fout_obj.write('usemtl %s\n' % material)
        fout_obj.write('v %f %f %f\n' % (x, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y, z))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z))
        fout_obj.write('g default\n')
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 3 + v_cnt, 2 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (1 + v_cnt, 2 + v_cnt, 6 + v_cnt, 5 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (7 + v_cnt, 6 + v_cnt, 2 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 8 + v_cnt, 7 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 8 + v_cnt, 4 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 6 + v_cnt, 7 + v_cnt, 8 + v_cnt))
        fout_obj.write('\n')
        fout_mtl.write('newmtl %s\n' % material)
        fout_mtl.write('Kd %f %f %f\n' % (color[0], color[1], color[2]))
        fout_mtl.write('\n')
        v_cnt += 8
        ins_cnt += 1
    fout_obj.close()
    fout_mtl.close()","'f %d %d %d %d\n' % (1 + v_cnt, 2 + v_cnt, 6 + v_cnt, 5 + v_cnt)",f'f {1+v_cnt} {2+v_cnt} {6+v_cnt} {5+v_cnt}\n',1,,,,,,,,,,
deep_gcns,https://github.com/lightaime/deep_gcns/tree/master/sem_seg/indoor3d_util.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/deep_gcns/sem_seg/indoor3d_util.py,,"def bbox_label_to_obj_room(input_filename, out_filename_prefix, easy_view=False, permute=None, center=False, exclude_table=False):
    """""" Visualization of bounding boxes.

  Args:
    input_filename: each line is x1 y1 z1 x2 y2 z2 label
    out_filename_prefix: OBJ filename prefix,
      visualize object by g_label2color
    easy_view: if True, only visualize furniture and floor
    permute: if not None, permute XYZ for rendering, e.g. [0 2 1]
    center: if True, move obj to have zero origin
  Returns:
    output a list of OBJ file and MTL files with the same prefix
  """"""
    bbox_label = np.loadtxt(input_filename)
    bbox = bbox_label[:, 0:6]
    if permute is not None:
        assert len(permute) == 3
        permute = np.array(permute)
        bbox[:, 0:3] = bbox[:, permute]
        bbox[:, 3:6] = bbox[:, permute + 3]
    if center:
        xyz_max = np.amax(bbox[:, 3:6], 0)
        bbox[:, 0:3] -= xyz_max / 2.0
        bbox[:, 3:6] -= xyz_max / 2.0
        bbox /= np.max(xyz_max / 2.0)
    label = bbox_label[:, -1].astype(int)
    obj_filename = out_filename_prefix + '.obj'
    mtl_filename = out_filename_prefix + '.mtl'
    fout_obj = open(obj_filename, 'w')
    fout_mtl = open(mtl_filename, 'w')
    fout_obj.write('mtllib %s\n' % os.path.basename(mtl_filename))
    v_cnt = 0
    ins_cnt = 0
    for i in range(bbox.shape[0]):
        if easy_view and label[i] not in g_easy_view_labels:
            continue
        if exclude_table and label[i] == g_classes.index('table'):
            continue
        length = bbox[i, 3:6] - bbox[i, 0:3]
        a = length[0]
        b = length[1]
        c = length[2]
        x = bbox[i, 0]
        y = bbox[i, 1]
        z = bbox[i, 2]
        color = np.array(g_label2color[label[i]], dtype=float) / 255.0
        material = 'material%d' % ins_cnt
        fout_obj.write('usemtl %s\n' % material)
        fout_obj.write('v %f %f %f\n' % (x, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y, z))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z))
        fout_obj.write('g default\n')
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 3 + v_cnt, 2 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (1 + v_cnt, 2 + v_cnt, 6 + v_cnt, 5 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (7 + v_cnt, 6 + v_cnt, 2 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 8 + v_cnt, 7 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 8 + v_cnt, 4 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 6 + v_cnt, 7 + v_cnt, 8 + v_cnt))
        fout_obj.write('\n')
        fout_mtl.write('newmtl %s\n' % material)
        fout_mtl.write('Kd %f %f %f\n' % (color[0], color[1], color[2]))
        fout_mtl.write('\n')
        v_cnt += 8
        ins_cnt += 1
    fout_obj.close()
    fout_mtl.close()","'f %d %d %d %d\n' % (7 + v_cnt, 6 + v_cnt, 2 + v_cnt, 3 + v_cnt)",f'f {7 + v_cnt} {6 + v_cnt} {2 + v_cnt} {3 + v_cnt}\n',1,,,,,,,,,,
deep_gcns,https://github.com/lightaime/deep_gcns/tree/master/sem_seg/indoor3d_util.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/deep_gcns/sem_seg/indoor3d_util.py,,"def bbox_label_to_obj_room(input_filename, out_filename_prefix, easy_view=False, permute=None, center=False, exclude_table=False):
    """""" Visualization of bounding boxes.

  Args:
    input_filename: each line is x1 y1 z1 x2 y2 z2 label
    out_filename_prefix: OBJ filename prefix,
      visualize object by g_label2color
    easy_view: if True, only visualize furniture and floor
    permute: if not None, permute XYZ for rendering, e.g. [0 2 1]
    center: if True, move obj to have zero origin
  Returns:
    output a list of OBJ file and MTL files with the same prefix
  """"""
    bbox_label = np.loadtxt(input_filename)
    bbox = bbox_label[:, 0:6]
    if permute is not None:
        assert len(permute) == 3
        permute = np.array(permute)
        bbox[:, 0:3] = bbox[:, permute]
        bbox[:, 3:6] = bbox[:, permute + 3]
    if center:
        xyz_max = np.amax(bbox[:, 3:6], 0)
        bbox[:, 0:3] -= xyz_max / 2.0
        bbox[:, 3:6] -= xyz_max / 2.0
        bbox /= np.max(xyz_max / 2.0)
    label = bbox_label[:, -1].astype(int)
    obj_filename = out_filename_prefix + '.obj'
    mtl_filename = out_filename_prefix + '.mtl'
    fout_obj = open(obj_filename, 'w')
    fout_mtl = open(mtl_filename, 'w')
    fout_obj.write('mtllib %s\n' % os.path.basename(mtl_filename))
    v_cnt = 0
    ins_cnt = 0
    for i in range(bbox.shape[0]):
        if easy_view and label[i] not in g_easy_view_labels:
            continue
        if exclude_table and label[i] == g_classes.index('table'):
            continue
        length = bbox[i, 3:6] - bbox[i, 0:3]
        a = length[0]
        b = length[1]
        c = length[2]
        x = bbox[i, 0]
        y = bbox[i, 1]
        z = bbox[i, 2]
        color = np.array(g_label2color[label[i]], dtype=float) / 255.0
        material = 'material%d' % ins_cnt
        fout_obj.write('usemtl %s\n' % material)
        fout_obj.write('v %f %f %f\n' % (x, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y, z))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z))
        fout_obj.write('g default\n')
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 3 + v_cnt, 2 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (1 + v_cnt, 2 + v_cnt, 6 + v_cnt, 5 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (7 + v_cnt, 6 + v_cnt, 2 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 8 + v_cnt, 7 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 8 + v_cnt, 4 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 6 + v_cnt, 7 + v_cnt, 8 + v_cnt))
        fout_obj.write('\n')
        fout_mtl.write('newmtl %s\n' % material)
        fout_mtl.write('Kd %f %f %f\n' % (color[0], color[1], color[2]))
        fout_mtl.write('\n')
        v_cnt += 8
        ins_cnt += 1
    fout_obj.close()
    fout_mtl.close()","'f %d %d %d %d\n' % (4 + v_cnt, 8 + v_cnt, 7 + v_cnt, 3 + v_cnt)",f'f {4 + v_cnt} {8 + v_cnt} {7 + v_cnt} {3 + v_cnt}\n',1,,,,,,,,,,
deep_gcns,https://github.com/lightaime/deep_gcns/tree/master/sem_seg/indoor3d_util.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/deep_gcns/sem_seg/indoor3d_util.py,,"def bbox_label_to_obj_room(input_filename, out_filename_prefix, easy_view=False, permute=None, center=False, exclude_table=False):
    """""" Visualization of bounding boxes.

  Args:
    input_filename: each line is x1 y1 z1 x2 y2 z2 label
    out_filename_prefix: OBJ filename prefix,
      visualize object by g_label2color
    easy_view: if True, only visualize furniture and floor
    permute: if not None, permute XYZ for rendering, e.g. [0 2 1]
    center: if True, move obj to have zero origin
  Returns:
    output a list of OBJ file and MTL files with the same prefix
  """"""
    bbox_label = np.loadtxt(input_filename)
    bbox = bbox_label[:, 0:6]
    if permute is not None:
        assert len(permute) == 3
        permute = np.array(permute)
        bbox[:, 0:3] = bbox[:, permute]
        bbox[:, 3:6] = bbox[:, permute + 3]
    if center:
        xyz_max = np.amax(bbox[:, 3:6], 0)
        bbox[:, 0:3] -= xyz_max / 2.0
        bbox[:, 3:6] -= xyz_max / 2.0
        bbox /= np.max(xyz_max / 2.0)
    label = bbox_label[:, -1].astype(int)
    obj_filename = out_filename_prefix + '.obj'
    mtl_filename = out_filename_prefix + '.mtl'
    fout_obj = open(obj_filename, 'w')
    fout_mtl = open(mtl_filename, 'w')
    fout_obj.write('mtllib %s\n' % os.path.basename(mtl_filename))
    v_cnt = 0
    ins_cnt = 0
    for i in range(bbox.shape[0]):
        if easy_view and label[i] not in g_easy_view_labels:
            continue
        if exclude_table and label[i] == g_classes.index('table'):
            continue
        length = bbox[i, 3:6] - bbox[i, 0:3]
        a = length[0]
        b = length[1]
        c = length[2]
        x = bbox[i, 0]
        y = bbox[i, 1]
        z = bbox[i, 2]
        color = np.array(g_label2color[label[i]], dtype=float) / 255.0
        material = 'material%d' % ins_cnt
        fout_obj.write('usemtl %s\n' % material)
        fout_obj.write('v %f %f %f\n' % (x, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y, z))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z))
        fout_obj.write('g default\n')
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 3 + v_cnt, 2 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (1 + v_cnt, 2 + v_cnt, 6 + v_cnt, 5 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (7 + v_cnt, 6 + v_cnt, 2 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 8 + v_cnt, 7 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 8 + v_cnt, 4 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 6 + v_cnt, 7 + v_cnt, 8 + v_cnt))
        fout_obj.write('\n')
        fout_mtl.write('newmtl %s\n' % material)
        fout_mtl.write('Kd %f %f %f\n' % (color[0], color[1], color[2]))
        fout_mtl.write('\n')
        v_cnt += 8
        ins_cnt += 1
    fout_obj.close()
    fout_mtl.close()","'f %d %d %d %d\n' % (5 + v_cnt, 8 + v_cnt, 4 + v_cnt, 1 + v_cnt)",f'f {5 + v_cnt} {8 + v_cnt} {4 + v_cnt} {1 + v_cnt}\n',1,,,,,,,,,,
deep_gcns,https://github.com/lightaime/deep_gcns/tree/master/sem_seg/indoor3d_util.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/deep_gcns/sem_seg/indoor3d_util.py,,"def bbox_label_to_obj_room(input_filename, out_filename_prefix, easy_view=False, permute=None, center=False, exclude_table=False):
    """""" Visualization of bounding boxes.

  Args:
    input_filename: each line is x1 y1 z1 x2 y2 z2 label
    out_filename_prefix: OBJ filename prefix,
      visualize object by g_label2color
    easy_view: if True, only visualize furniture and floor
    permute: if not None, permute XYZ for rendering, e.g. [0 2 1]
    center: if True, move obj to have zero origin
  Returns:
    output a list of OBJ file and MTL files with the same prefix
  """"""
    bbox_label = np.loadtxt(input_filename)
    bbox = bbox_label[:, 0:6]
    if permute is not None:
        assert len(permute) == 3
        permute = np.array(permute)
        bbox[:, 0:3] = bbox[:, permute]
        bbox[:, 3:6] = bbox[:, permute + 3]
    if center:
        xyz_max = np.amax(bbox[:, 3:6], 0)
        bbox[:, 0:3] -= xyz_max / 2.0
        bbox[:, 3:6] -= xyz_max / 2.0
        bbox /= np.max(xyz_max / 2.0)
    label = bbox_label[:, -1].astype(int)
    obj_filename = out_filename_prefix + '.obj'
    mtl_filename = out_filename_prefix + '.mtl'
    fout_obj = open(obj_filename, 'w')
    fout_mtl = open(mtl_filename, 'w')
    fout_obj.write('mtllib %s\n' % os.path.basename(mtl_filename))
    v_cnt = 0
    ins_cnt = 0
    for i in range(bbox.shape[0]):
        if easy_view and label[i] not in g_easy_view_labels:
            continue
        if exclude_table and label[i] == g_classes.index('table'):
            continue
        length = bbox[i, 3:6] - bbox[i, 0:3]
        a = length[0]
        b = length[1]
        c = length[2]
        x = bbox[i, 0]
        y = bbox[i, 1]
        z = bbox[i, 2]
        color = np.array(g_label2color[label[i]], dtype=float) / 255.0
        material = 'material%d' % ins_cnt
        fout_obj.write('usemtl %s\n' % material)
        fout_obj.write('v %f %f %f\n' % (x, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y, z))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z))
        fout_obj.write('g default\n')
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 3 + v_cnt, 2 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (1 + v_cnt, 2 + v_cnt, 6 + v_cnt, 5 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (7 + v_cnt, 6 + v_cnt, 2 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 8 + v_cnt, 7 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 8 + v_cnt, 4 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 6 + v_cnt, 7 + v_cnt, 8 + v_cnt))
        fout_obj.write('\n')
        fout_mtl.write('newmtl %s\n' % material)
        fout_mtl.write('Kd %f %f %f\n' % (color[0], color[1], color[2]))
        fout_mtl.write('\n')
        v_cnt += 8
        ins_cnt += 1
    fout_obj.close()
    fout_mtl.close()","'f %d %d %d %d\n' % (5 + v_cnt, 6 + v_cnt, 7 + v_cnt, 8 + v_cnt)",f'f {5+v_cnt} {6+v_cnt} {7+v_cnt} {8+v_cnt}\n',1,,,,,,,,,,
deep_gcns,https://github.com/lightaime/deep_gcns/tree/master/sem_seg/indoor3d_util.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/deep_gcns/sem_seg/indoor3d_util.py,,"def bbox_label_to_obj_room(input_filename, out_filename_prefix, easy_view=False, permute=None, center=False, exclude_table=False):
    """""" Visualization of bounding boxes.

  Args:
    input_filename: each line is x1 y1 z1 x2 y2 z2 label
    out_filename_prefix: OBJ filename prefix,
      visualize object by g_label2color
    easy_view: if True, only visualize furniture and floor
    permute: if not None, permute XYZ for rendering, e.g. [0 2 1]
    center: if True, move obj to have zero origin
  Returns:
    output a list of OBJ file and MTL files with the same prefix
  """"""
    bbox_label = np.loadtxt(input_filename)
    bbox = bbox_label[:, 0:6]
    if permute is not None:
        assert len(permute) == 3
        permute = np.array(permute)
        bbox[:, 0:3] = bbox[:, permute]
        bbox[:, 3:6] = bbox[:, permute + 3]
    if center:
        xyz_max = np.amax(bbox[:, 3:6], 0)
        bbox[:, 0:3] -= xyz_max / 2.0
        bbox[:, 3:6] -= xyz_max / 2.0
        bbox /= np.max(xyz_max / 2.0)
    label = bbox_label[:, -1].astype(int)
    obj_filename = out_filename_prefix + '.obj'
    mtl_filename = out_filename_prefix + '.mtl'
    fout_obj = open(obj_filename, 'w')
    fout_mtl = open(mtl_filename, 'w')
    fout_obj.write('mtllib %s\n' % os.path.basename(mtl_filename))
    v_cnt = 0
    ins_cnt = 0
    for i in range(bbox.shape[0]):
        if easy_view and label[i] not in g_easy_view_labels:
            continue
        if exclude_table and label[i] == g_classes.index('table'):
            continue
        length = bbox[i, 3:6] - bbox[i, 0:3]
        a = length[0]
        b = length[1]
        c = length[2]
        x = bbox[i, 0]
        y = bbox[i, 1]
        z = bbox[i, 2]
        color = np.array(g_label2color[label[i]], dtype=float) / 255.0
        material = 'material%d' % ins_cnt
        fout_obj.write('usemtl %s\n' % material)
        fout_obj.write('v %f %f %f\n' % (x, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y, z))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z))
        fout_obj.write('g default\n')
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 3 + v_cnt, 2 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (1 + v_cnt, 2 + v_cnt, 6 + v_cnt, 5 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (7 + v_cnt, 6 + v_cnt, 2 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 8 + v_cnt, 7 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 8 + v_cnt, 4 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 6 + v_cnt, 7 + v_cnt, 8 + v_cnt))
        fout_obj.write('\n')
        fout_mtl.write('newmtl %s\n' % material)
        fout_mtl.write('Kd %f %f %f\n' % (color[0], color[1], color[2]))
        fout_mtl.write('\n')
        v_cnt += 8
        ins_cnt += 1
    fout_obj.close()
    fout_mtl.close()",'newmtl %s\n' % material,f'newmtl {material}\n',1,,,,,,,,,,
deep_gcns,https://github.com/lightaime/deep_gcns/tree/master/sem_seg/indoor3d_util.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/deep_gcns/sem_seg/indoor3d_util.py,,"def bbox_label_to_obj_room(input_filename, out_filename_prefix, easy_view=False, permute=None, center=False, exclude_table=False):
    """""" Visualization of bounding boxes.

  Args:
    input_filename: each line is x1 y1 z1 x2 y2 z2 label
    out_filename_prefix: OBJ filename prefix,
      visualize object by g_label2color
    easy_view: if True, only visualize furniture and floor
    permute: if not None, permute XYZ for rendering, e.g. [0 2 1]
    center: if True, move obj to have zero origin
  Returns:
    output a list of OBJ file and MTL files with the same prefix
  """"""
    bbox_label = np.loadtxt(input_filename)
    bbox = bbox_label[:, 0:6]
    if permute is not None:
        assert len(permute) == 3
        permute = np.array(permute)
        bbox[:, 0:3] = bbox[:, permute]
        bbox[:, 3:6] = bbox[:, permute + 3]
    if center:
        xyz_max = np.amax(bbox[:, 3:6], 0)
        bbox[:, 0:3] -= xyz_max / 2.0
        bbox[:, 3:6] -= xyz_max / 2.0
        bbox /= np.max(xyz_max / 2.0)
    label = bbox_label[:, -1].astype(int)
    obj_filename = out_filename_prefix + '.obj'
    mtl_filename = out_filename_prefix + '.mtl'
    fout_obj = open(obj_filename, 'w')
    fout_mtl = open(mtl_filename, 'w')
    fout_obj.write('mtllib %s\n' % os.path.basename(mtl_filename))
    v_cnt = 0
    ins_cnt = 0
    for i in range(bbox.shape[0]):
        if easy_view and label[i] not in g_easy_view_labels:
            continue
        if exclude_table and label[i] == g_classes.index('table'):
            continue
        length = bbox[i, 3:6] - bbox[i, 0:3]
        a = length[0]
        b = length[1]
        c = length[2]
        x = bbox[i, 0]
        y = bbox[i, 1]
        z = bbox[i, 2]
        color = np.array(g_label2color[label[i]], dtype=float) / 255.0
        material = 'material%d' % ins_cnt
        fout_obj.write('usemtl %s\n' % material)
        fout_obj.write('v %f %f %f\n' % (x, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z + c))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z + c))
        fout_obj.write('v %f %f %f\n' % (x, y, z))
        fout_obj.write('v %f %f %f\n' % (x, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y + b, z))
        fout_obj.write('v %f %f %f\n' % (x + a, y, z))
        fout_obj.write('g default\n')
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 3 + v_cnt, 2 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (1 + v_cnt, 2 + v_cnt, 6 + v_cnt, 5 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (7 + v_cnt, 6 + v_cnt, 2 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (4 + v_cnt, 8 + v_cnt, 7 + v_cnt, 3 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 8 + v_cnt, 4 + v_cnt, 1 + v_cnt))
        fout_obj.write('f %d %d %d %d\n' % (5 + v_cnt, 6 + v_cnt, 7 + v_cnt, 8 + v_cnt))
        fout_obj.write('\n')
        fout_mtl.write('newmtl %s\n' % material)
        fout_mtl.write('Kd %f %f %f\n' % (color[0], color[1], color[2]))
        fout_mtl.write('\n')
        v_cnt += 8
        ins_cnt += 1
    fout_obj.close()
    fout_mtl.close()","'Kd %f %f %f\n' % (color[0], color[1], color[2])",f"Kd {color[0]} {color[1]} {color[2]}\n",1,,,,,,,,,,
muffin,https://github.com/klen/muffin/tree/master/muffin/manage.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/muffin/muffin/manage.py,Manager,"def process_arg(name, *, value=..., **opts):
    argname = name.lower()
    arghelp = docs.get(name, '')
    if value is ...:
        return parser.add_argument(argname, help=arghelp, **opts)
    argname = argname.replace('_', '-')
    if isinstance(value, bool):
        if value:
            return parser.add_argument('--no-' + argname, dest=name, action='store_false', help=arghelp or f'Disable {name}')
        return parser.add_argument('--' + argname, dest=name, action='store_true', help=arghelp or f'Enable {name}')
    if isinstance(value, list):
        return parser.add_argument('--' + argname, action='append', default=value, help=arghelp)
    return parser.add_argument('--' + argname, type=anns.get(name, type(value)), default=value, help=arghelp + ' [%s]' % repr(value))",' [%s]' % repr(value),f'[{repr(value)}]',1,,,,,,,,,,
napalm,https://github.com/napalm-automation/napalm/tree/master/napalm/base/helpers.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/napalm/napalm/base/helpers.py,,"def find_txt(xml_tree, path, default='', namespaces=None):
    """"""
    Extracts the text value from an XML tree, using XPath.
    In case of error or text element unavailability, will return a default value.

    :param xml_tree:   the XML Tree object. Assumed is <type 'lxml.etree._Element'>.
    :param path:       XPath to be applied, in order to extract the desired data.
    :param default:    Value to be returned in case of error.
    :param namespaces: prefix-namespace mappings to process XPath
    :return: a str value.
    """"""
    value = ''
    try:
        xpath_applied = xml_tree.xpath(path, namespaces=namespaces)
        xpath_length = len(xpath_applied)
        if xpath_length and xpath_applied[0] is not None:
            xpath_result = xpath_applied[0]
            if isinstance(xpath_result, type(xml_tree)):
                if xpath_result.text:
                    value = xpath_result.text.strip()
                else:
                    value = default
            else:
                value = xpath_result
        elif xpath_applied == '':
            logger.debug('Unable to find the specified-text-element/XML path: %s in                          the XML tree provided. Total Items in XML tree: %d ' % (path, xpath_length))
    except Exception as findTxtErr01:
        logger.error(findTxtErr01)
        value = default
    return str(value)","'Unable to find the specified-text-element/XML path: %s in                          the XML tree provided. Total Items in XML tree: %d ' % (path, xpath_length)",f"Unable to find the specified-text-element/XML path: {path} in the XML tree provided. Total Items in XML tree: {xpath_length}",1,,,,,,,,,,
not-youtube-dl,https://github.com/scastillo/not-youtube-dl/tree/master/youtube_dl/extractor/tvnow.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/not-youtube-dl/youtube_dl/extractor/tvnow.py,TVNowShowIE,"def _real_extract(self, url):
    (base_url, show_id) = re.match(self._VALID_URL, url).groups()
    result = self._call_api('teaserrow/format/navigation/' + show_id, show_id)
    items = result['items']
    entries = []
    navigation = result.get('navigationType')
    if navigation == 'annual':
        for item in items:
            if not isinstance(item, dict):
                continue
            year = int_or_none(item.get('year'))
            if year is None:
                continue
            months = item.get('months')
            if not isinstance(months, list):
                continue
            for month_dict in months:
                if not isinstance(month_dict, dict) or not month_dict:
                    continue
                month_number = int_or_none(list(month_dict.keys())[0])
                if month_number is None:
                    continue
                entries.append(self.url_result('%s/%04d-%02d' % (base_url, year, month_number), ie=TVNowAnnualIE.ie_key()))
    elif navigation == 'season':
        for item in items:
            if not isinstance(item, dict):
                continue
            season_number = int_or_none(item.get('season'))
            if season_number is None:
                continue
            entries.append(self.url_result('%s/staffel-%d' % (base_url, season_number), ie=TVNowSeasonIE.ie_key()))
    else:
        raise ExtractorError('Unknown navigationType')
    return self.playlist_result(entries, show_id)","'%s/%04d-%02d' % (base_url, year, month_number)",f"{base_url}/{year:04d}-{month_number:02d}",1,,,,,,,,,,
not-youtube-dl,https://github.com/scastillo/not-youtube-dl/tree/master/youtube_dl/extractor/tvnow.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/not-youtube-dl/youtube_dl/extractor/tvnow.py,TVNowShowIE,"def _real_extract(self, url):
    (base_url, show_id) = re.match(self._VALID_URL, url).groups()
    result = self._call_api('teaserrow/format/navigation/' + show_id, show_id)
    items = result['items']
    entries = []
    navigation = result.get('navigationType')
    if navigation == 'annual':
        for item in items:
            if not isinstance(item, dict):
                continue
            year = int_or_none(item.get('year'))
            if year is None:
                continue
            months = item.get('months')
            if not isinstance(months, list):
                continue
            for month_dict in months:
                if not isinstance(month_dict, dict) or not month_dict:
                    continue
                month_number = int_or_none(list(month_dict.keys())[0])
                if month_number is None:
                    continue
                entries.append(self.url_result('%s/%04d-%02d' % (base_url, year, month_number), ie=TVNowAnnualIE.ie_key()))
    elif navigation == 'season':
        for item in items:
            if not isinstance(item, dict):
                continue
            season_number = int_or_none(item.get('season'))
            if season_number is None:
                continue
            entries.append(self.url_result('%s/staffel-%d' % (base_url, season_number), ie=TVNowSeasonIE.ie_key()))
    else:
        raise ExtractorError('Unknown navigationType')
    return self.playlist_result(entries, show_id)","'%s/staffel-%d' % (base_url, season_number)",f"{base_url}/staffel-{season_number}",1,,,,,,,,,,
Misago,https://github.com/rafalp/Misago/tree/master/misago/themes/uploadto.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/Misago/misago/themes/uploadto.py,,"def upload_media_to(instance, filename):
    filename = add_hash_to_filename(instance.hash, filename)
    return 'themes/%s/media/%s' % (instance.theme.dirname, filename)","'themes/%s/media/%s' % (instance.theme.dirname, filename)",f"themes/{instance.theme.dirname}/media/{filename}",1,,,,,,,,,,
ParlAI,https://github.com/facebookresearch/ParlAI/tree/master/parlai/tasks/eli5/data_creation/download_reddit_qalist.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/ParlAI/parlai/tasks/eli5/data_creation/download_reddit_qalist.py,,"def download_and_process_comments(post_ids, st_time):
    lines = defaultdict(list)
    subreddit_names = set()
    for post_id in post_ids:
        for (i, (name, l)) in enumerate(get_comments_from_post(post_id)):
            if i % 1000000 == 0:
                print('read %d lines, found %d' % (i, sum([len(ls) for ls in lines.values()])), time() - st_time)
            lines[name] += [l.strip()]
            subreddit_names.add(name)
    print('tokenizing and selecting specific posts %2f' % (time() - st_time))
    processed_items = dict([(name, []) for name in subreddit_names])
    key_list = ['id', 'link_id', 'parent_id', 'score', 'body']
    for name in subreddit_names:
        for line in lines[name]:
            reddit_dct = json.loads(line)
            if valid_comment(reddit_dct):
                reddit_res = {}
                for k in key_list:
                    if k == 'body':
                        if reddit_dct[k].lower() in ['[removed]', '[deleted]']:
                            reddit_dct[k] = ''
                        (txt, url_list) = word_url_tokenize(reddit_dct[k])
                        reddit_res[k] = (' '.join(txt.split()), url_list)
                    else:
                        reddit_res[k] = reddit_dct[k]
                processed_items[name] += [reddit_res]
    print('Total found %d' % len(processed_items), time() - st_time)
    return (subreddit_names, processed_items)",'tokenizing and selecting specific posts %2f' % (time() - st_time),f"tokenizing and selecting specific posts {time() - st_time}%2f",1,,,,,,,,,,
ParlAI,https://github.com/facebookresearch/ParlAI/tree/master/parlai/tasks/eli5/data_creation/download_reddit_qalist.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/ParlAI/parlai/tasks/eli5/data_creation/download_reddit_qalist.py,,"def download_and_process_comments(post_ids, st_time):
    lines = defaultdict(list)
    subreddit_names = set()
    for post_id in post_ids:
        for (i, (name, l)) in enumerate(get_comments_from_post(post_id)):
            if i % 1000000 == 0:
                print('read %d lines, found %d' % (i, sum([len(ls) for ls in lines.values()])), time() - st_time)
            lines[name] += [l.strip()]
            subreddit_names.add(name)
    print('tokenizing and selecting specific posts %2f' % (time() - st_time))
    processed_items = dict([(name, []) for name in subreddit_names])
    key_list = ['id', 'link_id', 'parent_id', 'score', 'body']
    for name in subreddit_names:
        for line in lines[name]:
            reddit_dct = json.loads(line)
            if valid_comment(reddit_dct):
                reddit_res = {}
                for k in key_list:
                    if k == 'body':
                        if reddit_dct[k].lower() in ['[removed]', '[deleted]']:
                            reddit_dct[k] = ''
                        (txt, url_list) = word_url_tokenize(reddit_dct[k])
                        reddit_res[k] = (' '.join(txt.split()), url_list)
                    else:
                        reddit_res[k] = reddit_dct[k]
                processed_items[name] += [reddit_res]
    print('Total found %d' % len(processed_items), time() - st_time)
    return (subreddit_names, processed_items)",'Total found %d' % len(processed_items),f"Total found {len(processed_items)}",1,,,,,,,,,,
ParlAI,https://github.com/facebookresearch/ParlAI/tree/master/parlai/tasks/eli5/data_creation/download_reddit_qalist.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/ParlAI/parlai/tasks/eli5/data_creation/download_reddit_qalist.py,,"def download_and_process_comments(post_ids, st_time):
    lines = defaultdict(list)
    subreddit_names = set()
    for post_id in post_ids:
        for (i, (name, l)) in enumerate(get_comments_from_post(post_id)):
            if i % 1000000 == 0:
                print('read %d lines, found %d' % (i, sum([len(ls) for ls in lines.values()])), time() - st_time)
            lines[name] += [l.strip()]
            subreddit_names.add(name)
    print('tokenizing and selecting specific posts %2f' % (time() - st_time))
    processed_items = dict([(name, []) for name in subreddit_names])
    key_list = ['id', 'link_id', 'parent_id', 'score', 'body']
    for name in subreddit_names:
        for line in lines[name]:
            reddit_dct = json.loads(line)
            if valid_comment(reddit_dct):
                reddit_res = {}
                for k in key_list:
                    if k == 'body':
                        if reddit_dct[k].lower() in ['[removed]', '[deleted]']:
                            reddit_dct[k] = ''
                        (txt, url_list) = word_url_tokenize(reddit_dct[k])
                        reddit_res[k] = (' '.join(txt.split()), url_list)
                    else:
                        reddit_res[k] = reddit_dct[k]
                processed_items[name] += [reddit_res]
    print('Total found %d' % len(processed_items), time() - st_time)
    return (subreddit_names, processed_items)","'read %d lines, found %d' % (i, sum([len(ls) for ls in lines.values()]))","f""read {i} lines, found {sum([len(ls) for ls in lines.values()])}""",1,,,,,,,,,,
madmom,https://github.com/CPJKU/madmom/tree/master/madmom/io/audio.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/madmom/madmom/io/audio.py,,"def decode_to_memory(infile, fmt='f32le', sample_rate=None, num_channels=1, channel=None, skip=None, max_len=None, cmd_decode='ffmpeg', cmd_probe='ffprobe', replaygain_mode=None, replaygain_preamp=0.0):
    """"""
    Decode the given audio and return it as a binary string representation.

    Parameters
    ----------
    infile : str
        Name of the audio sound file to decode.
    fmt : {'f32le', 's16le'}, optional
        Format of the samples:
        - 'f32le' for float32, little-endian,
        - 's16le' for signed 16-bit int, little-endian.
    sample_rate : int, optional
        Sample rate to re-sample the signal to (if set) [Hz].
    num_channels : int, optional
        Number of channels to reduce the signal to.
        If 'None', return the signal with its original channels,
        or whatever is selected by `channel`.
    channel : int, optional
        When reducing a signal to `num_channels` of 1, use this channel,
        or 'None' to return the average across all channels.
    skip : float, optional
        Number of seconds to skip at beginning of file.
    max_len : float, optional
        Maximum length in seconds to decode.
    cmd_decode : {'ffmpeg', 'avconv'}, optional
        Decoding command (defaults to ffmpeg, alternatively supports avconv).
    cmd_probe : {'ffprobe', 'avprobe'}, optional
        Probing command (defaults to ffprobe, alternatively supports avprobe).
    replaygain_mode : {None, 'track','album'}, optional
        Specify the ReplayGain volume-levelling mode (None to disable).
    replaygain_preamp : float, optional
        ReplayGain preamp volume change level (in dB).

    Returns
    -------
    samples : str
        Binary string representation of the audio samples.

    """"""
    if not isinstance(infile, (string_types, file_types, Signal)):
        raise ValueError('only file names, file objects or Signal instances are supported as `infile`, not %s.' % infile)
    (_, proc) = decode_to_pipe(infile, fmt=fmt, sample_rate=sample_rate, num_channels=num_channels, channel=channel, skip=skip, max_len=max_len, cmd=cmd_decode, replaygain_mode=replaygain_mode, replaygain_preamp=replaygain_preamp)
    if isinstance(infile, Signal):
        try:
            (signal, _) = proc.communicate(np.getbuffer(infile))
        except AttributeError:
            mv = memoryview(infile)
            (signal, _) = proc.communicate(mv.cast('b'))
    elif isinstance(infile, file_types):
        (signal, _) = proc.communicate(infile.read())
        infile.seek(0)
        if not signal and nonstreamable_mp4_file_object(infile, cmd_probe):
            try:
                delete_file = False
                try:
                    path = infile.name
                except AttributeError:
                    with tempfile.NamedTemporaryFile(mode='wb', delete=False, suffix='.mp4') as f:
                        f.write(infile.read())
                    infile.seek(0)
                    path = f.name
                    delete_file = True
                signal = decode_to_memory(path, fmt, sample_rate, num_channels, channel, skip, max_len, cmd_decode, cmd_probe, replaygain_mode, replaygain_preamp)
            finally:
                if delete_file:
                    os.remove(path)
    else:
        (signal, _) = proc.communicate()
    if proc.returncode != 0:
        raise subprocess.CalledProcessError(proc.returncode, cmd_decode)
    return signal","'only file names, file objects or Signal instances are supported as `infile`, not %s.' % infile","f""only file names, file objects or Signal instances are supported as `infile`, not {infile}.""",1,,,,,,,,,,
pyhanlp,https://github.com/hankcs/pyhanlp/tree/master/tests/book/ch10/demo_clustering_f.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pyhanlp/tests/book/ch10/demo_clustering_f.py,,"if __name__ == '__main__':
    for algorithm in ('kmeans', 'repeated bisection'):
        print('%s F1=%.2f\n' % (algorithm, ClusterAnalyzer.evaluate(sogou_corpus_path, algorithm) * 100))","'%s F1=%.2f\n' % (algorithm, ClusterAnalyzer.evaluate(sogou_corpus_path, algorithm) * 100)","f""{algorithm} F1={ClusterAnalyzer.evaluate(sogou_corpus_path, algorithm) * 100:.2f}\n""",1,,,,,,,,,,
panoptic-deeplab,https://github.com/bowenc0221/panoptic-deeplab/tree/master/segmentation/utils/debug.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/panoptic-deeplab/segmentation/utils/debug.py,,"def save_debug_images(dataset, batch_images, batch_targets, batch_outputs, out_dir=None, iteration=0, target_keys=('semantic', 'center', 'offset', 'center_weights', 'offset_weights'), output_keys=('semantic', 'center', 'offset'), iteration_to_remove=-1, is_train=True):
    """"""Saves a mini-batch of images for debugging purpose.
        - image: the augmented input image
        - label: the augmented labels including
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
            - instance_ignore_mask: ignore mask
        - prediction: the raw output of the model (without post-processing)
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
    Args:
        dataset: The Dataset.
        batch_images: Tensor of shape [N, 3, H, W], a batch of input images.
        batch_targets: Dict, a dict containing batch of targets.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
            - semantic_weights: a Tensor of shape [N, H, W]
            - center_weights: a Tensor of shape [N, H, W]
            - offset_weights: a Tensor of shape [N, H, W]
        batch_outputs: Dict, a dict containing batch of outputs.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
        out_dir: String, the directory to which the results will be saved.
        iteration: Integer, iteration number.
        target_keys: List, target keys to save.
        output_keys: List, output keys to save.
        iteration_to_remove: Integer, iteration number to remove.
        is_train: Boolean, save train or test debugging image.
    """"""
    batch_size = batch_images.size(0)
    map_height = batch_images.size(2)
    map_width = batch_images.size(3)
    grid_image = np.zeros((map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_targets = len(target_keys)
    grid_target = np.zeros((num_targets * map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_outputs = len(output_keys)
    grid_output = np.zeros((num_outputs * map_height, batch_size * map_width, 3), dtype=np.uint8)
    semantic_pred = torch.argmax(batch_outputs['semantic'].detach(), dim=1)
    if 'foreground' in batch_outputs:
        foreground_pred = torch.argmax(batch_outputs['foreground'].detach(), dim=1)
    else:
        foreground_pred = None
    for i in range(batch_size):
        width_begin = map_width * i
        width_end = map_width * (i + 1)
        image = dataset.reverse_transform(batch_images[i])
        grid_image[:, width_begin:width_end, :] = image
        if 'semantic' in target_keys:
            gt_sem = batch_targets['semantic'][i].cpu().numpy()
            gt_sem = label_to_color_image(gt_sem, dataset.create_label_colormap())
            grid_target[:map_height, width_begin:width_end, :] = gt_sem
        if 'center' in target_keys:
            gt_ctr = batch_targets['center'][i].squeeze().cpu().numpy()
            gt_ctr = gt_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            gt_ctr = gt_ctr.clip(0, 255)
            grid_target[map_height:2 * map_height, width_begin:width_end, :] = gt_ctr
        if 'offset' in target_keys:
            gt_off = batch_targets['offset'][i].permute(1, 2, 0).cpu().numpy()
            gt_off = flow_compute_color(gt_off[:, :, 1], gt_off[:, :, 0])
            grid_target[2 * map_height:3 * map_height, width_begin:width_end, :] = gt_off
        if 'semantic_weights' in target_keys:
            gt_ign = batch_targets['semantic_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] / np.max(gt_ign) * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[3 * map_height:4 * map_height, width_begin:width_end, :] = gt_ign
        if 'center_weights' in target_keys:
            gt_ign = batch_targets['center_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[4 * map_height:5 * map_height, width_begin:width_end, :] = gt_ign
        if 'offset_weights' in target_keys:
            gt_ign = batch_targets['offset_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[5 * map_height:6 * map_height, width_begin:width_end, :] = gt_ign
        if 'foreground' in target_keys:
            gt_fg = batch_targets['foreground'][i].cpu().numpy()
            gt_fg = gt_fg[:, :, None] * 255
            grid_target[6 * map_height:7 * map_height, width_begin:width_end, :] = gt_fg
        if 'semantic' in output_keys:
            pred_sem = semantic_pred[i].cpu().numpy()
            pred_sem = label_to_color_image(pred_sem, dataset.create_label_colormap())
            grid_output[:map_height, width_begin:width_end, :] = pred_sem
        if 'center' in output_keys:
            pred_ctr = batch_outputs['center'][i].detach().squeeze().cpu().numpy()
            pred_ctr = pred_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            pred_ctr = pred_ctr.clip(0, 255)
            grid_output[map_height:2 * map_height, width_begin:width_end, :] = pred_ctr
        if 'offset' in output_keys:
            pred_ctr = batch_outputs['offset'][i].detach().permute(1, 2, 0).cpu().numpy()
            pred_ctr = flow_compute_color(pred_ctr[:, :, 1], pred_ctr[:, :, 0])
            grid_output[2 * map_height:3 * map_height, width_begin:width_end, :] = pred_ctr
        if 'foreground' in output_keys:
            if foreground_pred is not None:
                pred_fg = foreground_pred[i].cpu().numpy()
                pred_fg = pred_fg[:, :, None] * 255
                grid_output[3 * map_height:4 * map_height, width_begin:width_end, :] = pred_fg
    if out_dir is not None:
        if is_train:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
        else:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            if grid_target.size:
                pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
                with open('%s/%s_%d.png' % (out_dir, 'debug_test_targets', iteration), mode='wb') as f:
                    pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
    if is_train:
        if iteration_to_remove >= 0:
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0))","'%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove)",f"{out_dir}/debug_batch_images_{iteration_to_remove}.png",1,,,,,,,,,,
panoptic-deeplab,https://github.com/bowenc0221/panoptic-deeplab/tree/master/segmentation/utils/debug.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/panoptic-deeplab/segmentation/utils/debug.py,,"def save_debug_images(dataset, batch_images, batch_targets, batch_outputs, out_dir=None, iteration=0, target_keys=('semantic', 'center', 'offset', 'center_weights', 'offset_weights'), output_keys=('semantic', 'center', 'offset'), iteration_to_remove=-1, is_train=True):
    """"""Saves a mini-batch of images for debugging purpose.
        - image: the augmented input image
        - label: the augmented labels including
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
            - instance_ignore_mask: ignore mask
        - prediction: the raw output of the model (without post-processing)
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
    Args:
        dataset: The Dataset.
        batch_images: Tensor of shape [N, 3, H, W], a batch of input images.
        batch_targets: Dict, a dict containing batch of targets.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
            - semantic_weights: a Tensor of shape [N, H, W]
            - center_weights: a Tensor of shape [N, H, W]
            - offset_weights: a Tensor of shape [N, H, W]
        batch_outputs: Dict, a dict containing batch of outputs.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
        out_dir: String, the directory to which the results will be saved.
        iteration: Integer, iteration number.
        target_keys: List, target keys to save.
        output_keys: List, output keys to save.
        iteration_to_remove: Integer, iteration number to remove.
        is_train: Boolean, save train or test debugging image.
    """"""
    batch_size = batch_images.size(0)
    map_height = batch_images.size(2)
    map_width = batch_images.size(3)
    grid_image = np.zeros((map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_targets = len(target_keys)
    grid_target = np.zeros((num_targets * map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_outputs = len(output_keys)
    grid_output = np.zeros((num_outputs * map_height, batch_size * map_width, 3), dtype=np.uint8)
    semantic_pred = torch.argmax(batch_outputs['semantic'].detach(), dim=1)
    if 'foreground' in batch_outputs:
        foreground_pred = torch.argmax(batch_outputs['foreground'].detach(), dim=1)
    else:
        foreground_pred = None
    for i in range(batch_size):
        width_begin = map_width * i
        width_end = map_width * (i + 1)
        image = dataset.reverse_transform(batch_images[i])
        grid_image[:, width_begin:width_end, :] = image
        if 'semantic' in target_keys:
            gt_sem = batch_targets['semantic'][i].cpu().numpy()
            gt_sem = label_to_color_image(gt_sem, dataset.create_label_colormap())
            grid_target[:map_height, width_begin:width_end, :] = gt_sem
        if 'center' in target_keys:
            gt_ctr = batch_targets['center'][i].squeeze().cpu().numpy()
            gt_ctr = gt_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            gt_ctr = gt_ctr.clip(0, 255)
            grid_target[map_height:2 * map_height, width_begin:width_end, :] = gt_ctr
        if 'offset' in target_keys:
            gt_off = batch_targets['offset'][i].permute(1, 2, 0).cpu().numpy()
            gt_off = flow_compute_color(gt_off[:, :, 1], gt_off[:, :, 0])
            grid_target[2 * map_height:3 * map_height, width_begin:width_end, :] = gt_off
        if 'semantic_weights' in target_keys:
            gt_ign = batch_targets['semantic_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] / np.max(gt_ign) * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[3 * map_height:4 * map_height, width_begin:width_end, :] = gt_ign
        if 'center_weights' in target_keys:
            gt_ign = batch_targets['center_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[4 * map_height:5 * map_height, width_begin:width_end, :] = gt_ign
        if 'offset_weights' in target_keys:
            gt_ign = batch_targets['offset_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[5 * map_height:6 * map_height, width_begin:width_end, :] = gt_ign
        if 'foreground' in target_keys:
            gt_fg = batch_targets['foreground'][i].cpu().numpy()
            gt_fg = gt_fg[:, :, None] * 255
            grid_target[6 * map_height:7 * map_height, width_begin:width_end, :] = gt_fg
        if 'semantic' in output_keys:
            pred_sem = semantic_pred[i].cpu().numpy()
            pred_sem = label_to_color_image(pred_sem, dataset.create_label_colormap())
            grid_output[:map_height, width_begin:width_end, :] = pred_sem
        if 'center' in output_keys:
            pred_ctr = batch_outputs['center'][i].detach().squeeze().cpu().numpy()
            pred_ctr = pred_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            pred_ctr = pred_ctr.clip(0, 255)
            grid_output[map_height:2 * map_height, width_begin:width_end, :] = pred_ctr
        if 'offset' in output_keys:
            pred_ctr = batch_outputs['offset'][i].detach().permute(1, 2, 0).cpu().numpy()
            pred_ctr = flow_compute_color(pred_ctr[:, :, 1], pred_ctr[:, :, 0])
            grid_output[2 * map_height:3 * map_height, width_begin:width_end, :] = pred_ctr
        if 'foreground' in output_keys:
            if foreground_pred is not None:
                pred_fg = foreground_pred[i].cpu().numpy()
                pred_fg = pred_fg[:, :, None] * 255
                grid_output[3 * map_height:4 * map_height, width_begin:width_end, :] = pred_fg
    if out_dir is not None:
        if is_train:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
        else:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            if grid_target.size:
                pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
                with open('%s/%s_%d.png' % (out_dir, 'debug_test_targets', iteration), mode='wb') as f:
                    pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
    if is_train:
        if iteration_to_remove >= 0:
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0))","'%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove)",f"{out_dir}/debug_batch_targets_{iteration_to_remove}.png",1,,,,,,,,,,
panoptic-deeplab,https://github.com/bowenc0221/panoptic-deeplab/tree/master/segmentation/utils/debug.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/panoptic-deeplab/segmentation/utils/debug.py,,"def save_debug_images(dataset, batch_images, batch_targets, batch_outputs, out_dir=None, iteration=0, target_keys=('semantic', 'center', 'offset', 'center_weights', 'offset_weights'), output_keys=('semantic', 'center', 'offset'), iteration_to_remove=-1, is_train=True):
    """"""Saves a mini-batch of images for debugging purpose.
        - image: the augmented input image
        - label: the augmented labels including
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
            - instance_ignore_mask: ignore mask
        - prediction: the raw output of the model (without post-processing)
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
    Args:
        dataset: The Dataset.
        batch_images: Tensor of shape [N, 3, H, W], a batch of input images.
        batch_targets: Dict, a dict containing batch of targets.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
            - semantic_weights: a Tensor of shape [N, H, W]
            - center_weights: a Tensor of shape [N, H, W]
            - offset_weights: a Tensor of shape [N, H, W]
        batch_outputs: Dict, a dict containing batch of outputs.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
        out_dir: String, the directory to which the results will be saved.
        iteration: Integer, iteration number.
        target_keys: List, target keys to save.
        output_keys: List, output keys to save.
        iteration_to_remove: Integer, iteration number to remove.
        is_train: Boolean, save train or test debugging image.
    """"""
    batch_size = batch_images.size(0)
    map_height = batch_images.size(2)
    map_width = batch_images.size(3)
    grid_image = np.zeros((map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_targets = len(target_keys)
    grid_target = np.zeros((num_targets * map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_outputs = len(output_keys)
    grid_output = np.zeros((num_outputs * map_height, batch_size * map_width, 3), dtype=np.uint8)
    semantic_pred = torch.argmax(batch_outputs['semantic'].detach(), dim=1)
    if 'foreground' in batch_outputs:
        foreground_pred = torch.argmax(batch_outputs['foreground'].detach(), dim=1)
    else:
        foreground_pred = None
    for i in range(batch_size):
        width_begin = map_width * i
        width_end = map_width * (i + 1)
        image = dataset.reverse_transform(batch_images[i])
        grid_image[:, width_begin:width_end, :] = image
        if 'semantic' in target_keys:
            gt_sem = batch_targets['semantic'][i].cpu().numpy()
            gt_sem = label_to_color_image(gt_sem, dataset.create_label_colormap())
            grid_target[:map_height, width_begin:width_end, :] = gt_sem
        if 'center' in target_keys:
            gt_ctr = batch_targets['center'][i].squeeze().cpu().numpy()
            gt_ctr = gt_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            gt_ctr = gt_ctr.clip(0, 255)
            grid_target[map_height:2 * map_height, width_begin:width_end, :] = gt_ctr
        if 'offset' in target_keys:
            gt_off = batch_targets['offset'][i].permute(1, 2, 0).cpu().numpy()
            gt_off = flow_compute_color(gt_off[:, :, 1], gt_off[:, :, 0])
            grid_target[2 * map_height:3 * map_height, width_begin:width_end, :] = gt_off
        if 'semantic_weights' in target_keys:
            gt_ign = batch_targets['semantic_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] / np.max(gt_ign) * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[3 * map_height:4 * map_height, width_begin:width_end, :] = gt_ign
        if 'center_weights' in target_keys:
            gt_ign = batch_targets['center_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[4 * map_height:5 * map_height, width_begin:width_end, :] = gt_ign
        if 'offset_weights' in target_keys:
            gt_ign = batch_targets['offset_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[5 * map_height:6 * map_height, width_begin:width_end, :] = gt_ign
        if 'foreground' in target_keys:
            gt_fg = batch_targets['foreground'][i].cpu().numpy()
            gt_fg = gt_fg[:, :, None] * 255
            grid_target[6 * map_height:7 * map_height, width_begin:width_end, :] = gt_fg
        if 'semantic' in output_keys:
            pred_sem = semantic_pred[i].cpu().numpy()
            pred_sem = label_to_color_image(pred_sem, dataset.create_label_colormap())
            grid_output[:map_height, width_begin:width_end, :] = pred_sem
        if 'center' in output_keys:
            pred_ctr = batch_outputs['center'][i].detach().squeeze().cpu().numpy()
            pred_ctr = pred_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            pred_ctr = pred_ctr.clip(0, 255)
            grid_output[map_height:2 * map_height, width_begin:width_end, :] = pred_ctr
        if 'offset' in output_keys:
            pred_ctr = batch_outputs['offset'][i].detach().permute(1, 2, 0).cpu().numpy()
            pred_ctr = flow_compute_color(pred_ctr[:, :, 1], pred_ctr[:, :, 0])
            grid_output[2 * map_height:3 * map_height, width_begin:width_end, :] = pred_ctr
        if 'foreground' in output_keys:
            if foreground_pred is not None:
                pred_fg = foreground_pred[i].cpu().numpy()
                pred_fg = pred_fg[:, :, None] * 255
                grid_output[3 * map_height:4 * map_height, width_begin:width_end, :] = pred_fg
    if out_dir is not None:
        if is_train:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
        else:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            if grid_target.size:
                pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
                with open('%s/%s_%d.png' % (out_dir, 'debug_test_targets', iteration), mode='wb') as f:
                    pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
    if is_train:
        if iteration_to_remove >= 0:
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0))","'%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove)",f"{out_dir}/debug_batch_outputs_{iteration_to_remove}.png",1,,,,,,,,,,
panoptic-deeplab,https://github.com/bowenc0221/panoptic-deeplab/tree/master/segmentation/utils/debug.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/panoptic-deeplab/segmentation/utils/debug.py,,"def save_debug_images(dataset, batch_images, batch_targets, batch_outputs, out_dir=None, iteration=0, target_keys=('semantic', 'center', 'offset', 'center_weights', 'offset_weights'), output_keys=('semantic', 'center', 'offset'), iteration_to_remove=-1, is_train=True):
    """"""Saves a mini-batch of images for debugging purpose.
        - image: the augmented input image
        - label: the augmented labels including
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
            - instance_ignore_mask: ignore mask
        - prediction: the raw output of the model (without post-processing)
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
    Args:
        dataset: The Dataset.
        batch_images: Tensor of shape [N, 3, H, W], a batch of input images.
        batch_targets: Dict, a dict containing batch of targets.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
            - semantic_weights: a Tensor of shape [N, H, W]
            - center_weights: a Tensor of shape [N, H, W]
            - offset_weights: a Tensor of shape [N, H, W]
        batch_outputs: Dict, a dict containing batch of outputs.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
        out_dir: String, the directory to which the results will be saved.
        iteration: Integer, iteration number.
        target_keys: List, target keys to save.
        output_keys: List, output keys to save.
        iteration_to_remove: Integer, iteration number to remove.
        is_train: Boolean, save train or test debugging image.
    """"""
    batch_size = batch_images.size(0)
    map_height = batch_images.size(2)
    map_width = batch_images.size(3)
    grid_image = np.zeros((map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_targets = len(target_keys)
    grid_target = np.zeros((num_targets * map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_outputs = len(output_keys)
    grid_output = np.zeros((num_outputs * map_height, batch_size * map_width, 3), dtype=np.uint8)
    semantic_pred = torch.argmax(batch_outputs['semantic'].detach(), dim=1)
    if 'foreground' in batch_outputs:
        foreground_pred = torch.argmax(batch_outputs['foreground'].detach(), dim=1)
    else:
        foreground_pred = None
    for i in range(batch_size):
        width_begin = map_width * i
        width_end = map_width * (i + 1)
        image = dataset.reverse_transform(batch_images[i])
        grid_image[:, width_begin:width_end, :] = image
        if 'semantic' in target_keys:
            gt_sem = batch_targets['semantic'][i].cpu().numpy()
            gt_sem = label_to_color_image(gt_sem, dataset.create_label_colormap())
            grid_target[:map_height, width_begin:width_end, :] = gt_sem
        if 'center' in target_keys:
            gt_ctr = batch_targets['center'][i].squeeze().cpu().numpy()
            gt_ctr = gt_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            gt_ctr = gt_ctr.clip(0, 255)
            grid_target[map_height:2 * map_height, width_begin:width_end, :] = gt_ctr
        if 'offset' in target_keys:
            gt_off = batch_targets['offset'][i].permute(1, 2, 0).cpu().numpy()
            gt_off = flow_compute_color(gt_off[:, :, 1], gt_off[:, :, 0])
            grid_target[2 * map_height:3 * map_height, width_begin:width_end, :] = gt_off
        if 'semantic_weights' in target_keys:
            gt_ign = batch_targets['semantic_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] / np.max(gt_ign) * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[3 * map_height:4 * map_height, width_begin:width_end, :] = gt_ign
        if 'center_weights' in target_keys:
            gt_ign = batch_targets['center_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[4 * map_height:5 * map_height, width_begin:width_end, :] = gt_ign
        if 'offset_weights' in target_keys:
            gt_ign = batch_targets['offset_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[5 * map_height:6 * map_height, width_begin:width_end, :] = gt_ign
        if 'foreground' in target_keys:
            gt_fg = batch_targets['foreground'][i].cpu().numpy()
            gt_fg = gt_fg[:, :, None] * 255
            grid_target[6 * map_height:7 * map_height, width_begin:width_end, :] = gt_fg
        if 'semantic' in output_keys:
            pred_sem = semantic_pred[i].cpu().numpy()
            pred_sem = label_to_color_image(pred_sem, dataset.create_label_colormap())
            grid_output[:map_height, width_begin:width_end, :] = pred_sem
        if 'center' in output_keys:
            pred_ctr = batch_outputs['center'][i].detach().squeeze().cpu().numpy()
            pred_ctr = pred_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            pred_ctr = pred_ctr.clip(0, 255)
            grid_output[map_height:2 * map_height, width_begin:width_end, :] = pred_ctr
        if 'offset' in output_keys:
            pred_ctr = batch_outputs['offset'][i].detach().permute(1, 2, 0).cpu().numpy()
            pred_ctr = flow_compute_color(pred_ctr[:, :, 1], pred_ctr[:, :, 0])
            grid_output[2 * map_height:3 * map_height, width_begin:width_end, :] = pred_ctr
        if 'foreground' in output_keys:
            if foreground_pred is not None:
                pred_fg = foreground_pred[i].cpu().numpy()
                pred_fg = pred_fg[:, :, None] * 255
                grid_output[3 * map_height:4 * map_height, width_begin:width_end, :] = pred_fg
    if out_dir is not None:
        if is_train:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
        else:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            if grid_target.size:
                pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
                with open('%s/%s_%d.png' % (out_dir, 'debug_test_targets', iteration), mode='wb') as f:
                    pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
    if is_train:
        if iteration_to_remove >= 0:
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0))","'%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0)",f"{out_dir}/{'debug_batch_images'}_{0}.png",1,,,,,,,,,,
panoptic-deeplab,https://github.com/bowenc0221/panoptic-deeplab/tree/master/segmentation/utils/debug.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/panoptic-deeplab/segmentation/utils/debug.py,,"def save_debug_images(dataset, batch_images, batch_targets, batch_outputs, out_dir=None, iteration=0, target_keys=('semantic', 'center', 'offset', 'center_weights', 'offset_weights'), output_keys=('semantic', 'center', 'offset'), iteration_to_remove=-1, is_train=True):
    """"""Saves a mini-batch of images for debugging purpose.
        - image: the augmented input image
        - label: the augmented labels including
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
            - instance_ignore_mask: ignore mask
        - prediction: the raw output of the model (without post-processing)
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
    Args:
        dataset: The Dataset.
        batch_images: Tensor of shape [N, 3, H, W], a batch of input images.
        batch_targets: Dict, a dict containing batch of targets.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
            - semantic_weights: a Tensor of shape [N, H, W]
            - center_weights: a Tensor of shape [N, H, W]
            - offset_weights: a Tensor of shape [N, H, W]
        batch_outputs: Dict, a dict containing batch of outputs.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
        out_dir: String, the directory to which the results will be saved.
        iteration: Integer, iteration number.
        target_keys: List, target keys to save.
        output_keys: List, output keys to save.
        iteration_to_remove: Integer, iteration number to remove.
        is_train: Boolean, save train or test debugging image.
    """"""
    batch_size = batch_images.size(0)
    map_height = batch_images.size(2)
    map_width = batch_images.size(3)
    grid_image = np.zeros((map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_targets = len(target_keys)
    grid_target = np.zeros((num_targets * map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_outputs = len(output_keys)
    grid_output = np.zeros((num_outputs * map_height, batch_size * map_width, 3), dtype=np.uint8)
    semantic_pred = torch.argmax(batch_outputs['semantic'].detach(), dim=1)
    if 'foreground' in batch_outputs:
        foreground_pred = torch.argmax(batch_outputs['foreground'].detach(), dim=1)
    else:
        foreground_pred = None
    for i in range(batch_size):
        width_begin = map_width * i
        width_end = map_width * (i + 1)
        image = dataset.reverse_transform(batch_images[i])
        grid_image[:, width_begin:width_end, :] = image
        if 'semantic' in target_keys:
            gt_sem = batch_targets['semantic'][i].cpu().numpy()
            gt_sem = label_to_color_image(gt_sem, dataset.create_label_colormap())
            grid_target[:map_height, width_begin:width_end, :] = gt_sem
        if 'center' in target_keys:
            gt_ctr = batch_targets['center'][i].squeeze().cpu().numpy()
            gt_ctr = gt_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            gt_ctr = gt_ctr.clip(0, 255)
            grid_target[map_height:2 * map_height, width_begin:width_end, :] = gt_ctr
        if 'offset' in target_keys:
            gt_off = batch_targets['offset'][i].permute(1, 2, 0).cpu().numpy()
            gt_off = flow_compute_color(gt_off[:, :, 1], gt_off[:, :, 0])
            grid_target[2 * map_height:3 * map_height, width_begin:width_end, :] = gt_off
        if 'semantic_weights' in target_keys:
            gt_ign = batch_targets['semantic_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] / np.max(gt_ign) * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[3 * map_height:4 * map_height, width_begin:width_end, :] = gt_ign
        if 'center_weights' in target_keys:
            gt_ign = batch_targets['center_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[4 * map_height:5 * map_height, width_begin:width_end, :] = gt_ign
        if 'offset_weights' in target_keys:
            gt_ign = batch_targets['offset_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[5 * map_height:6 * map_height, width_begin:width_end, :] = gt_ign
        if 'foreground' in target_keys:
            gt_fg = batch_targets['foreground'][i].cpu().numpy()
            gt_fg = gt_fg[:, :, None] * 255
            grid_target[6 * map_height:7 * map_height, width_begin:width_end, :] = gt_fg
        if 'semantic' in output_keys:
            pred_sem = semantic_pred[i].cpu().numpy()
            pred_sem = label_to_color_image(pred_sem, dataset.create_label_colormap())
            grid_output[:map_height, width_begin:width_end, :] = pred_sem
        if 'center' in output_keys:
            pred_ctr = batch_outputs['center'][i].detach().squeeze().cpu().numpy()
            pred_ctr = pred_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            pred_ctr = pred_ctr.clip(0, 255)
            grid_output[map_height:2 * map_height, width_begin:width_end, :] = pred_ctr
        if 'offset' in output_keys:
            pred_ctr = batch_outputs['offset'][i].detach().permute(1, 2, 0).cpu().numpy()
            pred_ctr = flow_compute_color(pred_ctr[:, :, 1], pred_ctr[:, :, 0])
            grid_output[2 * map_height:3 * map_height, width_begin:width_end, :] = pred_ctr
        if 'foreground' in output_keys:
            if foreground_pred is not None:
                pred_fg = foreground_pred[i].cpu().numpy()
                pred_fg = pred_fg[:, :, None] * 255
                grid_output[3 * map_height:4 * map_height, width_begin:width_end, :] = pred_fg
    if out_dir is not None:
        if is_train:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
        else:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            if grid_target.size:
                pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
                with open('%s/%s_%d.png' % (out_dir, 'debug_test_targets', iteration), mode='wb') as f:
                    pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
    if is_train:
        if iteration_to_remove >= 0:
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0))","'%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0)",f"{out_dir}/{'debug_batch_targets'}_{0}.png",1,,,,,,,,,,
panoptic-deeplab,https://github.com/bowenc0221/panoptic-deeplab/tree/master/segmentation/utils/debug.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/panoptic-deeplab/segmentation/utils/debug.py,,"def save_debug_images(dataset, batch_images, batch_targets, batch_outputs, out_dir=None, iteration=0, target_keys=('semantic', 'center', 'offset', 'center_weights', 'offset_weights'), output_keys=('semantic', 'center', 'offset'), iteration_to_remove=-1, is_train=True):
    """"""Saves a mini-batch of images for debugging purpose.
        - image: the augmented input image
        - label: the augmented labels including
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
            - instance_ignore_mask: ignore mask
        - prediction: the raw output of the model (without post-processing)
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
    Args:
        dataset: The Dataset.
        batch_images: Tensor of shape [N, 3, H, W], a batch of input images.
        batch_targets: Dict, a dict containing batch of targets.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
            - semantic_weights: a Tensor of shape [N, H, W]
            - center_weights: a Tensor of shape [N, H, W]
            - offset_weights: a Tensor of shape [N, H, W]
        batch_outputs: Dict, a dict containing batch of outputs.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
        out_dir: String, the directory to which the results will be saved.
        iteration: Integer, iteration number.
        target_keys: List, target keys to save.
        output_keys: List, output keys to save.
        iteration_to_remove: Integer, iteration number to remove.
        is_train: Boolean, save train or test debugging image.
    """"""
    batch_size = batch_images.size(0)
    map_height = batch_images.size(2)
    map_width = batch_images.size(3)
    grid_image = np.zeros((map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_targets = len(target_keys)
    grid_target = np.zeros((num_targets * map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_outputs = len(output_keys)
    grid_output = np.zeros((num_outputs * map_height, batch_size * map_width, 3), dtype=np.uint8)
    semantic_pred = torch.argmax(batch_outputs['semantic'].detach(), dim=1)
    if 'foreground' in batch_outputs:
        foreground_pred = torch.argmax(batch_outputs['foreground'].detach(), dim=1)
    else:
        foreground_pred = None
    for i in range(batch_size):
        width_begin = map_width * i
        width_end = map_width * (i + 1)
        image = dataset.reverse_transform(batch_images[i])
        grid_image[:, width_begin:width_end, :] = image
        if 'semantic' in target_keys:
            gt_sem = batch_targets['semantic'][i].cpu().numpy()
            gt_sem = label_to_color_image(gt_sem, dataset.create_label_colormap())
            grid_target[:map_height, width_begin:width_end, :] = gt_sem
        if 'center' in target_keys:
            gt_ctr = batch_targets['center'][i].squeeze().cpu().numpy()
            gt_ctr = gt_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            gt_ctr = gt_ctr.clip(0, 255)
            grid_target[map_height:2 * map_height, width_begin:width_end, :] = gt_ctr
        if 'offset' in target_keys:
            gt_off = batch_targets['offset'][i].permute(1, 2, 0).cpu().numpy()
            gt_off = flow_compute_color(gt_off[:, :, 1], gt_off[:, :, 0])
            grid_target[2 * map_height:3 * map_height, width_begin:width_end, :] = gt_off
        if 'semantic_weights' in target_keys:
            gt_ign = batch_targets['semantic_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] / np.max(gt_ign) * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[3 * map_height:4 * map_height, width_begin:width_end, :] = gt_ign
        if 'center_weights' in target_keys:
            gt_ign = batch_targets['center_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[4 * map_height:5 * map_height, width_begin:width_end, :] = gt_ign
        if 'offset_weights' in target_keys:
            gt_ign = batch_targets['offset_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[5 * map_height:6 * map_height, width_begin:width_end, :] = gt_ign
        if 'foreground' in target_keys:
            gt_fg = batch_targets['foreground'][i].cpu().numpy()
            gt_fg = gt_fg[:, :, None] * 255
            grid_target[6 * map_height:7 * map_height, width_begin:width_end, :] = gt_fg
        if 'semantic' in output_keys:
            pred_sem = semantic_pred[i].cpu().numpy()
            pred_sem = label_to_color_image(pred_sem, dataset.create_label_colormap())
            grid_output[:map_height, width_begin:width_end, :] = pred_sem
        if 'center' in output_keys:
            pred_ctr = batch_outputs['center'][i].detach().squeeze().cpu().numpy()
            pred_ctr = pred_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            pred_ctr = pred_ctr.clip(0, 255)
            grid_output[map_height:2 * map_height, width_begin:width_end, :] = pred_ctr
        if 'offset' in output_keys:
            pred_ctr = batch_outputs['offset'][i].detach().permute(1, 2, 0).cpu().numpy()
            pred_ctr = flow_compute_color(pred_ctr[:, :, 1], pred_ctr[:, :, 0])
            grid_output[2 * map_height:3 * map_height, width_begin:width_end, :] = pred_ctr
        if 'foreground' in output_keys:
            if foreground_pred is not None:
                pred_fg = foreground_pred[i].cpu().numpy()
                pred_fg = pred_fg[:, :, None] * 255
                grid_output[3 * map_height:4 * map_height, width_begin:width_end, :] = pred_fg
    if out_dir is not None:
        if is_train:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
        else:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            if grid_target.size:
                pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
                with open('%s/%s_%d.png' % (out_dir, 'debug_test_targets', iteration), mode='wb') as f:
                    pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
    if is_train:
        if iteration_to_remove >= 0:
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0))","'%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0)",f"{out_dir}/{'debug_batch_outputs'}_{0}.png",1,,,,,,,,,,
panoptic-deeplab,https://github.com/bowenc0221/panoptic-deeplab/tree/master/segmentation/utils/debug.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/panoptic-deeplab/segmentation/utils/debug.py,,"def save_debug_images(dataset, batch_images, batch_targets, batch_outputs, out_dir=None, iteration=0, target_keys=('semantic', 'center', 'offset', 'center_weights', 'offset_weights'), output_keys=('semantic', 'center', 'offset'), iteration_to_remove=-1, is_train=True):
    """"""Saves a mini-batch of images for debugging purpose.
        - image: the augmented input image
        - label: the augmented labels including
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
            - instance_ignore_mask: ignore mask
        - prediction: the raw output of the model (without post-processing)
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
    Args:
        dataset: The Dataset.
        batch_images: Tensor of shape [N, 3, H, W], a batch of input images.
        batch_targets: Dict, a dict containing batch of targets.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
            - semantic_weights: a Tensor of shape [N, H, W]
            - center_weights: a Tensor of shape [N, H, W]
            - offset_weights: a Tensor of shape [N, H, W]
        batch_outputs: Dict, a dict containing batch of outputs.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
        out_dir: String, the directory to which the results will be saved.
        iteration: Integer, iteration number.
        target_keys: List, target keys to save.
        output_keys: List, output keys to save.
        iteration_to_remove: Integer, iteration number to remove.
        is_train: Boolean, save train or test debugging image.
    """"""
    batch_size = batch_images.size(0)
    map_height = batch_images.size(2)
    map_width = batch_images.size(3)
    grid_image = np.zeros((map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_targets = len(target_keys)
    grid_target = np.zeros((num_targets * map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_outputs = len(output_keys)
    grid_output = np.zeros((num_outputs * map_height, batch_size * map_width, 3), dtype=np.uint8)
    semantic_pred = torch.argmax(batch_outputs['semantic'].detach(), dim=1)
    if 'foreground' in batch_outputs:
        foreground_pred = torch.argmax(batch_outputs['foreground'].detach(), dim=1)
    else:
        foreground_pred = None
    for i in range(batch_size):
        width_begin = map_width * i
        width_end = map_width * (i + 1)
        image = dataset.reverse_transform(batch_images[i])
        grid_image[:, width_begin:width_end, :] = image
        if 'semantic' in target_keys:
            gt_sem = batch_targets['semantic'][i].cpu().numpy()
            gt_sem = label_to_color_image(gt_sem, dataset.create_label_colormap())
            grid_target[:map_height, width_begin:width_end, :] = gt_sem
        if 'center' in target_keys:
            gt_ctr = batch_targets['center'][i].squeeze().cpu().numpy()
            gt_ctr = gt_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            gt_ctr = gt_ctr.clip(0, 255)
            grid_target[map_height:2 * map_height, width_begin:width_end, :] = gt_ctr
        if 'offset' in target_keys:
            gt_off = batch_targets['offset'][i].permute(1, 2, 0).cpu().numpy()
            gt_off = flow_compute_color(gt_off[:, :, 1], gt_off[:, :, 0])
            grid_target[2 * map_height:3 * map_height, width_begin:width_end, :] = gt_off
        if 'semantic_weights' in target_keys:
            gt_ign = batch_targets['semantic_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] / np.max(gt_ign) * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[3 * map_height:4 * map_height, width_begin:width_end, :] = gt_ign
        if 'center_weights' in target_keys:
            gt_ign = batch_targets['center_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[4 * map_height:5 * map_height, width_begin:width_end, :] = gt_ign
        if 'offset_weights' in target_keys:
            gt_ign = batch_targets['offset_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[5 * map_height:6 * map_height, width_begin:width_end, :] = gt_ign
        if 'foreground' in target_keys:
            gt_fg = batch_targets['foreground'][i].cpu().numpy()
            gt_fg = gt_fg[:, :, None] * 255
            grid_target[6 * map_height:7 * map_height, width_begin:width_end, :] = gt_fg
        if 'semantic' in output_keys:
            pred_sem = semantic_pred[i].cpu().numpy()
            pred_sem = label_to_color_image(pred_sem, dataset.create_label_colormap())
            grid_output[:map_height, width_begin:width_end, :] = pred_sem
        if 'center' in output_keys:
            pred_ctr = batch_outputs['center'][i].detach().squeeze().cpu().numpy()
            pred_ctr = pred_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            pred_ctr = pred_ctr.clip(0, 255)
            grid_output[map_height:2 * map_height, width_begin:width_end, :] = pred_ctr
        if 'offset' in output_keys:
            pred_ctr = batch_outputs['offset'][i].detach().permute(1, 2, 0).cpu().numpy()
            pred_ctr = flow_compute_color(pred_ctr[:, :, 1], pred_ctr[:, :, 0])
            grid_output[2 * map_height:3 * map_height, width_begin:width_end, :] = pred_ctr
        if 'foreground' in output_keys:
            if foreground_pred is not None:
                pred_fg = foreground_pred[i].cpu().numpy()
                pred_fg = pred_fg[:, :, None] * 255
                grid_output[3 * map_height:4 * map_height, width_begin:width_end, :] = pred_fg
    if out_dir is not None:
        if is_train:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
        else:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            if grid_target.size:
                pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
                with open('%s/%s_%d.png' % (out_dir, 'debug_test_targets', iteration), mode='wb') as f:
                    pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
    if is_train:
        if iteration_to_remove >= 0:
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0))","'%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration)",f"{out_dir}/debug_batch_images_{iteration}.png",1,,,,,,,,,,
panoptic-deeplab,https://github.com/bowenc0221/panoptic-deeplab/tree/master/segmentation/utils/debug.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/panoptic-deeplab/segmentation/utils/debug.py,,"def save_debug_images(dataset, batch_images, batch_targets, batch_outputs, out_dir=None, iteration=0, target_keys=('semantic', 'center', 'offset', 'center_weights', 'offset_weights'), output_keys=('semantic', 'center', 'offset'), iteration_to_remove=-1, is_train=True):
    """"""Saves a mini-batch of images for debugging purpose.
        - image: the augmented input image
        - label: the augmented labels including
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
            - instance_ignore_mask: ignore mask
        - prediction: the raw output of the model (without post-processing)
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
    Args:
        dataset: The Dataset.
        batch_images: Tensor of shape [N, 3, H, W], a batch of input images.
        batch_targets: Dict, a dict containing batch of targets.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
            - semantic_weights: a Tensor of shape [N, H, W]
            - center_weights: a Tensor of shape [N, H, W]
            - offset_weights: a Tensor of shape [N, H, W]
        batch_outputs: Dict, a dict containing batch of outputs.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
        out_dir: String, the directory to which the results will be saved.
        iteration: Integer, iteration number.
        target_keys: List, target keys to save.
        output_keys: List, output keys to save.
        iteration_to_remove: Integer, iteration number to remove.
        is_train: Boolean, save train or test debugging image.
    """"""
    batch_size = batch_images.size(0)
    map_height = batch_images.size(2)
    map_width = batch_images.size(3)
    grid_image = np.zeros((map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_targets = len(target_keys)
    grid_target = np.zeros((num_targets * map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_outputs = len(output_keys)
    grid_output = np.zeros((num_outputs * map_height, batch_size * map_width, 3), dtype=np.uint8)
    semantic_pred = torch.argmax(batch_outputs['semantic'].detach(), dim=1)
    if 'foreground' in batch_outputs:
        foreground_pred = torch.argmax(batch_outputs['foreground'].detach(), dim=1)
    else:
        foreground_pred = None
    for i in range(batch_size):
        width_begin = map_width * i
        width_end = map_width * (i + 1)
        image = dataset.reverse_transform(batch_images[i])
        grid_image[:, width_begin:width_end, :] = image
        if 'semantic' in target_keys:
            gt_sem = batch_targets['semantic'][i].cpu().numpy()
            gt_sem = label_to_color_image(gt_sem, dataset.create_label_colormap())
            grid_target[:map_height, width_begin:width_end, :] = gt_sem
        if 'center' in target_keys:
            gt_ctr = batch_targets['center'][i].squeeze().cpu().numpy()
            gt_ctr = gt_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            gt_ctr = gt_ctr.clip(0, 255)
            grid_target[map_height:2 * map_height, width_begin:width_end, :] = gt_ctr
        if 'offset' in target_keys:
            gt_off = batch_targets['offset'][i].permute(1, 2, 0).cpu().numpy()
            gt_off = flow_compute_color(gt_off[:, :, 1], gt_off[:, :, 0])
            grid_target[2 * map_height:3 * map_height, width_begin:width_end, :] = gt_off
        if 'semantic_weights' in target_keys:
            gt_ign = batch_targets['semantic_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] / np.max(gt_ign) * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[3 * map_height:4 * map_height, width_begin:width_end, :] = gt_ign
        if 'center_weights' in target_keys:
            gt_ign = batch_targets['center_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[4 * map_height:5 * map_height, width_begin:width_end, :] = gt_ign
        if 'offset_weights' in target_keys:
            gt_ign = batch_targets['offset_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[5 * map_height:6 * map_height, width_begin:width_end, :] = gt_ign
        if 'foreground' in target_keys:
            gt_fg = batch_targets['foreground'][i].cpu().numpy()
            gt_fg = gt_fg[:, :, None] * 255
            grid_target[6 * map_height:7 * map_height, width_begin:width_end, :] = gt_fg
        if 'semantic' in output_keys:
            pred_sem = semantic_pred[i].cpu().numpy()
            pred_sem = label_to_color_image(pred_sem, dataset.create_label_colormap())
            grid_output[:map_height, width_begin:width_end, :] = pred_sem
        if 'center' in output_keys:
            pred_ctr = batch_outputs['center'][i].detach().squeeze().cpu().numpy()
            pred_ctr = pred_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            pred_ctr = pred_ctr.clip(0, 255)
            grid_output[map_height:2 * map_height, width_begin:width_end, :] = pred_ctr
        if 'offset' in output_keys:
            pred_ctr = batch_outputs['offset'][i].detach().permute(1, 2, 0).cpu().numpy()
            pred_ctr = flow_compute_color(pred_ctr[:, :, 1], pred_ctr[:, :, 0])
            grid_output[2 * map_height:3 * map_height, width_begin:width_end, :] = pred_ctr
        if 'foreground' in output_keys:
            if foreground_pred is not None:
                pred_fg = foreground_pred[i].cpu().numpy()
                pred_fg = pred_fg[:, :, None] * 255
                grid_output[3 * map_height:4 * map_height, width_begin:width_end, :] = pred_fg
    if out_dir is not None:
        if is_train:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
        else:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            if grid_target.size:
                pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
                with open('%s/%s_%d.png' % (out_dir, 'debug_test_targets', iteration), mode='wb') as f:
                    pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
    if is_train:
        if iteration_to_remove >= 0:
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0))","'%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration)",f"{out_dir}/debug_batch_targets_{iteration}.png",1,,,,,,,,,,
panoptic-deeplab,https://github.com/bowenc0221/panoptic-deeplab/tree/master/segmentation/utils/debug.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/panoptic-deeplab/segmentation/utils/debug.py,,"def save_debug_images(dataset, batch_images, batch_targets, batch_outputs, out_dir=None, iteration=0, target_keys=('semantic', 'center', 'offset', 'center_weights', 'offset_weights'), output_keys=('semantic', 'center', 'offset'), iteration_to_remove=-1, is_train=True):
    """"""Saves a mini-batch of images for debugging purpose.
        - image: the augmented input image
        - label: the augmented labels including
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
            - instance_ignore_mask: ignore mask
        - prediction: the raw output of the model (without post-processing)
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
    Args:
        dataset: The Dataset.
        batch_images: Tensor of shape [N, 3, H, W], a batch of input images.
        batch_targets: Dict, a dict containing batch of targets.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
            - semantic_weights: a Tensor of shape [N, H, W]
            - center_weights: a Tensor of shape [N, H, W]
            - offset_weights: a Tensor of shape [N, H, W]
        batch_outputs: Dict, a dict containing batch of outputs.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
        out_dir: String, the directory to which the results will be saved.
        iteration: Integer, iteration number.
        target_keys: List, target keys to save.
        output_keys: List, output keys to save.
        iteration_to_remove: Integer, iteration number to remove.
        is_train: Boolean, save train or test debugging image.
    """"""
    batch_size = batch_images.size(0)
    map_height = batch_images.size(2)
    map_width = batch_images.size(3)
    grid_image = np.zeros((map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_targets = len(target_keys)
    grid_target = np.zeros((num_targets * map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_outputs = len(output_keys)
    grid_output = np.zeros((num_outputs * map_height, batch_size * map_width, 3), dtype=np.uint8)
    semantic_pred = torch.argmax(batch_outputs['semantic'].detach(), dim=1)
    if 'foreground' in batch_outputs:
        foreground_pred = torch.argmax(batch_outputs['foreground'].detach(), dim=1)
    else:
        foreground_pred = None
    for i in range(batch_size):
        width_begin = map_width * i
        width_end = map_width * (i + 1)
        image = dataset.reverse_transform(batch_images[i])
        grid_image[:, width_begin:width_end, :] = image
        if 'semantic' in target_keys:
            gt_sem = batch_targets['semantic'][i].cpu().numpy()
            gt_sem = label_to_color_image(gt_sem, dataset.create_label_colormap())
            grid_target[:map_height, width_begin:width_end, :] = gt_sem
        if 'center' in target_keys:
            gt_ctr = batch_targets['center'][i].squeeze().cpu().numpy()
            gt_ctr = gt_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            gt_ctr = gt_ctr.clip(0, 255)
            grid_target[map_height:2 * map_height, width_begin:width_end, :] = gt_ctr
        if 'offset' in target_keys:
            gt_off = batch_targets['offset'][i].permute(1, 2, 0).cpu().numpy()
            gt_off = flow_compute_color(gt_off[:, :, 1], gt_off[:, :, 0])
            grid_target[2 * map_height:3 * map_height, width_begin:width_end, :] = gt_off
        if 'semantic_weights' in target_keys:
            gt_ign = batch_targets['semantic_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] / np.max(gt_ign) * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[3 * map_height:4 * map_height, width_begin:width_end, :] = gt_ign
        if 'center_weights' in target_keys:
            gt_ign = batch_targets['center_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[4 * map_height:5 * map_height, width_begin:width_end, :] = gt_ign
        if 'offset_weights' in target_keys:
            gt_ign = batch_targets['offset_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[5 * map_height:6 * map_height, width_begin:width_end, :] = gt_ign
        if 'foreground' in target_keys:
            gt_fg = batch_targets['foreground'][i].cpu().numpy()
            gt_fg = gt_fg[:, :, None] * 255
            grid_target[6 * map_height:7 * map_height, width_begin:width_end, :] = gt_fg
        if 'semantic' in output_keys:
            pred_sem = semantic_pred[i].cpu().numpy()
            pred_sem = label_to_color_image(pred_sem, dataset.create_label_colormap())
            grid_output[:map_height, width_begin:width_end, :] = pred_sem
        if 'center' in output_keys:
            pred_ctr = batch_outputs['center'][i].detach().squeeze().cpu().numpy()
            pred_ctr = pred_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            pred_ctr = pred_ctr.clip(0, 255)
            grid_output[map_height:2 * map_height, width_begin:width_end, :] = pred_ctr
        if 'offset' in output_keys:
            pred_ctr = batch_outputs['offset'][i].detach().permute(1, 2, 0).cpu().numpy()
            pred_ctr = flow_compute_color(pred_ctr[:, :, 1], pred_ctr[:, :, 0])
            grid_output[2 * map_height:3 * map_height, width_begin:width_end, :] = pred_ctr
        if 'foreground' in output_keys:
            if foreground_pred is not None:
                pred_fg = foreground_pred[i].cpu().numpy()
                pred_fg = pred_fg[:, :, None] * 255
                grid_output[3 * map_height:4 * map_height, width_begin:width_end, :] = pred_fg
    if out_dir is not None:
        if is_train:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
        else:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            if grid_target.size:
                pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
                with open('%s/%s_%d.png' % (out_dir, 'debug_test_targets', iteration), mode='wb') as f:
                    pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
    if is_train:
        if iteration_to_remove >= 0:
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0))","'%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration)",f"{out_dir}/debug_batch_outputs_{iteration}.png",1,,,,,,,,,,
panoptic-deeplab,https://github.com/bowenc0221/panoptic-deeplab/tree/master/segmentation/utils/debug.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/panoptic-deeplab/segmentation/utils/debug.py,,"def save_debug_images(dataset, batch_images, batch_targets, batch_outputs, out_dir=None, iteration=0, target_keys=('semantic', 'center', 'offset', 'center_weights', 'offset_weights'), output_keys=('semantic', 'center', 'offset'), iteration_to_remove=-1, is_train=True):
    """"""Saves a mini-batch of images for debugging purpose.
        - image: the augmented input image
        - label: the augmented labels including
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
            - instance_ignore_mask: ignore mask
        - prediction: the raw output of the model (without post-processing)
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
    Args:
        dataset: The Dataset.
        batch_images: Tensor of shape [N, 3, H, W], a batch of input images.
        batch_targets: Dict, a dict containing batch of targets.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
            - semantic_weights: a Tensor of shape [N, H, W]
            - center_weights: a Tensor of shape [N, H, W]
            - offset_weights: a Tensor of shape [N, H, W]
        batch_outputs: Dict, a dict containing batch of outputs.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
        out_dir: String, the directory to which the results will be saved.
        iteration: Integer, iteration number.
        target_keys: List, target keys to save.
        output_keys: List, output keys to save.
        iteration_to_remove: Integer, iteration number to remove.
        is_train: Boolean, save train or test debugging image.
    """"""
    batch_size = batch_images.size(0)
    map_height = batch_images.size(2)
    map_width = batch_images.size(3)
    grid_image = np.zeros((map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_targets = len(target_keys)
    grid_target = np.zeros((num_targets * map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_outputs = len(output_keys)
    grid_output = np.zeros((num_outputs * map_height, batch_size * map_width, 3), dtype=np.uint8)
    semantic_pred = torch.argmax(batch_outputs['semantic'].detach(), dim=1)
    if 'foreground' in batch_outputs:
        foreground_pred = torch.argmax(batch_outputs['foreground'].detach(), dim=1)
    else:
        foreground_pred = None
    for i in range(batch_size):
        width_begin = map_width * i
        width_end = map_width * (i + 1)
        image = dataset.reverse_transform(batch_images[i])
        grid_image[:, width_begin:width_end, :] = image
        if 'semantic' in target_keys:
            gt_sem = batch_targets['semantic'][i].cpu().numpy()
            gt_sem = label_to_color_image(gt_sem, dataset.create_label_colormap())
            grid_target[:map_height, width_begin:width_end, :] = gt_sem
        if 'center' in target_keys:
            gt_ctr = batch_targets['center'][i].squeeze().cpu().numpy()
            gt_ctr = gt_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            gt_ctr = gt_ctr.clip(0, 255)
            grid_target[map_height:2 * map_height, width_begin:width_end, :] = gt_ctr
        if 'offset' in target_keys:
            gt_off = batch_targets['offset'][i].permute(1, 2, 0).cpu().numpy()
            gt_off = flow_compute_color(gt_off[:, :, 1], gt_off[:, :, 0])
            grid_target[2 * map_height:3 * map_height, width_begin:width_end, :] = gt_off
        if 'semantic_weights' in target_keys:
            gt_ign = batch_targets['semantic_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] / np.max(gt_ign) * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[3 * map_height:4 * map_height, width_begin:width_end, :] = gt_ign
        if 'center_weights' in target_keys:
            gt_ign = batch_targets['center_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[4 * map_height:5 * map_height, width_begin:width_end, :] = gt_ign
        if 'offset_weights' in target_keys:
            gt_ign = batch_targets['offset_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[5 * map_height:6 * map_height, width_begin:width_end, :] = gt_ign
        if 'foreground' in target_keys:
            gt_fg = batch_targets['foreground'][i].cpu().numpy()
            gt_fg = gt_fg[:, :, None] * 255
            grid_target[6 * map_height:7 * map_height, width_begin:width_end, :] = gt_fg
        if 'semantic' in output_keys:
            pred_sem = semantic_pred[i].cpu().numpy()
            pred_sem = label_to_color_image(pred_sem, dataset.create_label_colormap())
            grid_output[:map_height, width_begin:width_end, :] = pred_sem
        if 'center' in output_keys:
            pred_ctr = batch_outputs['center'][i].detach().squeeze().cpu().numpy()
            pred_ctr = pred_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            pred_ctr = pred_ctr.clip(0, 255)
            grid_output[map_height:2 * map_height, width_begin:width_end, :] = pred_ctr
        if 'offset' in output_keys:
            pred_ctr = batch_outputs['offset'][i].detach().permute(1, 2, 0).cpu().numpy()
            pred_ctr = flow_compute_color(pred_ctr[:, :, 1], pred_ctr[:, :, 0])
            grid_output[2 * map_height:3 * map_height, width_begin:width_end, :] = pred_ctr
        if 'foreground' in output_keys:
            if foreground_pred is not None:
                pred_fg = foreground_pred[i].cpu().numpy()
                pred_fg = pred_fg[:, :, None] * 255
                grid_output[3 * map_height:4 * map_height, width_begin:width_end, :] = pred_fg
    if out_dir is not None:
        if is_train:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
        else:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            if grid_target.size:
                pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
                with open('%s/%s_%d.png' % (out_dir, 'debug_test_targets', iteration), mode='wb') as f:
                    pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
    if is_train:
        if iteration_to_remove >= 0:
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0))","'%s/%s_%d.png' % (out_dir, 'debug_test_images', iteration)",f"{out_dir}/debug_test_images_{iteration}.png",1,,,,,,,,,,
panoptic-deeplab,https://github.com/bowenc0221/panoptic-deeplab/tree/master/segmentation/utils/debug.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/panoptic-deeplab/segmentation/utils/debug.py,,"def save_debug_images(dataset, batch_images, batch_targets, batch_outputs, out_dir=None, iteration=0, target_keys=('semantic', 'center', 'offset', 'center_weights', 'offset_weights'), output_keys=('semantic', 'center', 'offset'), iteration_to_remove=-1, is_train=True):
    """"""Saves a mini-batch of images for debugging purpose.
        - image: the augmented input image
        - label: the augmented labels including
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
            - instance_ignore_mask: ignore mask
        - prediction: the raw output of the model (without post-processing)
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
    Args:
        dataset: The Dataset.
        batch_images: Tensor of shape [N, 3, H, W], a batch of input images.
        batch_targets: Dict, a dict containing batch of targets.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
            - semantic_weights: a Tensor of shape [N, H, W]
            - center_weights: a Tensor of shape [N, H, W]
            - offset_weights: a Tensor of shape [N, H, W]
        batch_outputs: Dict, a dict containing batch of outputs.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
        out_dir: String, the directory to which the results will be saved.
        iteration: Integer, iteration number.
        target_keys: List, target keys to save.
        output_keys: List, output keys to save.
        iteration_to_remove: Integer, iteration number to remove.
        is_train: Boolean, save train or test debugging image.
    """"""
    batch_size = batch_images.size(0)
    map_height = batch_images.size(2)
    map_width = batch_images.size(3)
    grid_image = np.zeros((map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_targets = len(target_keys)
    grid_target = np.zeros((num_targets * map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_outputs = len(output_keys)
    grid_output = np.zeros((num_outputs * map_height, batch_size * map_width, 3), dtype=np.uint8)
    semantic_pred = torch.argmax(batch_outputs['semantic'].detach(), dim=1)
    if 'foreground' in batch_outputs:
        foreground_pred = torch.argmax(batch_outputs['foreground'].detach(), dim=1)
    else:
        foreground_pred = None
    for i in range(batch_size):
        width_begin = map_width * i
        width_end = map_width * (i + 1)
        image = dataset.reverse_transform(batch_images[i])
        grid_image[:, width_begin:width_end, :] = image
        if 'semantic' in target_keys:
            gt_sem = batch_targets['semantic'][i].cpu().numpy()
            gt_sem = label_to_color_image(gt_sem, dataset.create_label_colormap())
            grid_target[:map_height, width_begin:width_end, :] = gt_sem
        if 'center' in target_keys:
            gt_ctr = batch_targets['center'][i].squeeze().cpu().numpy()
            gt_ctr = gt_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            gt_ctr = gt_ctr.clip(0, 255)
            grid_target[map_height:2 * map_height, width_begin:width_end, :] = gt_ctr
        if 'offset' in target_keys:
            gt_off = batch_targets['offset'][i].permute(1, 2, 0).cpu().numpy()
            gt_off = flow_compute_color(gt_off[:, :, 1], gt_off[:, :, 0])
            grid_target[2 * map_height:3 * map_height, width_begin:width_end, :] = gt_off
        if 'semantic_weights' in target_keys:
            gt_ign = batch_targets['semantic_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] / np.max(gt_ign) * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[3 * map_height:4 * map_height, width_begin:width_end, :] = gt_ign
        if 'center_weights' in target_keys:
            gt_ign = batch_targets['center_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[4 * map_height:5 * map_height, width_begin:width_end, :] = gt_ign
        if 'offset_weights' in target_keys:
            gt_ign = batch_targets['offset_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[5 * map_height:6 * map_height, width_begin:width_end, :] = gt_ign
        if 'foreground' in target_keys:
            gt_fg = batch_targets['foreground'][i].cpu().numpy()
            gt_fg = gt_fg[:, :, None] * 255
            grid_target[6 * map_height:7 * map_height, width_begin:width_end, :] = gt_fg
        if 'semantic' in output_keys:
            pred_sem = semantic_pred[i].cpu().numpy()
            pred_sem = label_to_color_image(pred_sem, dataset.create_label_colormap())
            grid_output[:map_height, width_begin:width_end, :] = pred_sem
        if 'center' in output_keys:
            pred_ctr = batch_outputs['center'][i].detach().squeeze().cpu().numpy()
            pred_ctr = pred_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            pred_ctr = pred_ctr.clip(0, 255)
            grid_output[map_height:2 * map_height, width_begin:width_end, :] = pred_ctr
        if 'offset' in output_keys:
            pred_ctr = batch_outputs['offset'][i].detach().permute(1, 2, 0).cpu().numpy()
            pred_ctr = flow_compute_color(pred_ctr[:, :, 1], pred_ctr[:, :, 0])
            grid_output[2 * map_height:3 * map_height, width_begin:width_end, :] = pred_ctr
        if 'foreground' in output_keys:
            if foreground_pred is not None:
                pred_fg = foreground_pred[i].cpu().numpy()
                pred_fg = pred_fg[:, :, None] * 255
                grid_output[3 * map_height:4 * map_height, width_begin:width_end, :] = pred_fg
    if out_dir is not None:
        if is_train:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
        else:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            if grid_target.size:
                pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
                with open('%s/%s_%d.png' % (out_dir, 'debug_test_targets', iteration), mode='wb') as f:
                    pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
    if is_train:
        if iteration_to_remove >= 0:
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0))","'%s/%s_%d.png' % (out_dir, 'debug_test_outputs', iteration)",f"{out_dir}/debug_test_outputs_{iteration}.png",1,,,,,,,,,,
panoptic-deeplab,https://github.com/bowenc0221/panoptic-deeplab/tree/master/segmentation/utils/debug.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/panoptic-deeplab/segmentation/utils/debug.py,,"def save_debug_images(dataset, batch_images, batch_targets, batch_outputs, out_dir=None, iteration=0, target_keys=('semantic', 'center', 'offset', 'center_weights', 'offset_weights'), output_keys=('semantic', 'center', 'offset'), iteration_to_remove=-1, is_train=True):
    """"""Saves a mini-batch of images for debugging purpose.
        - image: the augmented input image
        - label: the augmented labels including
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
            - instance_ignore_mask: ignore mask
        - prediction: the raw output of the model (without post-processing)
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
    Args:
        dataset: The Dataset.
        batch_images: Tensor of shape [N, 3, H, W], a batch of input images.
        batch_targets: Dict, a dict containing batch of targets.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
            - semantic_weights: a Tensor of shape [N, H, W]
            - center_weights: a Tensor of shape [N, H, W]
            - offset_weights: a Tensor of shape [N, H, W]
        batch_outputs: Dict, a dict containing batch of outputs.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
        out_dir: String, the directory to which the results will be saved.
        iteration: Integer, iteration number.
        target_keys: List, target keys to save.
        output_keys: List, output keys to save.
        iteration_to_remove: Integer, iteration number to remove.
        is_train: Boolean, save train or test debugging image.
    """"""
    batch_size = batch_images.size(0)
    map_height = batch_images.size(2)
    map_width = batch_images.size(3)
    grid_image = np.zeros((map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_targets = len(target_keys)
    grid_target = np.zeros((num_targets * map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_outputs = len(output_keys)
    grid_output = np.zeros((num_outputs * map_height, batch_size * map_width, 3), dtype=np.uint8)
    semantic_pred = torch.argmax(batch_outputs['semantic'].detach(), dim=1)
    if 'foreground' in batch_outputs:
        foreground_pred = torch.argmax(batch_outputs['foreground'].detach(), dim=1)
    else:
        foreground_pred = None
    for i in range(batch_size):
        width_begin = map_width * i
        width_end = map_width * (i + 1)
        image = dataset.reverse_transform(batch_images[i])
        grid_image[:, width_begin:width_end, :] = image
        if 'semantic' in target_keys:
            gt_sem = batch_targets['semantic'][i].cpu().numpy()
            gt_sem = label_to_color_image(gt_sem, dataset.create_label_colormap())
            grid_target[:map_height, width_begin:width_end, :] = gt_sem
        if 'center' in target_keys:
            gt_ctr = batch_targets['center'][i].squeeze().cpu().numpy()
            gt_ctr = gt_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            gt_ctr = gt_ctr.clip(0, 255)
            grid_target[map_height:2 * map_height, width_begin:width_end, :] = gt_ctr
        if 'offset' in target_keys:
            gt_off = batch_targets['offset'][i].permute(1, 2, 0).cpu().numpy()
            gt_off = flow_compute_color(gt_off[:, :, 1], gt_off[:, :, 0])
            grid_target[2 * map_height:3 * map_height, width_begin:width_end, :] = gt_off
        if 'semantic_weights' in target_keys:
            gt_ign = batch_targets['semantic_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] / np.max(gt_ign) * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[3 * map_height:4 * map_height, width_begin:width_end, :] = gt_ign
        if 'center_weights' in target_keys:
            gt_ign = batch_targets['center_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[4 * map_height:5 * map_height, width_begin:width_end, :] = gt_ign
        if 'offset_weights' in target_keys:
            gt_ign = batch_targets['offset_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[5 * map_height:6 * map_height, width_begin:width_end, :] = gt_ign
        if 'foreground' in target_keys:
            gt_fg = batch_targets['foreground'][i].cpu().numpy()
            gt_fg = gt_fg[:, :, None] * 255
            grid_target[6 * map_height:7 * map_height, width_begin:width_end, :] = gt_fg
        if 'semantic' in output_keys:
            pred_sem = semantic_pred[i].cpu().numpy()
            pred_sem = label_to_color_image(pred_sem, dataset.create_label_colormap())
            grid_output[:map_height, width_begin:width_end, :] = pred_sem
        if 'center' in output_keys:
            pred_ctr = batch_outputs['center'][i].detach().squeeze().cpu().numpy()
            pred_ctr = pred_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            pred_ctr = pred_ctr.clip(0, 255)
            grid_output[map_height:2 * map_height, width_begin:width_end, :] = pred_ctr
        if 'offset' in output_keys:
            pred_ctr = batch_outputs['offset'][i].detach().permute(1, 2, 0).cpu().numpy()
            pred_ctr = flow_compute_color(pred_ctr[:, :, 1], pred_ctr[:, :, 0])
            grid_output[2 * map_height:3 * map_height, width_begin:width_end, :] = pred_ctr
        if 'foreground' in output_keys:
            if foreground_pred is not None:
                pred_fg = foreground_pred[i].cpu().numpy()
                pred_fg = pred_fg[:, :, None] * 255
                grid_output[3 * map_height:4 * map_height, width_begin:width_end, :] = pred_fg
    if out_dir is not None:
        if is_train:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
        else:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            if grid_target.size:
                pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
                with open('%s/%s_%d.png' % (out_dir, 'debug_test_targets', iteration), mode='wb') as f:
                    pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
    if is_train:
        if iteration_to_remove >= 0:
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0))","'%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove)",f"{out_dir}/debug_batch_images_{iteration_to_remove}.png",1,,,,,,,,,,
panoptic-deeplab,https://github.com/bowenc0221/panoptic-deeplab/tree/master/segmentation/utils/debug.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/panoptic-deeplab/segmentation/utils/debug.py,,"def save_debug_images(dataset, batch_images, batch_targets, batch_outputs, out_dir=None, iteration=0, target_keys=('semantic', 'center', 'offset', 'center_weights', 'offset_weights'), output_keys=('semantic', 'center', 'offset'), iteration_to_remove=-1, is_train=True):
    """"""Saves a mini-batch of images for debugging purpose.
        - image: the augmented input image
        - label: the augmented labels including
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
            - instance_ignore_mask: ignore mask
        - prediction: the raw output of the model (without post-processing)
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
    Args:
        dataset: The Dataset.
        batch_images: Tensor of shape [N, 3, H, W], a batch of input images.
        batch_targets: Dict, a dict containing batch of targets.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
            - semantic_weights: a Tensor of shape [N, H, W]
            - center_weights: a Tensor of shape [N, H, W]
            - offset_weights: a Tensor of shape [N, H, W]
        batch_outputs: Dict, a dict containing batch of outputs.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
        out_dir: String, the directory to which the results will be saved.
        iteration: Integer, iteration number.
        target_keys: List, target keys to save.
        output_keys: List, output keys to save.
        iteration_to_remove: Integer, iteration number to remove.
        is_train: Boolean, save train or test debugging image.
    """"""
    batch_size = batch_images.size(0)
    map_height = batch_images.size(2)
    map_width = batch_images.size(3)
    grid_image = np.zeros((map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_targets = len(target_keys)
    grid_target = np.zeros((num_targets * map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_outputs = len(output_keys)
    grid_output = np.zeros((num_outputs * map_height, batch_size * map_width, 3), dtype=np.uint8)
    semantic_pred = torch.argmax(batch_outputs['semantic'].detach(), dim=1)
    if 'foreground' in batch_outputs:
        foreground_pred = torch.argmax(batch_outputs['foreground'].detach(), dim=1)
    else:
        foreground_pred = None
    for i in range(batch_size):
        width_begin = map_width * i
        width_end = map_width * (i + 1)
        image = dataset.reverse_transform(batch_images[i])
        grid_image[:, width_begin:width_end, :] = image
        if 'semantic' in target_keys:
            gt_sem = batch_targets['semantic'][i].cpu().numpy()
            gt_sem = label_to_color_image(gt_sem, dataset.create_label_colormap())
            grid_target[:map_height, width_begin:width_end, :] = gt_sem
        if 'center' in target_keys:
            gt_ctr = batch_targets['center'][i].squeeze().cpu().numpy()
            gt_ctr = gt_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            gt_ctr = gt_ctr.clip(0, 255)
            grid_target[map_height:2 * map_height, width_begin:width_end, :] = gt_ctr
        if 'offset' in target_keys:
            gt_off = batch_targets['offset'][i].permute(1, 2, 0).cpu().numpy()
            gt_off = flow_compute_color(gt_off[:, :, 1], gt_off[:, :, 0])
            grid_target[2 * map_height:3 * map_height, width_begin:width_end, :] = gt_off
        if 'semantic_weights' in target_keys:
            gt_ign = batch_targets['semantic_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] / np.max(gt_ign) * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[3 * map_height:4 * map_height, width_begin:width_end, :] = gt_ign
        if 'center_weights' in target_keys:
            gt_ign = batch_targets['center_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[4 * map_height:5 * map_height, width_begin:width_end, :] = gt_ign
        if 'offset_weights' in target_keys:
            gt_ign = batch_targets['offset_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[5 * map_height:6 * map_height, width_begin:width_end, :] = gt_ign
        if 'foreground' in target_keys:
            gt_fg = batch_targets['foreground'][i].cpu().numpy()
            gt_fg = gt_fg[:, :, None] * 255
            grid_target[6 * map_height:7 * map_height, width_begin:width_end, :] = gt_fg
        if 'semantic' in output_keys:
            pred_sem = semantic_pred[i].cpu().numpy()
            pred_sem = label_to_color_image(pred_sem, dataset.create_label_colormap())
            grid_output[:map_height, width_begin:width_end, :] = pred_sem
        if 'center' in output_keys:
            pred_ctr = batch_outputs['center'][i].detach().squeeze().cpu().numpy()
            pred_ctr = pred_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            pred_ctr = pred_ctr.clip(0, 255)
            grid_output[map_height:2 * map_height, width_begin:width_end, :] = pred_ctr
        if 'offset' in output_keys:
            pred_ctr = batch_outputs['offset'][i].detach().permute(1, 2, 0).cpu().numpy()
            pred_ctr = flow_compute_color(pred_ctr[:, :, 1], pred_ctr[:, :, 0])
            grid_output[2 * map_height:3 * map_height, width_begin:width_end, :] = pred_ctr
        if 'foreground' in output_keys:
            if foreground_pred is not None:
                pred_fg = foreground_pred[i].cpu().numpy()
                pred_fg = pred_fg[:, :, None] * 255
                grid_output[3 * map_height:4 * map_height, width_begin:width_end, :] = pred_fg
    if out_dir is not None:
        if is_train:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
        else:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            if grid_target.size:
                pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
                with open('%s/%s_%d.png' % (out_dir, 'debug_test_targets', iteration), mode='wb') as f:
                    pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
    if is_train:
        if iteration_to_remove >= 0:
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0))","'%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove)",f"{out_dir}/debug_batch_targets_{iteration_to_remove}.png",1,,,,,,,,,,
panoptic-deeplab,https://github.com/bowenc0221/panoptic-deeplab/tree/master/segmentation/utils/debug.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/panoptic-deeplab/segmentation/utils/debug.py,,"def save_debug_images(dataset, batch_images, batch_targets, batch_outputs, out_dir=None, iteration=0, target_keys=('semantic', 'center', 'offset', 'center_weights', 'offset_weights'), output_keys=('semantic', 'center', 'offset'), iteration_to_remove=-1, is_train=True):
    """"""Saves a mini-batch of images for debugging purpose.
        - image: the augmented input image
        - label: the augmented labels including
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
            - instance_ignore_mask: ignore mask
        - prediction: the raw output of the model (without post-processing)
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
    Args:
        dataset: The Dataset.
        batch_images: Tensor of shape [N, 3, H, W], a batch of input images.
        batch_targets: Dict, a dict containing batch of targets.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
            - semantic_weights: a Tensor of shape [N, H, W]
            - center_weights: a Tensor of shape [N, H, W]
            - offset_weights: a Tensor of shape [N, H, W]
        batch_outputs: Dict, a dict containing batch of outputs.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
        out_dir: String, the directory to which the results will be saved.
        iteration: Integer, iteration number.
        target_keys: List, target keys to save.
        output_keys: List, output keys to save.
        iteration_to_remove: Integer, iteration number to remove.
        is_train: Boolean, save train or test debugging image.
    """"""
    batch_size = batch_images.size(0)
    map_height = batch_images.size(2)
    map_width = batch_images.size(3)
    grid_image = np.zeros((map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_targets = len(target_keys)
    grid_target = np.zeros((num_targets * map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_outputs = len(output_keys)
    grid_output = np.zeros((num_outputs * map_height, batch_size * map_width, 3), dtype=np.uint8)
    semantic_pred = torch.argmax(batch_outputs['semantic'].detach(), dim=1)
    if 'foreground' in batch_outputs:
        foreground_pred = torch.argmax(batch_outputs['foreground'].detach(), dim=1)
    else:
        foreground_pred = None
    for i in range(batch_size):
        width_begin = map_width * i
        width_end = map_width * (i + 1)
        image = dataset.reverse_transform(batch_images[i])
        grid_image[:, width_begin:width_end, :] = image
        if 'semantic' in target_keys:
            gt_sem = batch_targets['semantic'][i].cpu().numpy()
            gt_sem = label_to_color_image(gt_sem, dataset.create_label_colormap())
            grid_target[:map_height, width_begin:width_end, :] = gt_sem
        if 'center' in target_keys:
            gt_ctr = batch_targets['center'][i].squeeze().cpu().numpy()
            gt_ctr = gt_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            gt_ctr = gt_ctr.clip(0, 255)
            grid_target[map_height:2 * map_height, width_begin:width_end, :] = gt_ctr
        if 'offset' in target_keys:
            gt_off = batch_targets['offset'][i].permute(1, 2, 0).cpu().numpy()
            gt_off = flow_compute_color(gt_off[:, :, 1], gt_off[:, :, 0])
            grid_target[2 * map_height:3 * map_height, width_begin:width_end, :] = gt_off
        if 'semantic_weights' in target_keys:
            gt_ign = batch_targets['semantic_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] / np.max(gt_ign) * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[3 * map_height:4 * map_height, width_begin:width_end, :] = gt_ign
        if 'center_weights' in target_keys:
            gt_ign = batch_targets['center_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[4 * map_height:5 * map_height, width_begin:width_end, :] = gt_ign
        if 'offset_weights' in target_keys:
            gt_ign = batch_targets['offset_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[5 * map_height:6 * map_height, width_begin:width_end, :] = gt_ign
        if 'foreground' in target_keys:
            gt_fg = batch_targets['foreground'][i].cpu().numpy()
            gt_fg = gt_fg[:, :, None] * 255
            grid_target[6 * map_height:7 * map_height, width_begin:width_end, :] = gt_fg
        if 'semantic' in output_keys:
            pred_sem = semantic_pred[i].cpu().numpy()
            pred_sem = label_to_color_image(pred_sem, dataset.create_label_colormap())
            grid_output[:map_height, width_begin:width_end, :] = pred_sem
        if 'center' in output_keys:
            pred_ctr = batch_outputs['center'][i].detach().squeeze().cpu().numpy()
            pred_ctr = pred_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            pred_ctr = pred_ctr.clip(0, 255)
            grid_output[map_height:2 * map_height, width_begin:width_end, :] = pred_ctr
        if 'offset' in output_keys:
            pred_ctr = batch_outputs['offset'][i].detach().permute(1, 2, 0).cpu().numpy()
            pred_ctr = flow_compute_color(pred_ctr[:, :, 1], pred_ctr[:, :, 0])
            grid_output[2 * map_height:3 * map_height, width_begin:width_end, :] = pred_ctr
        if 'foreground' in output_keys:
            if foreground_pred is not None:
                pred_fg = foreground_pred[i].cpu().numpy()
                pred_fg = pred_fg[:, :, None] * 255
                grid_output[3 * map_height:4 * map_height, width_begin:width_end, :] = pred_fg
    if out_dir is not None:
        if is_train:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
        else:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            if grid_target.size:
                pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
                with open('%s/%s_%d.png' % (out_dir, 'debug_test_targets', iteration), mode='wb') as f:
                    pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
    if is_train:
        if iteration_to_remove >= 0:
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0))","'%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove)",f"{out_dir}/debug_batch_outputs_{iteration_to_remove}.png",1,,,,,,,,,,
panoptic-deeplab,https://github.com/bowenc0221/panoptic-deeplab/tree/master/segmentation/utils/debug.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/panoptic-deeplab/segmentation/utils/debug.py,,"def save_debug_images(dataset, batch_images, batch_targets, batch_outputs, out_dir=None, iteration=0, target_keys=('semantic', 'center', 'offset', 'center_weights', 'offset_weights'), output_keys=('semantic', 'center', 'offset'), iteration_to_remove=-1, is_train=True):
    """"""Saves a mini-batch of images for debugging purpose.
        - image: the augmented input image
        - label: the augmented labels including
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
            - instance_ignore_mask: ignore mask
        - prediction: the raw output of the model (without post-processing)
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
    Args:
        dataset: The Dataset.
        batch_images: Tensor of shape [N, 3, H, W], a batch of input images.
        batch_targets: Dict, a dict containing batch of targets.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
            - semantic_weights: a Tensor of shape [N, H, W]
            - center_weights: a Tensor of shape [N, H, W]
            - offset_weights: a Tensor of shape [N, H, W]
        batch_outputs: Dict, a dict containing batch of outputs.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
        out_dir: String, the directory to which the results will be saved.
        iteration: Integer, iteration number.
        target_keys: List, target keys to save.
        output_keys: List, output keys to save.
        iteration_to_remove: Integer, iteration number to remove.
        is_train: Boolean, save train or test debugging image.
    """"""
    batch_size = batch_images.size(0)
    map_height = batch_images.size(2)
    map_width = batch_images.size(3)
    grid_image = np.zeros((map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_targets = len(target_keys)
    grid_target = np.zeros((num_targets * map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_outputs = len(output_keys)
    grid_output = np.zeros((num_outputs * map_height, batch_size * map_width, 3), dtype=np.uint8)
    semantic_pred = torch.argmax(batch_outputs['semantic'].detach(), dim=1)
    if 'foreground' in batch_outputs:
        foreground_pred = torch.argmax(batch_outputs['foreground'].detach(), dim=1)
    else:
        foreground_pred = None
    for i in range(batch_size):
        width_begin = map_width * i
        width_end = map_width * (i + 1)
        image = dataset.reverse_transform(batch_images[i])
        grid_image[:, width_begin:width_end, :] = image
        if 'semantic' in target_keys:
            gt_sem = batch_targets['semantic'][i].cpu().numpy()
            gt_sem = label_to_color_image(gt_sem, dataset.create_label_colormap())
            grid_target[:map_height, width_begin:width_end, :] = gt_sem
        if 'center' in target_keys:
            gt_ctr = batch_targets['center'][i].squeeze().cpu().numpy()
            gt_ctr = gt_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            gt_ctr = gt_ctr.clip(0, 255)
            grid_target[map_height:2 * map_height, width_begin:width_end, :] = gt_ctr
        if 'offset' in target_keys:
            gt_off = batch_targets['offset'][i].permute(1, 2, 0).cpu().numpy()
            gt_off = flow_compute_color(gt_off[:, :, 1], gt_off[:, :, 0])
            grid_target[2 * map_height:3 * map_height, width_begin:width_end, :] = gt_off
        if 'semantic_weights' in target_keys:
            gt_ign = batch_targets['semantic_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] / np.max(gt_ign) * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[3 * map_height:4 * map_height, width_begin:width_end, :] = gt_ign
        if 'center_weights' in target_keys:
            gt_ign = batch_targets['center_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[4 * map_height:5 * map_height, width_begin:width_end, :] = gt_ign
        if 'offset_weights' in target_keys:
            gt_ign = batch_targets['offset_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[5 * map_height:6 * map_height, width_begin:width_end, :] = gt_ign
        if 'foreground' in target_keys:
            gt_fg = batch_targets['foreground'][i].cpu().numpy()
            gt_fg = gt_fg[:, :, None] * 255
            grid_target[6 * map_height:7 * map_height, width_begin:width_end, :] = gt_fg
        if 'semantic' in output_keys:
            pred_sem = semantic_pred[i].cpu().numpy()
            pred_sem = label_to_color_image(pred_sem, dataset.create_label_colormap())
            grid_output[:map_height, width_begin:width_end, :] = pred_sem
        if 'center' in output_keys:
            pred_ctr = batch_outputs['center'][i].detach().squeeze().cpu().numpy()
            pred_ctr = pred_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            pred_ctr = pred_ctr.clip(0, 255)
            grid_output[map_height:2 * map_height, width_begin:width_end, :] = pred_ctr
        if 'offset' in output_keys:
            pred_ctr = batch_outputs['offset'][i].detach().permute(1, 2, 0).cpu().numpy()
            pred_ctr = flow_compute_color(pred_ctr[:, :, 1], pred_ctr[:, :, 0])
            grid_output[2 * map_height:3 * map_height, width_begin:width_end, :] = pred_ctr
        if 'foreground' in output_keys:
            if foreground_pred is not None:
                pred_fg = foreground_pred[i].cpu().numpy()
                pred_fg = pred_fg[:, :, None] * 255
                grid_output[3 * map_height:4 * map_height, width_begin:width_end, :] = pred_fg
    if out_dir is not None:
        if is_train:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
        else:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            if grid_target.size:
                pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
                with open('%s/%s_%d.png' % (out_dir, 'debug_test_targets', iteration), mode='wb') as f:
                    pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
    if is_train:
        if iteration_to_remove >= 0:
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0))","'%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0)",f"{out_dir}/{'debug_batch_images'}_{0}.png",1,,,,,,,,,,
panoptic-deeplab,https://github.com/bowenc0221/panoptic-deeplab/tree/master/segmentation/utils/debug.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/panoptic-deeplab/segmentation/utils/debug.py,,"def save_debug_images(dataset, batch_images, batch_targets, batch_outputs, out_dir=None, iteration=0, target_keys=('semantic', 'center', 'offset', 'center_weights', 'offset_weights'), output_keys=('semantic', 'center', 'offset'), iteration_to_remove=-1, is_train=True):
    """"""Saves a mini-batch of images for debugging purpose.
        - image: the augmented input image
        - label: the augmented labels including
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
            - instance_ignore_mask: ignore mask
        - prediction: the raw output of the model (without post-processing)
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
    Args:
        dataset: The Dataset.
        batch_images: Tensor of shape [N, 3, H, W], a batch of input images.
        batch_targets: Dict, a dict containing batch of targets.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
            - semantic_weights: a Tensor of shape [N, H, W]
            - center_weights: a Tensor of shape [N, H, W]
            - offset_weights: a Tensor of shape [N, H, W]
        batch_outputs: Dict, a dict containing batch of outputs.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
        out_dir: String, the directory to which the results will be saved.
        iteration: Integer, iteration number.
        target_keys: List, target keys to save.
        output_keys: List, output keys to save.
        iteration_to_remove: Integer, iteration number to remove.
        is_train: Boolean, save train or test debugging image.
    """"""
    batch_size = batch_images.size(0)
    map_height = batch_images.size(2)
    map_width = batch_images.size(3)
    grid_image = np.zeros((map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_targets = len(target_keys)
    grid_target = np.zeros((num_targets * map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_outputs = len(output_keys)
    grid_output = np.zeros((num_outputs * map_height, batch_size * map_width, 3), dtype=np.uint8)
    semantic_pred = torch.argmax(batch_outputs['semantic'].detach(), dim=1)
    if 'foreground' in batch_outputs:
        foreground_pred = torch.argmax(batch_outputs['foreground'].detach(), dim=1)
    else:
        foreground_pred = None
    for i in range(batch_size):
        width_begin = map_width * i
        width_end = map_width * (i + 1)
        image = dataset.reverse_transform(batch_images[i])
        grid_image[:, width_begin:width_end, :] = image
        if 'semantic' in target_keys:
            gt_sem = batch_targets['semantic'][i].cpu().numpy()
            gt_sem = label_to_color_image(gt_sem, dataset.create_label_colormap())
            grid_target[:map_height, width_begin:width_end, :] = gt_sem
        if 'center' in target_keys:
            gt_ctr = batch_targets['center'][i].squeeze().cpu().numpy()
            gt_ctr = gt_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            gt_ctr = gt_ctr.clip(0, 255)
            grid_target[map_height:2 * map_height, width_begin:width_end, :] = gt_ctr
        if 'offset' in target_keys:
            gt_off = batch_targets['offset'][i].permute(1, 2, 0).cpu().numpy()
            gt_off = flow_compute_color(gt_off[:, :, 1], gt_off[:, :, 0])
            grid_target[2 * map_height:3 * map_height, width_begin:width_end, :] = gt_off
        if 'semantic_weights' in target_keys:
            gt_ign = batch_targets['semantic_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] / np.max(gt_ign) * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[3 * map_height:4 * map_height, width_begin:width_end, :] = gt_ign
        if 'center_weights' in target_keys:
            gt_ign = batch_targets['center_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[4 * map_height:5 * map_height, width_begin:width_end, :] = gt_ign
        if 'offset_weights' in target_keys:
            gt_ign = batch_targets['offset_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[5 * map_height:6 * map_height, width_begin:width_end, :] = gt_ign
        if 'foreground' in target_keys:
            gt_fg = batch_targets['foreground'][i].cpu().numpy()
            gt_fg = gt_fg[:, :, None] * 255
            grid_target[6 * map_height:7 * map_height, width_begin:width_end, :] = gt_fg
        if 'semantic' in output_keys:
            pred_sem = semantic_pred[i].cpu().numpy()
            pred_sem = label_to_color_image(pred_sem, dataset.create_label_colormap())
            grid_output[:map_height, width_begin:width_end, :] = pred_sem
        if 'center' in output_keys:
            pred_ctr = batch_outputs['center'][i].detach().squeeze().cpu().numpy()
            pred_ctr = pred_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            pred_ctr = pred_ctr.clip(0, 255)
            grid_output[map_height:2 * map_height, width_begin:width_end, :] = pred_ctr
        if 'offset' in output_keys:
            pred_ctr = batch_outputs['offset'][i].detach().permute(1, 2, 0).cpu().numpy()
            pred_ctr = flow_compute_color(pred_ctr[:, :, 1], pred_ctr[:, :, 0])
            grid_output[2 * map_height:3 * map_height, width_begin:width_end, :] = pred_ctr
        if 'foreground' in output_keys:
            if foreground_pred is not None:
                pred_fg = foreground_pred[i].cpu().numpy()
                pred_fg = pred_fg[:, :, None] * 255
                grid_output[3 * map_height:4 * map_height, width_begin:width_end, :] = pred_fg
    if out_dir is not None:
        if is_train:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
        else:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            if grid_target.size:
                pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
                with open('%s/%s_%d.png' % (out_dir, 'debug_test_targets', iteration), mode='wb') as f:
                    pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
    if is_train:
        if iteration_to_remove >= 0:
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0))","'%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0)",f"{out_dir}/{'debug_batch_targets'}_{0}.png",1,,,,,,,,,,
panoptic-deeplab,https://github.com/bowenc0221/panoptic-deeplab/tree/master/segmentation/utils/debug.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/panoptic-deeplab/segmentation/utils/debug.py,,"def save_debug_images(dataset, batch_images, batch_targets, batch_outputs, out_dir=None, iteration=0, target_keys=('semantic', 'center', 'offset', 'center_weights', 'offset_weights'), output_keys=('semantic', 'center', 'offset'), iteration_to_remove=-1, is_train=True):
    """"""Saves a mini-batch of images for debugging purpose.
        - image: the augmented input image
        - label: the augmented labels including
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
            - instance_ignore_mask: ignore mask
        - prediction: the raw output of the model (without post-processing)
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
    Args:
        dataset: The Dataset.
        batch_images: Tensor of shape [N, 3, H, W], a batch of input images.
        batch_targets: Dict, a dict containing batch of targets.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
            - semantic_weights: a Tensor of shape [N, H, W]
            - center_weights: a Tensor of shape [N, H, W]
            - offset_weights: a Tensor of shape [N, H, W]
        batch_outputs: Dict, a dict containing batch of outputs.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
        out_dir: String, the directory to which the results will be saved.
        iteration: Integer, iteration number.
        target_keys: List, target keys to save.
        output_keys: List, output keys to save.
        iteration_to_remove: Integer, iteration number to remove.
        is_train: Boolean, save train or test debugging image.
    """"""
    batch_size = batch_images.size(0)
    map_height = batch_images.size(2)
    map_width = batch_images.size(3)
    grid_image = np.zeros((map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_targets = len(target_keys)
    grid_target = np.zeros((num_targets * map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_outputs = len(output_keys)
    grid_output = np.zeros((num_outputs * map_height, batch_size * map_width, 3), dtype=np.uint8)
    semantic_pred = torch.argmax(batch_outputs['semantic'].detach(), dim=1)
    if 'foreground' in batch_outputs:
        foreground_pred = torch.argmax(batch_outputs['foreground'].detach(), dim=1)
    else:
        foreground_pred = None
    for i in range(batch_size):
        width_begin = map_width * i
        width_end = map_width * (i + 1)
        image = dataset.reverse_transform(batch_images[i])
        grid_image[:, width_begin:width_end, :] = image
        if 'semantic' in target_keys:
            gt_sem = batch_targets['semantic'][i].cpu().numpy()
            gt_sem = label_to_color_image(gt_sem, dataset.create_label_colormap())
            grid_target[:map_height, width_begin:width_end, :] = gt_sem
        if 'center' in target_keys:
            gt_ctr = batch_targets['center'][i].squeeze().cpu().numpy()
            gt_ctr = gt_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            gt_ctr = gt_ctr.clip(0, 255)
            grid_target[map_height:2 * map_height, width_begin:width_end, :] = gt_ctr
        if 'offset' in target_keys:
            gt_off = batch_targets['offset'][i].permute(1, 2, 0).cpu().numpy()
            gt_off = flow_compute_color(gt_off[:, :, 1], gt_off[:, :, 0])
            grid_target[2 * map_height:3 * map_height, width_begin:width_end, :] = gt_off
        if 'semantic_weights' in target_keys:
            gt_ign = batch_targets['semantic_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] / np.max(gt_ign) * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[3 * map_height:4 * map_height, width_begin:width_end, :] = gt_ign
        if 'center_weights' in target_keys:
            gt_ign = batch_targets['center_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[4 * map_height:5 * map_height, width_begin:width_end, :] = gt_ign
        if 'offset_weights' in target_keys:
            gt_ign = batch_targets['offset_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[5 * map_height:6 * map_height, width_begin:width_end, :] = gt_ign
        if 'foreground' in target_keys:
            gt_fg = batch_targets['foreground'][i].cpu().numpy()
            gt_fg = gt_fg[:, :, None] * 255
            grid_target[6 * map_height:7 * map_height, width_begin:width_end, :] = gt_fg
        if 'semantic' in output_keys:
            pred_sem = semantic_pred[i].cpu().numpy()
            pred_sem = label_to_color_image(pred_sem, dataset.create_label_colormap())
            grid_output[:map_height, width_begin:width_end, :] = pred_sem
        if 'center' in output_keys:
            pred_ctr = batch_outputs['center'][i].detach().squeeze().cpu().numpy()
            pred_ctr = pred_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            pred_ctr = pred_ctr.clip(0, 255)
            grid_output[map_height:2 * map_height, width_begin:width_end, :] = pred_ctr
        if 'offset' in output_keys:
            pred_ctr = batch_outputs['offset'][i].detach().permute(1, 2, 0).cpu().numpy()
            pred_ctr = flow_compute_color(pred_ctr[:, :, 1], pred_ctr[:, :, 0])
            grid_output[2 * map_height:3 * map_height, width_begin:width_end, :] = pred_ctr
        if 'foreground' in output_keys:
            if foreground_pred is not None:
                pred_fg = foreground_pred[i].cpu().numpy()
                pred_fg = pred_fg[:, :, None] * 255
                grid_output[3 * map_height:4 * map_height, width_begin:width_end, :] = pred_fg
    if out_dir is not None:
        if is_train:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
        else:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            if grid_target.size:
                pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
                with open('%s/%s_%d.png' % (out_dir, 'debug_test_targets', iteration), mode='wb') as f:
                    pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
    if is_train:
        if iteration_to_remove >= 0:
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0))","'%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0)",f"{out_dir}/{'debug_batch_outputs'}_{0}.png",1,,,,,,,,,,
panoptic-deeplab,https://github.com/bowenc0221/panoptic-deeplab/tree/master/segmentation/utils/debug.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/panoptic-deeplab/segmentation/utils/debug.py,,"def save_debug_images(dataset, batch_images, batch_targets, batch_outputs, out_dir=None, iteration=0, target_keys=('semantic', 'center', 'offset', 'center_weights', 'offset_weights'), output_keys=('semantic', 'center', 'offset'), iteration_to_remove=-1, is_train=True):
    """"""Saves a mini-batch of images for debugging purpose.
        - image: the augmented input image
        - label: the augmented labels including
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
            - instance_ignore_mask: ignore mask
        - prediction: the raw output of the model (without post-processing)
            - semantic: semantic segmentation label
            - center: center heatmap
            - offset: offset field
    Args:
        dataset: The Dataset.
        batch_images: Tensor of shape [N, 3, H, W], a batch of input images.
        batch_targets: Dict, a dict containing batch of targets.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
            - semantic_weights: a Tensor of shape [N, H, W]
            - center_weights: a Tensor of shape [N, H, W]
            - offset_weights: a Tensor of shape [N, H, W]
        batch_outputs: Dict, a dict containing batch of outputs.
            - semantic: a Tensor of shape [N, H, W]
            - center: a Tensor of shape [N, 1, H, W]
            - offset: a Tensor of shape [N, 2, H, W]
        out_dir: String, the directory to which the results will be saved.
        iteration: Integer, iteration number.
        target_keys: List, target keys to save.
        output_keys: List, output keys to save.
        iteration_to_remove: Integer, iteration number to remove.
        is_train: Boolean, save train or test debugging image.
    """"""
    batch_size = batch_images.size(0)
    map_height = batch_images.size(2)
    map_width = batch_images.size(3)
    grid_image = np.zeros((map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_targets = len(target_keys)
    grid_target = np.zeros((num_targets * map_height, batch_size * map_width, 3), dtype=np.uint8)
    num_outputs = len(output_keys)
    grid_output = np.zeros((num_outputs * map_height, batch_size * map_width, 3), dtype=np.uint8)
    semantic_pred = torch.argmax(batch_outputs['semantic'].detach(), dim=1)
    if 'foreground' in batch_outputs:
        foreground_pred = torch.argmax(batch_outputs['foreground'].detach(), dim=1)
    else:
        foreground_pred = None
    for i in range(batch_size):
        width_begin = map_width * i
        width_end = map_width * (i + 1)
        image = dataset.reverse_transform(batch_images[i])
        grid_image[:, width_begin:width_end, :] = image
        if 'semantic' in target_keys:
            gt_sem = batch_targets['semantic'][i].cpu().numpy()
            gt_sem = label_to_color_image(gt_sem, dataset.create_label_colormap())
            grid_target[:map_height, width_begin:width_end, :] = gt_sem
        if 'center' in target_keys:
            gt_ctr = batch_targets['center'][i].squeeze().cpu().numpy()
            gt_ctr = gt_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            gt_ctr = gt_ctr.clip(0, 255)
            grid_target[map_height:2 * map_height, width_begin:width_end, :] = gt_ctr
        if 'offset' in target_keys:
            gt_off = batch_targets['offset'][i].permute(1, 2, 0).cpu().numpy()
            gt_off = flow_compute_color(gt_off[:, :, 1], gt_off[:, :, 0])
            grid_target[2 * map_height:3 * map_height, width_begin:width_end, :] = gt_off
        if 'semantic_weights' in target_keys:
            gt_ign = batch_targets['semantic_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] / np.max(gt_ign) * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[3 * map_height:4 * map_height, width_begin:width_end, :] = gt_ign
        if 'center_weights' in target_keys:
            gt_ign = batch_targets['center_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[4 * map_height:5 * map_height, width_begin:width_end, :] = gt_ign
        if 'offset_weights' in target_keys:
            gt_ign = batch_targets['offset_weights'][i].cpu().numpy()
            gt_ign = gt_ign[:, :, None] * 255
            gt_ign = np.tile(gt_ign, (1, 1, 3))
            grid_target[5 * map_height:6 * map_height, width_begin:width_end, :] = gt_ign
        if 'foreground' in target_keys:
            gt_fg = batch_targets['foreground'][i].cpu().numpy()
            gt_fg = gt_fg[:, :, None] * 255
            grid_target[6 * map_height:7 * map_height, width_begin:width_end, :] = gt_fg
        if 'semantic' in output_keys:
            pred_sem = semantic_pred[i].cpu().numpy()
            pred_sem = label_to_color_image(pred_sem, dataset.create_label_colormap())
            grid_output[:map_height, width_begin:width_end, :] = pred_sem
        if 'center' in output_keys:
            pred_ctr = batch_outputs['center'][i].detach().squeeze().cpu().numpy()
            pred_ctr = pred_ctr[:, :, None] * np.array([255, 0, 0]).reshape((1, 1, 3))
            pred_ctr = pred_ctr.clip(0, 255)
            grid_output[map_height:2 * map_height, width_begin:width_end, :] = pred_ctr
        if 'offset' in output_keys:
            pred_ctr = batch_outputs['offset'][i].detach().permute(1, 2, 0).cpu().numpy()
            pred_ctr = flow_compute_color(pred_ctr[:, :, 1], pred_ctr[:, :, 0])
            grid_output[2 * map_height:3 * map_height, width_begin:width_end, :] = pred_ctr
        if 'foreground' in output_keys:
            if foreground_pred is not None:
                pred_fg = foreground_pred[i].cpu().numpy()
                pred_fg = pred_fg[:, :, None] * 255
                grid_output[3 * map_height:4 * map_height, width_begin:width_end, :] = pred_fg
    if out_dir is not None:
        if is_train:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
        else:
            pil_image = img.fromarray(grid_image.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_images', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
            if grid_target.size:
                pil_image = img.fromarray(grid_target.astype(dtype=np.uint8))
                with open('%s/%s_%d.png' % (out_dir, 'debug_test_targets', iteration), mode='wb') as f:
                    pil_image.save(f, 'PNG')
            pil_image = img.fromarray(grid_output.astype(dtype=np.uint8))
            with open('%s/%s_%d.png' % (out_dir, 'debug_test_outputs', iteration), mode='wb') as f:
                pil_image.save(f, 'PNG')
    if is_train:
        if iteration_to_remove >= 0:
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', iteration_to_remove))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_images', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_targets', 0))
            if os.path.exists('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0)):
                os.remove('%s/%s_%d.png' % (out_dir, 'debug_batch_outputs', 0))","'%s/%s_%d.png' % (out_dir, 'debug_test_targets', iteration)",f"{out_dir}/debug_test_targets_{iteration}.png",1,,,,,,,,,,
tvm,https://github.com/apache/tvm/tree/master/python/tvm/autotvm/tuner/sa_model_optimizer.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/tvm/python/tvm/autotvm/tuner/sa_model_optimizer.py,SimulatedAnnealingOptimizer,"def find_maximums(self, model, num, exclusive):
    tic = time.time()
    (temp, n_iter, early_stop, log_interval) = (self.temp, self.n_iter, self.early_stop, self.log_interval)
    if self.persistent and self.points is not None:
        points = self.points
    else:
        points = self.task.config_space.sample_ints(self.parallel_size)
    scores = model.predict(points)
    heap_items = [(float('-inf'), -1 - i) for i in range(num)]
    heapq.heapify(heap_items)
    in_heap = set(exclusive)
    in_heap.update([x[1] for x in heap_items])
    for (s, p) in zip(scores, points):
        if s > heap_items[0][0] and p not in in_heap:
            pop = heapq.heapreplace(heap_items, (s, p))
            in_heap.remove(pop[1])
            in_heap.add(p)
    k = 0
    k_last_modify = 0
    if isinstance(temp, (tuple, list, np.ndarray)):
        t = temp[0]
        cool = 1.0 * (temp[0] - temp[1]) / (n_iter + 1)
    else:
        t = temp
        cool = 0
    while k < n_iter and k < k_last_modify + early_stop:
        new_points = np.empty_like(points)
        for (i, p) in enumerate(points):
            new_points[i] = self.task.config_space.random_walk(p)
        new_scores = model.predict(new_points)
        ac_prob = np.exp(np.minimum((new_scores - scores) / (t + 1e-05), 1))
        ac_index = np.random.random(len(ac_prob)) < ac_prob
        points[ac_index] = new_points[ac_index]
        scores[ac_index] = new_scores[ac_index]
        for (s, p) in zip(new_scores, new_points):
            if s > heap_items[0][0] and p not in in_heap:
                pop = heapq.heapreplace(heap_items, (s, p))
                in_heap.remove(pop[1])
                in_heap.add(p)
                k_last_modify = k
        k += 1
        t -= cool
        if log_interval and k % log_interval == 0:
            t_str = '%.2f' % t
            logger.debug('SA iter: %d\tlast_update: %d\tmax-0: %.2f\tmax-1: %.2f\ttemp: %s\telapsed: %.2f', k, k_last_modify, heap_items[0][0], np.max([v for (v, _) in heap_items]), t_str, time.time() - tic)
    heap_items.sort(key=lambda item: -item[0])
    heap_items = [x for x in heap_items if x[0] >= 0]
    logger.debug('SA iter: %d\tlast_update: %d\telapsed: %.2f', k, k_last_modify, time.time() - tic)
    logger.debug('SA Maximums: %s', heap_items)
    if self.persistent:
        self.points = points
    return [x[1] for x in heap_items]",'%.2f' % t,f"{t:.2f}",1,,,,,,,,,,
freeipa,https://github.com/freeipa/freeipa/tree/master/ipaserver/plugins/host.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/freeipa/ipaserver/plugins/host.py,host,"def get_managed_hosts(self, dn):
    host_filter = 'managedBy=%s' % dn
    host_attrs = ['fqdn']
    ldap = self.api.Backend.ldap2
    managed_hosts = []
    try:
        (hosts, _truncated) = ldap.find_entries(base_dn=DN(self.container_dn, api.env.basedn), filter=host_filter, attrs_list=host_attrs)
        for host in hosts:
            managed_hosts.append(host.dn)
    except errors.NotFound:
        return []
    return managed_hosts",'managedBy=%s' % dn,f"managedBy={dn}",1,,,,,,,,,,
Remarkable,https://github.com/jamiemcg/Remarkable/tree/master/remarkable_lib/Builder.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/Remarkable/remarkable_lib/Builder.py,,"def auto_connect_by_name(callback_obj, builder):
    """"""finds handlers like on_<widget_name>_<signal> and connects them

    i.e. find widget,signal pair in builder and call
    widget.connect(signal, on_<widget_name>_<signal>)""""""
    callback_handler_dict = dict_from_callback_obj(callback_obj)
    for item in builder.widgets.items():
        (widget_name, widget) = item
        signal_ids = []
        try:
            widget_type = type(widget)
            while widget_type:
                signal_ids.extend(GObject.signal_list_ids(widget_type))
                widget_type = GObject.type_parent(widget_type)
        except RuntimeError:
            pass
        signal_names = [GObject.signal_name(sid) for sid in signal_ids]
        for sig in signal_names:
            sig = sig.replace('-', '_')
            handler_names = ['on_%s_%s' % (widget_name, sig)]
            if widget is callback_obj:
                handler_names.append('on_%s' % sig)
            do_connect(item, sig, handler_names, callback_handler_dict, builder.connections)
    log_unconnected_functions(callback_handler_dict, builder.connections)","'on_%s_%s' % (widget_name, sig)",f"on_{widget_name}_{sig}",1,,,,,,,,,,
Remarkable,https://github.com/jamiemcg/Remarkable/tree/master/remarkable_lib/Builder.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/Remarkable/remarkable_lib/Builder.py,,"def auto_connect_by_name(callback_obj, builder):
    """"""finds handlers like on_<widget_name>_<signal> and connects them

    i.e. find widget,signal pair in builder and call
    widget.connect(signal, on_<widget_name>_<signal>)""""""
    callback_handler_dict = dict_from_callback_obj(callback_obj)
    for item in builder.widgets.items():
        (widget_name, widget) = item
        signal_ids = []
        try:
            widget_type = type(widget)
            while widget_type:
                signal_ids.extend(GObject.signal_list_ids(widget_type))
                widget_type = GObject.type_parent(widget_type)
        except RuntimeError:
            pass
        signal_names = [GObject.signal_name(sid) for sid in signal_ids]
        for sig in signal_names:
            sig = sig.replace('-', '_')
            handler_names = ['on_%s_%s' % (widget_name, sig)]
            if widget is callback_obj:
                handler_names.append('on_%s' % sig)
            do_connect(item, sig, handler_names, callback_handler_dict, builder.connections)
    log_unconnected_functions(callback_handler_dict, builder.connections)",'on_%s' % sig,f"on_{sig}",1,,,,,,,,,,
cobbler,https://github.com/cobbler/cobbler/tree/master/cobbler/cli.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/cobbler/cobbler/cli.py,CobblerCLI,"def start_task(self, name: str, options: dict) -> str:
    """"""
        Start an asynchronous task in the background.

        :param name: ""background\\_"" % name function must exist in remote.py. This function will be called in a
                      subthread.
        :param options: Dictionary of options passed to the newly started thread
        :return: Id of the newly started task
        """"""
    options = utils.strip_none(vars(options), omit_none=True)
    fn = getattr(self.remote, 'background_%s' % name)
    return fn(options, self.token)",'background_%s' % name,f'background_{name}',1,,,,,,,,,,
azure-cli,https://github.com/Azure/azure-cli/tree/master/src/azure-cli/azure/cli/command_modules/netappfiles/tests/latest/test_volume_commands.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/azure-cli/src/azure-cli/azure/cli/command_modules/netappfiles/tests/latest/test_volume_commands.py,AzureNetAppFilesVolumeServiceScenarioTest,"def test_export_policy(self):
    account_name = self.create_random_name(prefix='cli-acc-', length=24)
    pool_name = self.create_random_name(prefix='cli-pool-', length=24)
    volume_name = self.create_random_name(prefix='cli-vol-', length=24)
    volume = self.create_volume(account_name, pool_name, volume_name, '{rg}')
    assert volume['name'] == account_name + '/' + pool_name + '/' + volume_name
    vol_with_export_policy = self.cmd(""netappfiles volume export-policy add -g {rg} -a %s -p %s -v %s --allowed-clients '1.2.3.0/24' --rule-index 3 --unix-read-only true --unix-read-write false --cifs false --nfsv3 true --nfsv41 false --has-root-access false"" % (account_name, pool_name, volume_name)).get_output_in_json()
    assert vol_with_export_policy['name'] == account_name + '/' + pool_name + '/' + volume_name
    assert vol_with_export_policy['exportPolicy']['rules'][0]['allowedClients'] == '1.2.3.0/24'
    assert vol_with_export_policy['exportPolicy']['rules'][0]['ruleIndex'] == 3
    assert vol_with_export_policy['exportPolicy']['rules'][0]['cifs'] is False
    assert vol_with_export_policy['exportPolicy']['rules'][0]['hasRootAccess'] is False
    vol_with_export_policy = self.cmd(""netappfiles volume export-policy add -g {rg} -a %s -p %s -v %s --allowed-clients '1.2.4.0/24' --rule-index 2 --unix-read-only true --unix-read-write false --cifs true --nfsv3 true --nfsv41 false"" % (account_name, pool_name, volume_name)).get_output_in_json()
    assert vol_with_export_policy['name'] == account_name + '/' + pool_name + '/' + volume_name
    assert vol_with_export_policy['exportPolicy']['rules'][1]['allowedClients'] == '1.2.3.0/24'
    assert vol_with_export_policy['exportPolicy']['rules'][0]['allowedClients'] == '1.2.4.0/24'
    assert vol_with_export_policy['exportPolicy']['rules'][0]['cifs'] is True
    assert len(vol_with_export_policy['exportPolicy']['rules']) == 3
    export_policy = self.cmd('netappfiles volume export-policy list -g {rg} -a %s -p %s -v %s' % (account_name, pool_name, volume_name)).get_output_in_json()
    assert len(export_policy['rules']) == 3
    self.cmd('netappfiles volume export-policy remove -g {rg} -a %s -p %s -v %s --rule-index 3' % (account_name, pool_name, volume_name)).get_output_in_json()
    if self.is_live or self.in_recording:
        time.sleep(240)
    volume = self.cmd('az netappfiles volume show --resource-group {rg} -a %s -p %s -v %s' % (account_name, pool_name, volume_name)).get_output_in_json()
    assert volume['name'] == account_name + '/' + pool_name + '/' + volume_name
    assert len(volume['exportPolicy']['rules']) == 2","""netappfiles volume export-policy add -g {rg} -a %s -p %s -v %s --allowed-clients '1.2.3.0/24' --rule-index 3 --unix-read-only true --unix-read-write false --cifs false --nfsv3 true --nfsv41 false --has-root-access false"" % (account_name, pool_name, volume_name)",print(f"netappfiles volume export-policy add -g {rg} -a {account_name} -p {pool_name} -v {volume_name} --allowed-clients '1.2.3.0/24' --rule-index 3 --unix-read-only true --unix-read-write false --cifs false --nfsv3 true --nfsv41 false --has-root-access false"),1,,,,,,,,,,
azure-cli,https://github.com/Azure/azure-cli/tree/master/src/azure-cli/azure/cli/command_modules/netappfiles/tests/latest/test_volume_commands.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/azure-cli/src/azure-cli/azure/cli/command_modules/netappfiles/tests/latest/test_volume_commands.py,AzureNetAppFilesVolumeServiceScenarioTest,"def test_export_policy(self):
    account_name = self.create_random_name(prefix='cli-acc-', length=24)
    pool_name = self.create_random_name(prefix='cli-pool-', length=24)
    volume_name = self.create_random_name(prefix='cli-vol-', length=24)
    volume = self.create_volume(account_name, pool_name, volume_name, '{rg}')
    assert volume['name'] == account_name + '/' + pool_name + '/' + volume_name
    vol_with_export_policy = self.cmd(""netappfiles volume export-policy add -g {rg} -a %s -p %s -v %s --allowed-clients '1.2.3.0/24' --rule-index 3 --unix-read-only true --unix-read-write false --cifs false --nfsv3 true --nfsv41 false --has-root-access false"" % (account_name, pool_name, volume_name)).get_output_in_json()
    assert vol_with_export_policy['name'] == account_name + '/' + pool_name + '/' + volume_name
    assert vol_with_export_policy['exportPolicy']['rules'][0]['allowedClients'] == '1.2.3.0/24'
    assert vol_with_export_policy['exportPolicy']['rules'][0]['ruleIndex'] == 3
    assert vol_with_export_policy['exportPolicy']['rules'][0]['cifs'] is False
    assert vol_with_export_policy['exportPolicy']['rules'][0]['hasRootAccess'] is False
    vol_with_export_policy = self.cmd(""netappfiles volume export-policy add -g {rg} -a %s -p %s -v %s --allowed-clients '1.2.4.0/24' --rule-index 2 --unix-read-only true --unix-read-write false --cifs true --nfsv3 true --nfsv41 false"" % (account_name, pool_name, volume_name)).get_output_in_json()
    assert vol_with_export_policy['name'] == account_name + '/' + pool_name + '/' + volume_name
    assert vol_with_export_policy['exportPolicy']['rules'][1]['allowedClients'] == '1.2.3.0/24'
    assert vol_with_export_policy['exportPolicy']['rules'][0]['allowedClients'] == '1.2.4.0/24'
    assert vol_with_export_policy['exportPolicy']['rules'][0]['cifs'] is True
    assert len(vol_with_export_policy['exportPolicy']['rules']) == 3
    export_policy = self.cmd('netappfiles volume export-policy list -g {rg} -a %s -p %s -v %s' % (account_name, pool_name, volume_name)).get_output_in_json()
    assert len(export_policy['rules']) == 3
    self.cmd('netappfiles volume export-policy remove -g {rg} -a %s -p %s -v %s --rule-index 3' % (account_name, pool_name, volume_name)).get_output_in_json()
    if self.is_live or self.in_recording:
        time.sleep(240)
    volume = self.cmd('az netappfiles volume show --resource-group {rg} -a %s -p %s -v %s' % (account_name, pool_name, volume_name)).get_output_in_json()
    assert volume['name'] == account_name + '/' + pool_name + '/' + volume_name
    assert len(volume['exportPolicy']['rules']) == 2","""netappfiles volume export-policy add -g {rg} -a %s -p %s -v %s --allowed-clients '1.2.4.0/24' --rule-index 2 --unix-read-only true --unix-read-write false --cifs true --nfsv3 true --nfsv41 false"" % (account_name, pool_name, volume_name)",f"netappfiles volume export-policy add -g {rg} -a {account_name} -p {pool_name} -v {volume_name} --allowed-clients '1.2.4.0/24' --rule-index 2 --unix-read-only true --unix-read-write false --cifs true --nfsv3 true --nfsv41 false",1,,,,,,,,,,
azure-cli,https://github.com/Azure/azure-cli/tree/master/src/azure-cli/azure/cli/command_modules/netappfiles/tests/latest/test_volume_commands.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/azure-cli/src/azure-cli/azure/cli/command_modules/netappfiles/tests/latest/test_volume_commands.py,AzureNetAppFilesVolumeServiceScenarioTest,"def test_export_policy(self):
    account_name = self.create_random_name(prefix='cli-acc-', length=24)
    pool_name = self.create_random_name(prefix='cli-pool-', length=24)
    volume_name = self.create_random_name(prefix='cli-vol-', length=24)
    volume = self.create_volume(account_name, pool_name, volume_name, '{rg}')
    assert volume['name'] == account_name + '/' + pool_name + '/' + volume_name
    vol_with_export_policy = self.cmd(""netappfiles volume export-policy add -g {rg} -a %s -p %s -v %s --allowed-clients '1.2.3.0/24' --rule-index 3 --unix-read-only true --unix-read-write false --cifs false --nfsv3 true --nfsv41 false --has-root-access false"" % (account_name, pool_name, volume_name)).get_output_in_json()
    assert vol_with_export_policy['name'] == account_name + '/' + pool_name + '/' + volume_name
    assert vol_with_export_policy['exportPolicy']['rules'][0]['allowedClients'] == '1.2.3.0/24'
    assert vol_with_export_policy['exportPolicy']['rules'][0]['ruleIndex'] == 3
    assert vol_with_export_policy['exportPolicy']['rules'][0]['cifs'] is False
    assert vol_with_export_policy['exportPolicy']['rules'][0]['hasRootAccess'] is False
    vol_with_export_policy = self.cmd(""netappfiles volume export-policy add -g {rg} -a %s -p %s -v %s --allowed-clients '1.2.4.0/24' --rule-index 2 --unix-read-only true --unix-read-write false --cifs true --nfsv3 true --nfsv41 false"" % (account_name, pool_name, volume_name)).get_output_in_json()
    assert vol_with_export_policy['name'] == account_name + '/' + pool_name + '/' + volume_name
    assert vol_with_export_policy['exportPolicy']['rules'][1]['allowedClients'] == '1.2.3.0/24'
    assert vol_with_export_policy['exportPolicy']['rules'][0]['allowedClients'] == '1.2.4.0/24'
    assert vol_with_export_policy['exportPolicy']['rules'][0]['cifs'] is True
    assert len(vol_with_export_policy['exportPolicy']['rules']) == 3
    export_policy = self.cmd('netappfiles volume export-policy list -g {rg} -a %s -p %s -v %s' % (account_name, pool_name, volume_name)).get_output_in_json()
    assert len(export_policy['rules']) == 3
    self.cmd('netappfiles volume export-policy remove -g {rg} -a %s -p %s -v %s --rule-index 3' % (account_name, pool_name, volume_name)).get_output_in_json()
    if self.is_live or self.in_recording:
        time.sleep(240)
    volume = self.cmd('az netappfiles volume show --resource-group {rg} -a %s -p %s -v %s' % (account_name, pool_name, volume_name)).get_output_in_json()
    assert volume['name'] == account_name + '/' + pool_name + '/' + volume_name
    assert len(volume['exportPolicy']['rules']) == 2","'netappfiles volume export-policy list -g {rg} -a %s -p %s -v %s' % (account_name, pool_name, volume_name)",f"netappfiles volume export-policy list -g {rg} -a {account_name} -p {pool_name} -v {volume_name}",1,,,,,,,,,,
azure-cli,https://github.com/Azure/azure-cli/tree/master/src/azure-cli/azure/cli/command_modules/netappfiles/tests/latest/test_volume_commands.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/azure-cli/src/azure-cli/azure/cli/command_modules/netappfiles/tests/latest/test_volume_commands.py,AzureNetAppFilesVolumeServiceScenarioTest,"def test_export_policy(self):
    account_name = self.create_random_name(prefix='cli-acc-', length=24)
    pool_name = self.create_random_name(prefix='cli-pool-', length=24)
    volume_name = self.create_random_name(prefix='cli-vol-', length=24)
    volume = self.create_volume(account_name, pool_name, volume_name, '{rg}')
    assert volume['name'] == account_name + '/' + pool_name + '/' + volume_name
    vol_with_export_policy = self.cmd(""netappfiles volume export-policy add -g {rg} -a %s -p %s -v %s --allowed-clients '1.2.3.0/24' --rule-index 3 --unix-read-only true --unix-read-write false --cifs false --nfsv3 true --nfsv41 false --has-root-access false"" % (account_name, pool_name, volume_name)).get_output_in_json()
    assert vol_with_export_policy['name'] == account_name + '/' + pool_name + '/' + volume_name
    assert vol_with_export_policy['exportPolicy']['rules'][0]['allowedClients'] == '1.2.3.0/24'
    assert vol_with_export_policy['exportPolicy']['rules'][0]['ruleIndex'] == 3
    assert vol_with_export_policy['exportPolicy']['rules'][0]['cifs'] is False
    assert vol_with_export_policy['exportPolicy']['rules'][0]['hasRootAccess'] is False
    vol_with_export_policy = self.cmd(""netappfiles volume export-policy add -g {rg} -a %s -p %s -v %s --allowed-clients '1.2.4.0/24' --rule-index 2 --unix-read-only true --unix-read-write false --cifs true --nfsv3 true --nfsv41 false"" % (account_name, pool_name, volume_name)).get_output_in_json()
    assert vol_with_export_policy['name'] == account_name + '/' + pool_name + '/' + volume_name
    assert vol_with_export_policy['exportPolicy']['rules'][1]['allowedClients'] == '1.2.3.0/24'
    assert vol_with_export_policy['exportPolicy']['rules'][0]['allowedClients'] == '1.2.4.0/24'
    assert vol_with_export_policy['exportPolicy']['rules'][0]['cifs'] is True
    assert len(vol_with_export_policy['exportPolicy']['rules']) == 3
    export_policy = self.cmd('netappfiles volume export-policy list -g {rg} -a %s -p %s -v %s' % (account_name, pool_name, volume_name)).get_output_in_json()
    assert len(export_policy['rules']) == 3
    self.cmd('netappfiles volume export-policy remove -g {rg} -a %s -p %s -v %s --rule-index 3' % (account_name, pool_name, volume_name)).get_output_in_json()
    if self.is_live or self.in_recording:
        time.sleep(240)
    volume = self.cmd('az netappfiles volume show --resource-group {rg} -a %s -p %s -v %s' % (account_name, pool_name, volume_name)).get_output_in_json()
    assert volume['name'] == account_name + '/' + pool_name + '/' + volume_name
    assert len(volume['exportPolicy']['rules']) == 2","'netappfiles volume export-policy remove -g {rg} -a %s -p %s -v %s --rule-index 3' % (account_name, pool_name, volume_name)",f"netappfiles volume export-policy remove -g {rg} -a {account_name} -p {pool_name} -v {volume_name} --rule-index 3",1,,,,,,,,,,
azure-cli,https://github.com/Azure/azure-cli/tree/master/src/azure-cli/azure/cli/command_modules/netappfiles/tests/latest/test_volume_commands.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/azure-cli/src/azure-cli/azure/cli/command_modules/netappfiles/tests/latest/test_volume_commands.py,AzureNetAppFilesVolumeServiceScenarioTest,"def test_export_policy(self):
    account_name = self.create_random_name(prefix='cli-acc-', length=24)
    pool_name = self.create_random_name(prefix='cli-pool-', length=24)
    volume_name = self.create_random_name(prefix='cli-vol-', length=24)
    volume = self.create_volume(account_name, pool_name, volume_name, '{rg}')
    assert volume['name'] == account_name + '/' + pool_name + '/' + volume_name
    vol_with_export_policy = self.cmd(""netappfiles volume export-policy add -g {rg} -a %s -p %s -v %s --allowed-clients '1.2.3.0/24' --rule-index 3 --unix-read-only true --unix-read-write false --cifs false --nfsv3 true --nfsv41 false --has-root-access false"" % (account_name, pool_name, volume_name)).get_output_in_json()
    assert vol_with_export_policy['name'] == account_name + '/' + pool_name + '/' + volume_name
    assert vol_with_export_policy['exportPolicy']['rules'][0]['allowedClients'] == '1.2.3.0/24'
    assert vol_with_export_policy['exportPolicy']['rules'][0]['ruleIndex'] == 3
    assert vol_with_export_policy['exportPolicy']['rules'][0]['cifs'] is False
    assert vol_with_export_policy['exportPolicy']['rules'][0]['hasRootAccess'] is False
    vol_with_export_policy = self.cmd(""netappfiles volume export-policy add -g {rg} -a %s -p %s -v %s --allowed-clients '1.2.4.0/24' --rule-index 2 --unix-read-only true --unix-read-write false --cifs true --nfsv3 true --nfsv41 false"" % (account_name, pool_name, volume_name)).get_output_in_json()
    assert vol_with_export_policy['name'] == account_name + '/' + pool_name + '/' + volume_name
    assert vol_with_export_policy['exportPolicy']['rules'][1]['allowedClients'] == '1.2.3.0/24'
    assert vol_with_export_policy['exportPolicy']['rules'][0]['allowedClients'] == '1.2.4.0/24'
    assert vol_with_export_policy['exportPolicy']['rules'][0]['cifs'] is True
    assert len(vol_with_export_policy['exportPolicy']['rules']) == 3
    export_policy = self.cmd('netappfiles volume export-policy list -g {rg} -a %s -p %s -v %s' % (account_name, pool_name, volume_name)).get_output_in_json()
    assert len(export_policy['rules']) == 3
    self.cmd('netappfiles volume export-policy remove -g {rg} -a %s -p %s -v %s --rule-index 3' % (account_name, pool_name, volume_name)).get_output_in_json()
    if self.is_live or self.in_recording:
        time.sleep(240)
    volume = self.cmd('az netappfiles volume show --resource-group {rg} -a %s -p %s -v %s' % (account_name, pool_name, volume_name)).get_output_in_json()
    assert volume['name'] == account_name + '/' + pool_name + '/' + volume_name
    assert len(volume['exportPolicy']['rules']) == 2","'az netappfiles volume show --resource-group {rg} -a %s -p %s -v %s' % (account_name, pool_name, volume_name)",f"az netappfiles volume show --resource-group {rg} -a {account_name} -p {pool_name} -v {volume_name}",1,,,,,,,,,,
numpy,https://github.com/numpy/numpy/tree/master/numpy/_version.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/numpy/numpy/_version.py,,"def render_pep440_post_branch(pieces):
    """"""TAG[.postDISTANCE[.dev0]+gHEX[.dirty]] .

    The "".dev0"" means not master branch.

    Exceptions:
    1: no tags. 0.postDISTANCE[.dev0]+gHEX[.dirty]
    """"""
    if pieces['closest-tag']:
        rendered = pieces['closest-tag']
        if pieces['distance'] or pieces['dirty']:
            rendered += '.post%d' % pieces['distance']
            if pieces['branch'] != 'master':
                rendered += '.dev0'
            rendered += plus_or_dot(pieces)
            rendered += 'g%s' % pieces['short']
            if pieces['dirty']:
                rendered += '.dirty'
    else:
        rendered = '0.post%d' % pieces['distance']
        if pieces['branch'] != 'master':
            rendered += '.dev0'
        rendered += '+g%s' % pieces['short']
        if pieces['dirty']:
            rendered += '.dirty'
    return rendered",'0.post%d' % pieces['distance'],f"0.post{pieces['distance']}",1,,,,,,,,,,
numpy,https://github.com/numpy/numpy/tree/master/numpy/_version.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/numpy/numpy/_version.py,,"def render_pep440_post_branch(pieces):
    """"""TAG[.postDISTANCE[.dev0]+gHEX[.dirty]] .

    The "".dev0"" means not master branch.

    Exceptions:
    1: no tags. 0.postDISTANCE[.dev0]+gHEX[.dirty]
    """"""
    if pieces['closest-tag']:
        rendered = pieces['closest-tag']
        if pieces['distance'] or pieces['dirty']:
            rendered += '.post%d' % pieces['distance']
            if pieces['branch'] != 'master':
                rendered += '.dev0'
            rendered += plus_or_dot(pieces)
            rendered += 'g%s' % pieces['short']
            if pieces['dirty']:
                rendered += '.dirty'
    else:
        rendered = '0.post%d' % pieces['distance']
        if pieces['branch'] != 'master':
            rendered += '.dev0'
        rendered += '+g%s' % pieces['short']
        if pieces['dirty']:
            rendered += '.dirty'
    return rendered",'+g%s' % pieces['short'],f"+g{pieces['short']}",1,,,,,,,,,,
numpy,https://github.com/numpy/numpy/tree/master/numpy/_version.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/numpy/numpy/_version.py,,"def render_pep440_post_branch(pieces):
    """"""TAG[.postDISTANCE[.dev0]+gHEX[.dirty]] .

    The "".dev0"" means not master branch.

    Exceptions:
    1: no tags. 0.postDISTANCE[.dev0]+gHEX[.dirty]
    """"""
    if pieces['closest-tag']:
        rendered = pieces['closest-tag']
        if pieces['distance'] or pieces['dirty']:
            rendered += '.post%d' % pieces['distance']
            if pieces['branch'] != 'master':
                rendered += '.dev0'
            rendered += plus_or_dot(pieces)
            rendered += 'g%s' % pieces['short']
            if pieces['dirty']:
                rendered += '.dirty'
    else:
        rendered = '0.post%d' % pieces['distance']
        if pieces['branch'] != 'master':
            rendered += '.dev0'
        rendered += '+g%s' % pieces['short']
        if pieces['dirty']:
            rendered += '.dirty'
    return rendered",'.post%d' % pieces['distance'],f".post{pieces['distance']}",1,,,,,,,,,,
numpy,https://github.com/numpy/numpy/tree/master/numpy/_version.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/numpy/numpy/_version.py,,"def render_pep440_post_branch(pieces):
    """"""TAG[.postDISTANCE[.dev0]+gHEX[.dirty]] .

    The "".dev0"" means not master branch.

    Exceptions:
    1: no tags. 0.postDISTANCE[.dev0]+gHEX[.dirty]
    """"""
    if pieces['closest-tag']:
        rendered = pieces['closest-tag']
        if pieces['distance'] or pieces['dirty']:
            rendered += '.post%d' % pieces['distance']
            if pieces['branch'] != 'master':
                rendered += '.dev0'
            rendered += plus_or_dot(pieces)
            rendered += 'g%s' % pieces['short']
            if pieces['dirty']:
                rendered += '.dirty'
    else:
        rendered = '0.post%d' % pieces['distance']
        if pieces['branch'] != 'master':
            rendered += '.dev0'
        rendered += '+g%s' % pieces['short']
        if pieces['dirty']:
            rendered += '.dirty'
    return rendered",'g%s' % pieces['short'],f'g{pieces["short"]}',1,,,,,,,,,,
django-rest-framework,https://github.com/encode/django-rest-framework/tree/master/rest_framework/viewsets.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/django-rest-framework/rest_framework/viewsets.py,ViewSetMixin,"def get_extra_action_url_map(self):
    """"""
        Build a map of {names: urls} for the extra actions.

        This method will noop if `detail` was not provided as a view initkwarg.
        """"""
    action_urls = OrderedDict()
    if self.detail is None:
        return action_urls
    actions = [action for action in self.get_extra_actions() if action.detail == self.detail]
    for action in actions:
        try:
            url_name = '%s-%s' % (self.basename, action.url_name)
            url = reverse(url_name, self.args, self.kwargs, request=self.request)
            view = self.__class__(**action.kwargs)
            action_urls[view.get_view_name()] = url
        except NoReverseMatch:
            pass
    return action_urls","'%s-%s' % (self.basename, action.url_name)",f"{self.basename}-{action.url_name}",1,,,,,,,,,,
mock,https://github.com/testing-cabal/mock/tree/master/mock/tests/testpatch.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/mock/mock/tests/testpatch.py,PatchTest,"def test_nested_patch_with_spec_as_list(self):

    @patch('%s.open' % builtin_string)
    @patch('%s.SomeClass' % __name__, spec=['wibble'])
    def test(MockSomeClass, MockOpen):
        self.assertEqual(SomeClass, MockSomeClass)
        self.assertTrue(is_instance(SomeClass.wibble, MagicMock))
        self.assertRaises(AttributeError, lambda : SomeClass.not_wibble)
    test()",'%s.open' % builtin_string,f"{builtin_string}.open",1,,,,,,,,,,
mock,https://github.com/testing-cabal/mock/tree/master/mock/tests/testpatch.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/mock/mock/tests/testpatch.py,PatchTest,"def test_nested_patch_with_spec_as_list(self):

    @patch('%s.open' % builtin_string)
    @patch('%s.SomeClass' % __name__, spec=['wibble'])
    def test(MockSomeClass, MockOpen):
        self.assertEqual(SomeClass, MockSomeClass)
        self.assertTrue(is_instance(SomeClass.wibble, MagicMock))
        self.assertRaises(AttributeError, lambda : SomeClass.not_wibble)
    test()",'%s.SomeClass' % __name__,f"{__name__}.SomeClass",1,,,,,,,,,,
s3fs,https://github.com/fsspec/s3fs/tree/master/s3fs/tests/test_s3fs.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/s3fs/s3fs/tests/test_s3fs.py,,"def test_s3_big_ls(s3):
    for x in range(1200):
        s3.touch(test_bucket_name + '/thousand/%i.part' % x)
    assert len(s3.find(test_bucket_name)) > 1200
    s3.rm(test_bucket_name + '/thousand/', recursive=True)
    assert len(s3.find(test_bucket_name + '/thousand/')) == 0",'/thousand/%i.part' % x,f"/thousand/{x}.part",1,,,,,,,,,,
ansible-modules-core,https://github.com/ansible/ansible-modules-core/tree/master/network/netvisor/pn_vlag.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/ansible-modules-core/network/netvisor/pn_vlag.py,,"def pn_cli(module):
    """"""
    This method is to generate the cli portion to launch the Netvisor cli.
    It parses the username, password, switch parameters from module.
    :param module: The Ansible module to fetch username, password and switch
    :return: returns the cli string for further processing
    """"""
    username = module.params['pn_cliusername']
    password = module.params['pn_clipassword']
    cliswitch = module.params['pn_cliswitch']
    if username and password:
        cli = '/usr/bin/cli --quiet --user %s:%s ' % (username, password)
    else:
        cli = '/usr/bin/cli --quiet '
    if cliswitch == 'local':
        cli += ' switch-local '
    else:
        cli += ' switch ' + cliswitch
    return cli","'/usr/bin/cli --quiet --user %s:%s ' % (username, password)",f"/usr/bin/cli --quiet --user {username}:{password} ",1,,,,,,,,,,
yt-dlp,https://github.com/yt-dlp/yt-dlp/tree/master/yt_dlp/extractor/imdb.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/yt-dlp/yt_dlp/extractor/imdb.py,ImdbListIE,"def _real_extract(self, url):
    list_id = self._match_id(url)
    webpage = self._download_webpage(url, list_id)
    entries = [self.url_result('http://www.imdb.com' + m, 'Imdb') for m in re.findall('href=""(/list/ls%s/videoplayer/vi[^""]+)""' % list_id, webpage)]
    list_title = self._html_search_regex('<h1[^>]+class=""[^""]*header[^""]*""[^>]*>(.*?)</h1>', webpage, 'list title')
    list_description = self._html_search_regex('<div[^>]+class=""[^""]*list-description[^""]*""[^>]*><p>(.*?)</p>', webpage, 'list description')
    return self.playlist_result(entries, list_id, list_title, list_description)",'href="(/list/ls%s/videoplayer/vi[^"]+)"' % list_id,f'href="(/list/ls{list_id}/videoplayer/vi[^"]+)"',1,,,,,,,,,,
fiftyone,https://github.com/voxel51/fiftyone/tree/master/fiftyone/utils/data/exporters.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/fiftyone/fiftyone/utils/data/exporters.py,ImageClassificationDirectoryTreeExporter,"def export_sample(self, image_or_path, classification, metadata=None):
    _label = _parse_classifications(classification, include_confidence=False, include_attributes=False)
    if _label is None:
        _label = '_unlabeled'
    self._class_counts[_label] += 1
    if etau.is_str(image_or_path):
        image_path = fou.normalize_path(image_or_path)
    else:
        img = image_or_path
        image_path = self._default_filename_patt % self._class_counts[_label]
    if self.rel_dir is not None:
        filename = fou.safe_relpath(image_path, self.rel_dir)
    else:
        filename = os.path.basename(image_path)
    (name, ext) = os.path.splitext(filename)
    key = (_label, filename)
    self._filename_counts[key] += 1
    count = self._filename_counts[key]
    if count > 1:
        filename = name + '-%d' % count + ext
    outpath = os.path.join(self.export_dir, _label, filename)
    self._media_exporter.export(image_or_path, outpath=outpath)",'-%d' % count,f"-{count}",1,,,,,,,,,,
deep_sort_yolov3,https://github.com/Qidian213/deep_sort_yolov3/tree/master/tools/generate_detections.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/deep_sort_yolov3/tools/generate_detections.py,ImageEncoder,"def __init__(self, checkpoint_filename, input_name='images', output_name='features'):
    self.session = tf.Session()
    with tf.gfile.GFile(checkpoint_filename, 'rb') as file_handle:
        graph_def = tf.GraphDef()
        graph_def.ParseFromString(file_handle.read())
    tf.import_graph_def(graph_def, name='net')
    self.input_var = tf.get_default_graph().get_tensor_by_name('net/%s:0' % input_name)
    self.output_var = tf.get_default_graph().get_tensor_by_name('net/%s:0' % output_name)
    assert len(self.output_var.get_shape()) == 2
    assert len(self.input_var.get_shape()) == 4
    self.feature_dim = self.output_var.get_shape().as_list()[-1]
    self.image_shape = self.input_var.get_shape().as_list()[1:]",'net/%s:0' % input_name,f"net/{input_name}:0",1,,,,,,,,,,
deep_sort_yolov3,https://github.com/Qidian213/deep_sort_yolov3/tree/master/tools/generate_detections.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/deep_sort_yolov3/tools/generate_detections.py,ImageEncoder,"def __init__(self, checkpoint_filename, input_name='images', output_name='features'):
    self.session = tf.Session()
    with tf.gfile.GFile(checkpoint_filename, 'rb') as file_handle:
        graph_def = tf.GraphDef()
        graph_def.ParseFromString(file_handle.read())
    tf.import_graph_def(graph_def, name='net')
    self.input_var = tf.get_default_graph().get_tensor_by_name('net/%s:0' % input_name)
    self.output_var = tf.get_default_graph().get_tensor_by_name('net/%s:0' % output_name)
    assert len(self.output_var.get_shape()) == 2
    assert len(self.input_var.get_shape()) == 4
    self.feature_dim = self.output_var.get_shape().as_list()[-1]
    self.image_shape = self.input_var.get_shape().as_list()[1:]",'net/%s:0' % output_name,f"net/{output_name}:0",1,,,,,,,,,,
EasyTransfer,https://github.com/alibaba/EasyTransfer/tree/master/scripts/fashion_bert/image_feature_extract.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/EasyTransfer/scripts/fashion_bert/image_feature_extract.py,PredictorImpl,"def search_pb(self, directory):
    """"""
    search pb file recursively, if multiple pb files exist, exception will be
    raised

    Returns:
      directory contain pb file
    """"""
    dir_list = []
    for (root, dirs, files) in tf.gfile.Walk(directory):
        for f in files:
            (_, ext) = os.path.splitext(f)
            if ext == '.pb':
                dir_list.append(root)
    if len(dir_list) == 0:
        raise ValueError('savedmodel is not found in directory %s' % directory)
    elif len(dir_list) > 1:
        raise ValueError('multiple saved model found in directory %s' % directory)
    return dir_list[0]",'savedmodel is not found in directory %s' % directory,f"savedmodel is not found in directory {directory}",1,,,,,,,,,,
EasyTransfer,https://github.com/alibaba/EasyTransfer/tree/master/scripts/fashion_bert/image_feature_extract.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/EasyTransfer/scripts/fashion_bert/image_feature_extract.py,PredictorImpl,"def search_pb(self, directory):
    """"""
    search pb file recursively, if multiple pb files exist, exception will be
    raised

    Returns:
      directory contain pb file
    """"""
    dir_list = []
    for (root, dirs, files) in tf.gfile.Walk(directory):
        for f in files:
            (_, ext) = os.path.splitext(f)
            if ext == '.pb':
                dir_list.append(root)
    if len(dir_list) == 0:
        raise ValueError('savedmodel is not found in directory %s' % directory)
    elif len(dir_list) > 1:
        raise ValueError('multiple saved model found in directory %s' % directory)
    return dir_list[0]",'multiple saved model found in directory %s' % directory,f"multiple saved model found in directory {directory}",1,,,,,,,,,,
hangoutsbot,https://github.com/hangoutsbot/hangoutsbot/tree/master/hangupsbot/plugins/xkcd.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/hangoutsbot/hangupsbot/plugins/xkcd.py,,"def _search_comic(bot, event, terms):
    request = (yield from aiohttp.request('get', 'https://relevantxkcd.appspot.com/process?%s' % urllib.parse.urlencode({'action': 'xkcd', 'query': ' '.join(terms)})))
    raw = (yield from request.read())
    values = [row.strip().split(' ')[0] for row in raw.decode().strip().split('\n')]
    weight = float(values.pop(0))
    values.pop(0)
    comics = [int(i) for i in values]
    num = comics.pop(0)
    msg = 'Most relevant xkcd: #%d (relevance: %.2f%%)\nOther relevant comics: %s' % (num, weight * 100, ', '.join(('#%d' % i for i in comics)))
    yield from _get_comic(bot, num)
    yield from bot.coro_send_message(event.conv.id_, msg)
    yield from _print_comic(bot, event, num)","Most relevant xkcd: #%d (relevance: %.2f%%)\nOther relevant comics: %s' % (num, weight * 100, ', '.join(('#%d' % i for i in comics)))","f""Most relevant xkcd: #{num} (relevance: {weight*100:.2f}%)\nOther relevant comics: {', '.join(f'#{i}' for i in comics)}""",1,,,,,,,,,,
hangoutsbot,https://github.com/hangoutsbot/hangoutsbot/tree/master/hangupsbot/plugins/xkcd.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/hangoutsbot/hangupsbot/plugins/xkcd.py,,"def _search_comic(bot, event, terms):
    request = (yield from aiohttp.request('get', 'https://relevantxkcd.appspot.com/process?%s' % urllib.parse.urlencode({'action': 'xkcd', 'query': ' '.join(terms)})))
    raw = (yield from request.read())
    values = [row.strip().split(' ')[0] for row in raw.decode().strip().split('\n')]
    weight = float(values.pop(0))
    values.pop(0)
    comics = [int(i) for i in values]
    num = comics.pop(0)
    msg = 'Most relevant xkcd: #%d (relevance: %.2f%%)\nOther relevant comics: %s' % (num, weight * 100, ', '.join(('#%d' % i for i in comics)))
    yield from _get_comic(bot, num)
    yield from bot.coro_send_message(event.conv.id_, msg)
    yield from _print_comic(bot, event, num)","'https://relevantxkcd.appspot.com/process?%s' % urllib.parse.urlencode({'action': 'xkcd', 'query': ' '.join(terms)})","f'https://relevantxkcd.appspot.com/process?{urllib.parse.urlencode({""action"": ""xkcd"", ""query"": "" "".join(terms)})}'",1,,,,,,,,,,
hangoutsbot,https://github.com/hangoutsbot/hangoutsbot/tree/master/hangupsbot/plugins/xkcd.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/hangoutsbot/hangupsbot/plugins/xkcd.py,,"def _search_comic(bot, event, terms):
    request = (yield from aiohttp.request('get', 'https://relevantxkcd.appspot.com/process?%s' % urllib.parse.urlencode({'action': 'xkcd', 'query': ' '.join(terms)})))
    raw = (yield from request.read())
    values = [row.strip().split(' ')[0] for row in raw.decode().strip().split('\n')]
    weight = float(values.pop(0))
    values.pop(0)
    comics = [int(i) for i in values]
    num = comics.pop(0)
    msg = 'Most relevant xkcd: #%d (relevance: %.2f%%)\nOther relevant comics: %s' % (num, weight * 100, ', '.join(('#%d' % i for i in comics)))
    yield from _get_comic(bot, num)
    yield from bot.coro_send_message(event.conv.id_, msg)
    yield from _print_comic(bot, event, num)",'#%d' % i,f"#{i}",1,,,,,,,,,,
imgaug,https://github.com/aleju/imgaug/tree/master/imgaug/augmenters/arithmetic.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/imgaug/imgaug/augmenters/arithmetic.py,,"def _multiply_elementwise_to_non_uint8(image, multipliers):
    input_dtype = image.dtype
    mul_min = np.min(multipliers)
    mul_max = np.max(multipliers)
    itemsize = max(image.dtype.itemsize, 2 if multipliers.dtype.kind == 'f' else 1)
    dtype_target = np.dtype('%s%d' % (multipliers.dtype.kind, itemsize))
    multipliers = iadt.clip_to_dtype_value_range_(multipliers, dtype_target, validate=True, validate_values=(mul_min, mul_max))
    if multipliers.shape[2] == 1:
        nb_channels = image.shape[-1]
        multipliers = np.tile(multipliers, (1, 1, nb_channels))
    (image, multipliers) = iadt.promote_array_dtypes_([image, multipliers], dtypes=[image, dtype_target], increase_itemsize_factor=1)
    image = np.multiply(image, multipliers, out=image, casting='no')
    return iadt.restore_dtypes_(image, input_dtype)","'%s%d' % (multipliers.dtype.kind, itemsize)",f"{multipliers.dtype.kind}{itemsize}",1,,,,,,,,,,
pefile,https://github.com/erocarrera/pefile/tree/master//pefile.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pefile//pefile.py,PE,"def parse_sections(self, offset):
    """"""Fetch the PE file sections.

        The sections will be readily available in the ""sections"" attribute.
        Its attributes will contain all the section information plus ""data""
        a buffer containing the section's data.

        The ""Characteristics"" member will be processed and attributes
        representing the section characteristics (with the 'IMAGE_SCN_'
        string trimmed from the constant's names) will be added to the
        section instance.

        Refer to the SectionStructure class for additional info.
        """"""
    self.sections = []
    MAX_SIMULTANEOUS_ERRORS = 3
    for i in range(self.FILE_HEADER.NumberOfSections):
        if i >= MAX_SECTIONS:
            self.__warnings.append('Too many sections {0} (>={1})'.format(self.FILE_HEADER.NumberOfSections, MAX_SECTIONS))
            break
        simultaneous_errors = 0
        section = SectionStructure(self.__IMAGE_SECTION_HEADER_format__, pe=self)
        if not section:
            break
        section_offset = offset + section.sizeof() * i
        section.set_file_offset(section_offset)
        section_data = self.__data__[section_offset:section_offset + section.sizeof()]
        if count_zeroes(section_data) == section.sizeof():
            self.__warnings.append(f'Invalid section {i}. Contents are null-bytes.')
            break
        if not section_data:
            self.__warnings.append(f""Invalid section {i}. No data in the file (is this corkami's virtsectblXP?)."")
            break
        section.__unpack__(section_data)
        self.__structures__.append(section)
        if section.SizeOfRawData + section.PointerToRawData > len(self.__data__):
            simultaneous_errors += 1
            self.__warnings.append(f'Error parsing section {i}. SizeOfRawData is larger than file.')
        if self.adjust_FileAlignment(section.PointerToRawData, self.OPTIONAL_HEADER.FileAlignment) > len(self.__data__):
            simultaneous_errors += 1
            self.__warnings.append(f'Error parsing section {i}. PointerToRawData points beyond the end of the file.')
        if section.Misc_VirtualSize > 268435456:
            simultaneous_errors += 1
            self.__warnings.append(f'Suspicious value found parsing section {i}. VirtualSize is extremely large > 256MiB.')
        if self.adjust_SectionAlignment(section.VirtualAddress, self.OPTIONAL_HEADER.SectionAlignment, self.OPTIONAL_HEADER.FileAlignment) > 268435456:
            simultaneous_errors += 1
            self.__warnings.append(f'Suspicious value found parsing section {i}. VirtualAddress is beyond 0x10000000.')
        if self.OPTIONAL_HEADER.FileAlignment != 0 and section.PointerToRawData % self.OPTIONAL_HEADER.FileAlignment != 0:
            simultaneous_errors += 1
            self.__warnings.append(f'Error parsing section {i}. PointerToRawData should normally be a multiple of FileAlignment, this might imply the file is trying to confuse tools which parse this incorrectly.')
        if simultaneous_errors >= MAX_SIMULTANEOUS_ERRORS:
            self.__warnings.append('Too many warnings parsing section. Aborting.')
            break
        section_flags = retrieve_flags(SECTION_CHARACTERISTICS, 'IMAGE_SCN_')
        set_flags(section, section.Characteristics, section_flags)
        if section.__dict__.get('IMAGE_SCN_MEM_WRITE', False) and section.__dict__.get('IMAGE_SCN_MEM_EXECUTE', False):
            if section.Name.rstrip(b'\x00') == b'PAGE' and self.is_driver():
                pass
            else:
                self.__warnings.append(f'Suspicious flags set for section {i}. Both IMAGE_SCN_MEM_WRITE and IMAGE_SCN_MEM_EXECUTE are set. This might indicate a packed executable.')
        self.sections.append(section)
    self.sections.sort(key=lambda a: a.VirtualAddress)
    for (idx, section) in enumerate(self.sections):
        if idx == len(self.sections) - 1:
            section.next_section_virtual_address = None
        else:
            section.next_section_virtual_address = self.sections[idx + 1].VirtualAddress
    if self.FILE_HEADER.NumberOfSections > 0 and self.sections:
        return offset + self.sections[0].sizeof() * self.FILE_HEADER.NumberOfSections
    else:
        return offset",section.PointerToRawData % self.OPTIONAL_HEADER.FileAlignment,f"section.PointerToRawData % {self.OPTIONAL_HEADER.FileAlignment}",1,0,,,,,,,,,
thonny,https://github.com/thonny/thonny/tree/master/misc/mp/pyboard.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/thonny/misc/mp/pyboard.py,Pyboard,"def fs_cat(self, src, chunk_size=256):
    cmd = ""with open('%s') as f:\n while 1:\n  b=f.read(%u)\n  if not b:break\n  print(b,end='')"" % (src, chunk_size)
    self.exec_(cmd, data_consumer=stdout_write_bytes)","""with open('%s') as f:\n while 1:\n  b=f.read(%u)\n  if not b:break\n  print(b,end='')"" % (src, chunk_size)","f""with open('{src}') as f:\n while 1:\n  b=f.read({chunk_size})\n  if not b:break\n  print(b,end='')""",1,,,,,,,,,,
tensorflow-ocr,https://github.com/pannous/tensorflow-ocr/tree/master//net.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/tensorflow-ocr//net.py,net,"def buildDenseConv(self, nBlocks=3, nChannels=64, magic_factor=0):
    if magic_factor:
        print('magic_factor DEPRECATED!')
    depth = 3 * nBlocks + 4
    if (depth - 4) % 3:
        raise Exception('Depth must be 3N + 4! (4,7,10,...) ')
    N = (depth - 4) // 3
    print('N=%d' % N)
    do_dropout = True
    growthRate = 12
    self.conv([3, 3, 1, nChannels])
    for i in range(N):
        self.addLayer(nChannels, growthRate, do_dropout)
        nChannels += growthRate
    self.addTransition(nChannels, nChannels, do_dropout)
    for i in range(N):
        self.addLayer(nChannels, growthRate, do_dropout)
        nChannels += growthRate
    self.addTransition(nChannels, nChannels, do_dropout)
    for i in range(N):
        self.addLayer(nChannels, growthRate, do_dropout)
        nChannels += growthRate
    self.batchnorm()
    self.add(tf.nn.relu(self.last_layer))
    self.add(tf.nn.max_pool(self.last_layer, ksize=[1, 4, 4, 1], strides=[1, 2, 2, 1], padding='SAME'))
    shape = self.last_layer.get_shape()
    nBytes = shape[1] * shape[2] * shape[3]
    self.reshape([-1, int(nBytes)])",'N=%d' % N,f'N={N}',1,,,,,,,,,,
yt-dlp,https://github.com/yt-dlp/yt-dlp/tree/master/yt_dlp/extractor/common.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/yt-dlp/yt_dlp/extractor/common.py,SearchInfoExtractor,"def _real_extract(self, query):
    mobj = re.match(self._make_valid_url(), query)
    if mobj is None:
        raise ExtractorError('Invalid search query ""%s""' % query)
    prefix = mobj.group('prefix')
    query = mobj.group('query')
    if prefix == '':
        return self._get_n_results(query, 1)
    elif prefix == 'all':
        return self._get_n_results(query, self._MAX_RESULTS)
    else:
        n = int(prefix)
        if n <= 0:
            raise ExtractorError('invalid download number %s for query ""%s""' % (n, query))
        elif n > self._MAX_RESULTS:
            self.report_warning('%s returns max %i results (you requested %i)' % (self._SEARCH_KEY, self._MAX_RESULTS, n))
            n = self._MAX_RESULTS
        return self._get_n_results(query, n)",'Invalid search query "%s"' % query,f'Invalid search query "{query}"',1,,,,,,,,,,
yt-dlp,https://github.com/yt-dlp/yt-dlp/tree/master/yt_dlp/extractor/common.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/yt-dlp/yt_dlp/extractor/common.py,SearchInfoExtractor,"def _real_extract(self, query):
    mobj = re.match(self._make_valid_url(), query)
    if mobj is None:
        raise ExtractorError('Invalid search query ""%s""' % query)
    prefix = mobj.group('prefix')
    query = mobj.group('query')
    if prefix == '':
        return self._get_n_results(query, 1)
    elif prefix == 'all':
        return self._get_n_results(query, self._MAX_RESULTS)
    else:
        n = int(prefix)
        if n <= 0:
            raise ExtractorError('invalid download number %s for query ""%s""' % (n, query))
        elif n > self._MAX_RESULTS:
            self.report_warning('%s returns max %i results (you requested %i)' % (self._SEARCH_KEY, self._MAX_RESULTS, n))
            n = self._MAX_RESULTS
        return self._get_n_results(query, n)","'invalid download number %s for query ""%s""' % (n, query)",f'invalid download number {n} for query "{query}"',1,,,,,,,,,,
yt-dlp,https://github.com/yt-dlp/yt-dlp/tree/master/yt_dlp/extractor/common.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/yt-dlp/yt_dlp/extractor/common.py,SearchInfoExtractor,"def _real_extract(self, query):
    mobj = re.match(self._make_valid_url(), query)
    if mobj is None:
        raise ExtractorError('Invalid search query ""%s""' % query)
    prefix = mobj.group('prefix')
    query = mobj.group('query')
    if prefix == '':
        return self._get_n_results(query, 1)
    elif prefix == 'all':
        return self._get_n_results(query, self._MAX_RESULTS)
    else:
        n = int(prefix)
        if n <= 0:
            raise ExtractorError('invalid download number %s for query ""%s""' % (n, query))
        elif n > self._MAX_RESULTS:
            self.report_warning('%s returns max %i results (you requested %i)' % (self._SEARCH_KEY, self._MAX_RESULTS, n))
            n = self._MAX_RESULTS
        return self._get_n_results(query, n)","'%s returns max %i results (you requested %i)' % (self._SEARCH_KEY, self._MAX_RESULTS, n)",f"{self._SEARCH_KEY} returns max {self._MAX_RESULTS} results (you requested {n})",1,,,,,,,,,,
Paddle,https://github.com/PaddlePaddle/Paddle/tree/master/python/paddle/fluid/tests/unittests/test_split_op.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/Paddle/python/paddle/fluid/tests/unittests/test_split_op.py,TestSplitOp_AxisTensor,"def setUp(self):
    self._set_op_type()
    self.dtype = self.get_dtype()
    self.init_data()
    self.inputs = {'X': self.x, 'AxisTensor': np.array([self.axis]).astype('int32')}
    self.attrs = {'sections': self.sections, 'num': self.num}
    out = np.split(self.x, self.indices_or_sections, self.axis)
    self.outputs = {'Out': [('out%d' % i, out[i]) for i in range(len(out))]}",'out%d' % i,f'out{i}',1,,,,,,,,,,
s3cmd,https://github.com/s3tools/s3cmd/tree/master/S3/S3Uri.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/s3cmd/S3/S3Uri.py,S3UriS3,"def compose_uri(bucket, object=''):
    return u's3://%s/%s' % (bucket, object)","u's3://%s/%s' % (bucket, object)",f"s3://{bucket}/{object}",1,,,,,,,,,,
MxShop,https://github.com/derek-zhang123/MxShop/tree/master/extra_apps/rest_framework/renderers.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/MxShop/extra_apps/rest_framework/renderers.py,BrowsableAPIRenderer,"def get_content(self, renderer, data, accepted_media_type, renderer_context):
    """"""
        Get the content as if it had been rendered by the default
        non-documenting renderer.
        """"""
    if not renderer:
        return '[No renderers were found]'
    renderer_context['indent'] = 4
    content = renderer.render(data, accepted_media_type, renderer_context)
    render_style = getattr(renderer, 'render_style', 'text')
    assert render_style in ['text', 'binary'], 'Expected .render_style ""text"" or ""binary"", but got ""%s""' % render_style
    if render_style == 'binary':
        return '[%d bytes of binary content]' % len(content)
    return content","'Expected .render_style ""text"" or ""binary"", but got ""%s""' % render_style","f'Expected .render_style ""text"" or ""binary"", but got ""{render_style}""'",1,,,,,,,,,,
MxShop,https://github.com/derek-zhang123/MxShop/tree/master/extra_apps/rest_framework/renderers.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/MxShop/extra_apps/rest_framework/renderers.py,BrowsableAPIRenderer,"def get_content(self, renderer, data, accepted_media_type, renderer_context):
    """"""
        Get the content as if it had been rendered by the default
        non-documenting renderer.
        """"""
    if not renderer:
        return '[No renderers were found]'
    renderer_context['indent'] = 4
    content = renderer.render(data, accepted_media_type, renderer_context)
    render_style = getattr(renderer, 'render_style', 'text')
    assert render_style in ['text', 'binary'], 'Expected .render_style ""text"" or ""binary"", but got ""%s""' % render_style
    if render_style == 'binary':
        return '[%d bytes of binary content]' % len(content)
    return content",'[%d bytes of binary content]' % len(content),f"[{len(content)} bytes of binary content]",1,,,,,,,,,,
sdc,https://github.com/IntelPython/sdc/tree/master/sdc/tests/indexes/test_int64_index.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/sdc/sdc/tests/indexes/test_int64_index.py,TestInt64Index,"def test_int64_index_iterator_2(self):

    def test_impl(index):
        res = []
        for label in index:
            if not label % 2:
                res.append(label)
        return res
    sdc_func = self.jit(test_impl)
    index = pd.Int64Index([5, 3, 2, 1, 7, 4])
    result = sdc_func(index)
    result_ref = test_impl(index)
    self.assertEqual(result, result_ref)",label % 2,The given code cannot be refactored with fstring as it is performing a mathematical operation and not dealing with string formatting.,0,,,,,,,,,,
pyqtgraph,https://github.com/pyqtgraph/pyqtgraph/tree/master/pyqtgraph/examples/ScatterPlotSpeedTest.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pyqtgraph/pyqtgraph/examples/ScatterPlotSpeedTest.py,,"def update():
    global ptr, lastTime, fps
    mode = param['mode']
    if mode == 'newItem':
        mkItem()
    elif mode == 'reuseItem':
        item.setData(**getData())
    elif mode == 'panZoom':
        item.viewTransformChanged()
        item.update()
    elif mode == 'hover':
        pts = item.points()
        old = pts[(ptr - 1) % len(pts)]
        new = pts[ptr % len(pts)]
        item.pointsAt(new.pos())
        old.resetBrush()
        new.setBrush(hoverBrush)
    ptr += 1
    now = perf_counter()
    dt = now - lastTime
    lastTime = now
    if fps is None:
        fps = 1.0 / dt
    else:
        s = np.clip(dt * 3.0, 0, 1)
        fps = fps * (1 - s) + 1.0 / dt * s
    p.setTitle('%0.2f fps' % fps)
    p.repaint()",(ptr - 1) % len(pts),The given code cannot be refactored with fstring as it is a mathematical expression and not a string.,0,,,,,,,,,,
pyqtgraph,https://github.com/pyqtgraph/pyqtgraph/tree/master/pyqtgraph/examples/ScatterPlotSpeedTest.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pyqtgraph/pyqtgraph/examples/ScatterPlotSpeedTest.py,,"def update():
    global ptr, lastTime, fps
    mode = param['mode']
    if mode == 'newItem':
        mkItem()
    elif mode == 'reuseItem':
        item.setData(**getData())
    elif mode == 'panZoom':
        item.viewTransformChanged()
        item.update()
    elif mode == 'hover':
        pts = item.points()
        old = pts[(ptr - 1) % len(pts)]
        new = pts[ptr % len(pts)]
        item.pointsAt(new.pos())
        old.resetBrush()
        new.setBrush(hoverBrush)
    ptr += 1
    now = perf_counter()
    dt = now - lastTime
    lastTime = now
    if fps is None:
        fps = 1.0 / dt
    else:
        s = np.clip(dt * 3.0, 0, 1)
        fps = fps * (1 - s) + 1.0 / dt * s
    p.setTitle('%0.2f fps' % fps)
    p.repaint()",ptr % len(pts),"The given code is not a string, so it cannot be refactored with fstring.",0,,,,,,,,,,
bridgy,https://github.com/snarfed/bridgy/tree/master/tests/test_cron.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/bridgy/tests/test_cron.py,CronTest,"def test_update_mastodon_pictures_get_actor_404(self):
    self.expect_requests_get('https://foo.com' + test_mastodon.API_ACCOUNT % 123, headers={'Authorization': 'Bearer towkin'}).AndRaise(requests.exceptions.HTTPError(response=util.Struct(status_code='404', text='foo')))
    self.mox.ReplayAll()
    mastodon = self._setup_mastodon()
    resp = self.client.get('/cron/update_mastodon_pictures')
    self.assertEqual(200, resp.status_code)
    self.assertEqual('http://before', mastodon.key.get().picture)",test_mastodon.API_ACCOUNT % 123,"The given code is not a complete statement and it is not clear what is the value of `test_mastodon.API_ACCOUNT` and what is the expected output. Therefore, it is not possible to refactor this code with fstring.",0,,,,,,,,,,
fold,https://github.com/tensorflow/fold/tree/master/tensorflow_fold/blocks/plan.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/fold/tensorflow_fold/blocks/plan.py,TrainPlan,"def _run(self, supervisor, session):
    train_feed_dict = self.train_feeds.copy()
    train_fetches = {'train_op': self.train_op, 'loss': self.loss_total, 'step': self.global_step}
    if self.compute_summaries:
        train_fetches['summaries'] = self.summaries
    if self.examples:
        (epochs, train_size) = self._by_feed_dict(train_feed_dict)
    else:
        (epochs, train_size) = self._by_input_tensor(train_feed_dict)
    if self.dev_examples:
        gen_dev_batches = util.epochs(((len(batch), self.compiler.build_feed_dict(batch)) for batch in util.group_by_batches(self.dev_examples, self.batch_size)), shuffle=False)
        ckpt = tf.train.get_checkpoint_state(self.logdir)
        if ckpt and ckpt.model_checkpoint_path:
            (_, self._best_loss, _) = self._eval_batches(supervisor, session, next(gen_dev_batches), None, is_dev=True)
            if self._best_loss is None:
                return
    for (epoch, batches) in enumerate(epochs, 1):
        train_loss = 0.0
        for _ in batches:
            if self._should_stop(supervisor):
                return
            results = session.run(train_fetches, train_feed_dict)
            train_loss += results['loss']
            if self.compute_summaries:
                supervisor.summary_computed(session, results['summaries'], results['step'])
        if train_size == 0:
            raise ValueError('examples must be non-empty')
        if self.exact_batch_sizes and epoch == 1:
            if train_size < self.batch_size:
                raise ValueError('when exact_batch_sizes is true, examples must have at least batch_size items; %s vs. %s' % (train_size, self.batch_size))
            train_size -= train_size % self.batch_size
        train_loss /= train_size
        self.report_loss(results['step'], train_loss)
        log_str = 'epoch:%5d train[loss: %.3e]' % (epoch, train_loss)
        if self.dev_examples:
            (dev_size, dev_loss, dev_metrics) = self._eval_batches(supervisor, session, next(gen_dev_batches), results['step'], is_dev=True)
            if dev_size is None:
                return
            if epoch == 1:
                self.log_and_print('train_size: %d dev_size: %d' % (train_size, dev_size))
            log_str += ' dev[%s]' % _eval_str(dev_size, dev_loss, dev_metrics)
            self.log_and_print(log_str)
            self._save_best(session, supervisor.saver, dev_loss, results['step'])
        else:
            if epoch == 1:
                self.log_and_print('train_size: %d' % train_size)
            self.log_and_print(log_str)
    if not self.dev_examples and self.is_chief_trainer:
        save_path = os.path.join(self.logdir, 'model.ckpt')
        save_fname = supervisor.saver.save(session, save_path, global_step=results['step'])
        self.log_and_print('final model saved in file: %s' % save_fname)",train_size % self.batch_size,"The given code is not a string, it is a mathematical operation. Therefore, it cannot be refactored with fstring.",0,,,,,,,,,,
Paddle,https://github.com/PaddlePaddle/Paddle/tree/master/python/paddle/fluid/tests/unittests/test_dist_base.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/Paddle/python/paddle/fluid/tests/unittests/test_dist_base.py,TestDistRunnerBase,"def run_use_fleet_api_trainer(self, args):
    assert args.update_method == 'nccl2' or 'bkcl'
    self.lr = args.lr
    exec_strategy = fluid.ExecutionStrategy()
    exec_strategy.num_threads = 1
    dist_strategy = DistributedStrategy()
    dist_strategy.exec_strategy = exec_strategy
    dist_strategy.fuse_memory_size = 1
    dist_strategy.fuse_laryer_size = 1
    if args.use_local_sgd:
        dist_strategy.use_local_sgd = True
    if args.ut4grad_allreduce:
        dist_strategy._ut4grad_allreduce = True
    if args.sync_batch_norm:
        dist_strategy.sync_batch_norm = True
    role = role_maker.PaddleCloudRoleMaker(is_collective=True)
    fleet.init(role)
    print_to_err('use_fleet', 'fleet.node_num:')
    (test_program, avg_cost, train_reader, test_reader, batch_acc, predict) = self.get_model(batch_size=args.batch_size, dist_strategy=dist_strategy)
    trainer_prog = fleet._origin_program
    dist_prog = fleet.main_program
    if fluid.core.is_compiled_with_cuda():
        device_id = int(os.getenv('FLAGS_selected_gpus', '0'))
        place = fluid.CUDAPlace(device_id)
    elif fluid.core.is_compiled_with_xpu():
        device_id = int(os.getenv('FLAGS_selected_xpus', '0'))
        place = fluid.XPUPlace(device_id)
    else:
        raise ValueError('fleet dygraph api must in paddlepaddle-xpu or paddlepaddle-gpu.')
    exe = fluid.Executor(place)
    exe.run(fluid.default_startup_program())
    eprint(type(self).__name__, 'run worker startup program done.')
    feed_var_list = [var for var in trainer_prog.global_block().vars.values() if var.is_data]
    eprint('feed_var_list:', feed_var_list)
    if feed_var_list[0].name == 'label':
        feed_var_list = feed_var_list[::-1]
    feeder = fluid.DataFeeder(feed_var_list, place)
    reader_generator = train_reader()

    def get_data():
        origin_batch = next(reader_generator)
        if args.update_method != 'local' and args.use_reader_alloc:
            new_batch = []
            for (offset, item) in enumerate(origin_batch):
                if offset % 2 == args.trainer_id:
                    new_batch.append(item)
            return new_batch
        else:
            return origin_batch
    print_to_err(type(self).__name__, 'begin to train on trainer')
    out_losses = []
    for i in range(RUN_STEP):
        (loss,) = exe.run(dist_prog, fetch_list=[avg_cost.name], feed=feeder.feed(get_data()))
        out_losses.append(loss[0])
        print_to_err(type(self).__name__, 'run step %d finished' % i)
    print_to_err(type(self).__name__, 'trainer run finished')
    sys.stdout.buffer.write(pickle.dumps(out_losses))
    if args.save_model:
        model_save_dir = '/tmp'
        if fleet.worker_index() == 0:
            model_save_dir_fluid = os.path.join(model_save_dir, 'fluid_persistables')
            model_save_dir_fleet = os.path.join(model_save_dir, 'fleet_persistables')
            infer_save_dir_fluid = os.path.join(model_save_dir, 'fluid_infer')
            infer_save_dir_fleet = os.path.join(model_save_dir, 'fleet_infer')
        else:
            model_save_dir_fluid = os.path.join(model_save_dir, 'fluid_persistables_2')
            model_save_dir_fleet = os.path.join(model_save_dir, 'fleet_persistables_2')
            infer_save_dir_fluid = os.path.join(model_save_dir, 'fluid_infer_2')
            infer_save_dir_fleet = os.path.join(model_save_dir, 'fleet_infer_2')
        paddle.distributed.io.save_persistables(exe, model_save_dir_fluid, fleet._origin_program)
        fleet.save_persistables(executor=exe, dirname=model_save_dir_fleet)
        feeded_var_names = [var.name for var in feed_var_list]
        fluid.io.save_inference_model(infer_save_dir_fluid, feeded_var_names, [avg_cost], exe, fleet._origin_program)
        fleet.save_inference_model(exe, infer_save_dir_fleet, feeded_var_names, [avg_cost])",offset % 2,The given code cannot be refactored with fstring as it is not a string. It is a mathematical operation.,0,,,,,,,,,,
indico,https://github.com/indico/indico/tree/master/indico/core/logger.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/indico/indico/core/logger.py,FormattedSubjectSMTPHandler,"def getSubject(self, record):
    return self.subject % record.__dict__",self.subject % record.__dict__,The given code cannot be refactored with fstring as it is not a string. It is a dictionary operation.,0,,,,,,,,,,
wrapt,https://github.com/GrahamDumpleton/wrapt/tree/master/tests/test_object_proxy.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/wrapt/tests/test_object_proxy.py,TestAsNumberObjectProxy,"def test_mod_uninitialized_args(self):
    result = object()
    two = wrapt.ObjectProxy.__new__(wrapt.ObjectProxy)
    four = wrapt.ObjectProxy(4)
    try:
        assert two % four == result
    except ValueError:
        pass
    two = wrapt.ObjectProxy(2)
    four = wrapt.ObjectProxy.__new__(wrapt.ObjectProxy)
    try:
        assert two % four == result
    except ValueError:
        pass",two % four,The given code is not a string and cannot be refactored with fstring.,0,,,,,,,,,,
wrapt,https://github.com/GrahamDumpleton/wrapt/tree/master/tests/test_object_proxy.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/wrapt/tests/test_object_proxy.py,TestAsNumberObjectProxy,"def test_mod_uninitialized_args(self):
    result = object()
    two = wrapt.ObjectProxy.__new__(wrapt.ObjectProxy)
    four = wrapt.ObjectProxy(4)
    try:
        assert two % four == result
    except ValueError:
        pass
    two = wrapt.ObjectProxy(2)
    four = wrapt.ObjectProxy.__new__(wrapt.ObjectProxy)
    try:
        assert two % four == result
    except ValueError:
        pass",two % four,The given code is not a string and cannot be refactored with fstring.,0,,,,,,,,,,
Transformer-TTS,https://github.com/soobinseo/Transformer-TTS/tree/master//train_transformer.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/Transformer-TTS//train_transformer.py,,"def main():
    dataset = get_dataset()
    global_step = 0
    m = nn.DataParallel(Model().cuda())
    m.train()
    optimizer = t.optim.Adam(m.parameters(), lr=hp.lr)
    pos_weight = t.FloatTensor([5.0]).cuda()
    writer = SummaryWriter()
    for epoch in range(hp.epochs):
        dataloader = DataLoader(dataset, batch_size=hp.batch_size, shuffle=True, collate_fn=collate_fn_transformer, drop_last=True, num_workers=16)
        pbar = tqdm(dataloader)
        for (i, data) in enumerate(pbar):
            pbar.set_description('Processing at epoch %d' % epoch)
            global_step += 1
            if global_step < 400000:
                adjust_learning_rate(optimizer, global_step)
            (character, mel, mel_input, pos_text, pos_mel, _) = data
            stop_tokens = t.abs(pos_mel.ne(0).type(t.float) - 1)
            character = character.cuda()
            mel = mel.cuda()
            mel_input = mel_input.cuda()
            pos_text = pos_text.cuda()
            pos_mel = pos_mel.cuda()
            (mel_pred, postnet_pred, attn_probs, stop_preds, attns_enc, attns_dec) = m.forward(character, mel_input, pos_text, pos_mel)
            mel_loss = nn.L1Loss()(mel_pred, mel)
            post_mel_loss = nn.L1Loss()(postnet_pred, mel)
            loss = mel_loss + post_mel_loss
            writer.add_scalars('training_loss', {'mel_loss': mel_loss, 'post_mel_loss': post_mel_loss}, global_step)
            writer.add_scalars('alphas', {'encoder_alpha': m.module.encoder.alpha.data, 'decoder_alpha': m.module.decoder.alpha.data}, global_step)
            if global_step % hp.image_step == 1:
                for (i, prob) in enumerate(attn_probs):
                    num_h = prob.size(0)
                    for j in range(4):
                        x = vutils.make_grid(prob[j * 16] * 255)
                        writer.add_image('Attention_%d_0' % global_step, x, i * 4 + j)
                for (i, prob) in enumerate(attns_enc):
                    num_h = prob.size(0)
                    for j in range(4):
                        x = vutils.make_grid(prob[j * 16] * 255)
                        writer.add_image('Attention_enc_%d_0' % global_step, x, i * 4 + j)
                for (i, prob) in enumerate(attns_dec):
                    num_h = prob.size(0)
                    for j in range(4):
                        x = vutils.make_grid(prob[j * 16] * 255)
                        writer.add_image('Attention_dec_%d_0' % global_step, x, i * 4 + j)
            optimizer.zero_grad()
            loss.backward()
            nn.utils.clip_grad_norm_(m.parameters(), 1.0)
            optimizer.step()
            if global_step % hp.save_step == 0:
                t.save({'model': m.state_dict(), 'optimizer': optimizer.state_dict()}, os.path.join(hp.checkpoint_path, 'checkpoint_transformer_%d.pth.tar' % global_step))",global_step % hp.image_step,The given code cannot be refactored with fstring as it involves a mathematical operation.,0,,,,,,,,,,
Transformer-TTS,https://github.com/soobinseo/Transformer-TTS/tree/master//train_transformer.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/Transformer-TTS//train_transformer.py,,"def main():
    dataset = get_dataset()
    global_step = 0
    m = nn.DataParallel(Model().cuda())
    m.train()
    optimizer = t.optim.Adam(m.parameters(), lr=hp.lr)
    pos_weight = t.FloatTensor([5.0]).cuda()
    writer = SummaryWriter()
    for epoch in range(hp.epochs):
        dataloader = DataLoader(dataset, batch_size=hp.batch_size, shuffle=True, collate_fn=collate_fn_transformer, drop_last=True, num_workers=16)
        pbar = tqdm(dataloader)
        for (i, data) in enumerate(pbar):
            pbar.set_description('Processing at epoch %d' % epoch)
            global_step += 1
            if global_step < 400000:
                adjust_learning_rate(optimizer, global_step)
            (character, mel, mel_input, pos_text, pos_mel, _) = data
            stop_tokens = t.abs(pos_mel.ne(0).type(t.float) - 1)
            character = character.cuda()
            mel = mel.cuda()
            mel_input = mel_input.cuda()
            pos_text = pos_text.cuda()
            pos_mel = pos_mel.cuda()
            (mel_pred, postnet_pred, attn_probs, stop_preds, attns_enc, attns_dec) = m.forward(character, mel_input, pos_text, pos_mel)
            mel_loss = nn.L1Loss()(mel_pred, mel)
            post_mel_loss = nn.L1Loss()(postnet_pred, mel)
            loss = mel_loss + post_mel_loss
            writer.add_scalars('training_loss', {'mel_loss': mel_loss, 'post_mel_loss': post_mel_loss}, global_step)
            writer.add_scalars('alphas', {'encoder_alpha': m.module.encoder.alpha.data, 'decoder_alpha': m.module.decoder.alpha.data}, global_step)
            if global_step % hp.image_step == 1:
                for (i, prob) in enumerate(attn_probs):
                    num_h = prob.size(0)
                    for j in range(4):
                        x = vutils.make_grid(prob[j * 16] * 255)
                        writer.add_image('Attention_%d_0' % global_step, x, i * 4 + j)
                for (i, prob) in enumerate(attns_enc):
                    num_h = prob.size(0)
                    for j in range(4):
                        x = vutils.make_grid(prob[j * 16] * 255)
                        writer.add_image('Attention_enc_%d_0' % global_step, x, i * 4 + j)
                for (i, prob) in enumerate(attns_dec):
                    num_h = prob.size(0)
                    for j in range(4):
                        x = vutils.make_grid(prob[j * 16] * 255)
                        writer.add_image('Attention_dec_%d_0' % global_step, x, i * 4 + j)
            optimizer.zero_grad()
            loss.backward()
            nn.utils.clip_grad_norm_(m.parameters(), 1.0)
            optimizer.step()
            if global_step % hp.save_step == 0:
                t.save({'model': m.state_dict(), 'optimizer': optimizer.state_dict()}, os.path.join(hp.checkpoint_path, 'checkpoint_transformer_%d.pth.tar' % global_step))",global_step % hp.save_step,The given code cannot be refactored with fstring as it involves a modulo operation.,0,,,,,,,,,,
d2l-en,https://github.com/d2l-ai/d2l-en/tree/master/d2l/tensorflow.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/d2l-en/d2l/tensorflow.py,,"def train_ch11(trainer_fn, states, hyperparams, data_iter, feature_dim, num_epochs=2):
    """"""Defined in :numref:`sec_minibatches`""""""
    w = tf.Variable(tf.random.normal(shape=(feature_dim, 1), mean=0, stddev=0.01), trainable=True)
    b = tf.Variable(tf.zeros(1), trainable=True)
    (net, loss) = (lambda X: d2l.linreg(X, w, b), d2l.squared_loss)
    animator = d2l.Animator(xlabel='epoch', ylabel='loss', xlim=[0, num_epochs], ylim=[0.22, 0.35])
    (n, timer) = (0, d2l.Timer())
    for _ in range(num_epochs):
        for (X, y) in data_iter:
            with tf.GradientTape() as g:
                l = tf.math.reduce_mean(loss(net(X), y))
            (dw, db) = g.gradient(l, [w, b])
            trainer_fn([w, b], [dw, db], states, hyperparams)
            n += X.shape[0]
            if n % 200 == 0:
                timer.stop()
                p = n / X.shape[0]
                q = p / tf.data.experimental.cardinality(data_iter).numpy()
                r = (d2l.evaluate_loss(net, data_iter, loss),)
                animator.add(q, r)
                timer.start()
    print(f'loss: {animator.Y[0][-1]:.3f}, {timer.sum() / num_epochs:.3f} sec/epoch')
    return (timer.cumsum(), animator.Y[0])",n % 200,The given code cannot be refactored with fstring as it is performing a mathematical operation and not dealing with string formatting.,0,,,,,,,,,,
LIFT,https://github.com/cvlab-epfl/LIFT/tree/master/python-code/Utils/ghh_pool.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/LIFT/python-code/Utils/ghh_pool.py,,"def pool_function(input, axis):
    input_shape = tuple(input.shape)
    num_feature_maps_out = input_shape[axis - 1]
    pool_size = input_shape[axis]
    pool_shape = input_shape[:axis] + (num_in_sum, num_in_max) + input_shape[axis + 1:]
    input_reshaped = input.reshape(pool_shape)
    res_after_max = T.max(input_reshaped, axis=axis + 1)
    delta = np.cast[floatX](1.0) - np.cast[floatX](2.0) * (T.arange(num_in_sum, dtype=floatX) % np.cast[floatX](2))
    target_dimshuffle = ('x',) * axis + (0,) + ('x',) * (len(input_shape) - 1 - axis)
    delta = delta.flatten().dimshuffle(*target_dimshuffle)
    res_after_sum = T.sum(res_after_max * delta, axis=axis)
    return res_after_sum","T.arange(num_in_sum, dtype=floatX) % np.cast[floatX](2)",The given code cannot be refactored with fstring as it does not involve any string formatting.,0,,,,,,,,,,
PGL,https://github.com/PaddlePaddle/PGL/tree/master/legacy/examples/metapath2vec/main.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/PGL/legacy/examples/metapath2vec/main.py,,"def multiprocess_data_generator(config, dataset):
    """"""Using multiprocess to generate training data.
    """"""
    num_sample_workers = config['trainer']['args']['num_sample_workers']
    walkpath_files = [[] for i in range(num_sample_workers)]
    for (idx, f) in enumerate(glob.glob(dataset.walk_files)):
        walkpath_files[idx % num_sample_workers].append(f)
    gen_data_pool = [dataset.pairs_generator(files) for files in walkpath_files]
    if num_sample_workers == 1:
        gen_data_func = gen_data_pool[0]
    else:
        gen_data_func = mp_reader.multiprocess_reader(gen_data_pool, use_pipe=True, queue_size=100)
    return gen_data_func",idx % num_sample_workers,The given code cannot be refactored with fstring as it involves a mathematical operation.,0,,,,,,,,,,
qutebrowser,https://github.com/qutebrowser/qutebrowser/tree/master/qutebrowser/browser/commands.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/qutebrowser/qutebrowser/browser/commands.py,CommandDispatcher,"def tab_next(self, count=1):
    """"""Switch to the next tab, or switch [count] tabs forward.

        Args:
            count: How many tabs to switch forward.
        """"""
    if self._count() == 0:
        return
    newidx = self._current_index() + count
    if newidx < self._count():
        self._set_current_index(newidx)
    elif config.val.tabs.wrap:
        self._set_current_index(newidx % self._count())
    else:
        log.webview.debug('Last tab')",newidx % self._count(),The code cannot be refactored with fstring as it is not a string formatting operation.,0,,,,,,,,,,
pyannote-audio,https://github.com/pyannote/pyannote-audio/tree/master/pyannote/audio/_version.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pyannote-audio/pyannote/audio/_version.py,,"def git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):
    if not os.path.exists(os.path.join(root, '.git')):
        if verbose:
            print('no .git in %s' % root)
        raise NotThisMethod('no .git directory')
    GITS = ['git']
    if sys.platform == 'win32':
        GITS = ['git.cmd', 'git.exe']
    describe_out = run_command(GITS, ['describe', '--tags', '--dirty', '--always', '--long'], cwd=root)
    if describe_out is None:
        raise NotThisMethod(""'git describe' failed"")
    describe_out = describe_out.strip()
    full_out = run_command(GITS, ['rev-parse', 'HEAD'], cwd=root)
    if full_out is None:
        raise NotThisMethod(""'git rev-parse' failed"")
    full_out = full_out.strip()
    pieces = {}
    pieces['long'] = full_out
    pieces['short'] = full_out[:7]
    pieces['error'] = None
    git_describe = describe_out
    dirty = git_describe.endswith('-dirty')
    pieces['dirty'] = dirty
    if dirty:
        git_describe = git_describe[:git_describe.rindex('-dirty')]
    if '-' in git_describe:
        mo = re.search('^(.+)-(\\d+)-g([0-9a-f]+)$', git_describe)
        if not mo:
            pieces['error'] = ""unable to parse git-describe output: '%s'"" % describe_out
            return pieces
        full_tag = mo.group(1)
        if not full_tag.startswith(tag_prefix):
            if verbose:
                fmt = ""tag '%s' doesn't start with prefix '%s'""
                print(fmt % (full_tag, tag_prefix))
            pieces['error'] = ""tag '%s' doesn't start with prefix '%s'"" % (full_tag, tag_prefix)
            return pieces
        pieces['closest-tag'] = full_tag[len(tag_prefix):]
        pieces['distance'] = int(mo.group(2))
        pieces['short'] = mo.group(3)
    else:
        pieces['closest-tag'] = None
        count_out = run_command(GITS, ['rev-list', 'HEAD', '--count'], cwd=root)
        pieces['distance'] = int(count_out)
    return pieces","fmt % (full_tag, tag_prefix)",The given code cannot be refactored with fstring as it is using the old-style string formatting with the `%` operator.,0,,,,,,,,,,
robosuite,https://github.com/ARISE-Initiative/robosuite/tree/master/robosuite/demos/demo_collect_and_playback_data.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/robosuite/robosuite/demos/demo_collect_and_playback_data.py,,"def collect_random_trajectory(env, timesteps=1000):
    """"""Run a random policy to collect trajectories.

    The rollout trajectory is saved to files in npz format.
    Modify the DataCollectionWrapper wrapper to add new fields or change data formats.

    Args:
        env (MujocoEnv): environment instance to collect trajectories from
        timesteps(int): how many environment timesteps to run for a given trajectory
    """"""
    env.reset()
    dof = env.action_dim
    for t in range(timesteps):
        action = np.random.randn(dof)
        env.step(action)
        env.render()
        if t % 100 == 0:
            print(t)",t % 100,"The given code is not a string, so it cannot be refactored with fstring.",0,,,,,,,,,,
TensorFlow-and-DeepLearning-Tutorial,https://github.com/CreatCodeBuild/TensorFlow-and-DeepLearning-Tutorial/tree/master/Season1_Tensorflow1.1_Python3.5/12-15/dp_refined_api.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/TensorFlow-and-DeepLearning-Tutorial/Season1_Tensorflow1.1_Python3.5/12-15/dp_refined_api.py,Network,"def run(self, data_iterator, train_samples, train_labels, test_samples, test_labels):
    """"""
        Session
        :data_iterator: a function that yields chuck of data
        """"""

    def print_confusion_matrix(confusionMatrix):
        print('Confusion    Matrix:')
        for (i, line) in enumerate(confusionMatrix):
            print(line, line[i] / np.sum(line))
        a = 0
        for (i, column) in enumerate(np.transpose(confusionMatrix, (1, 0))):
            a += column[i] / np.sum(column) * (np.sum(column) / 26000)
            print(column[i] / np.sum(column))
        print('\n', np.sum(confusionMatrix), a)
    self.writer = tf.summary.FileWriter('./board', tf.get_default_graph())
    with tf.Session(graph=tf.get_default_graph()) as session:
        tf.initialize_all_variables().run()
        print('Start Training')
        for (i, samples, labels) in data_iterator(train_samples, train_labels, self.train_batch_size):
            (_, l, predictions, summary) = session.run([self.optimizer, self.loss, self.train_prediction, self.merged_train_summary], feed_dict={self.tf_train_samples: samples, self.tf_train_labels: labels})
            self.writer.add_summary(summary, i)
            (accuracy, _) = self.accuracy(predictions, labels)
            if i % 50 == 0:
                print('Minibatch loss at step %d: %f' % (i, l))
                print('Minibatch accuracy: %.1f%%' % accuracy)
        accuracies = []
        confusionMatrices = []
        for (i, samples, labels) in data_iterator(test_samples, test_labels, self.test_batch_size):
            print('samples shape', samples.shape)
            (result, summary) = session.run([self.test_prediction, self.merged_test_summary], feed_dict={self.tf_test_samples: samples})
            self.writer.add_summary(summary, i)
            (accuracy, cm) = self.accuracy(result, labels, need_confusion_matrix=True)
            accuracies.append(accuracy)
            confusionMatrices.append(cm)
            print('Test Accuracy: %.1f%%' % accuracy)
        print(' Average  Accuracy:', np.average(accuracies))
        print('Standard Deviation:', np.std(accuracies))
        print_confusion_matrix(np.add.reduce(confusionMatrices))",i % 50,The code cannot be refactored with fstring as it is not a string formatting operation. It is a modulo operation.,0,,,,,,,,,,
music-source-separation,https://github.com/andabi/music-source-separation/tree/master/mir_eval/key.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/music-source-separation/mir_eval/key.py,,"def weighted_score(reference_key, estimated_key):
    """"""Computes a heuristic score which is weighted according to the
    relationship of the reference and estimated key, as follows:

    +------------------------------------------------------+-------+
    | Relationship                                         | Score |
    +------------------------------------------------------+-------+
    | Same key                                             | 1.0   |
    +------------------------------------------------------+-------+
    | Estimated key is a perfect fifth above reference key | 0.5   |
    +------------------------------------------------------+-------+
    | Relative major/minor                                 | 0.3   |
    +------------------------------------------------------+-------+
    | Parallel major/minor                                 | 0.2   |
    +------------------------------------------------------+-------+
    | Other                                                | 0.0   |
    +------------------------------------------------------+-------+

    Examples
    --------
    >>> ref_key = mir_eval.io.load_key('ref.txt')
    >>> est_key = mir_eval.io.load_key('est.txt')
    >>> score = mir_eval.key.weighted_score(ref_key, est_key)

    Parameters
    ----------
    reference_key : str
        Reference key string.
    estimated_key : str
        Estimated key string.

    Returns
    -------
    score : float
        Score representing how closely related the keys are.
    """"""
    validate(reference_key, estimated_key)
    (reference_key, reference_mode) = split_key_string(reference_key)
    (estimated_key, estimated_mode) = split_key_string(estimated_key)
    if reference_key == estimated_key and reference_mode == estimated_mode:
        return 1.0
    if estimated_mode == reference_mode and (estimated_key - reference_key) % 12 == 7:
        return 0.5
    if estimated_mode != reference_mode == 'major' and (estimated_key - reference_key) % 12 == 9:
        return 0.3
    if estimated_mode != reference_mode == 'minor' and (estimated_key - reference_key) % 12 == 3:
        return 0.3
    if estimated_mode != reference_mode and reference_key == estimated_key:
        return 0.2
    return 0.0",(estimated_key - reference_key) % 12,The given code cannot be refactored with fstring as it involves a mathematical operation.,0,,,,,,,,,,
music-source-separation,https://github.com/andabi/music-source-separation/tree/master/mir_eval/key.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/music-source-separation/mir_eval/key.py,,"def weighted_score(reference_key, estimated_key):
    """"""Computes a heuristic score which is weighted according to the
    relationship of the reference and estimated key, as follows:

    +------------------------------------------------------+-------+
    | Relationship                                         | Score |
    +------------------------------------------------------+-------+
    | Same key                                             | 1.0   |
    +------------------------------------------------------+-------+
    | Estimated key is a perfect fifth above reference key | 0.5   |
    +------------------------------------------------------+-------+
    | Relative major/minor                                 | 0.3   |
    +------------------------------------------------------+-------+
    | Parallel major/minor                                 | 0.2   |
    +------------------------------------------------------+-------+
    | Other                                                | 0.0   |
    +------------------------------------------------------+-------+

    Examples
    --------
    >>> ref_key = mir_eval.io.load_key('ref.txt')
    >>> est_key = mir_eval.io.load_key('est.txt')
    >>> score = mir_eval.key.weighted_score(ref_key, est_key)

    Parameters
    ----------
    reference_key : str
        Reference key string.
    estimated_key : str
        Estimated key string.

    Returns
    -------
    score : float
        Score representing how closely related the keys are.
    """"""
    validate(reference_key, estimated_key)
    (reference_key, reference_mode) = split_key_string(reference_key)
    (estimated_key, estimated_mode) = split_key_string(estimated_key)
    if reference_key == estimated_key and reference_mode == estimated_mode:
        return 1.0
    if estimated_mode == reference_mode and (estimated_key - reference_key) % 12 == 7:
        return 0.5
    if estimated_mode != reference_mode == 'major' and (estimated_key - reference_key) % 12 == 9:
        return 0.3
    if estimated_mode != reference_mode == 'minor' and (estimated_key - reference_key) % 12 == 3:
        return 0.3
    if estimated_mode != reference_mode and reference_key == estimated_key:
        return 0.2
    return 0.0",(estimated_key - reference_key) % 12,The given code cannot be refactored with fstring as it involves a mathematical operation.,0,,,,,,,,,,
music-source-separation,https://github.com/andabi/music-source-separation/tree/master/mir_eval/key.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/music-source-separation/mir_eval/key.py,,"def weighted_score(reference_key, estimated_key):
    """"""Computes a heuristic score which is weighted according to the
    relationship of the reference and estimated key, as follows:

    +------------------------------------------------------+-------+
    | Relationship                                         | Score |
    +------------------------------------------------------+-------+
    | Same key                                             | 1.0   |
    +------------------------------------------------------+-------+
    | Estimated key is a perfect fifth above reference key | 0.5   |
    +------------------------------------------------------+-------+
    | Relative major/minor                                 | 0.3   |
    +------------------------------------------------------+-------+
    | Parallel major/minor                                 | 0.2   |
    +------------------------------------------------------+-------+
    | Other                                                | 0.0   |
    +------------------------------------------------------+-------+

    Examples
    --------
    >>> ref_key = mir_eval.io.load_key('ref.txt')
    >>> est_key = mir_eval.io.load_key('est.txt')
    >>> score = mir_eval.key.weighted_score(ref_key, est_key)

    Parameters
    ----------
    reference_key : str
        Reference key string.
    estimated_key : str
        Estimated key string.

    Returns
    -------
    score : float
        Score representing how closely related the keys are.
    """"""
    validate(reference_key, estimated_key)
    (reference_key, reference_mode) = split_key_string(reference_key)
    (estimated_key, estimated_mode) = split_key_string(estimated_key)
    if reference_key == estimated_key and reference_mode == estimated_mode:
        return 1.0
    if estimated_mode == reference_mode and (estimated_key - reference_key) % 12 == 7:
        return 0.5
    if estimated_mode != reference_mode == 'major' and (estimated_key - reference_key) % 12 == 9:
        return 0.3
    if estimated_mode != reference_mode == 'minor' and (estimated_key - reference_key) % 12 == 3:
        return 0.3
    if estimated_mode != reference_mode and reference_key == estimated_key:
        return 0.2
    return 0.0",(estimated_key - reference_key) % 12,The given code cannot be refactored with fstring as it involves a mathematical operation.,0,,,,,,,,,,
QRec,https://github.com/Coder-Yu/QRec/tree/master/model/rating/CUNE_MF.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/QRec/model/rating/CUNE_MF.py,CUNE_MF,"def trainModel(self):
    print('Kind Note: This method will probably take much time.')
    print('Building collaborative user network...')
    self.itemNet = {}
    for item in self.data.trainSet_i:
        if len(self.data.trainSet_i[item]) > 1:
            self.itemNet[item] = self.data.trainSet_i[item]
    self.filteredRatings = defaultdict(list)
    for item in self.itemNet:
        for user in self.itemNet[item]:
            if self.itemNet[item][user] >= 1:
                self.filteredRatings[user].append(item)
    self.CUNet = defaultdict(list)
    for user1 in self.filteredRatings:
        s1 = set(self.filteredRatings[user1])
        for user2 in self.filteredRatings:
            if user1 != user2:
                s2 = set(self.filteredRatings[user2])
                weight = len(s1.intersection(s2))
                if weight > 0:
                    self.CUNet[user1] += [user2] * weight
    print('Generating random deep walks...')
    self.walks = []
    self.visited = defaultdict(dict)
    for user in self.CUNet:
        for t in range(self.walkCount):
            path = [user]
            lastNode = user
            for i in range(1, self.walkLength):
                nextNode = choice(self.CUNet[lastNode])
                count = 0
                while nextNode in self.visited[lastNode]:
                    nextNode = choice(self.CUNet[lastNode])
                    count += 1
                    if count == 10:
                        break
                path.append(nextNode)
                self.visited[user][nextNode] = 1
                lastNode = nextNode
            self.walks.append(path)
    shuffle(self.walks)
    print('Generating user embedding...')
    model = w2v.Word2Vec(self.walks, size=self.walkDim, window=5, min_count=0, iter=3)
    print('User embedding generated.')
    print('Constructing similarity matrix...')
    self.W = np.random.rand(self.data.trainingSize()[0], self.walkDim) / 10
    self.topKSim = {}
    i = 0
    for user1 in self.CUNet:
        sims = []
        u1 = self.data.user[user1]
        self.W[u1] = model.wv[user1]
        for user2 in self.CUNet:
            if user1 != user2:
                u2 = self.data.user[user2]
                self.W[u2] = model.wv[user2]
                sims.append((user2, cosine(self.W[u1], self.W[u2])))
        self.topKSim[user1] = sorted(sims, key=lambda d: d[1], reverse=True)[:self.topK]
        i += 1
        if i % 200 == 0:
            print('progress:', i, '/', len(self.CUNet))
    print('Similarity matrix finished.')
    print('Decomposing...')
    epoch = 0
    while epoch < self.maxEpoch:
        self.loss = 0
        for entry in self.data.trainingData:
            (user, item, rating) = entry
            u = self.data.user[user]
            i = self.data.item[item]
            error = rating - self.P[u].dot(self.Q[i])
            self.loss += error ** 2
            p = self.P[u]
            q = self.Q[i]
            self.P[u] += self.lRate * (error * q - self.regU * p)
            self.Q[i] += self.lRate * (error * p - self.regI * q)
        for user in self.CUNet:
            u = self.data.user[user]
            friends = self.topKSim[user]
            for friend in friends:
                uf = self.data.user[friend[0]]
                self.P[u] -= self.lRate * (self.P[u] - self.P[uf]) * self.alpha
                self.loss += self.alpha * (self.P[u] - self.P[uf]).dot(self.P[u] - self.P[uf])
        self.loss += self.regU * (self.P * self.P).sum() + self.regI * (self.Q * self.Q).sum()
        epoch += 1
        if self.isConverged(epoch):
            break",i % 200,The given code cannot be refactored with fstring as it is performing a mathematical operation and not printing any string.,0,,,,,,,,,,
BasicSR,https://github.com/xinntao/BasicSR/tree/master/basicsr/models/swinir_model.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/BasicSR/basicsr/models/swinir_model.py,SwinIRModel,"def test(self):
    window_size = self.opt['network_g']['window_size']
    scale = self.opt.get('scale', 1)
    (mod_pad_h, mod_pad_w) = (0, 0)
    (_, _, h, w) = self.lq.size()
    if h % window_size != 0:
        mod_pad_h = window_size - h % window_size
    if w % window_size != 0:
        mod_pad_w = window_size - w % window_size
    img = F.pad(self.lq, (0, mod_pad_w, 0, mod_pad_h), 'reflect')
    if hasattr(self, 'net_g_ema'):
        self.net_g_ema.eval()
        with torch.no_grad():
            self.output = self.net_g_ema(img)
    else:
        self.net_g.eval()
        with torch.no_grad():
            self.output = self.net_g(img)
        self.net_g.train()
    (_, _, h, w) = self.output.size()
    self.output = self.output[:, :, 0:h - mod_pad_h * scale, 0:w - mod_pad_w * scale]",h % window_size,"The given code is not a string, it is a mathematical expression. Therefore, it cannot be refactored with fstring.",0,,,,,,,,,,
BasicSR,https://github.com/xinntao/BasicSR/tree/master/basicsr/models/swinir_model.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/BasicSR/basicsr/models/swinir_model.py,SwinIRModel,"def test(self):
    window_size = self.opt['network_g']['window_size']
    scale = self.opt.get('scale', 1)
    (mod_pad_h, mod_pad_w) = (0, 0)
    (_, _, h, w) = self.lq.size()
    if h % window_size != 0:
        mod_pad_h = window_size - h % window_size
    if w % window_size != 0:
        mod_pad_w = window_size - w % window_size
    img = F.pad(self.lq, (0, mod_pad_w, 0, mod_pad_h), 'reflect')
    if hasattr(self, 'net_g_ema'):
        self.net_g_ema.eval()
        with torch.no_grad():
            self.output = self.net_g_ema(img)
    else:
        self.net_g.eval()
        with torch.no_grad():
            self.output = self.net_g(img)
        self.net_g.train()
    (_, _, h, w) = self.output.size()
    self.output = self.output[:, :, 0:h - mod_pad_h * scale, 0:w - mod_pad_w * scale]",w % window_size,"The given code is not a string, it is a mathematical operation. Therefore, it cannot be refactored with fstring.",0,,,,,,,,,,
BasicSR,https://github.com/xinntao/BasicSR/tree/master/basicsr/models/swinir_model.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/BasicSR/basicsr/models/swinir_model.py,SwinIRModel,"def test(self):
    window_size = self.opt['network_g']['window_size']
    scale = self.opt.get('scale', 1)
    (mod_pad_h, mod_pad_w) = (0, 0)
    (_, _, h, w) = self.lq.size()
    if h % window_size != 0:
        mod_pad_h = window_size - h % window_size
    if w % window_size != 0:
        mod_pad_w = window_size - w % window_size
    img = F.pad(self.lq, (0, mod_pad_w, 0, mod_pad_h), 'reflect')
    if hasattr(self, 'net_g_ema'):
        self.net_g_ema.eval()
        with torch.no_grad():
            self.output = self.net_g_ema(img)
    else:
        self.net_g.eval()
        with torch.no_grad():
            self.output = self.net_g(img)
        self.net_g.train()
    (_, _, h, w) = self.output.size()
    self.output = self.output[:, :, 0:h - mod_pad_h * scale, 0:w - mod_pad_w * scale]",h % window_size,"The given code is not a string, it is a mathematical expression. Therefore, it cannot be refactored with fstring.",0,,,,,,,,,,
BasicSR,https://github.com/xinntao/BasicSR/tree/master/basicsr/models/swinir_model.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/BasicSR/basicsr/models/swinir_model.py,SwinIRModel,"def test(self):
    window_size = self.opt['network_g']['window_size']
    scale = self.opt.get('scale', 1)
    (mod_pad_h, mod_pad_w) = (0, 0)
    (_, _, h, w) = self.lq.size()
    if h % window_size != 0:
        mod_pad_h = window_size - h % window_size
    if w % window_size != 0:
        mod_pad_w = window_size - w % window_size
    img = F.pad(self.lq, (0, mod_pad_w, 0, mod_pad_h), 'reflect')
    if hasattr(self, 'net_g_ema'):
        self.net_g_ema.eval()
        with torch.no_grad():
            self.output = self.net_g_ema(img)
    else:
        self.net_g.eval()
        with torch.no_grad():
            self.output = self.net_g(img)
        self.net_g.train()
    (_, _, h, w) = self.output.size()
    self.output = self.output[:, :, 0:h - mod_pad_h * scale, 0:w - mod_pad_w * scale]",w % window_size,"The given code is not a string, it is a mathematical operation. Therefore, it cannot be refactored with fstring.",0,,,,,,,,,,
sphinx,https://github.com/sphinx-doc/sphinx/tree/master/sphinx/writers/html.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/sphinx/sphinx/writers/html.py,HTMLTranslator,"def visit_row(self, node: Element) -> None:
    self._table_row_indices[-1] += 1
    if self._table_row_indices[-1] % 2 == 0:
        node['classes'].append('row-even')
    else:
        node['classes'].append('row-odd')
    self.body.append(self.starttag(node, 'tr', ''))
    node.column = 0",self._table_row_indices[-1] % 2,The code cannot be refactored with fstring as it is not a string formatting operation.,0,,,,,,,,,,
drawing,https://github.com/maoschanz/drawing/tree/master/src/main.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/drawing/src/main.py,Application,"def is_beta(self):
    """"""Tells is the app version is even or odd, odd versions being considered
		as unstable versions. This affects available options and the style of
		the headerbar.""""""
    return int(self._version.split('.')[1]) * 5 % 10 == 5",int(self._version.split('.')[1]) * 5 % 10,The given code cannot be refactored with fstring as it is a mathematical expression and not a string.,0,,,,,,,,,,
pandas,https://github.com/pandas-dev/pandas/tree/master/asv_bench/benchmarks/groupby.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pandas/asv_bench/benchmarks/groupby.py,AggEngine,"def function(values, index):
    total = 0
    for (i, value) in enumerate(values):
        if i % 2:
            total += value + 5
        else:
            total += value * 2
    return total",i % 2,The code cannot be refactored with fstring as it is not a string. It is a mathematical operation.,0,,,,,,,,,,
core,https://github.com/home-assistant/core/tree/master/tests/components/logger/test_init.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/core/tests/components/logger/test_init.py,,"def msg_test(logger, result, message, *args):
    logger.error(message, *args)
    formatted_message = message % args
    assert (formatted_message in caplog.text) == result
    caplog.clear()",message % args,"The given code is not complete. It is missing the definition of the variables ""message"" and ""args"". Without knowing the data types and values of these variables, it is not possible to refactor the code with fstring.",0,,,,,,,,,,
erpnext,https://github.com/frappe/erpnext/tree/master/erpnext/loan_management/doctype/loan_interest_accrual/loan_interest_accrual.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/erpnext/erpnext/loan_management/doctype/loan_interest_accrual/loan_interest_accrual.py,,"def make_accrual_interest_entry_for_term_loans(posting_date, process_loan_interest, term_loan=None, loan_type=None, accrual_type='Regular'):
    curr_date = posting_date or add_days(nowdate(), 1)
    term_loans = get_term_loans(curr_date, term_loan, loan_type)
    accrued_entries = []
    for loan in term_loans:
        accrued_entries.append(loan.payment_entry)
        args = frappe._dict({'loan': loan.name, 'applicant_type': loan.applicant_type, 'applicant': loan.applicant, 'interest_income_account': loan.interest_income_account, 'loan_account': loan.loan_account, 'interest_amount': loan.interest_amount, 'payable_principal': loan.principal_amount, 'process_loan_interest': process_loan_interest, 'repayment_schedule_name': loan.payment_entry, 'posting_date': posting_date, 'accrual_type': accrual_type})
        make_loan_interest_accrual_entry(args)
    if accrued_entries:
        frappe.db.sql('UPDATE `tabRepayment Schedule`\n\t\t\tSET is_accrued = 1 where name in (%s)' % ', '.join(['%s'] * len(accrued_entries)), tuple(accrued_entries))","UPDATE `tabRepayment Schedule`\n\t\t\tSET is_accrued = 1 where name in (%s)' % ', '.join(['%s'] * len(accrued_entries))",Answer: No,0,,,,,,,,,,
ParlAI,https://github.com/facebookresearch/ParlAI/tree/master/parlai/tasks/eli5/data_creation/download_reddit_qalist.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/ParlAI/parlai/tasks/eli5/data_creation/download_reddit_qalist.py,,"def download_and_process_comments(post_ids, st_time):
    lines = defaultdict(list)
    subreddit_names = set()
    for post_id in post_ids:
        for (i, (name, l)) in enumerate(get_comments_from_post(post_id)):
            if i % 1000000 == 0:
                print('read %d lines, found %d' % (i, sum([len(ls) for ls in lines.values()])), time() - st_time)
            lines[name] += [l.strip()]
            subreddit_names.add(name)
    print('tokenizing and selecting specific posts %2f' % (time() - st_time))
    processed_items = dict([(name, []) for name in subreddit_names])
    key_list = ['id', 'link_id', 'parent_id', 'score', 'body']
    for name in subreddit_names:
        for line in lines[name]:
            reddit_dct = json.loads(line)
            if valid_comment(reddit_dct):
                reddit_res = {}
                for k in key_list:
                    if k == 'body':
                        if reddit_dct[k].lower() in ['[removed]', '[deleted]']:
                            reddit_dct[k] = ''
                        (txt, url_list) = word_url_tokenize(reddit_dct[k])
                        reddit_res[k] = (' '.join(txt.split()), url_list)
                    else:
                        reddit_res[k] = reddit_dct[k]
                processed_items[name] += [reddit_res]
    print('Total found %d' % len(processed_items), time() - st_time)
    return (subreddit_names, processed_items)",i % 1000000,The given code cannot be refactored with fstring as it is just a simple modulo operation.,0,,,,,,,,,,
transformers,https://github.com/huggingface/transformers/tree/master/src/transformers/models/segformer/modeling_segformer.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/transformers/src/transformers/models/segformer/modeling_segformer.py,SegformerEfficientSelfAttention,"def __init__(self, config, hidden_size, num_attention_heads, sequence_reduction_ratio):
    super().__init__()
    self.hidden_size = hidden_size
    self.num_attention_heads = num_attention_heads
    if self.hidden_size % self.num_attention_heads != 0:
        raise ValueError(f'The hidden size ({self.hidden_size}) is not a multiple of the number of attention heads ({self.num_attention_heads})')
    self.attention_head_size = int(self.hidden_size / self.num_attention_heads)
    self.all_head_size = self.num_attention_heads * self.attention_head_size
    self.query = nn.Linear(self.hidden_size, self.all_head_size)
    self.key = nn.Linear(self.hidden_size, self.all_head_size)
    self.value = nn.Linear(self.hidden_size, self.all_head_size)
    self.dropout = nn.Dropout(config.attention_probs_dropout_prob)
    self.sr_ratio = sequence_reduction_ratio
    if sequence_reduction_ratio > 1:
        self.sr = nn.Conv2d(hidden_size, hidden_size, kernel_size=sequence_reduction_ratio, stride=sequence_reduction_ratio)
        self.layer_norm = nn.LayerNorm(hidden_size)",self.hidden_size % self.num_attention_heads,The given code cannot be refactored with fstring as it involves a mathematical operation.,0,,,,,,,,,,
MaskFormer,https://github.com/facebookresearch/MaskFormer/tree/master/mask_former/modeling/backbone/swin.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/MaskFormer/mask_former/modeling/backbone/swin.py,PatchMerging,"def forward(self, x, H, W):
    """"""Forward function.
        Args:
            x: Input feature, tensor size (B, H*W, C).
            H, W: Spatial resolution of the input feature.
        """"""
    (B, L, C) = x.shape
    assert L == H * W, 'input feature has wrong size'
    x = x.view(B, H, W, C)
    pad_input = H % 2 == 1 or W % 2 == 1
    if pad_input:
        x = F.pad(x, (0, 0, 0, W % 2, 0, H % 2))
    x0 = x[:, 0::2, 0::2, :]
    x1 = x[:, 1::2, 0::2, :]
    x2 = x[:, 0::2, 1::2, :]
    x3 = x[:, 1::2, 1::2, :]
    x = torch.cat([x0, x1, x2, x3], -1)
    x = x.view(B, -1, 4 * C)
    x = self.norm(x)
    x = self.reduction(x)
    return x",H % 2,The given code is performing a mathematical operation and cannot be refactored with fstring.,0,,,,,,,,,,
MaskFormer,https://github.com/facebookresearch/MaskFormer/tree/master/mask_former/modeling/backbone/swin.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/MaskFormer/mask_former/modeling/backbone/swin.py,PatchMerging,"def forward(self, x, H, W):
    """"""Forward function.
        Args:
            x: Input feature, tensor size (B, H*W, C).
            H, W: Spatial resolution of the input feature.
        """"""
    (B, L, C) = x.shape
    assert L == H * W, 'input feature has wrong size'
    x = x.view(B, H, W, C)
    pad_input = H % 2 == 1 or W % 2 == 1
    if pad_input:
        x = F.pad(x, (0, 0, 0, W % 2, 0, H % 2))
    x0 = x[:, 0::2, 0::2, :]
    x1 = x[:, 1::2, 0::2, :]
    x2 = x[:, 0::2, 1::2, :]
    x3 = x[:, 1::2, 1::2, :]
    x = torch.cat([x0, x1, x2, x3], -1)
    x = x.view(B, -1, 4 * C)
    x = self.norm(x)
    x = self.reduction(x)
    return x",W % 2,"The given code is not a string, so it cannot be refactored with fstring.",0,,,,,,,,,,
MaskFormer,https://github.com/facebookresearch/MaskFormer/tree/master/mask_former/modeling/backbone/swin.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/MaskFormer/mask_former/modeling/backbone/swin.py,PatchMerging,"def forward(self, x, H, W):
    """"""Forward function.
        Args:
            x: Input feature, tensor size (B, H*W, C).
            H, W: Spatial resolution of the input feature.
        """"""
    (B, L, C) = x.shape
    assert L == H * W, 'input feature has wrong size'
    x = x.view(B, H, W, C)
    pad_input = H % 2 == 1 or W % 2 == 1
    if pad_input:
        x = F.pad(x, (0, 0, 0, W % 2, 0, H % 2))
    x0 = x[:, 0::2, 0::2, :]
    x1 = x[:, 1::2, 0::2, :]
    x2 = x[:, 0::2, 1::2, :]
    x3 = x[:, 1::2, 1::2, :]
    x = torch.cat([x0, x1, x2, x3], -1)
    x = x.view(B, -1, 4 * C)
    x = self.norm(x)
    x = self.reduction(x)
    return x",W % 2,"The given code is not a string, so it cannot be refactored with fstring.",0,,,,,,,,,,
MaskFormer,https://github.com/facebookresearch/MaskFormer/tree/master/mask_former/modeling/backbone/swin.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/MaskFormer/mask_former/modeling/backbone/swin.py,PatchMerging,"def forward(self, x, H, W):
    """"""Forward function.
        Args:
            x: Input feature, tensor size (B, H*W, C).
            H, W: Spatial resolution of the input feature.
        """"""
    (B, L, C) = x.shape
    assert L == H * W, 'input feature has wrong size'
    x = x.view(B, H, W, C)
    pad_input = H % 2 == 1 or W % 2 == 1
    if pad_input:
        x = F.pad(x, (0, 0, 0, W % 2, 0, H % 2))
    x0 = x[:, 0::2, 0::2, :]
    x1 = x[:, 1::2, 0::2, :]
    x2 = x[:, 0::2, 1::2, :]
    x3 = x[:, 1::2, 1::2, :]
    x = torch.cat([x0, x1, x2, x3], -1)
    x = x.view(B, -1, 4 * C)
    x = self.norm(x)
    x = self.reduction(x)
    return x",H % 2,The given code is performing a mathematical operation and cannot be refactored with fstring.,0,,,,,,,,,,
SimSiam,https://github.com/PatrickHua/SimSiam/tree/master/augmentations/gaussian_blur.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/SimSiam/augmentations/gaussian_blur.py,,"def gaussian_blur(img: Tensor, kernel_size: List[int], sigma: Optional[List[float]]=None) -> Tensor:
    """"""Performs Gaussian blurring on the img by given kernel.
    The image can be a PIL Image or a Tensor, in which case it is expected
    to have [..., H, W] shape, where ... means an arbitrary number of leading dimensions

    Args:
        img (PIL Image or Tensor): Image to be blurred
        kernel_size (sequence of ints or int): Gaussian kernel size. Can be a sequence of integers
            like ``(kx, ky)`` or a single integer for square kernels.
            In torchscript mode kernel_size as single int is not supported, use a tuple or
            list of length 1: ``[ksize, ]``.
        sigma (sequence of floats or float, optional): Gaussian kernel standard deviation. Can be a
            sequence of floats like ``(sigma_x, sigma_y)`` or a single float to define the
            same sigma in both X/Y directions. If None, then it is computed using
            ``kernel_size`` as ``sigma = 0.3 * ((kernel_size - 1) * 0.5 - 1) + 0.8``.
            Default, None. In torchscript mode sigma as single float is
            not supported, use a tuple or list of length 1: ``[sigma, ]``.

    Returns:
        PIL Image or Tensor: Gaussian Blurred version of the image.
    """"""
    if not isinstance(kernel_size, (int, list, tuple)):
        raise TypeError('kernel_size should be int or a sequence of integers. Got {}'.format(type(kernel_size)))
    if isinstance(kernel_size, int):
        kernel_size = [kernel_size, kernel_size]
    if len(kernel_size) != 2:
        raise ValueError('If kernel_size is a sequence its length should be 2. Got {}'.format(len(kernel_size)))
    for ksize in kernel_size:
        if ksize % 2 == 0 or ksize < 0:
            raise ValueError('kernel_size should have odd and positive integers. Got {}'.format(kernel_size))
    if sigma is None:
        sigma = [ksize * 0.15 + 0.35 for ksize in kernel_size]
    if sigma is not None and (not isinstance(sigma, (int, float, list, tuple))):
        raise TypeError('sigma should be either float or sequence of floats. Got {}'.format(type(sigma)))
    if isinstance(sigma, (int, float)):
        sigma = [float(sigma), float(sigma)]
    if isinstance(sigma, (list, tuple)) and len(sigma) == 1:
        sigma = [sigma[0], sigma[0]]
    if len(sigma) != 2:
        raise ValueError('If sigma is a sequence, its length should be 2. Got {}'.format(len(sigma)))
    for s in sigma:
        if s <= 0.0:
            raise ValueError('sigma should have positive values. Got {}'.format(sigma))
    t_img = img
    if not isinstance(img, torch.Tensor):
        if not _is_pil_image(img):
            raise TypeError('img should be PIL Image or Tensor. Got {}'.format(type(img)))
        t_img = to_tensor(img)
    output = _gaussian_blur(t_img, kernel_size, sigma)
    if not isinstance(img, torch.Tensor):
        output = to_pil_image(output)
    return output",ksize % 2,The given code cannot be refactored with fstring as it is not a string.,0,,,,,,,,,,
ignite,https://github.com/pytorch/ignite/tree/master/tests/ignite/handlers/test_state_param_scheduler.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/ignite/tests/ignite/handlers/test_state_param_scheduler.py,,"def test_custom_scheduler():
    engine = Engine(lambda e, b: None)

    class LambdaState:

        def __init__(self, initial_value, gamma):
            self.initial_value = initial_value
            self.gamma = gamma

        def __call__(self, event_index):
            return self.initial_value * self.gamma ** (event_index % 9)
    lambda_state_parameter_scheduler = LambdaStateScheduler(param_name='custom_scheduled_param', lambda_obj=LambdaState(initial_value=10, gamma=0.99))
    lambda_state_parameter_scheduler.attach(engine, Events.EPOCH_COMPLETED)
    engine.run([0] * 8, max_epochs=2)
    torch.testing.assert_allclose(getattr(engine.state, 'custom_scheduled_param'), LambdaState(initial_value=10, gamma=0.99)(2))
    engine.run([0] * 8, max_epochs=20)
    torch.testing.assert_allclose(getattr(engine.state, 'custom_scheduled_param'), LambdaState(initial_value=10, gamma=0.99)(20))
    state_dict = lambda_state_parameter_scheduler.state_dict()
    lambda_state_parameter_scheduler.load_state_dict(state_dict)",event_index % 9,The given code cannot be refactored with fstring as it is performing a mathematical operation and not dealing with string formatting.,0,,,,,,,,,,
tvm,https://github.com/apache/tvm/tree/master/python/tvm/autotvm/tuner/sa_model_optimizer.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/tvm/python/tvm/autotvm/tuner/sa_model_optimizer.py,SimulatedAnnealingOptimizer,"def find_maximums(self, model, num, exclusive):
    tic = time.time()
    (temp, n_iter, early_stop, log_interval) = (self.temp, self.n_iter, self.early_stop, self.log_interval)
    if self.persistent and self.points is not None:
        points = self.points
    else:
        points = self.task.config_space.sample_ints(self.parallel_size)
    scores = model.predict(points)
    heap_items = [(float('-inf'), -1 - i) for i in range(num)]
    heapq.heapify(heap_items)
    in_heap = set(exclusive)
    in_heap.update([x[1] for x in heap_items])
    for (s, p) in zip(scores, points):
        if s > heap_items[0][0] and p not in in_heap:
            pop = heapq.heapreplace(heap_items, (s, p))
            in_heap.remove(pop[1])
            in_heap.add(p)
    k = 0
    k_last_modify = 0
    if isinstance(temp, (tuple, list, np.ndarray)):
        t = temp[0]
        cool = 1.0 * (temp[0] - temp[1]) / (n_iter + 1)
    else:
        t = temp
        cool = 0
    while k < n_iter and k < k_last_modify + early_stop:
        new_points = np.empty_like(points)
        for (i, p) in enumerate(points):
            new_points[i] = self.task.config_space.random_walk(p)
        new_scores = model.predict(new_points)
        ac_prob = np.exp(np.minimum((new_scores - scores) / (t + 1e-05), 1))
        ac_index = np.random.random(len(ac_prob)) < ac_prob
        points[ac_index] = new_points[ac_index]
        scores[ac_index] = new_scores[ac_index]
        for (s, p) in zip(new_scores, new_points):
            if s > heap_items[0][0] and p not in in_heap:
                pop = heapq.heapreplace(heap_items, (s, p))
                in_heap.remove(pop[1])
                in_heap.add(p)
                k_last_modify = k
        k += 1
        t -= cool
        if log_interval and k % log_interval == 0:
            t_str = '%.2f' % t
            logger.debug('SA iter: %d\tlast_update: %d\tmax-0: %.2f\tmax-1: %.2f\ttemp: %s\telapsed: %.2f', k, k_last_modify, heap_items[0][0], np.max([v for (v, _) in heap_items]), t_str, time.time() - tic)
    heap_items.sort(key=lambda item: -item[0])
    heap_items = [x for x in heap_items if x[0] >= 0]
    logger.debug('SA iter: %d\tlast_update: %d\telapsed: %.2f', k, k_last_modify, time.time() - tic)
    logger.debug('SA Maximums: %s', heap_items)
    if self.persistent:
        self.points = points
    return [x[1] for x in heap_items]",k % log_interval,The given code cannot be refactored with fstring as it is a mathematical expression and not a string.,0,,,,,,,,,,
taskwiki,https://github.com/tools-life/taskwiki/tree/master/tests/conftest.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/taskwiki/tests/conftest.py,,"def test_syntax(request):
    markup = request.param
    format_header_dict = markup_headers[markup]

    def header_expand(string):
        """"""
        The function perform string replacement of 'HEADER1(.+)' with a header
        syntax for a markup containing the string found in '.+'. This function
        is constructed with a dict of three header levels containing their regex
        and actual syntax.
        When a markup is selected and this function is executed, the function
        will find instance of 'HEADER1' with 1 being any number between 1 and 3
        inclusive.
        """"""
        for (header_level, format_header) in format_header_dict.items():
            regex = header_level + '\\((.*?)\\)'
            string = re.sub(regex, lambda match: format_header % match.group(1), string)
        return string
    return (markup, header_expand)",format_header % match.group(1),The code cannot be refactored with fstring as it is missing the variable or expression to be formatted.,0,,,,,,,,,,
mmaction2,https://github.com/open-mmlab/mmaction2/tree/master/mmaction/datasets/pipelines/augmentations.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/mmaction2/mmaction/datasets/pipelines/augmentations.py,ColorJitter,"def adjust_hue(img, factor):
    img = np.clip(img, 0, 255).astype(np.uint8)
    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)
    offset = int(factor * 255)
    hsv[..., 0] = (hsv[..., 0] + offset) % 180
    img = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)
    return img.astype(np.float32)","(hsv[..., 0] + offset) % 180",The given code cannot be refactored with fstring as it does not involve any string formatting.,0,,,,,,,,,,
AlgorithmsByPython,https://github.com/Jack-Lee-Hiter/AlgorithmsByPython/tree/master//RadixSort.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/AlgorithmsByPython//RadixSort.py,,"def radixSortLSD(alist):
    if len(alist) == 0:
        return
    if len(alist) == 1:
        return alist
    tempList = alist
    maxNum = max(alist)
    radix = 10
    while maxNum * 10 > radix:
        newArr = [[], [], [], [], [], [], [], [], [], []]
        for n1 in tempList:
            testnum = n1 % radix
            testnum = testnum // (radix / 10)
            for n2 in range(10):
                if testnum == n2:
                    newArr[n2].append(n1)
        tempList = []
        for i in range(len(newArr)):
            for j in range(len(newArr[i])):
                tempList.append(newArr[i][j])
        radix *= 10
    return tempList",n1 % radix,The given code cannot be refactored with fstring as it is a mathematical operation and not a string.,0,,,,,,,,,,
PaddleGAN,https://github.com/PaddlePaddle/PaddleGAN/tree/master/ppgan/apps/wav2lip_predictor.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/PaddleGAN/ppgan/apps/wav2lip_predictor.py,Wav2LipPredictor,"def datagen(self, frames, mels):
    (img_batch, mel_batch, frame_batch, coords_batch) = ([], [], [], [])
    if self.box[0] == -1:
        if not self.static:
            face_det_results = self.face_detect(frames)
        else:
            face_det_results = self.face_detect([frames[0]])
    else:
        print('Using the specified bounding box instead of face detection...')
        (y1, y2, x1, x2) = self.box
        face_det_results = [[f[y1:y2, x1:x2], (y1, y2, x1, x2)] for f in frames]
    for (i, m) in enumerate(mels):
        idx = 0 if self.static else i % len(frames)
        frame_to_save = frames[idx].copy()
        (face, coords) = face_det_results[idx].copy()
        face = cv2.resize(face, (self.img_size, self.img_size))
        img_batch.append(face)
        mel_batch.append(m)
        frame_batch.append(frame_to_save)
        coords_batch.append(coords)
        if len(img_batch) >= self.wav2lip_batch_size:
            (img_batch, mel_batch) = (np.asarray(img_batch), np.asarray(mel_batch))
            img_masked = img_batch.copy()
            img_masked[:, self.img_size // 2:] = 0
            img_batch = np.concatenate((img_masked, img_batch), axis=3) / 255.0
            mel_batch = np.reshape(mel_batch, [len(mel_batch), mel_batch.shape[1], mel_batch.shape[2], 1])
            yield (img_batch, mel_batch, frame_batch, coords_batch)
            (img_batch, mel_batch, frame_batch, coords_batch) = ([], [], [], [])
    if len(img_batch) > 0:
        (img_batch, mel_batch) = (np.asarray(img_batch), np.asarray(mel_batch))
        img_masked = img_batch.copy()
        img_masked[:, self.img_size // 2:] = 0
        img_batch = np.concatenate((img_masked, img_batch), axis=3) / 255.0
        mel_batch = np.reshape(mel_batch, [len(mel_batch), mel_batch.shape[1], mel_batch.shape[2], 1])
        yield (img_batch, mel_batch, frame_batch, coords_batch)",i % len(frames),The code cannot be refactored with fstring as it is not a string formatting operation. It is a modulo operation.,0,,,,,,,,,,
espresso,https://github.com/freewym/espresso/tree/master/examples/discriminative_reranking_nmt/criterions/discriminative_reranking_criterion.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/espresso/examples/discriminative_reranking_nmt/criterions/discriminative_reranking_criterion.py,KLDivergenceRerankingCriterion,"def forward(self, model, sample, reduce=True):
    """"""Compute the loss for the given sample.

        Returns a tuple with three elements:
        1) the loss
        2) the sample size, which is used as the denominator for the gradient
        3) logging outputs to display while training
        """"""
    sample_size = sample['id'].numel()
    assert sample_size % self.task.cfg.mt_beam == 0, f'sample_size ({sample_size}) cannot be divided by beam size ({self.task.cfg.mt_beam}).Please set --required-batch-size-multiple={self.task.cfg.mt_beam}.'
    batch_out = []
    for i in range(0, sample_size, self.forward_batch_size):
        j = min(i + self.forward_batch_size, sample_size)
        out = model(src_tokens=sample['net_input']['src_tokens'][i:j, :], src_lengths=sample['net_input']['src_lengths'][i:j])
        batch_out.append(model.sentence_forward(out, sample['net_input']['src_tokens'][i:j, :]))
    batch_out = torch.cat(batch_out, dim=0).view(self.task.cfg.mt_beam, sample_size // self.task.cfg.mt_beam, -1)
    if model.joint_classification == 'sent':
        batch_out = model.joint_forward(batch_out)
    scores = model.classification_forward(batch_out.view(sample_size, 1, -1)).view(-1, self.task.cfg.mt_beam)
    loss = self.compute_kl_loss(scores, sample['target'][:, 0].view(-1, self.task.cfg.mt_beam))
    sample_size = sample_size // self.task.cfg.mt_beam
    logging_output = {'loss': loss.detach(), 'ntokens': sample['ntokens'], 'nsentences': sample_size * self.task.cfg.mt_beam, 'sample_size': sample_size, 'scores': scores.detach()}
    return (loss, sample_size, logging_output)",sample_size % self.task.cfg.mt_beam,The given code cannot be refactored with fstring as it is not a string.,0,,,,,,,,,,
fiftyone,https://github.com/voxel51/fiftyone/tree/master/fiftyone/utils/data/exporters.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/fiftyone/fiftyone/utils/data/exporters.py,ImageClassificationDirectoryTreeExporter,"def export_sample(self, image_or_path, classification, metadata=None):
    _label = _parse_classifications(classification, include_confidence=False, include_attributes=False)
    if _label is None:
        _label = '_unlabeled'
    self._class_counts[_label] += 1
    if etau.is_str(image_or_path):
        image_path = fou.normalize_path(image_or_path)
    else:
        img = image_or_path
        image_path = self._default_filename_patt % self._class_counts[_label]
    if self.rel_dir is not None:
        filename = fou.safe_relpath(image_path, self.rel_dir)
    else:
        filename = os.path.basename(image_path)
    (name, ext) = os.path.splitext(filename)
    key = (_label, filename)
    self._filename_counts[key] += 1
    count = self._filename_counts[key]
    if count > 1:
        filename = name + '-%d' % count + ext
    outpath = os.path.join(self.export_dir, _label, filename)
    self._media_exporter.export(image_or_path, outpath=outpath)",self._default_filename_patt % self._class_counts[_label],The given code cannot be refactored with fstring as it is using the old-style string formatting with the modulo operator.,0,,,,,,,,,,
faust,https://github.com/robinhood/faust/tree/master/t/stress/producer.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/faust/t/stress/producer.py,,"def install_produce_command(app) -> None:

    @app.command(option('--max-latency', type=float, default=0.5, envvar='PRODUCE_LATENCY', help='Add delay of (at most) n seconds between publishing.'), option('--max-messages', type=int, default=None, help='Send at most N messages or 0 for infinity.'))
    async def produce(self, max_latency: float, max_messages: int):
        """"""Produce example events.""""""
        prods = {aiter(p(max_messages)) for p in app.stress_producers}
        i = 0
        while not app.should_stop:
            to_remove: Set[Any] = set()
            for producer in prods:
                i += 1
                try:
                    await anext(producer)
                except StopAsyncIteration:
                    to_remove.add(producer)
                if not max_latency:
                    if not i % 10000:
                        self.say(f'+SEND {i}')
                elif not i % 10:
                    self.say(f'+SEND {i}')
            if not prods:
                await asyncio.sleep(1.0)
            if max_latency:
                await asyncio.sleep(random.uniform(0, max_latency))
            for producer in to_remove:
                prods.discard(producer)
        print('No more producers - exiting', file=sys.stderr)",i % 10000,"The given code is not a string, so it cannot be refactored with fstring.",0,,,,,,,,,,
faust,https://github.com/robinhood/faust/tree/master/t/stress/producer.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/faust/t/stress/producer.py,,"def install_produce_command(app) -> None:

    @app.command(option('--max-latency', type=float, default=0.5, envvar='PRODUCE_LATENCY', help='Add delay of (at most) n seconds between publishing.'), option('--max-messages', type=int, default=None, help='Send at most N messages or 0 for infinity.'))
    async def produce(self, max_latency: float, max_messages: int):
        """"""Produce example events.""""""
        prods = {aiter(p(max_messages)) for p in app.stress_producers}
        i = 0
        while not app.should_stop:
            to_remove: Set[Any] = set()
            for producer in prods:
                i += 1
                try:
                    await anext(producer)
                except StopAsyncIteration:
                    to_remove.add(producer)
                if not max_latency:
                    if not i % 10000:
                        self.say(f'+SEND {i}')
                elif not i % 10:
                    self.say(f'+SEND {i}')
            if not prods:
                await asyncio.sleep(1.0)
            if max_latency:
                await asyncio.sleep(random.uniform(0, max_latency))
            for producer in to_remove:
                prods.discard(producer)
        print('No more producers - exiting', file=sys.stderr)",i % 10,The code `i % 10` is not a string and cannot be refactored with fstring.,0,,,,,,,,,,
tensorflow-ocr,https://github.com/pannous/tensorflow-ocr/tree/master//net.py,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/tensorflow-ocr//net.py,net,"def buildDenseConv(self, nBlocks=3, nChannels=64, magic_factor=0):
    if magic_factor:
        print('magic_factor DEPRECATED!')
    depth = 3 * nBlocks + 4
    if (depth - 4) % 3:
        raise Exception('Depth must be 3N + 4! (4,7,10,...) ')
    N = (depth - 4) // 3
    print('N=%d' % N)
    do_dropout = True
    growthRate = 12
    self.conv([3, 3, 1, nChannels])
    for i in range(N):
        self.addLayer(nChannels, growthRate, do_dropout)
        nChannels += growthRate
    self.addTransition(nChannels, nChannels, do_dropout)
    for i in range(N):
        self.addLayer(nChannels, growthRate, do_dropout)
        nChannels += growthRate
    self.addTransition(nChannels, nChannels, do_dropout)
    for i in range(N):
        self.addLayer(nChannels, growthRate, do_dropout)
        nChannels += growthRate
    self.batchnorm()
    self.add(tf.nn.relu(self.last_layer))
    self.add(tf.nn.max_pool(self.last_layer, ksize=[1, 4, 4, 1], strides=[1, 2, 2, 1], padding='SAME'))
    shape = self.last_layer.get_shape()
    nBytes = shape[1] * shape[2] * shape[3]
    self.reshape([-1, int(nBytes)])",(depth - 4) % 3,The code cannot be refactored with fstring as it is a mathematical expression and not a string.,0,,,,,,,,,,
