repo_name,file_path,file_html,class_name,me_name,me_code,old_code,chatGPT_code,abstract_code,ground_code,truth_code,,,,
find_or_refactor_wrong,,,,,,,,,,,,,,
trax,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/trax/trax/tf_numpy/numpy_impl/math_ops.py,https://github.com/google/trax/tree/master/trax/tf_numpy/numpy_impl/math_ops.py,,f$765,"def f(a):
    nd = a.shape.rank
    if (axis + nd if axis < 0 else axis) >= nd:
      raise ValueError(""axis %s is out of bounds for array of dimension %s"" %
                       (axis, nd))
    if n < 0:
      raise ValueError(""order must be non-negative but got %s"" % n)
    slice1 = [slice(None)] * nd
    slice2 = [slice(None)] * nd
    slice1[axis] = slice(1, None)
    slice2[axis] = slice(None, -1)
    slice1 = tuple(slice1)
    slice2 = tuple(slice2)
    op = tf.not_equal if a.dtype == tf.bool else tf.subtract
    for _ in range(n):
      a = op(a[slice1], a[slice2])
    return a","slice1 = [slice(None)] * nd
slice2 = [slice(None)] * nd",slice1 = slice2 = [slice(None)] * nd,"slice1 = zejun1
slice2 = zejun1",Cannot refactor,-1,0,0,1,it actually cannot refactor
trax,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/trax/trax/tf_numpy/numpy_impl/math_ops.py,https://github.com/google/trax/tree/master/trax/tf_numpy/numpy_impl/math_ops.py,,f$765,"def f(a):
    nd = a.shape.rank
    if (axis + nd if axis < 0 else axis) >= nd:
      raise ValueError(""axis %s is out of bounds for array of dimension %s"" %
                       (axis, nd))
    if n < 0:
      raise ValueError(""order must be non-negative but got %s"" % n)
    slice1 = [slice(None)] * nd
    slice2 = [slice(None)] * nd
    slice1[axis] = slice(1, None)
    slice2[axis] = slice(None, -1)
    slice1 = tuple(slice1)
    slice2 = tuple(slice2)
    op = tf.not_equal if a.dtype == tf.bool else tf.subtract
    for _ in range(n):
      a = op(a[slice1], a[slice2])
    return a","slice2 = [slice(None)] * nd
slice1[axis] = slice(1, None)","slice2 = [slice(None)] * nd; slice2[axis] = slice(1, None) # Note that this code is not recommended as it is not a good practice to have multiple statements in a single line.","slice2 = zejun1
slice2[axis] = zejun2",Cannot refactor,-1,0,0,1,it actually cannot refactor
trax,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/trax/trax/tf_numpy/numpy_impl/math_ops.py,https://github.com/google/trax/tree/master/trax/tf_numpy/numpy_impl/math_ops.py,,f$765,"def f(a):
    nd = a.shape.rank
    if (axis + nd if axis < 0 else axis) >= nd:
      raise ValueError(""axis %s is out of bounds for array of dimension %s"" %
                       (axis, nd))
    if n < 0:
      raise ValueError(""order must be non-negative but got %s"" % n)
    slice1 = [slice(None)] * nd
    slice2 = [slice(None)] * nd
    slice1[axis] = slice(1, None)
    slice2[axis] = slice(None, -1)
    slice1 = tuple(slice1)
    slice2 = tuple(slice2)
    op = tf.not_equal if a.dtype == tf.bool else tf.subtract
    for _ in range(n):
      a = op(a[slice1], a[slice2])
    return a","slice2[axis] = slice(None, -1)
slice1 = tuple(slice1)",'Cannot refactor',"slice2[axis] = zejun1
slice1 = zejun2",Cannot refactor,-1,,,,it actually cannot refactor
text_classification,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/text_classification/a04_TextRCNN/p71_TextRCNN_mode2.py,https://github.com/brightmart/text_classification/tree/master/a04_TextRCNN/p71_TextRCNN_mode2.py,,test$195,"def test():
    #below is a function test; if you use this for text classifiction, you need to tranform sentence to indices of vocabulary first. then feed data to the graph.
    num_classes=10
    learning_rate=0.01
    batch_size=8
    decay_steps=1000
    decay_rate=0.9
    sequence_length=5
    vocab_size=10000
    embed_size=100
    is_training=True
    dropout_keep_prob=1#0.5
    textRNN=TextRCNN(num_classes, learning_rate, batch_size, decay_steps, decay_rate,sequence_length,vocab_size,embed_size,is_training)
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for i in range(100):
            input_x=np.zeros((batch_size,sequence_length)) #[None, self.sequence_length]
            input_y=input_y=np.array([1,0,1,1,1,2,1,1]) #np.zeros((batch_size),dtype=np.int32) #[None, self.sequence_length]
            loss,acc,predict,_=sess.run([textRNN.loss_val,textRNN.accuracy,textRNN.predictions,textRNN.train_op],
                                        feed_dict={textRNN.input_x:input_x,textRNN.input_y:input_y,textRNN.dropout_keep_prob:dropout_keep_prob})
            print(""loss:"",loss,""acc:"",acc,""label:"",input_y,""prediction:"",predict)","num_classes = 10
learning_rate = 0.01
batch_size = 8
decay_steps = 1000
decay_rate = 0.9
sequence_length = 5
vocab_size = 10000
embed_size = 100
is_training = True
dropout_keep_prob = 1","num_classes, learning_rate, batch_size, decay_steps, decay_rate, sequence_length, vocab_size, embed_size, is_training, dropout_keep_prob = 10, 0.01, 8, 1000, 0.9, 5, 10000, 100, True, 100","num_classes = zejun1
learning_rate = zejun2
batch_size = zejun3
decay_steps = zejun4
decay_rate = zejun5
sequence_length = zejun6
vocab_size = zejun7
embed_size = zejun8
is_training = zejun9
dropout_keep_prob = zejun10",Cannot refactor,-1,0,0,1,it actually cannot refactor
devpi,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/devpi/client/testing/test_use.py,https://github.com/devpi/devpi/tree/master/client/testing/test_use.py,TestUnit,test_auth_multisite$253,"def test_auth_multisite(self):
        current = Current()
        login1 = ""http://site.com/+login""
        login2 = ""http://site2.com/+login""
        current.login = login1
        current.set_auth(""hello"", ""pass1"")
        current.login = login2
        current.set_auth(""hello"", ""pass2"")
        assert current.get_auth(login1) == (""hello"", ""pass1"")
        assert current.get_auth(login2) == (""hello"", ""pass2"")
        current.login = login1
        current.del_auth()
        assert not current.get_auth(login1)
        assert current.get_auth(login2) == (""hello"", ""pass2"")
        current.login = login2
        current.del_auth()
        assert not current.get_auth(login2)","login2 = 'http://site2.com/+login'
current.login = login1","""""""Cannot refactor""""""","login2 = zejun1
current.login = login1","(login2, current.login) = ('http://site2.com/+login', login1)",0,,,,
not-youtube-dl,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/not-youtube-dl/youtube_dl/extractor/cspan.py,https://github.com/scastillo/not-youtube-dl/tree/master/youtube_dl/extractor/cspan.py,CSpanIE,_real_extract$79,"def _real_extract(self, url):
        video_id = self._match_id(url)
        video_type = None
        webpage = self._download_webpage(url, video_id)

        ustream_url = UstreamIE._extract_url(webpage)
        if ustream_url:
            return self.url_result(ustream_url, UstreamIE.ie_key())

        if '&vod' not in url:
            bc = self._search_regex(
                r""(<[^>]+id='brightcove-player-embed'[^>]+>)"",
                webpage, 'brightcove embed', default=None)
            if bc:
                bc_attr = extract_attributes(bc)
                bc_url = self.BRIGHTCOVE_URL_TEMPLATE % (
                    bc_attr.get('data-bcaccountid', '3162030207001'),
                    bc_attr.get('data-noprebcplayerid', 'SyGGpuJy3g'),
                    bc_attr.get('data-newbcplayerid', 'default'),
                    bc_attr['data-bcid'])
                return self.url_result(smuggle_url(bc_url, {'source_url': url}))

        # We first look for clipid, because clipprog always appears before
        patterns = [r'id=\'clip(%s)\'\s*value=\'([0-9]+)\'' % t for t in ('id', 'prog')]
        results = list(filter(None, (re.search(p, webpage) for p in patterns)))
        if results:
            matches = results[0]
            video_type, video_id = matches.groups()
            video_type = 'clip' if video_type == 'id' else 'program'
        else:
            m = re.search(r'data-(?P<type>clip|prog)id=[""\'](?P<id>\d+)', webpage)
            if m:
                video_id = m.group('id')
                video_type = 'program' if m.group('type') == 'prog' else 'clip'
            else:
                senate_isvp_url = SenateISVPIE._search_iframe_url(webpage)
                if senate_isvp_url:
                    title = self._og_search_title(webpage)
                    surl = smuggle_url(senate_isvp_url, {'force_title': title})
                    return self.url_result(surl, 'SenateISVP', video_id, title)
                video_id = self._search_regex(
                    r'jwsetup\.clipprog\s*=\s*(\d+);',
                    webpage, 'jwsetup program id', default=None)
                if video_id:
                    video_type = 'program'
        if video_type is None or video_id is None:
            error_message = get_element_by_class('VLplayer-error-message', webpage)
            if error_message:
                raise ExtractorError(error_message)
            raise ExtractorError('unable to find video id and type')

        def get_text_attr(d, attr):
            return d.get(attr, {}).get('#text')

        data = self._download_json(
            'http://www.c-span.org/assets/player/ajax-player.php?os=android&html5=%s&id=%s' % (video_type, video_id),
            video_id)['video']
        if data['@status'] != 'Success':
            raise ExtractorError('%s said: %s' % (self.IE_NAME, get_text_attr(data, 'error')), expected=True)

        doc = self._download_xml(
            'http://www.c-span.org/common/services/flashXml.php?%sid=%s' % (video_type, video_id),
            video_id)

        description = self._html_search_meta('description', webpage)

        title = find_xpath_attr(doc, './/string', 'name', 'title').text
        thumbnail = find_xpath_attr(doc, './/string', 'name', 'poster').text

        files = data['files']
        capfile = get_text_attr(data, 'capfile')

        entries = []
        for partnum, f in enumerate(files):
            formats = []
            for quality in f.get('qualities', []):
                formats.append({
                    'format_id': '%s-%sp' % (get_text_attr(quality, 'bitrate'), get_text_attr(quality, 'height')),
                    'url': unescapeHTML(get_text_attr(quality, 'file')),
                    'height': int_or_none(get_text_attr(quality, 'height')),
                    'tbr': int_or_none(get_text_attr(quality, 'bitrate')),
                })
            if not formats:
                path = unescapeHTML(get_text_attr(f, 'path'))
                if not path:
                    continue
                formats = self._extract_m3u8_formats(
                    path, video_id, 'mp4', entry_protocol='m3u8_native',
                    m3u8_id='hls') if determine_ext(path) == 'm3u8' else [{'url': path, }]
            self._sort_formats(formats)
            entries.append({
                'id': '%s_%d' % (video_id, partnum + 1),
                'title': (
                    title if len(files) == 1 else
                    '%s part %d' % (title, partnum + 1)),
                'formats': formats,
                'description': description,
                'thumbnail': thumbnail,
                'duration': int_or_none(get_text_attr(f, 'length')),
                'subtitles': {
                    'en': [{
                        'url': capfile,
                        'ext': determine_ext(capfile, 'dfxp')
                    }],
                } if capfile else None,
            })

        if len(entries) == 1:
            entry = dict(entries[0])
            entry['id'] = 'c' + video_id if video_type == 'clip' else video_id
            return entry
        else:
            return {
                '_type': 'playlist',
                'entries': entries,
                'title': title,
                'id': 'c' + video_id if video_type == 'clip' else video_id,
            }","doc = self._download_xml('http://www.c-span.org/common/services/flashXml.php?%sid=%s' % (video_type, video_id), video_id)
description = self._html_search_meta('description', webpage)","doc, description = self._download_xml(zejun1, video_id), self._html_search_meta('description', webpage)","doc = zejun2
description = zejun3",Cannot refactor,-1,0,0,1,it actually cannot refactor
PARL,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/PARL/examples/NeurIPS2018-AI-for-Prosthetics-Challenge/opensim_model.py,https://github.com/PaddlePaddle/PARL/tree/master/examples/NeurIPS2018-AI-for-Prosthetics-Challenge/opensim_model.py,ActorModel,__init__$39,"def __init__(self, obs_dim, vel_obs_dim, act_dim, model_id, shared):
        hid0_size = 800
        hid1_size = 400
        hid2_size = 200
        vel_hid0_size = 200
        vel_hid1_size = 400

        self.obs_dim = obs_dim
        self.vel_obs_dim = vel_obs_dim

        # bottom layers
        if shared:
            scope_name = 'policy_shared'
        else:
            scope_name = 'policy_identity_{}'.format(model_id)

        self.fc0 = layers.fc(
            size=hid0_size,
            act='tanh',
            param_attr=ParamAttr(name='{}/h0/W'.format(scope_name)),
            bias_attr=ParamAttr(name='{}/h0/b'.format(scope_name)))
        self.fc1 = layers.fc(
            size=hid1_size,
            act='tanh',
            param_attr=ParamAttr(name='{}/h1/W'.format(scope_name)),
            bias_attr=ParamAttr(name='{}/h1/b'.format(scope_name)))
        self.vel_fc0 = layers.fc(
            size=vel_hid0_size,
            act='tanh',
            param_attr=ParamAttr(name='{}/vel_h0/W'.format(scope_name)),
            bias_attr=ParamAttr(name='{}/vel_h0/b'.format(scope_name)))
        self.vel_fc1 = layers.fc(
            size=vel_hid1_size,
            act='tanh',
            param_attr=ParamAttr(name='{}/vel_h1/W'.format(scope_name)),
            bias_attr=ParamAttr(name='{}/vel_h1/b'.format(scope_name)))

        # top layers
        scope_name = 'policy_identity_{}'.format(model_id)

        self.fc2 = layers.fc(
            size=hid2_size,
            act='tanh',
            param_attr=ParamAttr(name='{}/h2/W'.format(scope_name)),
            bias_attr=ParamAttr(name='{}/h2/b'.format(scope_name)))
        self.fc3 = layers.fc(
            size=act_dim,
            act='tanh',
            param_attr=ParamAttr(name='{}/means/W'.format(scope_name)),
            bias_attr=ParamAttr(name='{}/means/b'.format(scope_name)))","self.fc0 = layers.fc(size=hid0_size, act='tanh', param_attr=ParamAttr(name='{}/h0/W'.format(scope_name)), bias_attr=ParamAttr(name='{}/h0/b'.format(scope_name)))
self.fc1 = layers.fc(size=hid1_size, act='tanh', param_attr=ParamAttr(name='{}/h1/W'.format(scope_name)), bias_attr=ParamAttr(name='{}/h1/b'.format(scope_name)))
self.vel_fc0 = layers.fc(size=vel_hid0_size, act='tanh', param_attr=ParamAttr(name='{}/vel_h0/W'.format(scope_name)), bias_attr=ParamAttr(name='{}/vel_h0/b'.format(scope_name)))
self.vel_fc1 = layers.fc(size=vel_hid1_size, act='tanh', param_attr=ParamAttr(name='{}/vel_h1/W'.format(scope_name)), bias_attr=ParamAttr(name='{}/vel_h1/b'.format(scope_name)))
scope_name = 'policy_identity_{}'.format(model_id)","(self.fc0, self.fc1, self.vel_fc0, self.vel_fc1, scope_name) = (layers.fc(size=hid0_size, act='tanh', param_attr=ParamAttr(name='{}/h0/W'.format(scope_name)), bias_attr=ParamAttr(name='{}/h0/b'.format(scope_name))), layers.fc(size=hid1_size, act='tanh', param_attr=ParamAttr(name='{}/h1/W'.format(scope_name)), bias_attr=ParamAttr(name='{}/h1/b'.format(scope_name))), layers.fc(size=vel_hid0_size, act='tanh', param_attr=ParamAttr(name='{}/vel_h0/W'.format(scope_name)), bias_attr=ParamAttr(name='{}/vel_h0/b'.format(scope_name))), layers.fc(size=hid0_size0, act='tanh', param_attr=ParamAttr(name=hid0_size1), bias_attr=ParamAttr(name=hid0_size2)), hid0_size3)","self.fc0 = layers.fc(size=zejun1, act='tanh', param_attr=ParamAttr(name=zejun2), bias_attr=ParamAttr(name=zejun3))
self.fc1 = layers.fc(size=zejun4, act='tanh', param_attr=ParamAttr(name=zejun5), bias_attr=ParamAttr(name=zejun6))
self.vel_fc0 = layers.fc(size=zejun7, act='tanh', param_attr=ParamAttr(name=zejun8), bias_attr=ParamAttr(name=zejun9))
self.vel_fc1 = layers.fc(size=zejun10, act='tanh', param_attr=ParamAttr(name=zejun11), bias_attr=ParamAttr(name=zejun12))
scope_name = zejun13","(self.fc0, self.fc1, self.vel_fc0, self.vel_fc1, scope_name) = (layers.fc(size=hid0_size, act='tanh', param_attr=ParamAttr(name='{}/h0/W'.format(scope_name)), bias_attr=ParamAttr(name='{}/h0/b'.format(scope_name))), layers.fc(size=hid1_size, act='tanh', param_attr=ParamAttr(name='{}/h1/W'.format(scope_name)), bias_attr=ParamAttr(name='{}/h1/b'.format(scope_name))), layers.fc(size=vel_hid0_size, act='tanh', param_attr=ParamAttr(name='{}/vel_h0/W'.format(scope_name)), bias_attr=ParamAttr(name='{}/vel_h0/b'.format(scope_name))), layers.fc(size=vel_hid1_size, act='tanh', param_attr=ParamAttr(name='{}/vel_h1/W'.format(scope_name)), bias_attr=ParamAttr(name='{}/vel_h1/b'.format(scope_name))), 'policy_identity_{}'.format(model_id))",0,,,,
kivy,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/kivy/kivy/tests/test_imageloader.py,https://github.com/kivy/kivy/tree/master/kivy/tests/test_imageloader.py,_TestContext,end$183,"def end(self, fn=None):
        assert not fn or self._fn == fn, ""unexpected ctx.end(), fn mismatch""
        self._fn = None
        self._fd = None","self._fn = None
self._fd = None","""""""Cannot refactor""""""","self._fn = zejun1
self._fd = zejun1","(self._fn, self._fd) = (None, None)",0,,,,
adapter-transformers,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/adapter-transformers/src/transformers/data/datasets/language_modeling.py,https://github.com/Adapter-Hub/adapter-transformers/tree/master/src/transformers/data/datasets/language_modeling.py,TextDatasetForNextSentencePrediction,__init__$353,"def __init__(
        self,
        tokenizer: PreTrainedTokenizer,
        file_path: str,
        block_size: int,
        overwrite_cache=False,
        short_seq_probability=0.1,
        nsp_probability=0.5,
    ):
        warnings.warn(
            DEPRECATION_WARNING.format(
                ""https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py""
            ),
            FutureWarning,
        )
        if not os.path.isfile(file_path):
            raise ValueError(f""Input file path {file_path} not found"")

        self.short_seq_probability = short_seq_probability
        self.nsp_probability = nsp_probability

        directory, filename = os.path.split(file_path)
        cached_features_file = os.path.join(
            directory,
            f""cached_nsp_{tokenizer.__class__.__name__}_{block_size}_{filename}"",
        )

        self.tokenizer = tokenizer

        # Make sure only the first process in distributed training processes the dataset,
        # and the others will use the cache.
        lock_path = cached_features_file + "".lock""

        # Input file format:
        # (1) One sentence per line. These should ideally be actual sentences, not
        # entire paragraphs or arbitrary spans of text. (Because we use the
        # sentence boundaries for the ""next sentence prediction"" task).
        # (2) Blank lines between documents. Document boundaries are needed so
        # that the ""next sentence prediction"" task doesn't span between documents.
        #
        # Example:
        # I am very happy.
        # Here is the second sentence.
        #
        # A new document.

        with FileLock(lock_path):
            if os.path.exists(cached_features_file) and not overwrite_cache:
                start = time.time()
                with open(cached_features_file, ""rb"") as handle:
                    self.examples = pickle.load(handle)
                logger.info(
                    f""Loading features from cached file {cached_features_file} [took %.3f s]"", time.time() - start
                )
            else:
                logger.info(f""Creating features from dataset file at {directory}"")

                self.documents = [[]]
                with open(file_path, encoding=""utf-8"") as f:
                    while True:
                        line = f.readline()
                        if not line:
                            break
                        line = line.strip()

                        # Empty lines are used as document delimiters
                        if not line and len(self.documents[-1]) != 0:
                            self.documents.append([])
                        tokens = tokenizer.tokenize(line)
                        tokens = tokenizer.convert_tokens_to_ids(tokens)
                        if tokens:
                            self.documents[-1].append(tokens)

                logger.info(f""Creating examples from {len(self.documents)} documents."")
                self.examples = []
                for doc_index, document in enumerate(self.documents):
                    self.create_examples_from_document(document, doc_index, block_size)

                start = time.time()
                with open(cached_features_file, ""wb"") as handle:
                    pickle.dump(self.examples, handle, protocol=pickle.HIGHEST_PROTOCOL)
                logger.info(
                    f""Saving features into cached file {cached_features_file} [took {time.time() - start:.3f} s]""
                )","self.tokenizer = tokenizer
lock_path = cached_features_file + '.lock'","""""""Cannot refactor""""""","self.tokenizer = zejun1
lock_path = zejun2","(self.tokenizer, lock_path) = (tokenizer, cached_features_file + '.lock')",0,,,,
CRNN_Chinese_Characters_Rec,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/CRNN_Chinese_Characters_Rec/lib/core/function.py,https://github.com/Sierkinhane/CRNN_Chinese_Characters_Rec/tree/master/lib/core/function.py,,train$27,"def train(config, train_loader, dataset, converter, model, criterion, optimizer, device, epoch, writer_dict=None, output_dict=None):

    batch_time = AverageMeter()
    data_time = AverageMeter()
    losses = AverageMeter()

    model.train()

    end = time.time()
    for i, (inp, idx) in enumerate(train_loader):
        # measure data time
        data_time.update(time.time() - end)

        labels = utils.get_batch_label(dataset, idx)
        inp = inp.to(device)

        # inference
        preds = model(inp).cpu()

        # compute loss
        batch_size = inp.size(0)
        text, length = converter.encode(labels)                    # length = 涓涓猙atch涓鐨勬诲瓧绗﹂暱搴, text = 涓涓猙atch涓鐨勫瓧绗︽墍瀵瑰簲鐨勪笅鏍
        preds_size = torch.IntTensor([preds.size(0)] * batch_size) # timestep * batchsize
        loss = criterion(preds, text, preds_size, length)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        losses.update(loss.item(), inp.size(0))

        batch_time.update(time.time()-end)
        if i % config.PRINT_FREQ == 0:
            msg = 'Epoch: [{0}][{1}/{2}]\t' \
                  'Time {batch_time.val:.3f}s ({batch_time.avg:.3f}s)\t' \
                  'Speed {speed:.1f} samples/s\t' \
                  'Data {data_time.val:.3f}s ({data_time.avg:.3f}s)\t' \
                  'Loss {loss.val:.5f} ({loss.avg:.5f})\t'.format(
                      epoch, i, len(train_loader), batch_time=batch_time,
                      speed=inp.size(0)/batch_time.val,
                      data_time=data_time, loss=losses)
            print(msg)

            if writer_dict:
                writer = writer_dict['writer']
                global_steps = writer_dict['train_global_steps']
                writer.add_scalar('train_loss', losses.avg, global_steps)
                writer_dict['train_global_steps'] = global_steps + 1

        end = time.time()","labels = utils.get_batch_label(dataset, idx)
inp = inp.to(device)","""""""Cannot refactor""""""","labels = zejun1
inp = inp.to(device)","(labels, inp) = (utils.get_batch_label(dataset, idx), inp.to(device))",0,,,,
salt,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/salt/tests/unit/modules/test_file.py,https://github.com/saltstack/salt/tree/master/tests/unit/modules/test_file.py,FilemodLineTests,test_if_not_location_or_before_but_after_then_line_should_be_inserted_after_after$1883,"def test_if_not_location_or_before_but_after_then_line_should_be_inserted_after_after(
        self,
    ):
        location = before = None
        after = ""indessed""
        content = ""roscivs""
        indent = ""\t\t\t   ""
        original_lines = [""foo"", indent + after, ""bar""]
        expected_lines = [""foo"", indent + after, indent + content, ""bar""]

        actual_lines = filemod._set_line(
            lines=original_lines,
            content=content,
            mode=""insert"",
            location=location,
            before=before,
            after=after,
        )

        self.assertEqual(actual_lines, expected_lines)","original_lines = ['foo', indent + after, 'bar']
expected_lines = ['foo', indent + after, indent + content, 'bar']",'Cannot refactor',"original_lines = [zejun1, zejun2, zejun4]
expected_lines = [zejun1, zejun2, zejun3, zejun4]",Cannot refactor,-1,0,0,1,it actually cannot refactor
sentry,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/sentry/src/sentry/runner/commands/backup.py,https://github.com/getsentry/sentry/tree/master/src/sentry/runner/commands/backup.py,,sort_dependencies$34,"def sort_dependencies():
    """"""
    Similar to Django's except that we discard the important of natural keys
    when sorting dependencies (i.e. it works without them).
    """"""
    from django.apps import apps

    # Process the list of models, and get the list of dependencies
    model_dependencies = []
    models = set()
    for app_config in apps.get_app_configs():
        if app_config.label in EXCLUDED_APPS:
            continue

        model_list = app_config.get_models()

        for model in model_list:
            models.add(model)
            # Add any explicitly defined dependencies
            if hasattr(model, ""natural_key""):
                deps = getattr(model.natural_key, ""dependencies"", [])
                if deps:
                    deps = [apps.get_model(*d.split(""."")) for d in deps]
            else:
                deps = []

            # Now add a dependency for any FK relation with a model that
            # defines a natural key
            for field in model._meta.fields:
                if hasattr(field.remote_field, ""model""):
                    rel_model = field.remote_field.model
                    if rel_model != model:
                        deps.append(rel_model)

            # Also add a dependency for any simple M2M relation with a model
            # that defines a natural key.  M2M relations with explicit through
            # models don't count as dependencies.
            for field in model._meta.many_to_many:
                rel_model = field.remote_field.model
                if rel_model != model:
                    deps.append(rel_model)
            model_dependencies.append((model, deps))

    model_dependencies.reverse()
    # Now sort the models to ensure that dependencies are met. This
    # is done by repeatedly iterating over the input list of models.
    # If all the dependencies of a given model are in the final list,
    # that model is promoted to the end of the final list. This process
    # continues until the input list is empty, or we do a full iteration
    # over the input models without promoting a model to the final list.
    # If we do a full iteration without a promotion, that means there are
    # circular dependencies in the list.
    model_list = []
    while model_dependencies:
        skipped = []
        changed = False
        while model_dependencies:
            model, deps = model_dependencies.pop()

            # If all of the models in the dependency list are either already
            # on the final model list, or not on the original serialization list,
            # then we've found another model with all it's dependencies satisfied.
            found = True
            for candidate in ((d not in models or d in model_list) for d in deps):
                if not candidate:
                    found = False
            if found:
                model_list.append(model)
                changed = True
            else:
                skipped.append((model, deps))
        if not changed:
            raise RuntimeError(
                ""Can't resolve dependencies for %s in serialized app list.""
                % "", "".join(
                    f""{model._meta.app_label}.{model._meta.object_name}""
                    for model, deps in sorted(skipped, key=lambda obj: obj[0].__name__)
                )
            )
        model_dependencies = skipped

    return model_list","(model, deps) = model_dependencies.pop()
found = True",'Cannot refactor',"(zejun1, deps) = zejun1
found = True",Cannot refactor,-1,0,0,1,it actually cannot refactor
QUANTAXIS,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/QUANTAXIS/QUANTAXIS/QAMarket/QAOrder.py,https://github.com/QUANTAXIS/QUANTAXIS/tree/master/QUANTAXIS/QAMarket/QAOrder.py,QA_Order,from_dict$649,"def from_dict(self, order_dict):
        '''
        浠庡瓧娈电被鍨嬬殑瀛楁 濉鍏 瀵硅薄鐨勫瓧娈
        :param order_dict:  dict 绫诲瀷
        :return: self QA_Order
        '''
        try:
            # QA_util_log_info('QA_ORDER CHANGE: from {} change to {}'.format(
            #     self.order_id, order['order_id']))
            self.price = order_dict['price']
            self.date = order_dict['date']
            self.datetime = order_dict['datetime']
            self.sending_time = order_dict['sending_time']  # 涓嬪崟鏃堕棿
            self.trade_time = order_dict['trade_time']
            self.amount = order_dict['amount']
            self.frequence = order_dict['frequence']
            self.market_type = order_dict['market_type']
            self.towards = order_dict['towards']
            self.code = order_dict['code']
            self.user_cookie = order_dict['user_cookie']
            self.account_cookie = order_dict['account_cookie']
            self.strategy = order_dict['strategy']
            self.type = order_dict['type']
            self.order_model = order_dict['order_model']
            self.amount_model = order_dict['amount_model']
            self.order_id = order_dict['order_id']
            self.realorder_id = order_dict['realorder_id']
            self.trade_id = order_dict['trade_id']
            self.callback = order_dict['callback']
            self.commission_coeff = order_dict['commission_coeff']
            self.tax_coeff = order_dict['tax_coeff']

            self.money = order_dict['money']
            self._status = order_dict['_status']

            self.cancel_amount = order_dict['cancel_amount']
            self.trade_amount = order_dict['trade_amount']
            self.trade_price = order_dict['trade_price']
            self.reason = order_dict['reason']

            return self
        except Exception as e:
            QA_util_log_info('Failed to tran from dict {}'.format(e))","self.price = order_dict['price']
self.date = order_dict['date']
self.datetime = order_dict['datetime']
self.sending_time = order_dict['sending_time']
self.trade_time = order_dict['trade_time']
self.amount = order_dict['amount']
self.frequence = order_dict['frequence']
self.market_type = order_dict['market_type']
self.towards = order_dict['towards']
self.code = order_dict['code']
self.user_cookie = order_dict['user_cookie']
self.account_cookie = order_dict['account_cookie']
self.strategy = order_dict['strategy']
self.type = order_dict['type']
self.order_model = order_dict['order_model']
self.amount_model = order_dict['amount_model']
self.order_id = order_dict['order_id']
self.realorder_id = order_dict['realorder_id']
self.trade_id = order_dict['trade_id']
self.callback = order_dict['callback']
self.commission_coeff = order_dict['commission_coeff']
self.tax_coeff = order_dict['tax_coeff']
self.money = order_dict['money']
self._status = order_dict['_status']
self.cancel_amount = order_dict['cancel_amount']
self.trade_amount = order_dict['trade_amount']
self.trade_price = order_dict['trade_price']
self.reason = order_dict['reason']","""""""Cannot refactor""""""","self.price = zejun1
self.date = zejun2
self.datetime = zejun3
self.sending_time = zejun4
self.trade_time = zejun5
self.amount = zejun6
self.frequence = zejun7
self.market_type = zejun8
self.towards = zejun9
self.code = zejun10
self.user_cookie = zejun11
self.account_cookie = zejun12
self.strategy = zejun13
self.type = zejun14
self.order_model = zejun15
self.amount_model = zejun16
self.order_id = zejun17
self.realorder_id = zejun18
self.trade_id = zejun19
self.callback = zejun20
self.commission_coeff = zejun21
self.tax_coeff = zejun22
self.money = zejun23
self._status = zejun24
self.cancel_amount = zejun25
self.trade_amount = zejun26
self.trade_price = zejun27
self.reason = zejun28","(self.price, self.date, self.datetime, self.sending_time, self.trade_time, self.amount, self.frequence, self.market_type, self.towards, self.code, self.user_cookie, self.account_cookie, self.strategy, self.type, self.order_model, self.amount_model, self.order_id, self.realorder_id, self.trade_id, self.callback, self.commission_coeff, self.tax_coeff, self.money, self._status, self.cancel_amount, self.trade_amount, self.trade_price, self.reason) = (order_dict['price'], order_dict['date'], order_dict['datetime'], order_dict['sending_time'], order_dict['trade_time'], order_dict['amount'], order_dict['frequence'], order_dict['market_type'], order_dict['towards'], order_dict['code'], order_dict['user_cookie'], order_dict['account_cookie'], order_dict['strategy'], order_dict['type'], order_dict['order_model'], order_dict['amount_model'], order_dict['order_id'], order_dict['realorder_id'], order_dict['trade_id'], order_dict['callback'], order_dict['commission_coeff'], order_dict['tax_coeff'], order_dict['money'], order_dict['_status'], order_dict['cancel_amount'], order_dict['trade_amount'], order_dict['trade_price'], order_dict['reason'])",0,,,,
espnet,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/espnet/espnet2/gan_tts/joint/joint_text2wav.py,https://github.com/espnet/espnet/tree/master/espnet2/gan_tts/joint/joint_text2wav.py,JointText2Wav,_forward_discrminator$511,"def _forward_discrminator(
        self,
        text: torch.Tensor,
        text_lengths: torch.Tensor,
        feats: torch.Tensor,
        feats_lengths: torch.Tensor,
        speech: torch.Tensor,
        speech_lengths: torch.Tensor,
        **kwargs,
    ) -> Dict[str, Any]:
        """"""Perform discriminator forward.

        Args:
            text (Tensor): Text index tensor (B, T_text).
            text_lengths (Tensor): Text length tensor (B,).
            feats (Tensor): Feature tensor (B, T_feats, aux_channels).
            feats_lengths (Tensor): Feature length tensor (B,).
            speech (Tensor): Speech waveform tensor (B, T_wav).
            speech_lengths (Tensor): Speech length tensor (B,).

        Returns:
            Dict[str, Any]:
                * loss (Tensor): Loss scalar tensor.
                * stats (Dict[str, float]): Statistics to be monitored.
                * weight (Tensor): Weight tensor to summarize losses.
                * optim_idx (int): Optimizer index (0 for G and 1 for D).

        """"""
        # setup
        batch_size = text.size(0)
        speech = speech.unsqueeze(1)

        # calculate generator outputs
        reuse_cache = True
        if not self.cache_generator_outputs or self._cache is None:
            reuse_cache = False
            # calculate text2mel outputs
            text2mel_loss, stats, feats_gen = self.generator[""text2mel""](
                text=text,
                text_lengths=text_lengths,
                feats=feats,
                feats_lengths=feats_lengths,
                joint_training=True,
                **kwargs,
            )
            # get random segments
            feats_gen_, start_idxs = get_random_segments(
                x=feats_gen.transpose(1, 2),
                x_lengths=feats_lengths,
                segment_size=self.segment_size,
            )
            # calculate vocoder outputs
            speech_hat_ = self.generator[""vocoder""](feats_gen_)
            if self.use_pqmf:
                speech_hat_ = self.pqmf.synthesis(speech_hat_)
        else:
            _, _, speech_hat_, start_idxs = self._cache

        # store cache
        if self.cache_generator_outputs and not reuse_cache:
            self._cache = (text2mel_loss, stats, speech_hat_, start_idxs)

        # parse outputs
        speech_ = get_segments(
            x=speech,
            start_idxs=start_idxs * self.generator[""vocoder""].upsample_factor,
            segment_size=self.segment_size * self.generator[""vocoder""].upsample_factor,
        )

        # calculate discriminator outputs
        p_hat = self.discriminator(speech_hat_.detach())
        p = self.discriminator(speech_)

        # calculate losses
        real_loss, fake_loss = self.discriminator_adv_loss(p_hat, p)
        loss = real_loss + fake_loss

        stats = dict(
            discriminator_loss=loss.item(),
            real_loss=real_loss.item(),
            fake_loss=fake_loss.item(),
        )
        loss, stats, weight = force_gatherable((loss, stats, batch_size), loss.device)

        # reset cache
        if reuse_cache or not self.training:
            self._cache = None

        return {
            ""loss"": loss,
            ""stats"": stats,
            ""weight"": weight,
            ""optim_idx"": 1,  # needed for trainer
        }","reuse_cache = False
(text2mel_loss, stats, feats_gen) = self.generator['text2mel'](text=text, text_lengths=text_lengths, feats=feats, feats_lengths=feats_lengths, joint_training=True, **kwargs)",'Cannot refactor',"reuse_cache = zejun1
zejun2 = zejun3",Cannot refactor,-1,0,0,1,it actually cannot refactor
gluon-cv,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/gluon-cv/gluoncv/data/transforms/video.py,https://github.com/dmlc/gluon-cv/tree/master/gluoncv/data/transforms/video.py,VideoGroupTrainTransformV3,forward$752,"def forward(self, clips):
        h, w, _ = clips[0].shape

        # step 1: random short side scale jittering
        size = int(round(np.random.uniform(self.min_size, self.max_size)))
        new_w = size
        new_h = size
        if w < h:
            new_h = int(math.floor((float(h) / w) * size))
        else:
            new_w = int(math.floor((float(w) / h) * size))

        # step 2: random crop
        h_off = 0
        if new_h > self.height:
            h_off = int(np.random.randint(0, new_h - self.height))
        w_off = 0
        if new_w > self.width:
            w_off = int(np.random.randint(0, new_w - self.width))

        # step 3: random horizontal flip
        is_flip = random.random() < self.prob

        new_clips = []
        for cur_img in clips:
            scale_img = self.cv2.resize(cur_img, (new_w, new_h))
            crop_img = scale_img[h_off:h_off+self.height, w_off:w_off+self.width, :]
            if is_flip:
                flip_img = np.flip(crop_img, axis=1)
            else:
                flip_img = crop_img
            tensor_img = np.transpose(flip_img, axes=(2, 0, 1)) / self.max_intensity
            new_clips.append((tensor_img - self.mean) / self.std)
        return new_clips","(h, w, _) = clips[0].shape
size = int(round(np.random.uniform(self.min_size, self.max_size)))",'Cannot refactor',"(h, w, _) = zejun1
size = zejun3",Cannot refactor,-1,0,0,1,it actually cannot refactor
gluon-cv,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/gluon-cv/gluoncv/data/transforms/video.py,https://github.com/dmlc/gluon-cv/tree/master/gluoncv/data/transforms/video.py,VideoGroupTrainTransformV3,forward$752,"def forward(self, clips):
        h, w, _ = clips[0].shape

        # step 1: random short side scale jittering
        size = int(round(np.random.uniform(self.min_size, self.max_size)))
        new_w = size
        new_h = size
        if w < h:
            new_h = int(math.floor((float(h) / w) * size))
        else:
            new_w = int(math.floor((float(w) / h) * size))

        # step 2: random crop
        h_off = 0
        if new_h > self.height:
            h_off = int(np.random.randint(0, new_h - self.height))
        w_off = 0
        if new_w > self.width:
            w_off = int(np.random.randint(0, new_w - self.width))

        # step 3: random horizontal flip
        is_flip = random.random() < self.prob

        new_clips = []
        for cur_img in clips:
            scale_img = self.cv2.resize(cur_img, (new_w, new_h))
            crop_img = scale_img[h_off:h_off+self.height, w_off:w_off+self.width, :]
            if is_flip:
                flip_img = np.flip(crop_img, axis=1)
            else:
                flip_img = crop_img
            tensor_img = np.transpose(flip_img, axes=(2, 0, 1)) / self.max_intensity
            new_clips.append((tensor_img - self.mean) / self.std)
        return new_clips","new_w = size
new_h = size","""""""Cannot refactor""""""","new_w = zejun1
new_h = zejun1","(new_w, new_h) = (size, size)",0,,,,
deprecated-binaryninja-python,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/deprecated-binaryninja-python/Analysis.py,https://github.com/Vector35/deprecated-binaryninja-python/tree/master//Analysis.py,X86Instruction,format_text$82,"def format_text(self, block, options):
		old_lines = []
		old_tokens = []
		self.text.lines = []
		self.text.tokens = []

		line = []
		tokens = []
		x = 0
		instr = self.disasm

		if ""address"" in options:
			string = ""%.8x   "" % self.addr
			line += [[string, QColor(0, 0, 128)]]
			x += len(string)

		if instr.operation == None:
			line += [[""??"", Qt.black]]
			self.text.lines += [line]
			self.text.tokens += [tokens]
			return (old_lines != self.text.lines) or (old_tokens != self.text.tokens)

		result = """"
		operation = """"
		if instr.flags & X86.FLAG_LOCK:
			operation += ""lock ""
		if instr.flags & X86.FLAG_ANY_REP:
			operation += ""rep""
			if instr.flags & X86.FLAG_REPNE:
				operation += ""ne""
			elif instr.flags & X86.FLAG_REPE:
				operation += ""e""
			operation += "" ""
		operation += instr.operation
		if len(operation) < 7:
			operation += "" "" * (7 - len(operation))
		result += operation + "" ""

		for j in range(0, len(instr.operands)):
			if j != 0:
				result += "", ""
			if instr.operands[j].operand == ""imm"":
				value = instr.operands[j].immediate & ((1 << (instr.operands[j].size * 8)) - 1)
				numfmt = ""0x%%.%dx"" % (instr.operands[j].size * 2)
				string = numfmt % value
				if (instr.operands[j].size == self.addr_size) and (block.analysis.functions.has_key(value)):
					# Pointer to existing function
					func = block.analysis.functions[value]
					string = func.name
					if func.plt:
						color = QColor(192, 0, 192)
					else:
						color = QColor(0, 0, 192)
					if len(result) > 0:
						line += [[result, Qt.black]]
						x += len(result)
						result = """"
					line += [[string, color]]
					tokens += [[x, len(string), ""ptr"", value, string]]
					x += len(string)
				elif (instr.operands[j].size == self.addr_size) and (value >= block.exe.start()) and (value < block.exe.end()) and (not self.isLocalJump()):
					# Pointer within module
					if len(result) > 0:
						line += [[result, Qt.black]]
						x += len(result)
						result = """"
					if value in block.exe.symbols_by_addr:
						string = block.exe.symbols_by_addr[value]
					line += [[string, QColor(0, 0, 192)]]
					tokens += [[x, len(string), ""ptr"", value, string]]
					x += len(string)
				else:
					result += string
			elif instr.operands[j].operand == ""mem"":
				plus = False
				result += X86.get_size_string(instr.operands[j].size)
				if (instr.segment != None) or (instr.operands[j].segment == ""es""):
					result += instr.operands[j].segment + "":""
				result += '['
				if instr.operands[j].components[0] != None:
					tokens += [[x + len(result), len(instr.operands[j].components[0]), ""reg"", instr.operands[j].components[0]]]
					result += instr.operands[j].components[0]
					plus = True
				if instr.operands[j].components[1] != None:
					if plus:
						tokens += [[x + len(result) + 1, len(instr.operands[j].components[1]), ""reg"", instr.operands[j].components[1]]]
					else:
						tokens += [[x + len(result), len(instr.operands[j].components[1]), ""reg"", instr.operands[j].components[1]]]
					result += X86.get_operand_string(instr.operands[j].components[1],
						instr.operands[j].scale, plus)
					plus = True
				if (instr.operands[j].immediate != 0) or ((instr.operands[j].components[0] == None) and (instr.operands[j].components[1] == None)):
					if plus and (instr.operands[j].immediate >= -0x80) and (instr.operands[j].immediate < 0):
						result += '-'
						result += ""0x%.2x"" % (-instr.operands[j].immediate)
					elif plus and (instr.operands[j].immediate > 0) and (instr.operands[j].immediate <= 0x7f):
						result += '+'
						result += ""0x%.2x"" % instr.operands[j].immediate
					elif plus and (instr.operands[j].immediate >= -0x8000) and (instr.operands[j].immediate < 0):
						result += '-'
						result += ""0x%.8x"" % (-instr.operands[j].immediate)
					elif instr.flags & X86.FLAG_64BIT_ADDRESS:
						if plus:
							result += '+'
						value = instr.operands[j].immediate
						string = ""0x%.16x"" % instr.operands[j].immediate
						if hasattr(block.exe, ""plt"") and block.exe.plt.has_key(value):
							# Pointer to PLT entry
							self.plt = block.exe.plt[value]
							if len(result) > 0:
								line += [[result, Qt.black]]
								x += len(result)
								result = """"
							string = self.plt + ""@PLT""
							line += [[string, QColor(0, 0, 192)]]
							tokens += [[x, len(string), ""ptr"", value, string]]
							x += len(string)
						elif (value >= block.exe.start()) and (value < block.exe.end()):
							# Pointer within module
							if len(result) > 0:
								line += [[result, Qt.black]]
								x += len(result)
								result = """"
							if value in block.exe.symbols_by_addr:
								string = block.exe.symbols_by_addr[value]
							line += [[string, QColor(0, 0, 192)]]
							tokens += [[x, len(string), ""ptr"", value, string]]
							x += len(string)
						else:
							result += string
					else:
						if plus:
							result += '+'
						value = instr.operands[j].immediate & 0xffffffff
						string = ""0x%.8x"" % value
						if (self.addr_size == 4) and hasattr(block.exe, ""plt"") and block.exe.plt.has_key(value):
							# Pointer to PLT entry
							self.plt = block.exe.plt[value]
							if len(result) > 0:
								line += [[result, Qt.black]]
								x += len(result)
								result = """"
							string = block.exe.decorate_plt_name(self.plt)
							line += [[string, QColor(0, 0, 192)]]
							tokens += [[x, len(string), ""ptr"", value, string]]
							x += len(string)
						elif (self.addr_size == 4) and (value >= block.exe.start()) and (value < block.exe.end()):
							# Pointer within module
							if len(result) > 0:
								line += [[result, Qt.black]]
								x += len(result)
								result = """"
							if value in block.exe.symbols_by_addr:
								string = block.exe.symbols_by_addr[value]
							line += [[string, QColor(0, 0, 192)]]
							tokens += [[x, len(string), ""ptr"", value, string]]
							x += len(string)
						else:
							result += string
				result += ']'
			else:
				tokens += [[x + len(result), len(instr.operands[j].operand), ""reg"", instr.operands[j].operand]]
				result += instr.operands[j].operand

		if len(result) > 0:
			line += [[result, Qt.black]]
		self.text.lines += [line]
		self.text.tokens += [tokens]

		return (old_lines != self.text.lines) or (old_tokens != self.text.tokens)","old_lines = []
old_tokens = []
self.text.lines = []
self.text.tokens = []
line = []
tokens = []
x = 0",'Cannot refactor',"old_lines = zejun1
old_tokens = zejun2
self.text.lines = zejun3
self.text.tokens = zejun4
line = zejun5
tokens = zejun6
x = 0",Cannot refactor,-1,0,0,1,it actually cannot refactor
Hardware-Target-Game-Database,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/Hardware-Target-Game-Database/verify_pack.py,https://github.com/frederic-mahe/Hardware-Target-Game-Database/tree/master//verify_pack.py,,if_main_my$172,"if __name__ == '__main__':
    TARGET_FOLDER = ARGS.target_folder
    TARGET_DATABASE = ARGS.target_database
    MISMATCH_FILES = ARGS.mismatch_files
    END_LINE = ""\n"" if ARGS.new_line else ""\r""
    DROP_INITIAL_DIRECTORY = ARGS.drop_initial_directory

    DATABASE, NUMBER_OF_ENTRIES = parse_database(TARGET_DATABASE,
                                                 DROP_INITIAL_DIRECTORY)
    BAD_LOCATION_FILES, EXTRA_FILES = parse_folder(TARGET_FOLDER, DATABASE)

    MISSING_FILES = []
    for key in DATABASE:
        for file in DATABASE[key]:
            MISSING_FILES.append((file, key))

    # write information to log file only if there are any bad, extra
    # or missing files to report
    if MISMATCH_FILES and (BAD_LOCATION_FILES or EXTRA_FILES or MISSING_FILES):
        BAD_LOCATION_FILES.sort()
        EXTRA_FILES.sort()
        MISSING_FILES.sort()

        with open(MISMATCH_FILES, ""w"") as mismatch_files:
            if BAD_LOCATION_FILES:
                print(""Incorrect Location Files:"", file=mismatch_files)
                for file, hash_sha256 in BAD_LOCATION_FILES:
                    print(os.path.abspath(file), hash_sha256,
                          sep=""\t"", file=mismatch_files)
                print(""\n"", file=mismatch_files)

            if EXTRA_FILES:
                print(""Extra Files:"", file=mismatch_files)
                for file, hash_sha256 in EXTRA_FILES:
                    print(os.path.abspath(file), hash_sha256,
                          sep=""\t"", file=mismatch_files)
                print(""\n"", file=mismatch_files)

            if MISSING_FILES:
                print(""Missing Files:"", file=mismatch_files)
                for file, hash_sha256 in MISSING_FILES:
                    print(file, hash_sha256, sep=""\t"", file=mismatch_files)
                print(""\n"", file=mismatch_files)

    print(""incorrect location: {}"".format(len(BAD_LOCATION_FILES)),
          file=sys.stdout)
    print(""extra: {}"".format(len(EXTRA_FILES)), file=sys.stdout)
    print(""missing: {}"".format(len(MISSING_FILES)), file=sys.stdout)

    sys.exit(0)","(BAD_LOCATION_FILES, EXTRA_FILES) = parse_folder(TARGET_FOLDER, DATABASE)
MISSING_FILES = []",'Cannot refactor',"zejun3, zejun4 = zejun1
zejun5 = zejun2",Cannot refactor,-1,0,0,1,it actually cannot refactor
localstack,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/localstack/localstack/utils/server/proxy_server.py,https://github.com/localstack/localstack/tree/master/localstack/utils/server/proxy_server.py,,_do_start_ssl_proxy$115,"def _do_start_ssl_proxy(port: int, target: str, target_ssl=False):
    import pproxy

    from localstack.services.generic_proxy import GenericProxy

    if "":"" not in str(target):
        target = ""127.0.0.1:%s"" % target
    LOG.debug(""Starting SSL proxy server %s -> %s"" % (port, target))

    # create server and remote connection
    server = pproxy.Server(""secure+tunnel://0.0.0.0:%s"" % port)
    target_proto = ""ssl+tunnel"" if target_ssl else ""tunnel""
    remote = pproxy.Connection(""%s://%s"" % (target_proto, target))
    args = dict(rserver=[remote], verbose=print)

    # set SSL contexts
    _, cert_file_name, key_file_name = GenericProxy.create_ssl_cert()
    for context in pproxy.server.sslcontexts:
        context.load_cert_chain(cert_file_name, key_file_name)

    loop = ensure_event_loop()
    handler = loop.run_until_complete(server.start_server(args))
    try:
        loop.run_forever()
    except KeyboardInterrupt:
        print(""exit!"")

    handler.close()
    loop.run_until_complete(handler.wait_closed())
    loop.run_until_complete(loop.shutdown_asyncgens())
    loop.close()","args = dict(rserver=[remote], verbose=print)
(_, cert_file_name, key_file_name) = GenericProxy.create_ssl_cert()","args = dict(rserver=[remote], verbose=print); (_, cert_file_name, key_file_name) = GenericProxy.create_ssl_cert()","args = dict(rserver=zejun1, verbose=zejun2)
(_, cert_file_name, key_file_name) = zejun3",Cannot refactor,-1,0,0,1,it actually cannot refactor
sympy,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/sympy/sympy/simplify/tests/test_radsimp.py,https://github.com/sympy/sympy/tree/master/sympy/simplify/tests/test_radsimp.py,,test_collect_Wild$320,"def test_collect_Wild():
    """"""Collect with respect to functions with Wild argument""""""
    a, b, x, y = symbols('a b x y')
    f = Function('f')
    w1 = Wild('.1')
    w2 = Wild('.2')
    assert collect(f(x) + a*f(x), f(w1)) == (1 + a)*f(x)
    assert collect(f(x, y) + a*f(x, y), f(w1)) == f(x, y) + a*f(x, y)
    assert collect(f(x, y) + a*f(x, y), f(w1, w2)) == (1 + a)*f(x, y)
    assert collect(f(x, y) + a*f(x, y), f(w1, w1)) == f(x, y) + a*f(x, y)
    assert collect(f(x, x) + a*f(x, x), f(w1, w1)) == (1 + a)*f(x, x)
    assert collect(a*(x + 1)**y + (x + 1)**y, w1**y) == (1 + a)*(x + 1)**y
    assert collect(a*(x + 1)**y + (x + 1)**y, w1**b) == \
        a*(x + 1)**y + (x + 1)**y
    assert collect(a*(x + 1)**y + (x + 1)**y, (x + 1)**w2) == \
        (1 + a)*(x + 1)**y
    assert collect(a*(x + 1)**y + (x + 1)**y, w1**w2) == (1 + a)*(x + 1)**y","(a, b, x, y) = symbols('a b x y')
f = Function('f')
w1 = Wild('.1')
w2 = Wild('.2')",'Cannot refactor',"(zejun1, zejun2, zejun3, zejun4) = symbols('a b x y'), Function('f'), Wild('.1'), Wild('.2')",Cannot refactor,-1,0,0,1,it actually cannot refactor
chainercv,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/chainercv/chainercv/extensions/evaluator/semantic_segmentation_evaluator.py,https://github.com/chainer/chainercv/tree/master/chainercv/extensions/evaluator/semantic_segmentation_evaluator.py,SemanticSegmentationEvaluator,evaluate$79,"def evaluate(self):
        target = self._targets['main']
        if self.comm is not None and self.comm.rank != 0:
            apply_to_iterator(target.predict, None, comm=self.comm)
            return {}
        iterator = self._iterators['main']

        if hasattr(iterator, 'reset'):
            iterator.reset()
            it = iterator
        else:
            it = copy.copy(iterator)

        in_values, out_values, rest_values = apply_to_iterator(
            target.predict, it, comm=self.comm)
        # delete unused iterators explicitly
        del in_values

        pred_labels, = out_values
        gt_labels, = rest_values

        result = eval_semantic_segmentation(pred_labels, gt_labels)

        report = {'miou': result['miou'],
                  'pixel_accuracy': result['pixel_accuracy'],
                  'mean_class_accuracy': result['mean_class_accuracy']}

        if self.label_names is not None:
            for l, label_name in enumerate(self.label_names):
                try:
                    report['iou/{:s}'.format(label_name)] = result['iou'][l]
                    report['class_accuracy/{:s}'.format(label_name)] =\
                        result['class_accuracy'][l]
                except IndexError:
                    report['iou/{:s}'.format(label_name)] = np.nan
                    report['class_accuracy/{:s}'.format(label_name)] = np.nan

        observation = {}
        with reporter.report_scope(observation):
            reporter.report(report, target)
        return observation","report['iou/{:s}'.format(label_name)] = np.nan
report['class_accuracy/{:s}'.format(label_name)] = np.nan","""""""Cannot refactor""""""","report['iou/{:s}'.format(label_name)] = zejun1
report['class_accuracy/{:s}'.format(label_name)] = zejun1","(report['iou/{:s}'.format(label_name)], report['class_accuracy/{:s}'.format(label_name)]) = (np.nan, np.nan)",0,,,,
maml_rl,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/maml_rl/rllab/algos/util.py,https://github.com/cbfinn/maml_rl/tree/master/rllab/algos/util.py,,speed_tests$299,"def speed_tests():
    dataset = ReplayPool(
        observation_shape=(80, 80),
        action_dim=1,
        max_steps=20000,
        concat_observations=True,
        concat_length=4,
    )

    img = np.random.randint(0, 256, size=(80, 80))
    action = np.random.randint(16)
    reward = np.random.random()
    start = time.time()
    for _ in range(100000):
        terminal = False
        if np.random.random() < .05:
            terminal = True
        dataset.add_sample(img, action, reward, terminal)
    print(""samples per second: "", 100000 / (time.time() - start))

    start = time.time()
    for _ in range(200):
        dataset.random_batch(32)
    print(""batches per second: "", 200 / (time.time() - start))

    print(dataset.last_concat_state())","dataset = ReplayPool(observation_shape=(80, 80), action_dim=1, max_steps=20000, concat_observations=True, concat_length=4)
img = np.random.randint(0, 256, size=(80, 80))
action = np.random.randint(16)
reward = np.random.random()
start = time.time()","(dataset, img, action, reward, start) = (ReplayPool(observation_shape=(80, 80), action_dim=1, max_steps=20000, concat_observations=True, concat_length=4), np.random.randint(0, 256, size=zejun1), np.random.randint(16), np.random.random(), time.time())","dataset = ReplayPool(observation_shape=zejun1, action_dim=zejun2, max_steps=zejun3, concat_observations=zejun4, concat_length=zejun5)
img = zejun6
action = zejun7
reward = zejun8
start = zejun9","(dataset, img, action, reward, start) = (ReplayPool(observation_shape=(80, 80), action_dim=1, max_steps=20000, concat_observations=True, concat_length=4), np.random.randint(0, 256, size=(80, 80)), np.random.randint(16), np.random.random(), time.time())",0,,,,
devpi,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/devpi/server/test_devpi_server/test_view_auth.py,https://github.com/devpi/devpi/tree/master/server/test_devpi_server/test_view_auth.py,TestCredentialPlugins,test_credential_plugins_no_credentials$61,"def test_credential_plugins_no_credentials(self, blank_request, dsp, plugin1, plugin2):
        plugin1.results = [None]
        plugin2.results = [None]
        request = blank_request()
        assert dsp._get_credentials(request) is None","plugin1.results = [None]
plugin2.results = [None]
request = blank_request()","""""""Cannot refactor""""""","plugin1.results = zejun1
plugin2.results = zejun1
request = zejun2","(plugin1.results, plugin2.results, request) = ([None], [None], blank_request())",0,,,,
ansible-modules-extras,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/ansible-modules-extras/network/f5/bigip_selfip.py,https://github.com/ansible/ansible-modules-extras/tree/master/network/f5/bigip_selfip.py,BigIpSelfIp,update$416,"def update(self):
        changed = False
        svcs = []
        params = dict()
        current = self.read()

        check_mode = self.params['check_mode']
        address = self.params['address']
        allow_service = self.params['allow_service']
        name = self.params['name']
        netmask = self.params['netmask']
        partition = self.params['partition']
        traffic_group = self.params['traffic_group']
        vlan = self.params['vlan']
        route_domain = self.params['route_domain']

        if address is not None and address != current['address']:
            raise F5ModuleError(
                'Self IP addresses cannot be updated'
            )

        if netmask is not None:
            # I ignore the address value here even if they provide it because
            # you are not allowed to change it.
            try:
                address = IPNetwork(current['address'])

                new_addr = ""%s/%s"" % (address.ip, netmask)
                nipnet = IPNetwork(new_addr)
                if route_domain is not None:
                    nipnet = ""%s%s%s"" % (address.ip, route_domain, netmask)

                cur_addr = ""%s/%s"" % (current['address'], current['netmask'])
                cipnet = IPNetwork(cur_addr)
                if route_domain is not None:
                    cipnet = ""%s%s%s"" % (current['address'], current['route_domain'], current['netmask'])

                if nipnet != cipnet:
                    if route_domain is not None:
                        address = ""%s%s%s/%s"" % (address.ip, '%', route_domain, netmask)
                    else:
                        address = ""%s/%s"" % (nipnet.ip, nipnet.prefixlen)
                    params['address'] = address
            except AddrFormatError:
                raise F5ModuleError(
                    'The provided address/netmask value was invalid'
                )

        if traffic_group is not None:
            traffic_group = ""/%s/%s"" % (partition, traffic_group)
            if traffic_group not in self.traffic_groups():
                raise F5ModuleError(
                    'The specified traffic group was not found'
                )

            if 'traffic_group' in current:
                if traffic_group != current['traffic_group']:
                    params['trafficGroup'] = traffic_group
            else:
                params['trafficGroup'] = traffic_group

        if vlan is not None:
            vlans = self.get_vlans()
            vlan = ""/%s/%s"" % (partition, vlan)

            if 'vlan' in current:
                if vlan != current['vlan']:
                    params['vlan'] = vlan
            else:
                params['vlan'] = vlan

            if vlan not in vlans:
                raise F5ModuleError(
                    'The specified VLAN was not found'
                )

        if allow_service is not None:
            svcs = self.verify_services()
            if 'allow_service' in current:
                if svcs != current['allow_service']:
                    params['allowService'] = self.fmt_services(svcs)
            else:
                params['allowService'] = self.fmt_services(svcs)

        if params:
            changed = True
            params['name'] = name
            params['partition'] = partition
            if check_mode:
                return changed
            self.cparams = camel_dict_to_snake_dict(params)
            if svcs:
                self.cparams['allow_service'] = list(svcs)
        else:
            return changed

        r = self.api.tm.net.selfips.selfip.load(
            name=name,
            partition=partition
        )
        r.update(**params)
        r.refresh()

        return True","changed = False
svcs = []
params = dict()
current = self.read()
check_mode = self.params['check_mode']
address = self.params['address']
allow_service = self.params['allow_service']
name = self.params['name']
netmask = self.params['netmask']
partition = self.params['partition']
traffic_group = self.params['traffic_group']
vlan = self.params['vlan']
route_domain = self.params['route_domain']","(changed, svcs, params, current, check_mode, address, allow_service, name, netmask, partition, traffic_group, vlan, route_domain) = (False, [], dict(), self.read(), self.params['check_mode'], self.params['address'], self.params['allow_service'], self.params['name'], self.params['netmask'], False0, False1, False2, False3)","changed = zejun1
svcs = zejun2
params = zejun3
current = zejun4
check_mode = zejun5
address = zejun6
allow_service = zejun7
name = zejun8
netmask = zejun9
partition = zejun10
traffic_group = zejun11
vlan = zejun12
route_domain = zejun13","(changed, svcs, params, current, check_mode, address, allow_service, name, netmask, partition, traffic_group, vlan, route_domain) = (False, [], dict(), self.read(), self.params['check_mode'], self.params['address'], self.params['allow_service'], self.params['name'], self.params['netmask'], self.params['partition'], self.params['traffic_group'], self.params['vlan'], self.params['route_domain'])",0,,,,
pyradio,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pyradio/pyradio/config_window.py,https://github.com/coderholic/pyradio/tree/master/pyradio/config_window.py,PyRadioConfigWindow,_load_default_values$295,"def _load_default_values(self):
        self._config_options['general_title'][1] = ''
        self._config_options['player'][1] = 'mpv,mplayer,vlc'
        self._config_options['open_last_playlist'][1] = 'False'
        self._config_options['default_playlist'][1] = 'stations'
        self._config_options['default_station'][1] = 'False'
        self._config_options['default_encoding'][1] = 'utf-8'
        self._config_options['enable_mouse'][1] = 'False'
        self._config_options['connection_timeout'][1] = '10'
        self._config_options['theme_title'][1] = ''
        ''' Transparency '''
        #self._old_use_transparency = self._config_options['use_transparency'][1]
        self._config_options['use_transparency'][1] = False
        self._config_options['force_http'][1] = False
        self._toggle_transparency_function(changed_from_config_window=True, force_value=False)
        self._config_options['playlist_manngement_title'][1] = ''
        self._config_options['confirm_station_deletion'][1] = True
        self._config_options['confirm_playlist_reload'][1] = True
        self._config_options['auto_save_playlist'][1] = False
        self._config_options['requested_player'][1] = ''
        ''' Theme
            Put this AFTER applying transparency, so that _do_init_pairs in
            _toggle_transparency does not overwrite pairs with applied theme values
        '''
        self._config_options['theme'][1] = 'dark'
        self._apply_a_theme('dark', False)
        self._check_if_config_is_dirty()","self._config_options['general_title'][1] = ''
self._config_options['player'][1] = 'mpv,mplayer,vlc'
self._config_options['open_last_playlist'][1] = 'False'
self._config_options['default_playlist'][1] = 'stations'
self._config_options['default_station'][1] = 'False'
self._config_options['default_encoding'][1] = 'utf-8'
self._config_options['enable_mouse'][1] = 'False'
self._config_options['connection_timeout'][1] = '10'
self._config_options['theme_title'][1] = ''","self._config_options = {'general_title': [None, ''], 'player': [None, 'mpv,mplayer,vlc'], 'open_last_playlist': [None, 'False'], 'default_playlist': [None, 'stations'], 'default_station': [None, 'False'], 'default_encoding': [None, 'utf-8'], 'enable_mouse': [None, 'False'], 'connection_timeout': [None, '10'], 'theme_title': [None, '']}","self._config_options['general_title'][1] = zejun1
self._config_options['player'][1] = zejun2
self._config_options['open_last_playlist'][1] = zejun3
self._config_options['default_playlist'][1] = zejun4
self._config_options['default_station'][1] = zejun5
self._config_options['default_encoding'][1] = zejun6
self._config_options['enable_mouse'][1] = zejun7
self._config_options['connection_timeout'][1] = zejun8
self._config_options['theme_title'][1] = zejun9","(self._config_options['general_title'][1], self._config_options['player'][1], self._config_options['open_last_playlist'][1], self._config_options['default_playlist'][1], self._config_options['default_station'][1], self._config_options['default_encoding'][1], self._config_options['enable_mouse'][1], self._config_options['connection_timeout'][1], self._config_options['theme_title'][1]) = ('', 'mpv,mplayer,vlc', 'False', 'stations', 'False', 'utf-8', 'False', '10', '')",0,,,,
pyradio,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pyradio/pyradio/config_window.py,https://github.com/coderholic/pyradio/tree/master/pyradio/config_window.py,PyRadioConfigWindow,_load_default_values$295,"def _load_default_values(self):
        self._config_options['general_title'][1] = ''
        self._config_options['player'][1] = 'mpv,mplayer,vlc'
        self._config_options['open_last_playlist'][1] = 'False'
        self._config_options['default_playlist'][1] = 'stations'
        self._config_options['default_station'][1] = 'False'
        self._config_options['default_encoding'][1] = 'utf-8'
        self._config_options['enable_mouse'][1] = 'False'
        self._config_options['connection_timeout'][1] = '10'
        self._config_options['theme_title'][1] = ''
        ''' Transparency '''
        #self._old_use_transparency = self._config_options['use_transparency'][1]
        self._config_options['use_transparency'][1] = False
        self._config_options['force_http'][1] = False
        self._toggle_transparency_function(changed_from_config_window=True, force_value=False)
        self._config_options['playlist_manngement_title'][1] = ''
        self._config_options['confirm_station_deletion'][1] = True
        self._config_options['confirm_playlist_reload'][1] = True
        self._config_options['auto_save_playlist'][1] = False
        self._config_options['requested_player'][1] = ''
        ''' Theme
            Put this AFTER applying transparency, so that _do_init_pairs in
            _toggle_transparency does not overwrite pairs with applied theme values
        '''
        self._config_options['theme'][1] = 'dark'
        self._apply_a_theme('dark', False)
        self._check_if_config_is_dirty()","self._config_options['use_transparency'][1] = False
self._config_options['force_http'][1] = False","""""""Cannot refactor""""""","self._config_options['use_transparency'][1] = zejun1
self._config_options['force_http'][1] = zejun1","(self._config_options['use_transparency'][1], self._config_options['force_http'][1]) = (False, False)",0,,,,
growlab,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/growlab/app/camera.py,https://github.com/alexellis/growlab/tree/master/app/camera.py,camera,get_frame$9,"def get_frame(self):
        stream = io.BytesIO()
        with picamera.PiCamera() as camera:
            camera.start_preview()
            camera.vflip = self.camera_opts[""vertical_flip""]
            camera.hflip = self.camera_opts[""horizontal_flip""]
            camera.meter_mode = self.camera_opts[""meter_mode""]
            camera.exposure_mode = ""auto""
            camera.resolution = (self.camera_opts[""width""], self.camera_opts[""height""])
            # Camera warm-up time
            time.sleep(self.camera_opts[""preview_seconds""])
            camera.capture(stream, format=self.camera_opts[""encoding""], quality=self.camera_opts[""image_quality""])

        return stream","camera.vflip = self.camera_opts['vertical_flip']
camera.hflip = self.camera_opts['horizontal_flip']
camera.meter_mode = self.camera_opts['meter_mode']
camera.exposure_mode = 'auto'
camera.resolution = (self.camera_opts['width'], self.camera_opts['height'])","(camera.vflip, camera.hflip, camera.meter_mode, camera.resolution) = (self.camera_opts['vertical_flip'], self.camera_opts['horizontal_flip'], self.camera_opts['meter_mode'], (self.camera_opts['width'], self.camera_opts['height']))","camera.vflip = zejun1
camera.hflip = zejun2
camera.meter_mode = zejun3
camera.exposure_mode = 'auto'
camera.resolution = zejun4","(camera.vflip, camera.hflip, camera.meter_mode, camera.exposure_mode, camera.resolution) = (self.camera_opts['vertical_flip'], self.camera_opts['horizontal_flip'], self.camera_opts['meter_mode'], 'auto', (self.camera_opts['width'], self.camera_opts['height']))",0,,,,
cleanlab,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/cleanlab/examples/mnist/label_errors_mnist_train_cnn.py,https://github.com/cleanlab/cleanlab/tree/master/examples/mnist/label_errors_mnist_train_cnn.py,,imshow$77,"def imshow(inp, img_labels=None, img_pred=None, img_fns = None, figsize=(10,10), normalize=False, method_name = '', savefig = False):
    """"""Imshow for Tensor.""""""
    height, width = inp.shape[1:]
    xbins = 8
    ybins = int(np.ceil(len(img_labels)/xbins))
    xbin_width = width // xbins
    ybin_height = height // ybins
    
    inp = inp.numpy().transpose((1, 2, 0))
    if normalize:
        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])
        inp = std * inp + mean
        inp = np.clip(inp, 0, 1)
    
    ax = plt.figure(figsize=figsize).gca()
    ax.imshow(inp)
    pad_size = (8-len(img_pred)%8)%8
    img_labels = img_labels + ['']*pad_size #padding
    img_pred = img_pred + ['']*pad_size #padding
    img_fns = img_fns + ['']*pad_size #padding
#     grid = np.asarray(img_labels).reshape((ybins, xbins))
       
    num_red_boxes = 0
    for (j,i),idx in np.ndenumerate(np.arange(ybins*xbins).reshape((ybins, xbins))):
        prediction = img_pred[idx]
        label = img_labels[idx]
        img_fn = img_fns[idx]
        image_index = int(img_fn[13:])
        
        plt.hlines([j*ybin_height - .5], xmin=i*xbin_width, xmax=i*xbin_width + xbin_width, color = 'lightgray', linewidth=2)
        
        fontsize=max(min(1.4*figsize[0], .9*figsize[0]-.7*len(prediction)), 12) if prediction != '' else 1
        tt = ax.text(i*xbin_width + xbin_width/2,j*ybin_height + ybin_height/20,prediction,ha='center',va='center', fontsize=fontsize)
        tt.set_bbox(dict(facecolor='lime', alpha=0.8, edgecolor=None))
        
        fontsize=min(.5*figsize[0], 1.25*figsize[0]-len(img_fn)) if img_fn != '' else 1
        tt = ax.text(i*xbin_width + xbin_width/2.8,j*ybin_height + ybin_height/7,img_fn,ha='center',va='center', fontsize=fontsize)
        tt.set_bbox(dict(facecolor='lightgray', alpha=0.8, edgecolor=None))
        
        fontsize=max(min(1.4*figsize[0], .9*figsize[0]-.7*len(label)),12) if label != '' else 1
        t = ax.text(i*xbin_width + xbin_width/2,j*ybin_height + ybin_height/10*9,label,ha='center',va='center', fontsize=fontsize)
        t.set_bbox(dict(facecolor='cyan', alpha=0.8, edgecolor=None))
        
        
        if image_index in [21601, 40466, 29922, 40144, 51248, 43454, 59915, 57662, 25678, 2676, 24798, 31727, 7080, 26560, 10994, 53396, 54264]:#, 59701, 42566, 26940, 47759
            # Draw red bounding box
            plt.hlines([j*ybin_height + 0.5,(j+1)*ybin_height - 1.5], xmin=i*xbin_width - 0.3, xmax=i*xbin_width + xbin_width - 0.65, color = 'red', linewidth=15)
            plt.vlines([i*xbin_width + 0.5,(i+1)*xbin_width - 1.5], ymin=j*ybin_height + 0.5, ymax=j*ybin_height + ybin_height - 0.5, color = 'red', linewidth=15)
            num_red_boxes += 1
    
    print(""Number of red boxes:"", num_red_boxes)
    plt.axis('off')
    if savefig:
        plt.savefig('figs/mnist_training_label_errors'+str(len(img_pred))+""_""+method_name+'.pdf', pad_inches=0.0, bbox_inches='tight')
    plt.pause(0.001)","img_labels = img_labels + [''] * pad_size
img_pred = img_pred + [''] * pad_size
img_fns = img_fns + [''] * pad_size
num_red_boxes = 0","""""""Cannot refactor""""""","img_labels = img_labels + zejun1
img_pred = img_pred + zejun1
img_fns = img_fns + zejun1
num_red_boxes = 0","(img_labels, img_pred, img_fns, num_red_boxes) = (img_labels + [''] * pad_size, img_pred + [''] * pad_size, img_fns + [''] * pad_size, 0)",0,,,,
nilearn,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/nilearn/nilearn/plotting/html_stat_map.py,https://github.com/nilearn/nilearn/tree/master/nilearn/plotting/html_stat_map.py,,_get_bg_mask_and_cmap$314,"def _get_bg_mask_and_cmap(bg_img, black_bg):
    """"""Helper function of _json_view_data.""""""
    bg_mask = _safe_get_data(compute_brain_mask(bg_img),
                             ensure_finite=True)
    bg_mask = np.logical_not(bg_mask).astype(float)
    bg_mask[bg_mask == 1] = np.nan
    bg_cmap = copy.copy(matplotlib.cm.get_cmap('gray'))
    if black_bg:
        bg_cmap.set_bad('black')
    else:
        bg_cmap.set_bad('white')
    return bg_mask, bg_cmap","bg_mask[bg_mask == 1] = np.nan
bg_cmap = copy.copy(matplotlib.cm.get_cmap('gray'))",'Cannot refactor',"bg_mask[bg_mask == 1] = zejun1
bg_cmap = zejun2",Cannot refactor,-1,0,0,1,it actually cannot refactor
SOLO,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/SOLO/mmdet/models/necks/nas_fpn.py,https://github.com/WXinlong/SOLO/tree/master/mmdet/models/necks/nas_fpn.py,NASFPN,__init__$75,"def __init__(self,
                 in_channels,
                 out_channels,
                 num_outs,
                 stack_times,
                 start_level=0,
                 end_level=-1,
                 add_extra_convs=False,
                 norm_cfg=None):
        super(NASFPN, self).__init__()
        assert isinstance(in_channels, list)
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.num_ins = len(in_channels)  # num of input feature levels
        self.num_outs = num_outs  # num of output feature levels
        self.stack_times = stack_times
        self.norm_cfg = norm_cfg

        if end_level == -1:
            self.backbone_end_level = self.num_ins
            assert num_outs >= self.num_ins - start_level
        else:
            # if end_level < inputs, no extra level is allowed
            self.backbone_end_level = end_level
            assert end_level <= len(in_channels)
            assert num_outs == end_level - start_level
        self.start_level = start_level
        self.end_level = end_level
        self.add_extra_convs = add_extra_convs

        # add lateral connections
        self.lateral_convs = nn.ModuleList()
        for i in range(self.start_level, self.backbone_end_level):
            l_conv = ConvModule(
                in_channels[i],
                out_channels,
                1,
                norm_cfg=norm_cfg,
                activation=None)
            self.lateral_convs.append(l_conv)

        # add extra downsample layers (stride-2 pooling or conv)
        extra_levels = num_outs - self.backbone_end_level + self.start_level
        self.extra_downsamples = nn.ModuleList()
        for i in range(extra_levels):
            extra_conv = ConvModule(
                out_channels,
                out_channels,
                1,
                norm_cfg=norm_cfg,
                activation=None)
            self.extra_downsamples.append(
                nn.Sequential(extra_conv, nn.MaxPool2d(2, 2)))

        # add NAS FPN connections
        self.fpn_stages = nn.ModuleList()
        for _ in range(self.stack_times):
            stage = nn.ModuleDict()
            # gp(p6, p4) -> p4_1
            stage['gp_64_4'] = GPCell(out_channels, norm_cfg=norm_cfg)
            # sum(p4_1, p4) -> p4_2
            stage['sum_44_4'] = SumCell(out_channels, norm_cfg=norm_cfg)
            # sum(p4_2, p3) -> p3_out
            stage['sum_43_3'] = SumCell(out_channels, norm_cfg=norm_cfg)
            # sum(p3_out, p4_2) -> p4_out
            stage['sum_34_4'] = SumCell(out_channels, norm_cfg=norm_cfg)
            # sum(p5, gp(p4_out, p3_out)) -> p5_out
            stage['gp_43_5'] = GPCell(with_conv=False)
            stage['sum_55_5'] = SumCell(out_channels, norm_cfg=norm_cfg)
            # sum(p7, gp(p5_out, p4_2)) -> p7_out
            stage['gp_54_7'] = GPCell(with_conv=False)
            stage['sum_77_7'] = SumCell(out_channels, norm_cfg=norm_cfg)
            # gp(p7_out, p5_out) -> p6_out
            stage['gp_75_6'] = GPCell(out_channels, norm_cfg=norm_cfg)
            self.fpn_stages.append(stage)","stage['gp_64_4'] = GPCell(out_channels, norm_cfg=norm_cfg)
stage['sum_44_4'] = SumCell(out_channels, norm_cfg=norm_cfg)
stage['sum_43_3'] = SumCell(out_channels, norm_cfg=norm_cfg)
stage['sum_34_4'] = SumCell(out_channels, norm_cfg=norm_cfg)
stage['gp_43_5'] = GPCell(with_conv=False)
stage['sum_55_5'] = SumCell(out_channels, norm_cfg=norm_cfg)
stage['gp_54_7'] = GPCell(with_conv=False)
stage['sum_77_7'] = SumCell(out_channels, norm_cfg=norm_cfg)
stage['gp_75_6'] = GPCell(out_channels, norm_cfg=norm_cfg)","stage = {'gp_64_4': GPCell(out_channels, norm_cfg=norm_cfg), 'sum_44_4': SumCell(out_channels, norm_cfg=norm_cfg), 'sum_43_3': SumCell(out_channels, norm_cfg=norm_cfg), 'sum_34_4': SumCell(out_channels, norm_cfg=norm_cfg), 'gp_43_5': GPCell(with_conv=False), 'sum_55_5': SumCell(out_channels, norm_cfg=norm_cfg), 'gp_54_7': GPCell(with_conv=False), 'sum_77_7': SumCell(out_channels, norm_cfg=norm_cfg), 'gp_75_6': GPCell(out_channels, norm_cfg=norm_cfg)}","stage['gp_64_4'] = zejun1
stage['sum_44_4'] = zejun2
stage['sum_43_3'] = zejun3
stage['sum_34_4'] = zejun4
stage['gp_43_5'] = zejun5
stage['sum_55_5'] = zejun6
stage['gp_54_7'] = zejun7
stage['sum_77_7'] = zejun8
stage['gp_75_6'] = zejun9","(stage['gp_64_4'], stage['sum_44_4'], stage['sum_43_3'], stage['sum_34_4'], stage['gp_43_5'], stage['sum_55_5'], stage['gp_54_7'], stage['sum_77_7'], stage['gp_75_6']) = (GPCell(out_channels, norm_cfg=norm_cfg), SumCell(out_channels, norm_cfg=norm_cfg), SumCell(out_channels, norm_cfg=norm_cfg), SumCell(out_channels, norm_cfg=norm_cfg), GPCell(with_conv=False), SumCell(out_channels, norm_cfg=norm_cfg), GPCell(with_conv=False), SumCell(out_channels, norm_cfg=norm_cfg), GPCell(out_channels, norm_cfg=norm_cfg))",0,,,,
cfn-lint,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/cfn-lint/src/cfnlint/rules/functions/RelationshipConditions.py,https://github.com/aws-cloudformation/cfn-lint/tree/master/src/cfnlint/rules/functions/RelationshipConditions.py,RelationshipConditions,match$22,"def match(self, cfn):
        """"""Check CloudFormation Ref/GetAtt for Conditions""""""

        matches = []

        # Start with Ref checks
        ref_objs = cfn.search_deep_keys(searchText=""Ref"", includeGlobals=False)
        for ref_obj in ref_objs:
            value = ref_obj[-1]
            if value not in PSEUDOPARAMS:
                scenarios = cfn.is_resource_available(ref_obj, value)
                for scenario in scenarios:
                    # pylint: disable=consider-using-f-string
                    scenario_text = "" and "".join(
                        [
                            'when condition ""%s"" is %s' % (k, v)
                            for (k, v) in scenario.items()
                        ]
                    )
                    message = (
                        'Ref to resource ""{0}"" that may not be available {1} at {2}'
                    )
                    matches.append(
                        RuleMatch(
                            ref_obj[:-1],
                            message.format(
                                value, scenario_text, ""/"".join(map(str, ref_obj[:-1]))
                            ),
                        )
                    )

        # The do GetAtt
        getatt_objs = cfn.search_deep_keys(
            searchText=""Fn::GetAtt"", includeGlobals=False
        )
        for getatt_obj in getatt_objs:
            value_obj = getatt_obj[-1]
            value = None
            if isinstance(value_obj, list):
                value = value_obj[0]
            elif isinstance(value_obj, str):
                value = value_obj.split(""."")[0]
            if value:
                if value not in PSEUDOPARAMS:
                    scenarios = cfn.is_resource_available(getatt_obj, value)
                    for scenario in scenarios:
                        scenario_text = "" and "".join(
                            [
                                f'when condition ""{k}"" is {v}'
                                for (k, v) in scenario.items()
                            ]
                        )
                        message = 'GetAtt to resource ""{0}"" that may not be available {1} at {2}'
                        matches.append(
                            RuleMatch(
                                getatt_obj[:-1],
                                message.format(
                                    value,
                                    scenario_text,
                                    ""/"".join(map(str, getatt_obj[:-1])),
                                ),
                            )
                        )

        return matches","scenario_text = ' and '.join([f'when condition ""{k}"" is {v}' for (k, v) in scenario.items()])
message = 'GetAtt to resource ""{0}"" that may not be available {1} at {2}'","""""""Cannot refactor""""""","scenario_text = zejun1
message = message.format(resource, 'now', scenario_text)","(scenario_text, message) = (' and '.join([f'when condition ""{k}"" is {v}' for (k, v) in scenario.items()]), 'GetAtt to resource ""{0}"" that may not be available {1} at {2}')",0,,,,
sdc,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/sdc/sdc/tests/test_utils.py,https://github.com/IntelPython/sdc/tree/master/sdc/tests/test_utils.py,,msg_and_func$181,"def msg_and_func(msg_or_func=None):
    if msg_or_func is None:
        # No signature, no function
        func = None
        msg = None
    elif isinstance(msg_or_func, str):
        # A message is passed
        func = None
        msg = msg_or_func
    else:
        # A function is passed
        func = msg_or_func
        msg = None
    return msg, func","func = None
msg = None","""""""Cannot refactor""""""","func = zejun1
msg = zejun1","(func, msg) = (None, None)",0,,,,
mmdetection,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/mmdetection/mmdet/core/anchor/point_generator.py,https://github.com/open-mmlab/mmdetection/tree/master/mmdet/core/anchor/point_generator.py,MlvlPointGenerator,valid_flags$177,"def valid_flags(self, featmap_sizes, pad_shape, device='cuda'):
        """"""Generate valid flags of points of multiple feature levels.

        Args:
            featmap_sizes (list(tuple)): List of feature map sizes in
                multiple feature levels, each size arrange as
                as (h, w).
            pad_shape (tuple(int)): The padded shape of the image,
                 arrange as (h, w).
            device (str): The device where the anchors will be put on.

        Return:
            list(torch.Tensor): Valid flags of points of multiple levels.
        """"""
        assert self.num_levels == len(featmap_sizes)
        multi_level_flags = []
        for i in range(self.num_levels):
            point_stride = self.strides[i]
            feat_h, feat_w = featmap_sizes[i]
            h, w = pad_shape[:2]
            valid_feat_h = min(int(np.ceil(h / point_stride[1])), feat_h)
            valid_feat_w = min(int(np.ceil(w / point_stride[0])), feat_w)
            flags = self.single_level_valid_flags((feat_h, feat_w),
                                                  (valid_feat_h, valid_feat_w),
                                                  device=device)
            multi_level_flags.append(flags)
        return multi_level_flags","point_stride = self.strides[i]
(feat_h, feat_w) = featmap_sizes[i]
(h, w) = pad_shape[:2]",'Cannot refactor',"point_stride = zejun1
(feat_h, feat_w) = zejun2
(h, w) = zejun3",Cannot refactor,-1,0,0,1,it actually cannot refactor
python,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/python/kubernetes/client/api/core_v1_api.py,https://github.com/zhanghe06/python/tree/master/kubernetes/client/api/core_v1_api.py,CoreV1Api,list_namespaced_secret_with_http_info$16081,"def list_namespaced_secret_with_http_info(self, namespace, **kwargs):  # noqa: E501
        """"""list_namespaced_secret  # noqa: E501

        list or watch objects of kind Secret  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.list_namespaced_secret_with_http_info(namespace, async_req=True)
        >>> result = thread.get()

        :param async_req bool: execute request asynchronously
        :param str namespace: object name and auth scope, such as for teams and projects (required)
        :param str pretty: If 'true', then the output is pretty printed.
        :param bool allow_watch_bookmarks: allowWatchBookmarks requests watch events with type \""BOOKMARK\"". Servers that do not implement bookmarks may ignore this flag and bookmarks are sent at the server's discretion. Clients should not assume bookmarks are returned at any specific interval, nor may they assume the server will send any BOOKMARK event during a session. If this is not a watch, this field is ignored. If the feature gate WatchBookmarks is not enabled in apiserver, this field is ignored.
        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \""next key\"".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.
        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.
        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.
        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.
        :param str resource_version: resourceVersion sets a constraint on what resource versions a request may be served from. See https://kubernetes.io/docs/reference/using-api/api-concepts/#resource-versions for details.  Defaults to unset
        :param str resource_version_match: resourceVersionMatch determines how resourceVersion is applied to list calls. It is highly recommended that resourceVersionMatch be set for list calls where resourceVersion is set See https://kubernetes.io/docs/reference/using-api/api-concepts/#resource-versions for details.  Defaults to unset
        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.
        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.
        :param _return_http_data_only: response data without head status code
                                       and headers
        :param _preload_content: if False, the urllib3.HTTPResponse object will
                                 be returned without reading/decoding response
                                 data. Default is True.
        :param _request_timeout: timeout setting for this request. If one
                                 number provided, it will be total request
                                 timeout. It can also be a pair (tuple) of
                                 (connection, read) timeouts.
        :return: tuple(V1SecretList, status_code(int), headers(HTTPHeaderDict))
                 If the method is called asynchronously,
                 returns the request thread.
        """"""

        local_var_params = locals()

        all_params = [
            'namespace',
            'pretty',
            'allow_watch_bookmarks',
            '_continue',
            'field_selector',
            'label_selector',
            'limit',
            'resource_version',
            'resource_version_match',
            'timeout_seconds',
            'watch'
        ]
        all_params.extend(
            [
                'async_req',
                '_return_http_data_only',
                '_preload_content',
                '_request_timeout'
            ]
        )

        for key, val in six.iteritems(local_var_params['kwargs']):
            if key not in all_params:
                raise ApiTypeError(
                    ""Got an unexpected keyword argument '%s'""
                    "" to method list_namespaced_secret"" % key
                )
            local_var_params[key] = val
        del local_var_params['kwargs']
        # verify the required parameter 'namespace' is set
        if self.api_client.client_side_validation and ('namespace' not in local_var_params or  # noqa: E501
                                                        local_var_params['namespace'] is None):  # noqa: E501
            raise ApiValueError(""Missing the required parameter `namespace` when calling `list_namespaced_secret`"")  # noqa: E501

        collection_formats = {}

        path_params = {}
        if 'namespace' in local_var_params:
            path_params['namespace'] = local_var_params['namespace']  # noqa: E501

        query_params = []
        if 'pretty' in local_var_params and local_var_params['pretty'] is not None:  # noqa: E501
            query_params.append(('pretty', local_var_params['pretty']))  # noqa: E501
        if 'allow_watch_bookmarks' in local_var_params and local_var_params['allow_watch_bookmarks'] is not None:  # noqa: E501
            query_params.append(('allowWatchBookmarks', local_var_params['allow_watch_bookmarks']))  # noqa: E501
        if '_continue' in local_var_params and local_var_params['_continue'] is not None:  # noqa: E501
            query_params.append(('continue', local_var_params['_continue']))  # noqa: E501
        if 'field_selector' in local_var_params and local_var_params['field_selector'] is not None:  # noqa: E501
            query_params.append(('fieldSelector', local_var_params['field_selector']))  # noqa: E501
        if 'label_selector' in local_var_params and local_var_params['label_selector'] is not None:  # noqa: E501
            query_params.append(('labelSelector', local_var_params['label_selector']))  # noqa: E501
        if 'limit' in local_var_params and local_var_params['limit'] is not None:  # noqa: E501
            query_params.append(('limit', local_var_params['limit']))  # noqa: E501
        if 'resource_version' in local_var_params and local_var_params['resource_version'] is not None:  # noqa: E501
            query_params.append(('resourceVersion', local_var_params['resource_version']))  # noqa: E501
        if 'resource_version_match' in local_var_params and local_var_params['resource_version_match'] is not None:  # noqa: E501
            query_params.append(('resourceVersionMatch', local_var_params['resource_version_match']))  # noqa: E501
        if 'timeout_seconds' in local_var_params and local_var_params['timeout_seconds'] is not None:  # noqa: E501
            query_params.append(('timeoutSeconds', local_var_params['timeout_seconds']))  # noqa: E501
        if 'watch' in local_var_params and local_var_params['watch'] is not None:  # noqa: E501
            query_params.append(('watch', local_var_params['watch']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.select_header_accept(
            ['application/json', 'application/yaml', 'application/vnd.kubernetes.protobuf', 'application/json;stream=watch', 'application/vnd.kubernetes.protobuf;stream=watch'])  # noqa: E501

        # Authentication setting
        auth_settings = ['BearerToken']  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/namespaces/{namespace}/secrets', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type='V1SecretList',  # noqa: E501
            auth_settings=auth_settings,
            async_req=local_var_params.get('async_req'),
            _return_http_data_only=local_var_params.get('_return_http_data_only'),  # noqa: E501
            _preload_content=local_var_params.get('_preload_content', True),
            _request_timeout=local_var_params.get('_request_timeout'),
            collection_formats=collection_formats)","form_params = []
local_var_files = {}
body_params = None
header_params['Accept'] = self.api_client.select_header_accept(['application/json', 'application/yaml', 'application/vnd.kubernetes.protobuf', 'application/json;stream=watch', 'application/vnd.kubernetes.protobuf;stream=watch'])
auth_settings = ['BearerToken']","""""""Cannot refactor""""""","form_params = zejun1
local_var_files = zejun2
body_params = None
header_params['Accept'] = zejun3
auth_settings = zejun4","(form_params, local_var_files, body_params, header_params['Accept'], auth_settings) = ([], {}, None, self.api_client.select_header_accept(['application/json', 'application/yaml', 'application/vnd.kubernetes.protobuf', 'application/json;stream=watch', 'application/vnd.kubernetes.protobuf;stream=watch']), ['BearerToken'])",0,,,,
angr,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/angr/angr/state_plugins/solver.py,https://github.com/angr/angr/tree/master/angr/state_plugins/solver.py,,timed_function$23,"def timed_function(f):
    if _timing_enabled:
        @functools.wraps(f)
        def timing_guy(*args, **kwargs):
            the_solver = kwargs.pop('the_solver', None)
            the_solver = args[0] if the_solver is None else the_solver
            s = the_solver.state

            start = time.time()
            r = f(*args, **kwargs)
            end = time.time()
            duration = end-start

            try:
                if s.scratch.sim_procedure is None and s.scratch.bbl_addr is not None:
                    location = ""bbl %#x, stmt %s (inst %s)"" % (
                        s.scratch.bbl_addr,
                        s.scratch.stmt_idx,
                        ('%s' % s.scratch.ins_addr if s.scratch.ins_addr is None else '%#x' % s.scratch.ins_addr)
                    )
                elif s.scratch.sim_procedure is not None:
                    location = ""sim_procedure %s"" % s.scratch.sim_procedure
                else:
                    location = ""unknown""
            except Exception: #pylint:disable=broad-except
                l.error(""Got exception while generating timer message:"", exc_info=True)
                location = ""unknown""
            lt.log(int((end-start)*10), '%s took %s seconds at %s', f.__name__, round(duration, 2), location)

            if 0 <= break_time < duration:
                #pylint: disable = import-outside-toplevel
                import ipdb; ipdb.set_trace()

            return r

        return timing_guy
    else:
        return f","s = the_solver.state
start = time.time()
r = f(*args, **kwargs)
end = time.time()","(s, start, r, end) = (the_solver.state, time.time()(), f(*args, **kwargs), time.time()())","s = zejun1
start = zejun2()
r = zejun3
end = zejun2()","(s, start, r, end) = (the_solver.state, time.time(), f(*args, **kwargs), time.time())",0,,,,
toolkit,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/toolkit/got10k/experiments/lasot.py,https://github.com/got-10k/toolkit/tree/master/got10k/experiments/lasot.py,ExperimentLaSOT,plot_curves$163,"def plot_curves(self, tracker_names, extension='.png'):
        # assume tracker_names[0] is your tracker
        report_dir = os.path.join(self.report_dir, tracker_names[0])
        assert os.path.exists(report_dir), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'
        report_file = os.path.join(report_dir, 'performance.json')
        assert os.path.exists(report_file), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'

        # load pre-computed performance
        with open(report_file) as f:
            performance = json.load(f)

        succ_file = os.path.join(report_dir, 'success_plots'+extension)
        prec_file = os.path.join(report_dir, 'precision_plots'+extension)
        norm_prec_file = os.path.join(report_dir, 'norm_precision_plots'+extension)
        key = 'overall'

        # markers
        markers = ['-', '--', '-.']
        markers = [c + m for m in markers for c in [''] * 10]

        # filter performance by tracker_names
        performance = {k:v for k,v in performance.items() if k in tracker_names}

        # sort trackers by success score
        tracker_names = list(performance.keys())
        succ = [t[key]['success_score'] for t in performance.values()]
        inds = np.argsort(succ)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot success curves
        thr_iou = np.linspace(0, 1, self.nbins_iou)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_iou,
                            performance[name][key]['success_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['success_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower left', bbox_to_anchor=(0., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Overlap threshold',
               ylabel='Success rate',
               xlim=(0, 1), ylim=(0, 1),
               title='Success plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving success plots to', succ_file)
        fig.savefig(succ_file,
                    bbox_extra_artists=(legend,),
                    bbox_inches='tight',
                    dpi=300)

        # sort trackers by precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot precision curves
        thr_ce = np.arange(0, self.nbins_ce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_ce,
                            performance[name][key]['precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Location error threshold',
               ylabel='Precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving precision plots to', prec_file)
        fig.savefig(prec_file, dpi=300)

# added by user
        # sort trackers by normalized precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['normalized_precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot normalized precision curves
        thr_nce = np.arange(0, self.nbins_nce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_nce,
                            performance[name][key]['normalized_precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['normalized_precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Normalized location error threshold',
               ylabel='Normalized precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Normalized precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving normalized precision plots to', norm_prec_file)
        fig.savefig(norm_prec_file, dpi=300)","tracker_names = [tracker_names[i] for i in inds]
thr_iou = np.linspace(0, 1, self.nbins_iou)
(fig, ax) = plt.subplots()
lines = []
legends = []","tracker_names, thr_iou, (fig, ax), lines, legends = [tracker_names[i] for i in inds], np.linspace(0, 1, self.nbins_iou), (fig, ax), [], []","tracker_names = zejun1
thr_iou = zejun2
(fig, ax) = zejun3
lines = zejun4
legends = zejun5",Cannot refactor,-1,0,0,1,it actually cannot refactor
toolkit,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/toolkit/got10k/experiments/lasot.py,https://github.com/got-10k/toolkit/tree/master/got10k/experiments/lasot.py,ExperimentLaSOT,plot_curves$163,"def plot_curves(self, tracker_names, extension='.png'):
        # assume tracker_names[0] is your tracker
        report_dir = os.path.join(self.report_dir, tracker_names[0])
        assert os.path.exists(report_dir), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'
        report_file = os.path.join(report_dir, 'performance.json')
        assert os.path.exists(report_file), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'

        # load pre-computed performance
        with open(report_file) as f:
            performance = json.load(f)

        succ_file = os.path.join(report_dir, 'success_plots'+extension)
        prec_file = os.path.join(report_dir, 'precision_plots'+extension)
        norm_prec_file = os.path.join(report_dir, 'norm_precision_plots'+extension)
        key = 'overall'

        # markers
        markers = ['-', '--', '-.']
        markers = [c + m for m in markers for c in [''] * 10]

        # filter performance by tracker_names
        performance = {k:v for k,v in performance.items() if k in tracker_names}

        # sort trackers by success score
        tracker_names = list(performance.keys())
        succ = [t[key]['success_score'] for t in performance.values()]
        inds = np.argsort(succ)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot success curves
        thr_iou = np.linspace(0, 1, self.nbins_iou)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_iou,
                            performance[name][key]['success_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['success_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower left', bbox_to_anchor=(0., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Overlap threshold',
               ylabel='Success rate',
               xlim=(0, 1), ylim=(0, 1),
               title='Success plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving success plots to', succ_file)
        fig.savefig(succ_file,
                    bbox_extra_artists=(legend,),
                    bbox_inches='tight',
                    dpi=300)

        # sort trackers by precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot precision curves
        thr_ce = np.arange(0, self.nbins_ce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_ce,
                            performance[name][key]['precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Location error threshold',
               ylabel='Precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving precision plots to', prec_file)
        fig.savefig(prec_file, dpi=300)

# added by user
        # sort trackers by normalized precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['normalized_precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot normalized precision curves
        thr_nce = np.arange(0, self.nbins_nce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_nce,
                            performance[name][key]['normalized_precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['normalized_precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Normalized location error threshold',
               ylabel='Normalized precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Normalized precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving normalized precision plots to', norm_prec_file)
        fig.savefig(norm_prec_file, dpi=300)","tracker_names = [tracker_names[i] for i in inds]
thr_ce = np.arange(0, self.nbins_ce)
(fig, ax) = plt.subplots()
lines = []
legends = []","tracker_names, thr_ce, (fig, ax), lines, legends = [tracker_names[i] for i in inds], np.arange(0, self.nbins_ce), (fig, ax), [], []","tracker_names = zejun1
thr_ce = zejun2
(fig, ax) = zejun3
lines = zejun4
legends = zejun5",Cannot refactor,-1,0,0,1,it actually cannot refactor
toolkit,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/toolkit/got10k/experiments/lasot.py,https://github.com/got-10k/toolkit/tree/master/got10k/experiments/lasot.py,ExperimentLaSOT,plot_curves$163,"def plot_curves(self, tracker_names, extension='.png'):
        # assume tracker_names[0] is your tracker
        report_dir = os.path.join(self.report_dir, tracker_names[0])
        assert os.path.exists(report_dir), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'
        report_file = os.path.join(report_dir, 'performance.json')
        assert os.path.exists(report_file), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'

        # load pre-computed performance
        with open(report_file) as f:
            performance = json.load(f)

        succ_file = os.path.join(report_dir, 'success_plots'+extension)
        prec_file = os.path.join(report_dir, 'precision_plots'+extension)
        norm_prec_file = os.path.join(report_dir, 'norm_precision_plots'+extension)
        key = 'overall'

        # markers
        markers = ['-', '--', '-.']
        markers = [c + m for m in markers for c in [''] * 10]

        # filter performance by tracker_names
        performance = {k:v for k,v in performance.items() if k in tracker_names}

        # sort trackers by success score
        tracker_names = list(performance.keys())
        succ = [t[key]['success_score'] for t in performance.values()]
        inds = np.argsort(succ)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot success curves
        thr_iou = np.linspace(0, 1, self.nbins_iou)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_iou,
                            performance[name][key]['success_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['success_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower left', bbox_to_anchor=(0., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Overlap threshold',
               ylabel='Success rate',
               xlim=(0, 1), ylim=(0, 1),
               title='Success plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving success plots to', succ_file)
        fig.savefig(succ_file,
                    bbox_extra_artists=(legend,),
                    bbox_inches='tight',
                    dpi=300)

        # sort trackers by precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot precision curves
        thr_ce = np.arange(0, self.nbins_ce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_ce,
                            performance[name][key]['precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Location error threshold',
               ylabel='Precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving precision plots to', prec_file)
        fig.savefig(prec_file, dpi=300)

# added by user
        # sort trackers by normalized precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['normalized_precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot normalized precision curves
        thr_nce = np.arange(0, self.nbins_nce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_nce,
                            performance[name][key]['normalized_precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['normalized_precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Normalized location error threshold',
               ylabel='Normalized precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Normalized precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving normalized precision plots to', norm_prec_file)
        fig.savefig(norm_prec_file, dpi=300)","tracker_names = [tracker_names[i] for i in inds]
thr_nce = np.arange(0, self.nbins_nce)
(fig, ax) = plt.subplots()
lines = []
legends = []",'Cannot refactor',"tracker_names = zejun1
thr_nce = zejun2
zejun3, zejun4 = plt.subplots()
lines = zejun5
legends = zejun5",Cannot refactor,-1,0,0,1,it actually cannot refactor
python3-saml,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/python3-saml/tests/src/OneLogin/saml2_tests/idp_metadata_parser_test.py,https://github.com/onelogin/python3-saml/tree/master/tests/src/OneLogin/saml2_tests/idp_metadata_parser_test.py,OneLogin_Saml2_IdPMetadataParser_Test,test_parse_multi_singing_certs$360,"def test_parse_multi_singing_certs(self):
        """"""
        Tests the parse method of the OneLogin_Saml2_IdPMetadataParser
        Case: IdP metadata contains multiple signing certs and no encryption certs
        """"""
        xml_idp_metadata = self.file_contents(join(self.data_path, 'metadata', 'idp_metadata_multi_signing_certs.xml'))
        data = OneLogin_Saml2_IdPMetadataParser.parse(xml_idp_metadata)

        expected_settings_json = """"""
        {
            ""sp"": {
                ""NameIDFormat"": ""urn:oasis:names:tc:SAML:2.0:nameid-format:transient""
            },
            ""idp"": {
                ""singleLogoutService"": {
                    ""url"": ""https://idp.examle.com/saml/slo"",
                    ""binding"": ""urn:oasis:names:tc:SAML:2.0:bindings:HTTP-Redirect""
                },
                ""x509certMulti"": {
                    ""signing"": [
                        ""MIIEZTCCA02gAwIBAgIUPyy/A3bZAZ4m28PzEUUoT7RJhxIwDQYJKoZIhvcNAQEFBQAwcjELMAkGA1UEBhMCVVMxKzApBgNVBAoMIk9uZUxvZ2luIFRlc3QgKHNnYXJjaWEtdXMtcHJlcHJvZCkxFTATBgNVBAsMDE9uZUxvZ2luIElkUDEfMB0GA1UEAwwWT25lTG9naW4gQWNjb3VudCA4OTE0NjAeFw0xNjA4MDQyMjI5MzdaFw0yMTA4MDUyMjI5MzdaMHIxCzAJBgNVBAYTAlVTMSswKQYDVQQKDCJPbmVMb2dpbiBUZXN0IChzZ2FyY2lhLXVzLXByZXByb2QpMRUwEwYDVQQLDAxPbmVMb2dpbiBJZFAxHzAdBgNVBAMMFk9uZUxvZ2luIEFjY291bnQgODkxNDYwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDN6iqQGcLOCglNO42I2rkzE05UXSiMXT6c8ALThMMiaDw6qqzo3sd/tKK+NcNKWLIIC8TozWVyh5ykUiVZps+08xil7VsTU7E+wKu3kvmOsvw2wlRwtnoKZJwYhnr+RkBa+h1r3ZYUgXm1ZPeHMKj1g18KaWz9+MxYL6BhKqrOzfW/P2xxVRcFH7/pq+ZsDdgNzD2GD+apzY4MZyZj/N6BpBWJ0GlFsmtBegpbX3LBitJuFkk5L4/U/jjF1AJa3boBdCUVfATqO5G03H4XS1GySjBIRQXmlUF52rLjg6xCgWJ30/+t1X+IHLJeixiQ0vxyh6C4/usCEt94cgD1r8ADAgMBAAGjgfIwge8wDAYDVR0TAQH/BAIwADAdBgNVHQ4EFgQUPW0DcH0G3IwynWgi74co4wZ6n7gwga8GA1UdIwSBpzCBpIAUPW0DcH0G3IwynWgi74co4wZ6n7ihdqR0MHIxCzAJBgNVBAYTAlVTMSswKQYDVQQKDCJPbmVMb2dpbiBUZXN0IChzZ2FyY2lhLXVzLXByZXByb2QpMRUwEwYDVQQLDAxPbmVMb2dpbiBJZFAxHzAdBgNVBAMMFk9uZUxvZ2luIEFjY291bnQgODkxNDaCFD8svwN22QGeJtvD8xFFKE+0SYcSMA4GA1UdDwEB/wQEAwIHgDANBgkqhkiG9w0BAQUFAAOCAQEAQhB4q9jrycwbHrDSoYR1X4LFFzvJ9Us75wQquRHXpdyS9D6HUBXMGI6ahPicXCQrfLgN8vzMIiqZqfySXXv/8/dxe/X4UsWLYKYJHDJmxXD5EmWTa65chjkeP1oJAc8f3CKCpcP2lOBTthbnk2fEVAeLHR4xNdQO0VvGXWO9BliYPpkYqUIBvlm+Fg9mF7AM/Uagq2503XXIE1Lq//HON68P10vNMwLSKOtYLsoTiCnuIKGJqG37MsZVjQ1ZPRcO+LSLkq0i91gFxrOrVCrgztX4JQi5XkvEsYZGIXXjwHqxTVyt3adZWQO0LPxPqRiUqUzyhDhLo/xXNrHCu4VbMw=="",
                        ""MIICZDCCAc2gAwIBAgIBADANBgkqhkiG9w0BAQ0FADBPMQswCQYDVQQGEwJ1czEUMBIGA1UECAwLZXhhbXBsZS5jb20xFDASBgNVBAoMC2V4YW1wbGUuY29tMRQwEgYDVQQDDAtleGFtcGxlLmNvbTAeFw0xNzA0MTUxNjMzMThaFw0xODA0MTUxNjMzMThaME8xCzAJBgNVBAYTAnVzMRQwEgYDVQQIDAtleGFtcGxlLmNvbTEUMBIGA1UECgwLZXhhbXBsZS5jb20xFDASBgNVBAMMC2V4YW1wbGUuY29tMIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQC6GLkl5lDUZdHNDAojp5i24OoPlqrt5TGXJIPqAZYT1hQvJW5nv17MFDHrjmtEnmW4ACKEy0fAX80QWIcHunZSkbEGHb+NG/6oTi5RipXMvmHnfFnPJJ0AdtiLiPE478CV856gXekV4Xx5u3KrylcOgkpYsp0GMIQBDzleMUXlYQIDAQABo1AwTjAdBgNVHQ4EFgQUnP8vlYPGPL2n6ZzDYij2kMDC8wMwHwYDVR0jBBgwFoAUnP8vlYPGPL2n6ZzDYij2kMDC8wMwDAYDVR0TBAUwAwEB/zANBgkqhkiG9w0BAQ0FAAOBgQAlQGAl+b8Cpot1g+65lLLjVoY7APJPWLW0klKQNlMU0s4MU+71Y3ExUEOXDAZgKcFoavb1fEOGMwEf38NaJAy1e/l6VNuixXShffq20ymqHQxOG0q8ujeNkgZF9k6XDfn/QZ3AD0o/IrCT7UMc/0QsfgIjWYxwCvp2syApc5CYfQ=="",
                        ""MIIEZTCCA02gAwIBAgIUPyy/A3bZAZ4m28PzEUUoT7RJhxIwDQYJKoZIhvcNAQEFBQAwcjELMAkGA1UEBhMCVVMxKzApBgNVBAoMIk9uZUxvZ2luIFRlc3QgKHNnYXJjaWEtdXMtcHJlcHJvZCkxFTATBgNVBAsMDE9uZUxvZ2luIElkUDEfMB0GA1UEAwwWT25lTG9naW4gQWNjb3VudCA4OTE0NjAeFw0xNjA4MDQyMjI5MzdaFw0yMTA4MDUyMjI5MzdaMHIxCzAJBgNVBAYTAlVTMSswKQYDVQQKDCJPbmVMb2dpbiBUZXN0IChzZ2FyY2lhLXVzLXByZXByb2QpMRUwEwYDVQQLDAxPbmVMb2dpbiBJZFAxHzAdBgNVBAMMFk9uZUxvZ2luIEFjY291bnQgODkxNDYwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDN6iqQGcLOCglNO42I2rkzE05UXSiMXT6c8ALThMMiaDw6qqzo3sd/tKK+NcNKWLIIC8TozWVyh5ykUiVZps+08xil7VsTU7E+wKu3kvmOsvw2wlRwtnoKZJwYhnr+RkBa+h1r3ZYUgXm1ZPeHMKj1g18KaWz9+MxYL6BhKqrOzfW/P2xxVRcFH7/pq+ZsDdgNzD2GD+apzY4MZyZj/N6BpBWJ0GlFsmtBegpbX3LBitJuFkk5L4/U/jjF1AJa3boBdCUVfATqO5G03H4XS1GySjBIRQXmlUF52rLjg6xCgWJ30/+t1X+IHLJeixiQ0vxyh6C4/usCEt94cgD1r8ADAgMBAAGjgfIwge8wDAYDVR0TAQH/BAIwADAdBgNVHQ4EFgQUPW0DcH0G3IwynWgi74co4wZ6n7gwga8GA1UdIwSBpzCBpIAUPW0DcH0G3IwynWgi74co4wZ6n7ihdqR0MHIxCzAJBgNVBAYTAlVTMSswKQYDVQQKDCJPbmVMb2dpbiBUZXN0IChzZ2FyY2lhLXVzLXByZXByb2QpMRUwEwYDVQQLDAxPbmVMb2dpbiBJZFAxHzAdBgNVBAMMFk9uZUxvZ2luIEFjY291bnQgODkxNDaCFD8svwN22QGeJtvD8xFFKE+0SYcSMA4GA1UdDwEB/wQEAwIHgDANBgkqhkiG9w0BAQUFAAOCAQEAQhB4q9jrycwbHrDSoYR1X4LFFzvJ9Us75wQquRHXpdyS9D6HUBXMGI6ahPicXCQrfLgN8vzMIiqZqfySXXv/8/dxe/X4UsWLYKYJHDJmxXD5EmWTa65chjkeP1oJAc8f3CKCpcP2lOBTthbnk2fEVAeLHR4xNdQO0VvGXWO9BliYPpkYqUIBvlm+Fg9mF7AM/Uagq2503XXIE1Lq//HON68P10vNMwLSKOtYLsoTiCnuIKGJqG37MsZVjQ1ZPRcO+LSLkq0i91gFxrOrVCrgztX4JQi5XkvEsYZGIXXjwHqxTVyt3adZWQO0LPxPqRiUqUzyhDhLo/xXNrHCu4VbMw==""
                    ]
                },
                ""entityId"": ""https://idp.examle.com/saml/metadata"",
                ""singleSignOnService"": {
                    ""url"": ""https://idp.examle.com/saml/sso"",
                    ""binding"": ""urn:oasis:names:tc:SAML:2.0:bindings:HTTP-Redirect""
                }
            }
        }
        """"""
        expected_settings = json.loads(expected_settings_json)
        self.assertEqual(expected_settings, data)","data = OneLogin_Saml2_IdPMetadataParser.parse(xml_idp_metadata)
expected_settings_json = '\n        {\n            ""sp"": {\n                ""NameIDFormat"": ""urn:oasis:names:tc:SAML:2.0:nameid-format:transient""\n            },\n            ""idp"": {\n                ""singleLogoutService"": {\n                    ""url"": ""https://idp.examle.com/saml/slo"",\n                    ""binding"": ""urn:oasis:names:tc:SAML:2.0:bindings:HTTP-Redirect""\n                },\n                ""x509certMulti"": {\n                    ""signing"": [\n                        ""MIIEZTCCA02gAwIBAgIUPyy/A3bZAZ4m28PzEUUoT7RJhxIwDQYJKoZIhvcNAQEFBQAwcjELMAkGA1UEBhMCVVMxKzApBgNVBAoMIk9uZUxvZ2luIFRlc3QgKHNnYXJjaWEtdXMtcHJlcHJvZCkxFTATBgNVBAsMDE9uZUxvZ2luIElkUDEfMB0GA1UEAwwWT25lTG9naW4gQWNjb3VudCA4OTE0NjAeFw0xNjA4MDQyMjI5MzdaFw0yMTA4MDUyMjI5MzdaMHIxCzAJBgNVBAYTAlVTMSswKQYDVQQKDCJPbmVMb2dpbiBUZXN0IChzZ2FyY2lhLXVzLXByZXByb2QpMRUwEwYDVQQLDAxPbmVMb2dpbiBJZFAxHzAdBgNVBAMMFk9uZUxvZ2luIEFjY291bnQgODkxNDYwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDN6iqQGcLOCglNO42I2rkzE05UXSiMXT6c8ALThMMiaDw6qqzo3sd/tKK+NcNKWLIIC8TozWVyh5ykUiVZps+08xil7VsTU7E+wKu3kvmOsvw2wlRwtnoKZJwYhnr+RkBa+h1r3ZYUgXm1ZPeHMKj1g18KaWz9+MxYL6BhKqrOzfW/P2xxVRcFH7/pq+ZsDdgNzD2GD+apzY4MZyZj/N6BpBWJ0GlFsmtBegpbX3LBitJuFkk5L4/U/jjF1AJa3boBdCUVfATqO5G03H4XS1GySjBIRQXmlUF52rLjg6xCgWJ30/+t1X+IHLJeixiQ0vxyh6C4/usCEt94cgD1r8ADAgMBAAGjgfIwge8wDAYDVR0TAQH/BAIwADAdBgNVHQ4EFgQUPW0DcH0G3IwynWgi74co4wZ6n7gwga8GA1UdIwSBpzCBpIAUPW0DcH0G3IwynWgi74co4wZ6n7ihdqR0MHIxCzAJBgNVBAYTAlVTMSswKQYDVQQKDCJPbmVMb2dpbiBUZXN0IChzZ2FyY2lhLXVzLXByZXByb2QpMRUwEwYDVQQLDAxPbmVMb2dpbiBJZFAxHzAdBgNVBAMMFk9uZUxvZ2luIEFjY291bnQgODkxNDaCFD8svwN22QGeJtvD8xFFKE+0SYcSMA4GA1UdDwEB/wQEAwIHgDANBgkqhkiG9w0BAQUFAAOCAQEAQhB4q9jrycwbHrDSoYR1X4LFFzvJ9Us75wQquRHXpdyS9D6HUBXMGI6ahPicXCQrfLgN8vzMIiqZqfySXXv/8/dxe/X4UsWLYKYJHDJmxXD5EmWTa65chjkeP1oJAc8f3CKCpcP2lOBTthbnk2fEVAeLHR4xNdQO0VvGXWO9BliYPpkYqUIBvlm+Fg9mF7AM/Uagq2503XXIE1Lq//HON68P10vNMwLSKOtYLsoTiCnuIKGJqG37MsZVjQ1ZPRcO+LSLkq0i91gFxrOrVCrgztX4JQi5XkvEsYZGIXXjwHqxTVyt3adZWQO0LPxPqRiUqUzyhDhLo/xXNrHCu4VbMw=="",\n                        ""MIICZDCCAc2gAwIBAgIBADANBgkqhkiG9w0BAQ0FADBPMQswCQYDVQQGEwJ1czEUMBIGA1UECAwLZXhhbXBsZS5jb20xFDASBgNVBAoMC2V4YW1wbGUuY29tMRQwEgYDVQQDDAtleGFtcGxlLmNvbTAeFw0xNzA0MTUxNjMzMThaFw0xODA0MTUxNjMzMThaME8xCzAJBgNVBAYTAnVzMRQwEgYDVQQIDAtleGFtcGxlLmNvbTEUMBIGA1UECgwLZXhhbXBsZS5jb20xFDASBgNVBAMMC2V4YW1wbGUuY29tMIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQC6GLkl5lDUZdHNDAojp5i24OoPlqrt5TGXJIPqAZYT1hQvJW5nv17MFDHrjmtEnmW4ACKEy0fAX80QWIcHunZSkbEGHb+NG/6oTi5RipXMvmHnfFnPJJ0AdtiLiPE478CV856gXekV4Xx5u3KrylcOgkpYsp0GMIQBDzleMUXlYQIDAQABo1AwTjAdBgNVHQ4EFgQUnP8vlYPGPL2n6ZzDYij2kMDC8wMwHwYDVR0jBBgwFoAUnP8vlYPGPL2n6ZzDYij2kMDC8wMwDAYDVR0TBAUwAwEB/zANBgkqhkiG9w0BAQ0FAAOBgQAlQGAl+b8Cpot1g+65lLLjVoY7APJPWLW0klKQNlMU0s4MU+71Y3ExUEOXDAZgKcFoavb1fEOGMwEf38NaJAy1e/l6VNuixXShffq20ymqHQxOG0q8ujeNkgZF9k6XDfn/QZ3AD0o/IrCT7UMc/0QsfgIjWYxwCvp2syApc5CYfQ=="",\n                        ""MIIEZTCCA02gAwIBAgIUPyy/A3bZAZ4m28PzEUUoT7RJhxIwDQYJKoZIhvcNAQEFBQAwcjELMAkGA1UEBhMCVVMxKzApBgNVBAoMIk9uZUxvZ2luIFRlc3QgKHNnYXJjaWEtdXMtcHJlcHJvZCkxFTATBgNVBAsMDE9uZUxvZ2luIElkUDEfMB0GA1UEAwwWT25lTG9naW4gQWNjb3VudCA4OTE0NjAeFw0xNjA4MDQyMjI5MzdaFw0yMTA4MDUyMjI5MzdaMHIxCzAJBgNVBAYTAlVTMSswKQYDVQQKDCJPbmVMb2dpbiBUZXN0IChzZ2FyY2lhLXVzLXByZXByb2QpMRUwEwYDVQQLDAxPbmVMb2dpbiBJZFAxHzAdBgNVBAMMFk9uZUxvZ2luIEFjY291bnQgODkxNDYwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDN6iqQGcLOCglNO42I2rkzE05UXSiMXT6c8ALThMMiaDw6qqzo3sd/tKK+NcNKWLIIC8TozWVyh5ykUiVZps+08xil7VsTU7E+wKu3kvmOsvw2wlRwtnoKZJwYhnr+RkBa+h1r3ZYUgXm1ZPeHMKj1g18KaWz9+MxYL6BhKqrOzfW/P2xxVRcFH7/pq+ZsDdgNzD2GD+apzY4MZyZj/N6BpBWJ0GlFsmtBegpbX3LBitJuFkk5L4/U/jjF1AJa3boBdCUVfATqO5G03H4XS1GySjBIRQXmlUF52rLjg6xCgWJ30/+t1X+IHLJeixiQ0vxyh6C4/usCEt94cgD1r8ADAgMBAAGjgfIwge8wDAYDVR0TAQH/BAIwADAdBgNVHQ4EFgQUPW0DcH0G3IwynWgi74co4wZ6n7gwga8GA1UdIwSBpzCBpIAUPW0DcH0G3IwynWgi74co4wZ6n7ihdqR0MHIxCzAJBgNVBAYTAlVTMSswKQYDVQQKDCJPbmVMb2dpbiBUZXN0IChzZ2FyY2lhLXVzLXByZXByb2QpMRUwEwYDVQQLDAxPbmVMb2dpbiBJZFAxHzAdBgNVBAMMFk9uZUxvZ2luIEFjY291bnQgODkxNDaCFD8svwN22QGeJtvD8xFFKE+0SYcSMA4GA1UdDwEB/wQEAwIHgDANBgkqhkiG9w0BAQUFAAOCAQEAQhB4q9jrycwbHrDSoYR1X4LFFzvJ9Us75wQquRHXpdyS9D6HUBXMGI6ahPicXCQrfLgN8vzMIiqZqfySXXv/8/dxe/X4UsWLYKYJHDJmxXD5EmWTa65chjkeP1oJAc8f3CKCpcP2lOBTthbnk2fEVAeLHR4xNdQO0VvGXWO9BliYPpkYqUIBvlm+Fg9mF7AM/Uagq2503XXIE1Lq//HON68P10vNMwLSKOtYLsoTiCnuIKGJqG37MsZVjQ1ZPRcO+LSLkq0i91gFxrOrVCrgztX4JQi5XkvEsYZGIXXjwHqxTVyt3adZWQO0LPxPqRiUqUzyhDhLo/xXNrHCu4VbMw==""\n                    ]\n                },\n                ""entityId"": ""https://idp.examle.com/saml/metadata"",\n                ""singleSignOnService"": {\n                    ""url"": ""https://idp.examle.com/saml/sso"",\n                    ""binding"": ""urn:oasis:names:tc:SAML:2.0:bindings:HTTP-Redirect""\n                }\n            }\n        }\n        '","""""""Cannot refactor""""""","symbols:
zejun1: OneLogin_Saml2_IdPMetadataParser.parse(xml_idp_metadata)
zejun2: '\n        {\n            ""sp"": {\n                ""NameIDFormat"": ""urn:oasis:names:tc:SAML:2.0:nameid-format:transient""\n            },\n            ""idp"": {\n                ""singleLogoutService"": {\n                    ""url"": ""https://idp.examle.com/saml/slo"",\n                    ""binding"": ""urn:oasis:names:tc:SAML:2.0:bindings:HTTP-Redirect""\n                },\n                ""x509certMulti"": {\n                    ""signing"": [\n                        ""MIIEZTCCA02gAwIBAgIUPyy/A3bZAZ4m28PzEUUoT7RJhxIwDQYJKoZIhvcNAQEFBQAwcjELMAkGA1UEBhMCVVMxKzApBgNVBAoMIk9uZUxvZ2luIFRlc3QgKHNnYXJjaWEtdXMtcHJlcHJvZCkxFTATBgNVBAsMDE9uZUxvZ2luIElkUDEfMB0GA1UEAwwWT25lTG9naW4gQWNjb3VudCA4OTE0NjAeFw0xNjA4MDQyMjI5MzdaFw0yMTA4MDUyMjI5MzdaMHIxCzAJBgNVBAYTAlVTMSswKQYDVQQKDCJPbmVMb2dpbiBUZXN0IChzZ2FyY2lhLXVzLXByZXByb2QpMRUwEwYDVQQLDAxPbmVMb2dpbiBJZFAxHzAdBgNVBAMMFk9uZUxvZ2luIEFjY291bnQgODkxNDYwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDN6iqQGcLOCglNO42I2rkzE05UXSiMXT6c8ALThMMiaDw6qqzo3sd/tKK+NcNKWLIIC8TozWVyh5ykUiVZps+08xil7VsTU7E+wKu3kvmOsvw2wlRwtnoKZJwYhnr+RkBa+h1r3ZYUgXm1ZPeHMKj1g18KaWz9+MxYL6BhKqrOzfW/P2xxVRcFH7/pq+ZsDdgNzD2GD+apzY4MZyZj/N6BpBWJ0GlFsmtBegpbX3LBitJuFkk5L4/U/jjF1AJa3boBdCUVfATqO5G03H4XS1GySjBIRQXmlUF52rLjg6xC","(data, expected_settings_json) = (OneLogin_Saml2_IdPMetadataParser.parse(xml_idp_metadata), '\n        {\n            ""sp"": {\n                ""NameIDFormat"": ""urn:oasis:names:tc:SAML:2.0:nameid-format:transient""\n            },\n            ""idp"": {\n                ""singleLogoutService"": {\n                    ""url"": ""https://idp.examle.com/saml/slo"",\n                    ""binding"": ""urn:oasis:names:tc:SAML:2.0:bindings:HTTP-Redirect""\n                },\n                ""x509certMulti"": {\n                    ""signing"": [\n                        ""MIIEZTCCA02gAwIBAgIUPyy/A3bZAZ4m28PzEUUoT7RJhxIwDQYJKoZIhvcNAQEFBQAwcjELMAkGA1UEBhMCVVMxKzApBgNVBAoMIk9uZUxvZ2luIFRlc3QgKHNnYXJjaWEtdXMtcHJlcHJvZCkxFTATBgNVBAsMDE9uZUxvZ2luIElkUDEfMB0GA1UEAwwWT25lTG9naW4gQWNjb3VudCA4OTE0NjAeFw0xNjA4MDQyMjI5MzdaFw0yMTA4MDUyMjI5MzdaMHIxCzAJBgNVBAYTAlVTMSswKQYDVQQKDCJPbmVMb2dpbiBUZXN0IChzZ2FyY2lhLXVzLXByZXByb2QpMRUwEwYDVQQLDAxPbmVMb2dpbiBJZFAxHzAdBgNVBAMMFk9uZUxvZ2luIEFjY291bnQgODkxNDYwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDN6iqQGcLOCglNO42I2rkzE05UXSiMXT6c8ALThMMiaDw6qqzo3sd/tKK+NcNKWLIIC8TozWVyh5ykUiVZps+08xil7VsTU7E+wKu3kvmOsvw2wlRwtnoKZJwYhnr+RkBa+h1r3ZYUgXm1ZPeHMKj1g18KaWz9+MxYL6BhKqrOzfW/P2xxVRcFH7/pq+ZsDdgNzD2GD+apzY4MZyZj/N6BpBWJ0GlFsmtBegpbX3LBitJuFkk5L4/U/jjF1AJa3boBdCUVfATqO5G03H4XS1GySjBIRQXmlUF52rLjg6xCgWJ30/+t1X+IHLJeixiQ0vxyh6C4/usCEt94cgD1r8ADAgMBAAGjgfIwge8wDAYDVR0TAQH/BAIwADAdBgNVHQ4EFgQUPW0DcH0G3IwynWgi74co4wZ6n7gwga8GA1UdIwSBpzCBpIAUPW0DcH0G3IwynWgi74co4wZ6n7ihdqR0MHIxCzAJBgNVBAYTAlVTMSswKQYDVQQKDCJPbmVMb2dpbiBUZXN0IChzZ2FyY2lhLXVzLXByZXByb2QpMRUwEwYDVQQLDAxPbmVMb2dpbiBJZFAxHzAdBgNVBAMMFk9uZUxvZ2luIEFjY291bnQgODkxNDaCFD8svwN22QGeJtvD8xFFKE+0SYcSMA4GA1UdDwEB/wQEAwIHgDANBgkqhkiG9w0BAQUFAAOCAQEAQhB4q9jrycwbHrDSoYR1X4LFFzvJ9Us75wQquRHXpdyS9D6HUBXMGI6ahPicXCQrfLgN8vzMIiqZqfySXXv/8/dxe/X4UsWLYKYJHDJmxXD5EmWTa65chjkeP1oJAc8f3CKCpcP2lOBTthbnk2fEVAeLHR4xNdQO0VvGXWO9BliYPpkYqUIBvlm+Fg9mF7AM/Uagq2503XXIE1Lq//HON68P10vNMwLSKOtYLsoTiCnuIKGJqG37MsZVjQ1ZPRcO+LSLkq0i91gFxrOrVCrgztX4JQi5XkvEsYZGIXXjwHqxTVyt3adZWQO0LPxPqRiUqUzyhDhLo/xXNrHCu4VbMw=="",\n                        ""MIICZDCCAc2gAwIBAgIBADANBgkqhkiG9w0BAQ0FADBPMQswCQYDVQQGEwJ1czEUMBIGA1UECAwLZXhhbXBsZS5jb20xFDASBgNVBAoMC2V4YW1wbGUuY29tMRQwEgYDVQQDDAtleGFtcGxlLmNvbTAeFw0xNzA0MTUxNjMzMThaFw0xODA0MTUxNjMzMThaME8xCzAJBgNVBAYTAnVzMRQwEgYDVQQIDAtleGFtcGxlLmNvbTEUMBIGA1UECgwLZXhhbXBsZS5jb20xFDASBgNVBAMMC2V4YW1wbGUuY29tMIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQC6GLkl5lDUZdHNDAojp5i24OoPlqrt5TGXJIPqAZYT1hQvJW5nv17MFDHrjmtEnmW4ACKEy0fAX80QWIcHunZSkbEGHb+NG/6oTi5RipXMvmHnfFnPJJ0AdtiLiPE478CV856gXekV4Xx5u3KrylcOgkpYsp0GMIQBDzleMUXlYQIDAQABo1AwTjAdBgNVHQ4EFgQUnP8vlYPGPL2n6ZzDYij2kMDC8wMwHwYDVR0jBBgwFoAUnP8vlYPGPL2n6ZzDYij2kMDC8wMwDAYDVR0TBAUwAwEB/zANBgkqhkiG9w0BAQ0FAAOBgQAlQGAl+b8Cpot1g+65lLLjVoY7APJPWLW0klKQNlMU0s4MU+71Y3ExUEOXDAZgKcFoavb1fEOGMwEf38NaJAy1e/l6VNuixXShffq20ymqHQxOG0q8ujeNkgZF9k6XDfn/QZ3AD0o/IrCT7UMc/0QsfgIjWYxwCvp2syApc5CYfQ=="",\n                        ""MIIEZTCCA02gAwIBAgIUPyy/A3bZAZ4m28PzEUUoT7RJhxIwDQYJKoZIhvcNAQEFBQAwcjELMAkGA1UEBhMCVVMxKzApBgNVBAoMIk9uZUxvZ2luIFRlc3QgKHNnYXJjaWEtdXMtcHJlcHJvZCkxFTATBgNVBAsMDE9uZUxvZ2luIElkUDEfMB0GA1UEAwwWT25lTG9naW4gQWNjb3VudCA4OTE0NjAeFw0xNjA4MDQyMjI5MzdaFw0yMTA4MDUyMjI5MzdaMHIxCzAJBgNVBAYTAlVTMSswKQYDVQQKDCJPbmVMb2dpbiBUZXN0IChzZ2FyY2lhLXVzLXByZXByb2QpMRUwEwYDVQQLDAxPbmVMb2dpbiBJZFAxHzAdBgNVBAMMFk9uZUxvZ2luIEFjY291bnQgODkxNDYwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDN6iqQGcLOCglNO42I2rkzE05UXSiMXT6c8ALThMMiaDw6qqzo3sd/tKK+NcNKWLIIC8TozWVyh5ykUiVZps+08xil7VsTU7E+wKu3kvmOsvw2wlRwtnoKZJwYhnr+RkBa+h1r3ZYUgXm1ZPeHMKj1g18KaWz9+MxYL6BhKqrOzfW/P2xxVRcFH7/pq+ZsDdgNzD2GD+apzY4MZyZj/N6BpBWJ0GlFsmtBegpbX3LBitJuFkk5L4/U/jjF1AJa3boBdCUVfATqO5G03H4XS1GySjBIRQXmlUF52rLjg6xCgWJ30/+t1X+IHLJeixiQ0vxyh6C4/usCEt94cgD1r8ADAgMBAAGjgfIwge8wDAYDVR0TAQH/BAIwADAdBgNVHQ4EFgQUPW0DcH0G3IwynWgi74co4wZ6n7gwga8GA1UdIwSBpzCBpIAUPW0DcH0G3IwynWgi74co4wZ6n7ihdqR0MHIxCzAJBgNVBAYTAlVTMSswKQYDVQQKDCJPbmVMb2dpbiBUZXN0IChzZ2FyY2lhLXVzLXByZXByb2QpMRUwEwYDVQQLDAxPbmVMb2dpbiBJZFAxHzAdBgNVBAMMFk9uZUxvZ2luIEFjY291bnQgODkxNDaCFD8svwN22QGeJtvD8xFFKE+0SYcSMA4GA1UdDwEB/wQEAwIHgDANBgkqhkiG9w0BAQUFAAOCAQEAQhB4q9jrycwbHrDSoYR1X4LFFzvJ9Us75wQquRHXpdyS9D6HUBXMGI6ahPicXCQrfLgN8vzMIiqZqfySXXv/8/dxe/X4UsWLYKYJHDJmxXD5EmWTa65chjkeP1oJAc8f3CKCpcP2lOBTthbnk2fEVAeLHR4xNdQO0VvGXWO9BliYPpkYqUIBvlm+Fg9mF7AM/Uagq2503XXIE1Lq//HON68P10vNMwLSKOtYLsoTiCnuIKGJqG37MsZVjQ1ZPRcO+LSLkq0i91gFxrOrVCrgztX4JQi5XkvEsYZGIXXjwHqxTVyt3adZWQO0LPxPqRiUqUzyhDhLo/xXNrHCu4VbMw==""\n                    ]\n                },\n                ""entityId"": ""https://idp.examle.com/saml/metadata"",\n                ""singleSignOnService"": {\n                    ""url"": ""https://idp.examle.com/saml/sso"",\n                    ""binding"": ""urn:oasis:names:tc:SAML:2.0:bindings:HTTP-Redirect""\n                }\n            }\n        }\n        ')",0,,,,
pandas,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pandas/pandas/tests/frame/methods/test_replace.py,https://github.com/pandas-dev/pandas/tree/master/pandas/tests/frame/methods/test_replace.py,TestDataFrameReplace,test_replace_with_duplicate_columns$1344,"def test_replace_with_duplicate_columns(self, replacement):
        # GH 24798
        result = DataFrame({""A"": [1, 2, 3], ""A1"": [4, 5, 6], ""B"": [7, 8, 9]})
        result.columns = list(""AAB"")

        expected = DataFrame(
            {""A"": [1, 2, 3], ""A1"": [4, 5, 6], ""B"": [replacement, 8, 9]}
        )
        expected.columns = list(""AAB"")

        result[""B""] = result[""B""].replace(7, replacement)

        tm.assert_frame_equal(result, expected)","expected.columns = list('AAB')
result['B'] = result['B'].replace(7, replacement)","""""""Cannot refactor""""""","expected.columns = zejun1
result['B'] = result['B'].replace(7, zejun2)","(expected.columns, result['B']) = (list('AAB'), result['B'].replace(7, replacement))",0,,,,
imgaug,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/imgaug/test/augmenters/test_geometric.py,https://github.com/aleju/imgaug/tree/master/test/augmenters/test_geometric.py,TestWithPolarWarping,test_heatmaps_translation_x$9105,"def test_heatmaps_translation_x(self):
        hm = np.zeros((50, 70, 2), dtype=np.float32)
        hm[20-1:20+1, 30-1:30+1, 0] = 1.0
        hm[30-1:30+1, 40-1:40+1, 1] = 1.0
        hm = ia.HeatmapsOnImage(hm, shape=(50, 70, 3))
        aug = iaa.WithPolarWarping(iaa.Affine(translate_px={""x"": 15}))

        hm_aug = aug(heatmaps=hm)

        hm_aug_arr = hm_aug.get_arr()
        x1 = np.argmax(np.max(hm_aug_arr[..., 0], axis=0))
        y1 = np.argmax(np.max(hm_aug_arr[..., 0], axis=1))
        x2 = np.argmax(np.max(hm_aug_arr[..., 1], axis=0))
        y2 = np.argmax(np.max(hm_aug_arr[..., 1], axis=1))

        # translation on x axis in polar representation should move all points
        # a bit away from the center
        min_diff = 4
        assert hm_aug_arr.shape == (50, 70, 2)
        assert hm_aug.shape == (50, 70, 3)
        assert x1 < 30 - min_diff
        assert y1 < 20 - min_diff
        assert x2 > 40 + min_diff
        assert y2 > 30 + min_diff","hm[20 - 1:20 + 1, 30 - 1:30 + 1, 0] = 1.0
hm[30 - 1:30 + 1, 40 - 1:40 + 1, 1] = 1.0","""""""Cannot refactor""""""","hm[zejun1 - 1:zejun1 + 1, zejun2 - 1:zejun2 + 1, 0] = zejun4
hm[zejun2 - 1:zejun2 + 1, zejun3 - 1:zejun3 + 1, 1] = zejun4","(hm[20 - 1:20 + 1, 30 - 1:30 + 1, 0], hm[30 - 1:30 + 1, 40 - 1:40 + 1, 1]) = (1.0, 1.0)",0,,,,
django,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/django/django/db/backends/base/creation.py,https://github.com/django/django/tree/master/django/db/backends/base/creation.py,BaseDatabaseCreation,destroy_test_db$259,"def destroy_test_db(self, old_database_name=None, verbosity=1, keepdb=False, suffix=None):
        """"""
        Destroy a test database, prompting the user for confirmation if the
        database already exists.
        """"""
        self.connection.close()
        if suffix is None:
            test_database_name = self.connection.settings_dict['NAME']
        else:
            test_database_name = self.get_test_db_clone_settings(suffix)['NAME']

        if verbosity >= 1:
            action = 'Destroying'
            if keepdb:
                action = 'Preserving'
            self.log('%s test database for alias %s...' % (
                action,
                self._get_database_display_str(verbosity, test_database_name),
            ))

        # if we want to preserve the database
        # skip the actual destroying piece.
        if not keepdb:
            self._destroy_test_db(test_database_name, verbosity)

        # Restore the original database name
        if old_database_name is not None:
            settings.DATABASES[self.connection.alias][""NAME""] = old_database_name
            self.connection.settings_dict[""NAME""] = old_database_name","settings.DATABASES[self.connection.alias]['NAME'] = old_database_name
self.connection.settings_dict['NAME'] = old_database_name","""""""Cannot refactor""""""","settings.DATABASES[self.connection.alias]['NAME'] = zejun1
self.connection.settings_dict['NAME'] = zejun1","(settings.DATABASES[self.connection.alias]['NAME'], self.connection.settings_dict['NAME']) = (old_database_name, old_database_name)",0,,,,
Paddle,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/Paddle/python/paddle/distributed/fleet/meta_optimizers/pipeline_optimizer.py,https://github.com/PaddlePaddle/Paddle/tree/master/python/paddle/distributed/fleet/meta_optimizers/pipeline_optimizer.py,PipelineOptimizer,minimize_impl$200,"def minimize_impl(
        self, loss, startup_program=None, parameter_list=None, no_grad_set=None
    ):
        self.endpoints = self.role_maker._get_trainer_endpoints()
        self.current_endpoint = self.endpoints[self.role_maker._worker_index()]
        self.rank = self.role_maker._worker_index()
        self.nranks = self.role_maker._worker_num()

        self.wrapped_opt = PO(
            self.inner_opt, num_microbatches=self.num_microbatches
        )
        orig_startup_program = (
            startup_program
            if startup_program
            else paddle.static.default_startup_program()
        )
        block = loss.block
        program = block.program

        program._pipeline_opt = dict()
        program._pipeline_opt['local_rank'] = self.rank
        program._pipeline_opt['global_ring_id'] = self.global_ring_id
        program._pipeline_opt['ring_id'] = self.start_pipeline_ring_id
        program._pipeline_opt['micro_batch_size'] = self.micro_batch_size
        program._pipeline_opt['schedule_mode'] = self.schedule_mode
        program._pipeline_opt['use_sharding'] = False
        program._pipeline_opt['mp_degree'] = 1
        program._pipeline_opt['mp_rank'] = 0
        (
            optimize_ops,
            params_grads,
            prog_list,
            pp_pair,
            ring_map,
        ) = self.wrapped_opt.minimize(
            loss, startup_program, parameter_list, no_grad_set
        )
        self.startup_program = orig_startup_program._pipeline_opt[
            'startup_program'
        ]
        self.inner_parallelism = program._pipeline_opt['inner_parallelism']
        assert self.nranks % self.inner_parallelism == 0
        assert prog_list
        self.pipeline_num = len(self.endpoints) // self.inner_parallelism

        self._init_process_group(pp_pair, ring_map)

        self.main_program_list = prog_list
        self.main_program = program
        if self.pipeline_num > 1:
            self._transpile_main_program(loss)
        return optimize_ops, params_grads","program._pipeline_opt = dict()
program._pipeline_opt['local_rank'] = self.rank
program._pipeline_opt['global_ring_id'] = self.global_ring_id
program._pipeline_opt['ring_id'] = self.start_pipeline_ring_id
program._pipeline_opt['micro_batch_size'] = self.micro_batch_size
program._pipeline_opt['schedule_mode'] = self.schedule_mode
program._pipeline_opt['use_sharding'] = False
program._pipeline_opt['mp_degree'] = 1
program._pipeline_opt['mp_rank'] = 0
(optimize_ops, params_grads, prog_list, pp_pair, ring_map) = self.wrapped_opt.minimize(loss, startup_program, parameter_list, no_grad_set)
self.startup_program = orig_startup_program._pipeline_opt['startup_program']",'Cannot refactor',"program._pipeline_opt = zejun1
program._pipeline_opt['local_rank'] = zejun2
program._pipeline_opt['global_ring_id'] = zejun3
program._pipeline_opt['ring_id'] = zejun4
program._pipeline_opt['micro_batch_size'] = zejun5
program._pipeline_opt['schedule_mode'] = zejun6
program._pipeline_opt['use_sharding'] = zejun7
program._pipeline_opt['mp_degree'] = zejun8
program._pipeline_opt['mp_rank'] = zejun9
(optimize_ops, params_grads, prog_list, pp_pair, ring_map) = self.wrapped_opt.minimize(zejun10)
self.startup_program = zejun11",Cannot refactor,-1,0,0,1,it actually cannot refactor
glTF-Blender-Exporter,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/glTF-Blender-Exporter/scripts/addons/io_scene_gltf2/gltf2_generate.py,https://github.com/KhronosGroup/glTF-Blender-Exporter/tree/master/scripts/addons/io_scene_gltf2/gltf2_generate.py,,generate_nodes$1720,"def generate_nodes(operator,
                   context,
                   export_settings,
                   glTF):
    """"""
    Generates the top level nodes entry.
    """"""

    nodes = []

    skins = []

    #
    #

    filtered_objects = export_settings['filtered_objects']

    for blender_object in filtered_objects:
        node = generate_node_instance(context, export_settings, glTF, nodes, blender_object, False)

        #
        #

        nodes.append(node)

    #
    #

    for blender_object in filtered_objects:
        if blender_object.dupli_type == 'GROUP' and blender_object.dupli_group != None:

            if export_settings['gltf_layers'] or (blender_object.layers[0] and blender_object.dupli_group.layers[0]):

                for blender_dupli_object in blender_object.dupli_group.objects:
                    node = generate_node_instance(context, export_settings, glTF, nodes, blender_dupli_object,
                                                  True)

                    node['name'] = 'Duplication_' + blender_object.name + '_' + blender_dupli_object.name

                    #
                    #

                    nodes.append(node)

                #

                node = {}

                node['name'] = 'Duplication_Offset_' + blender_object.name

                translation = convert_swizzle_location(blender_object.dupli_group.dupli_offset, export_settings)

                node['translation'] = [-translation[0], -translation[1], -translation[2]]

                nodes.append(node)

    #
    #

    if len(nodes) > 0:
        glTF['nodes'] = nodes

    #
    #

    if export_settings['gltf_skins']:
        for blender_object in filtered_objects:
            if blender_object.type != 'ARMATURE' or len(blender_object.pose.bones) == 0:
                continue

            temp_action = None

            if export_settings['gltf_bake_skins'] and not export_settings['gltf_animations']:
                if blender_object.animation_data is not None:
                    temp_action = blender_object.animation_data.action

                bpy.context.scene.objects.active = blender_object
                bpy.ops.object.mode_set(mode='POSE')
                bpy.ops.nla.bake(frame_start=bpy.context.scene.frame_current, frame_end=bpy.context.scene.frame_current,
                                 only_selected=False, visual_keying=True, clear_constraints=False,
                                 use_current_action=False, bake_types={'POSE'})

            joints = []

            joints_written = False

            #

            children_list = list(blender_object.children)

            for blender_check_object in filtered_objects:
                blender_check_armature = blender_check_object.find_armature()

                if blender_check_armature == blender_object and blender_check_object not in children_list:
                    children_list.append(blender_check_object)

            #

            for blender_object_child in children_list:
                #
                # Property: skin and node
                #

                inverse_matrices = []

                for blender_bone in blender_object.pose.bones:

                    if export_settings['gltf_yup']:
                        axis_basis_change = mathutils.Matrix(
                            ((1.0, 0.0, 0.0, 0.0), (0.0, 0.0, 1.0, 0.0), (0.0, -1.0, 0.0, 0.0), (0.0, 0.0, 0.0, 1.0)))
                    else:
                        axis_basis_change = mathutils.Matrix.Identity(4)

                    if not joints_written:
                        node = {}

                        if blender_bone.parent is None:
                            correction_matrix_local = axis_basis_change * blender_bone.bone.matrix_local
                        else:
                            correction_matrix_local = blender_bone.parent.bone.matrix_local.inverted() * blender_bone.bone.matrix_local

                        matrix_basis = blender_bone.matrix_basis

                        if export_settings['gltf_bake_skins']:
                            matrix_basis = blender_object.convert_space(blender_bone, blender_bone.matrix,
                                                                        from_space='POSE', to_space='LOCAL')

                        generate_node_parameter(export_settings, correction_matrix_local * matrix_basis, node, 'JOINT')

                        #

                        node['name'] = blender_object.name + ""_"" + blender_bone.name

                        #
                        #

                        joints.append(len(nodes))

                        nodes.append(node)

                    #
                    #

                    inverse_bind_matrix = axis_basis_change * blender_bone.bone.matrix_local

                    bind_shape_matrix = axis_basis_change * blender_object.matrix_world.inverted() * blender_object_child.matrix_world * axis_basis_change.inverted()

                    inverse_bind_matrix = inverse_bind_matrix.inverted() * bind_shape_matrix

                    for column in range(0, 4):
                        for row in range(0, 4):
                            inverse_matrices.append(inverse_bind_matrix[row][column])

                #

                joints_written = True

                #

                skin = {}

                skin['skeleton'] = get_node_index(glTF, blender_object.name)

                skin['joints'] = joints

                #
                count = len(inverse_matrices) // 16
                type = ""MAT4""

                inverseBindMatrices = create_accessor(
                    operator,
                    context,
                    export_settings,
                    glTF,
                    inverse_matrices,
                    GLTF_COMPONENT_TYPE_FLOAT,
                    count,
                    GLTF_DATA_TYPE_MAT4,
                    """"
                )

                skin['inverseBindMatrices'] = inverseBindMatrices

                #

                skins.append(skin)

            #

            if temp_action is not None:
                blender_object.animation_data.action = temp_action

    #
    #

    if len(skins) > 0:
        glTF['skins'] = skins

    #
    # Resolve children etc.
    #

    for blender_object in filtered_objects:
        node_index = get_node_index(glTF, blender_object.name)

        node = nodes[node_index]

        #

        if export_settings['gltf_skins']:
            blender_armature = blender_object.find_armature()
            if blender_armature is not None:

                if blender_object in blender_armature.children:
                    index_offset = blender_armature.children.index(blender_object)
                else:
                    index_local_offset = 0

                    for blender_check_object in filtered_objects:
                        blender_check_armature = blender_check_object.find_armature()
                        if blender_check_armature == blender_armature:
                            index_local_offset += 1

                        if blender_object == blender_check_object:
                            index_local_offset -= 1
                            break

                    index_offset = len(blender_armature.children) + index_local_offset

                node['skin'] = get_skin_index(glTF, blender_armature.name, index_offset)

        #

        children = []

        # Camera
        if export_settings['gltf_cameras']:
            if blender_object.type == 'CAMERA':
                child_index = get_node_index(glTF, 'Correction_' + blender_object.name)
                if child_index >= 0:
                    children.append(child_index)

        # Light
        if export_settings['gltf_lights']:
            if blender_object.type == 'LAMP':
                child_index = get_node_index(glTF, 'Correction_' + blender_object.name)
                if child_index >= 0:
                    children.append(child_index)

        # Nodes
        for blender_child_node in blender_object.children:
            child_index = get_node_index(glTF, blender_child_node.name)

            if blender_child_node.parent_type == 'BONE' and export_settings['gltf_skins']:
                continue

            if child_index < 0:
                continue

            children.append(child_index)

        # Duplications
        if blender_object.dupli_type == 'GROUP' and blender_object.dupli_group is not None:

            child_index = get_node_index(glTF, 'Duplication_Offset_' + blender_object.name)
            if child_index >= 0:
                children.append(child_index)

                duplication_node = nodes[child_index]

                duplication_children = []

                for blender_dupli_object in blender_object.dupli_group.objects:
                    child_index = get_node_index(
                        glTF,
                        'Duplication_' + blender_object.name + '_' + blender_dupli_object.name
                    )
                    if child_index >= 0:
                        duplication_children.append(child_index)

                duplication_node['children'] = duplication_children

                #

        if export_settings['gltf_skins']:
            # Joint
            if blender_object.type == 'ARMATURE' and len(blender_object.pose.bones) > 0:

                #

                blender_object_to_bone = {}

                if export_settings['gltf_skins']:
                    for blender_child_node in blender_object.children:
                        if blender_child_node.parent_type == 'BONE':
                            blender_object_to_bone[blender_child_node.name] = blender_child_node.parent_bone

                #

                for blender_bone in blender_object.pose.bones:

                    if blender_bone.parent:
                        continue

                    child_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone.name)

                    if child_index < 0:
                        continue

                    children.append(child_index)

                for blender_bone in blender_object.pose.bones:
                    joint_children = []
                    for blender_bone_child in blender_bone.children:
                        child_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone_child.name)

                        if child_index < 0:
                            continue

                        joint_children.append(child_index)

                    for blender_object_name in blender_object_to_bone:
                        blender_bone_name = blender_object_to_bone[blender_object_name]
                        if blender_bone_name == blender_bone.name:
                            child_index = get_node_index(glTF, blender_object_name)

                            if child_index < 0:
                                continue

                            joint_children.append(child_index)

                    if len(joint_children) > 0:
                        node_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone.name)

                        child_node = nodes[node_index]

                        child_node['children'] = joint_children

        if len(children) > 0:
            node['children'] = children","inverse_bind_matrix = axis_basis_change * blender_bone.bone.matrix_local
bind_shape_matrix = axis_basis_change * blender_object.matrix_world.inverted() * blender_object_child.matrix_world * axis_basis_change.inverted()",'Cannot refactor',"inverse_bind_matrix = zejun1 * zejun2
bind_shape_matrix = zejun1 * zejun3 * zejun4 * zejun5",Cannot refactor,-1,0,0,1,it actually cannot refactor
saleor,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/saleor/saleor/payment/gateways/stripe/tests/test_webhooks.py,https://github.com/saleor/saleor/tree/master/saleor/payment/gateways/stripe/tests/test_webhooks.py,,test_handle_authorized_payment_intent_for_checkout$385,"def test_handle_authorized_payment_intent_for_checkout(
    _wrapped_update_payment_method,
    wrapped_checkout_complete,
    payment_stripe_for_checkout,
    checkout_with_items,
    stripe_plugin,
    channel_USD,
):
    payment = payment_stripe_for_checkout
    payment.to_confirm = True
    payment.save()
    payment.transactions.create(
        is_success=True,
        action_required=True,
        kind=TransactionKind.ACTION_TO_CONFIRM,
        amount=payment.total,
        currency=payment.currency,
        token=""ABC"",
        gateway_response={},
    )
    plugin = stripe_plugin()
    payment_intent = StripeObject(id=""ABC"", last_response={})
    payment_intent[""amount""] = price_to_minor_unit(payment.total, payment.currency)
    payment_intent[""currency""] = payment.currency
    payment_intent[""status""] = AUTHORIZED_STATUS
    payment_intent[""payment_method""] = StripeObject()
    handle_authorized_payment_intent(payment_intent, plugin.config, channel_USD.slug)

    payment.refresh_from_db()

    assert wrapped_checkout_complete.called
    assert payment.checkout_id is None
    assert not payment.cc_brand
    assert not payment.cc_last_digits
    assert not payment.cc_exp_year
    assert not payment.cc_exp_month
    assert not payment.payment_method_type
    assert payment.order
    assert payment.order.checkout_token == str(checkout_with_items.token)
    transaction = payment.transactions.get(kind=TransactionKind.AUTH)
    assert transaction.token == payment_intent.id","payment_intent['amount'] = price_to_minor_unit(payment.total, payment.currency)
payment_intent['currency'] = payment.currency
payment_intent['status'] = AUTHORIZED_STATUS
payment_intent['payment_method'] = StripeObject()","(payment_intent['amount'], payment_intent['status'], payment_intent['payment_method']) = (price_to_minor_unit(payment.total, payment.currency), AUTHORIZED_STATUS, StripeObject())","payment_intent['amount'] = zejun1
payment_intent['currency'] = payment.currency
payment_intent['status'] = zejun2
payment_intent['payment_method'] = zejun3","(payment_intent['amount'], payment_intent['currency'], payment_intent['status'], payment_intent['payment_method']) = (price_to_minor_unit(payment.total, payment.currency), payment.currency, AUTHORIZED_STATUS, StripeObject())",0,abstract 不完整,,,
Ghostwriter,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/Ghostwriter/ghostwriter/rolodex/tests/test_views.py,https://github.com/GhostManager/Ghostwriter/tree/master/ghostwriter/rolodex/tests/test_views.py,RollCodenameViewTests,setUp$129,"def setUp(self):
        self.client = Client()
        self.client_auth = Client()
        self.client_auth.login(username=self.user.username, password=PASSWORD)
        self.assertTrue(
            self.client_auth.login(username=self.user.username, password=PASSWORD)
        )","self.client = Client()
self.client_auth = Client()","""""""Cannot refactor""""""","self.client = zejun1
self.client_auth = zejun1","(self.client, self.client_auth) = (Client(), Client())",0,,,,
nibabel,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/nibabel/nibabel/tests/test_round_trip.py,https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_round_trip.py,,check_arr$123,"def check_arr(test_id, V_in, in_type, out_type, scaling_type):
    arr, arr_dash, slope, inter = check_params(V_in, in_type, out_type)
    if arr_dash is None:
        # Scaling causes a header or writer error
        return
    nzs = arr != 0  # avoid divide by zero error
    if not np.any(nzs):
        if DEBUG:
            raise ValueError('Array all zero')
        return
    arr = arr[nzs]
    arr_dash_L = arr_dash.astype(BIG_FLOAT)[nzs]
    top = arr - arr_dash_L
    if not np.any(top != 0):
        return
    rel_err = np.abs(top / arr)
    abs_err = np.abs(top)
    if slope == 1:  # integers output, offset only scaling
        if {in_type, out_type} == {np.int64, np.uint64}:
            # Scaling to or from 64 bit ints can go outside range of continuous
            # integers for float64 and thus lose precision; take this into
            # account
            A = arr.astype(float)
            Ai = A - inter
            ulps = [big_bad_ulp(A), big_bad_ulp(Ai)]
            exp_abs_err = np.max(ulps, axis=0)
        else:  # floats can give full precision - no error!
            exp_abs_err = np.zeros_like(abs_err)
        rel_thresh = 0
    else:
        # Error from integer rounding
        inting_err = np.abs(scaling_type(slope) / 2)
        inting_err = inting_err + ulp(inting_err)
        # Error from calculation of inter
        inter_err = ulp(scaling_type(inter))
        # Max abs error from floating point
        with np.errstate(over='ignore'):
            Ai = arr - scaling_type(inter)
        Ais = Ai / scaling_type(slope)
        exp_abs_err = inting_err + inter_err + (
            big_bad_ulp(Ai) + big_bad_ulp(Ais))
        # Relative scaling error from calculation of slope
        # This threshold needs to be 2 x larger on windows 32 bit and PPC for
        # some reason
        rel_thresh = ulp(scaling_type(1))
    test_vals = (abs_err <= exp_abs_err) | (rel_err <= rel_thresh)
    this_test = np.all(test_vals)
    if DEBUG:
        abs_fails = (abs_err > exp_abs_err)
        rel_fails = (rel_err > rel_thresh)
        all_fails = abs_fails & rel_fails
        if np.any(rel_fails):
            abs_mx_e = abs_err[rel_fails].max()
            exp_abs_mx_e = exp_abs_err[rel_fails].max()
        else:
            abs_mx_e = None
            exp_abs_mx_e = None
        if np.any(abs_fails):
            rel_mx_e = rel_err[abs_fails].max()
        else:
            rel_mx_e = None
        print((test_id,
               np.dtype(in_type).str,
               np.dtype(out_type).str,
               exp_abs_mx_e,
               abs_mx_e,
               rel_thresh,
               rel_mx_e,
               slope, inter))
        # To help debugging failures with --pdb-failure
        np.nonzero(all_fails)
    assert this_test","abs_mx_e = None
exp_abs_mx_e = None",'Cannot refactor',"abs_mx_e = zejun1
exp_abs_mx_e = zejun1",Cannot refactor,-1,0,0,1,it actually cannot refactor
new_find,,,,,,,,,,,,,,
trax,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/trax/trax/tf_numpy/numpy_impl/math_ops.py,https://github.com/google/trax/tree/master/trax/tf_numpy/numpy_impl/math_ops.py,,f$765,"def f(a):
    nd = a.shape.rank
    if (axis + nd if axis < 0 else axis) >= nd:
      raise ValueError(""axis %s is out of bounds for array of dimension %s"" %
                       (axis, nd))
    if n < 0:
      raise ValueError(""order must be non-negative but got %s"" % n)
    slice1 = [slice(None)] * nd
    slice2 = [slice(None)] * nd
    slice1[axis] = slice(1, None)
    slice2[axis] = slice(None, -1)
    slice1 = tuple(slice1)
    slice2 = tuple(slice2)
    op = tf.not_equal if a.dtype == tf.bool else tf.subtract
    for _ in range(n):
      a = op(a[slice1], a[slice2])
    return a","slice1[axis] = slice(1, None)
slice2[axis] = slice(None, -1)","slice1[axis], slice2[axis] = slice(1, None), slice(None, -1)","slice1[axis] = zejun1
slice2[axis] = zejun2",Cannot refactor,-1,1,,,
text_classification,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/text_classification/a04_TextRCNN/p71_TextRCNN_mode2.py,https://github.com/brightmart/text_classification/tree/master/a04_TextRCNN/p71_TextRCNN_mode2.py,,test$195,"def test():
    #below is a function test; if you use this for text classifiction, you need to tranform sentence to indices of vocabulary first. then feed data to the graph.
    num_classes=10
    learning_rate=0.01
    batch_size=8
    decay_steps=1000
    decay_rate=0.9
    sequence_length=5
    vocab_size=10000
    embed_size=100
    is_training=True
    dropout_keep_prob=1#0.5
    textRNN=TextRCNN(num_classes, learning_rate, batch_size, decay_steps, decay_rate,sequence_length,vocab_size,embed_size,is_training)
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for i in range(100):
            input_x=np.zeros((batch_size,sequence_length)) #[None, self.sequence_length]
            input_y=input_y=np.array([1,0,1,1,1,2,1,1]) #np.zeros((batch_size),dtype=np.int32) #[None, self.sequence_length]
            loss,acc,predict,_=sess.run([textRNN.loss_val,textRNN.accuracy,textRNN.predictions,textRNN.train_op],
                                        feed_dict={textRNN.input_x:input_x,textRNN.input_y:input_y,textRNN.dropout_keep_prob:dropout_keep_prob})
            print(""loss:"",loss,""acc:"",acc,""label:"",input_y,""prediction:"",predict)","input_x = np.zeros((batch_size, sequence_length))
input_y = input_y = np.array([1, 0, 1, 1, 1, 2, 1, 1])","input_x, input_y = np.zeros((batch_size, sequence_length)), np.array([1, 0, 1, 1, 1, 2, 1, 1])","input_x = np.zeros(zejun1)
input_y = zejun2",Cannot refactor,-1,1,,,
django-cms,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/django-cms/cms/tests/test_admin.py,https://github.com/django-cms/django-cms/tree/master/cms/tests/test_admin.py,AdminTests,test_change_innavigation$503,"def test_change_innavigation(self):
        page = self.get_page()
        permless = self.get_permless()
        admin_user = self.get_admin()
        with self.login_user_context(permless):
            request = self.get_request()
            response = self.admin_class.change_innavigation(request, page.pk)
            self.assertEqual(response.status_code, 405)
        with self.login_user_context(permless):
            request = self.get_request(post_data={'no': 'data'})
            response = self.admin_class.change_innavigation(request, page.pk)
            self.assertEqual(response.status_code, 403)
        with self.login_user_context(permless):
            request = self.get_request(post_data={'no': 'data'})
            self.assertEqual(response.status_code, 403)
        with self.login_user_context(admin_user):
            request = self.get_request(post_data={'no': 'data'})
            self.assertRaises(Http404, self.admin_class.change_innavigation,
                              request, page.pk + 100)
        with self.login_user_context(permless):
            request = self.get_request(post_data={'no': 'data'})
            response = self.admin_class.change_innavigation(request, page.pk)
            self.assertEqual(response.status_code, 403)
        with self.login_user_context(admin_user):
            request = self.get_request(post_data={'no': 'data'})
            old = page.in_navigation
            response = self.admin_class.change_innavigation(request, page.pk)
            self.assertEqual(response.status_code, 204)
            page = self.reload(page)
            self.assertEqual(old, not page.in_navigation)","request = self.get_request(post_data={'no': 'data'})
old = page.in_navigation","request, old = self.get_request(post_data={'no': 'data'}), page.in_navigation","request = zejun1
old = zejun2",Cannot refactor,-1,1,,,
django-axes,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/django-axes/axes/handlers/database.py,https://github.com/jazzband/django-axes/tree/master/axes/handlers/database.py,AxesDatabaseHandler,user_login_failed$117,"def user_login_failed(self, sender, credentials: dict, request=None, **kwargs):
        """"""When user login fails, save AccessFailureLog record in database,
        save AccessAttempt record in database, mark request with
        lockout attribute and emit lockout signal.

        """"""

        log.info(""AXES: User login failed, running database handler for failure."")

        if request is None:
            log.error(
                ""AXES: AxesDatabaseHandler.user_login_failed does not function without a request.""
            )
            return

        # 1. database query: Clean up expired user attempts from the database before logging new attempts
        clean_expired_user_attempts(request.axes_attempt_time)

        username = get_client_username(request, credentials)
        client_str = get_client_str(
            username,
            request.axes_ip_address,
            request.axes_user_agent,
            request.axes_path_info,
            request,
        )

        # If axes denied access, don't record the failed attempt as that would reset the lockout time.
        if (
            not settings.AXES_RESET_COOL_OFF_ON_FAILURE_DURING_LOCKOUT
            and request.axes_locked_out
        ):
            request.axes_credentials = credentials
            user_locked_out.send(
                ""axes"",
                request=request,
                username=username,
                ip_address=request.axes_ip_address,
            )
            return

        # This replaces null byte chars that crash saving failures.
        get_data = get_query_str(request.GET).replace(""\0"", ""0x00"")
        post_data = get_query_str(request.POST).replace(""\0"", ""0x00"")

        if self.is_whitelisted(request, credentials):
            log.info(""AXES: Login failed from whitelisted client %s."", client_str)
            return

        # 2. database query: Get or create access record with the new failure data
        if settings.AXES_ONLY_USER_FAILURES and username is None:
            log.warning(
                ""AXES: Username is None and AXES_ONLY_USER_FAILURES is enabled, new record will NOT be created.""
            )
        else:
            with transaction.atomic():
                (
                    attempt,
                    created,
                ) = AccessAttempt.objects.select_for_update().get_or_create(
                    username=username,
                    ip_address=request.axes_ip_address,
                    user_agent=request.axes_user_agent,
                    defaults={
                        ""get_data"": get_data,
                        ""post_data"": post_data,
                        ""http_accept"": request.axes_http_accept,
                        ""path_info"": request.axes_path_info,
                        ""failures_since_start"": 1,
                        ""attempt_time"": request.axes_attempt_time,
                    },
                )

                # Record failed attempt with all the relevant information.
                # Filtering based on username, IP address and user agent handled elsewhere,
                # and this handler just records the available information for further use.
                if created:
                    log.warning(
                        ""AXES: New login failure by %s. Created new record in the database."",
                        client_str,
                    )

                # 3. database query if there were previous attempts in the database
                # Update failed attempt information but do not touch the username, IP address, or user agent fields,
                # because attackers can request the site with multiple different configurations
                # in order to bypass the defense mechanisms that are used by the site.
                else:
                    separator = ""\n---------\n""

                    attempt.get_data = Concat(""get_data"", Value(separator + get_data))
                    attempt.post_data = Concat(
                        ""post_data"", Value(separator + post_data)
                    )
                    attempt.http_accept = request.axes_http_accept
                    attempt.path_info = request.axes_path_info
                    attempt.failures_since_start = F(""failures_since_start"") + 1
                    attempt.attempt_time = request.axes_attempt_time
                    attempt.save()

                    log.warning(
                        ""AXES: Repeated login failure by %s. Updated existing record in the database."",
                        client_str,
                    )

        # 3. or 4. database query: Calculate the current maximum failure number from the existing attempts
        failures_since_start = self.get_failures(request, credentials)
        request.axes_failures_since_start = failures_since_start

        if (
            settings.AXES_LOCK_OUT_AT_FAILURE
            and failures_since_start >= get_failure_limit(request, credentials)
        ):
            log.warning(
                ""AXES: Locking out %s after repeated login failures."", client_str
            )

            request.axes_locked_out = True
            request.axes_credentials = credentials
            user_locked_out.send(
                ""axes"",
                request=request,
                username=username,
                ip_address=request.axes_ip_address,
            )

        # 5. database entry: Log for ever the attempt in the AccessFailureLog
        if settings.AXES_ENABLE_ACCESS_FAILURE_LOG:
            with transaction.atomic():
                AccessFailureLog.objects.create(
                    username=username,
                    ip_address=request.axes_ip_address,
                    user_agent=request.axes_user_agent,
                    http_accept=request.axes_http_accept,
                    path_info=request.axes_path_info,
                    attempt_time=request.axes_attempt_time,
                    locked_out=request.axes_locked_out,
                )
                self.remove_out_of_limit_failure_logs(username=username)","attempt.get_data = Concat('get_data', Value(separator + get_data))
attempt.post_data = Concat('post_data', Value(separator + post_data))
attempt.http_accept = request.axes_http_accept
attempt.path_info = request.axes_path_info
attempt.failures_since_start = F('failures_since_start') + 1
attempt.attempt_time = request.axes_attempt_time","attempt.get_data, attempt.post_data, attempt.http_accept, attempt.path_info, attempt.failures_since_start, attempt.attempt_time = Concat('get_data', Value(separator + get_data)), Concat('post_data', Value(separator + post_data)), request.axes_http_accept, request.axes_path_info, F('failures_since_start') + 1, request.axes_attempt_time","attempt.get_data = zejun1
attempt.post_data = zejun2
attempt.http_accept = zejun3
attempt.path_info = zejun4
attempt.failures_since_start = zejun5
attempt.attempt_time = zejun6",Cannot refactor,-1,1,,,
addons,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/addons/tensorflow_addons/layers/crf.py,https://github.com/tensorflow/addons/tree/master/tensorflow_addons/layers/crf.py,CRF,add_boundary_energy$217,"def add_boundary_energy(self, potentials, mask, start, end):
        def expand_scalar_to_3d(x):
            # expand tensor from shape (x, ) to (1, 1, x)
            return tf.reshape(x, (1, 1, -1))

        start = tf.cast(expand_scalar_to_3d(start), potentials.dtype)
        end = tf.cast(expand_scalar_to_3d(end), potentials.dtype)
        if mask is None:
            potentials = tf.concat(
                [potentials[:, :1, :] + start, potentials[:, 1:, :]], axis=1
            )
            potentials = tf.concat(
                [potentials[:, :-1, :], potentials[:, -1:, :] + end], axis=1
            )
        else:
            mask = tf.keras.backend.expand_dims(tf.cast(mask, start.dtype), axis=-1)
            start_mask = tf.cast(self._compute_mask_left_boundary(mask), start.dtype)

            end_mask = tf.cast(self._compute_mask_right_boundary(mask), end.dtype)
            potentials = potentials + start_mask * start
            potentials = potentials + end_mask * end
        return potentials","end_mask = tf.cast(self._compute_mask_right_boundary(mask), end.dtype)
potentials = potentials + start_mask * start","end_mask, potentials= tf.cast(self._compute_mask_right_boundary(mask), end.dtype), potentials + start_mask * start","end_mask = zejun1
potentials = zejun2",Cannot refactor,-1,1,,,
addons,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/addons/tensorflow_addons/layers/crf.py,https://github.com/tensorflow/addons/tree/master/tensorflow_addons/layers/crf.py,CRF,add_boundary_energy$217,"def add_boundary_energy(self, potentials, mask, start, end):
        def expand_scalar_to_3d(x):
            # expand tensor from shape (x, ) to (1, 1, x)
            return tf.reshape(x, (1, 1, -1))

        start = tf.cast(expand_scalar_to_3d(start), potentials.dtype)
        end = tf.cast(expand_scalar_to_3d(end), potentials.dtype)
        if mask is None:
            potentials = tf.concat(
                [potentials[:, :1, :] + start, potentials[:, 1:, :]], axis=1
            )
            potentials = tf.concat(
                [potentials[:, :-1, :], potentials[:, -1:, :] + end], axis=1
            )
        else:
            mask = tf.keras.backend.expand_dims(tf.cast(mask, start.dtype), axis=-1)
            start_mask = tf.cast(self._compute_mask_left_boundary(mask), start.dtype)

            end_mask = tf.cast(self._compute_mask_right_boundary(mask), end.dtype)
            potentials = potentials + start_mask * start
            potentials = potentials + end_mask * end
        return potentials","start_mask = tf.cast(self._compute_mask_left_boundary(mask), start.dtype)
end_mask = tf.cast(self._compute_mask_right_boundary(mask), end.dtype)","start_mask, end_mask= tf.cast(self._compute_mask_left_boundary(mask), start.dtype), tf.cast(self._compute_mask_right_boundary(mask), end.dtype)","start_mask = zejun1
end_mask = zejun2",Cannot refactor,-1,1,,,
imgclsmob,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/imgclsmob/pytorch/pytorchcv/models/isqrtcovresnet.py,https://github.com/osmr/imgclsmob/tree/master/pytorch/pytorchcv/models/isqrtcovresnet.py,,get_isqrtcovresnet$247,"def get_isqrtcovresnet(blocks,
                       conv1_stride=True,
                       model_name=None,
                       pretrained=False,
                       root=os.path.join(""~"", "".torch"", ""models""),
                       **kwargs):
    """"""
    Create iSQRT-COV-ResNet model with specific parameters.

    Parameters:
    ----------
    blocks : int
        Number of blocks.
    conv1_stride : bool, default True
        Whether to use stride in the first or the second convolution layer in units.
    model_name : str or None, default None
        Model name for loading pretrained model.
    pretrained : bool, default False
        Whether to load the pretrained weights for model.
    root : str, default '~/.torch/models'
        Location for keeping the model parameters.
    """"""

    if blocks == 18:
        layers = [2, 2, 2, 2]
    elif blocks == 34:
        layers = [3, 4, 6, 3]
    elif blocks == 50:
        layers = [3, 4, 6, 3]
    elif blocks == 101:
        layers = [3, 4, 23, 3]
    elif blocks == 152:
        layers = [3, 8, 36, 3]
    elif blocks == 200:
        layers = [3, 24, 36, 3]
    else:
        raise ValueError(""Unsupported iSQRT-COV-ResNet with number of blocks: {}"".format(blocks))

    init_block_channels = 64
    final_block_channels = 256

    if blocks < 50:
        channels_per_layers = [64, 128, 256, 512]
        bottleneck = False
    else:
        channels_per_layers = [256, 512, 1024, 2048]
        bottleneck = True

    channels = [[ci] * li for (ci, li) in zip(channels_per_layers, layers)]

    net = iSQRTCOVResNet(
        channels=channels,
        init_block_channels=init_block_channels,
        final_block_channels=final_block_channels,
        bottleneck=bottleneck,
        conv1_stride=conv1_stride,
        **kwargs)

    if pretrained:
        if (model_name is None) or (not model_name):
            raise ValueError(""Parameter `model_name` should be properly initialized for loading pretrained model."")
        from .model_store import download_model
        download_model(
            net=net,
            model_name=model_name,
            local_model_store_dir_path=root)

    return net","channels_per_layers = [256, 512, 1024, 2048]
bottleneck = True","channels_per_layers, bottleneck = [256, 512, 1024, 2048], True","channels_per_layers = zejun1
bottleneck = zejun2",Cannot refactor,-1,1,,,
GyoiThon,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/GyoiThon/modules/Gyoi_Inventory.py,https://github.com/gyoisamurai/GyoiThon/tree/master/modules/Gyoi_Inventory.py,Inventory,sub_domain_explore$410,"def sub_domain_explore(self, domain_info_dict, google_hack):
        self.utility.print_message(NOTE, 'Explore sub-domain.')
        msg = self.utility.make_log_msg(self.utility.log_in,
                                        self.utility.log_dis,
                                        self.file_name,
                                        action=self.action_name,
                                        note='Explore sub-domain.',
                                        dest=self.utility.target_host)
        self.utility.write_log(20, msg)

        # Get whois information for mutated domain.
        for idx, domain in enumerate(domain_info_dict.keys()):
            self.utility.print_message(OK, '[{}/{}] Sub-domain Explore of ""{}""'.format(idx + 1, len(domain_info_dict), domain))
            if self.check_existing_tmp_json(domain):
                self.utility.print_message(WARNING, 'Existing temporary Json file for ""{}"".'.format(domain))
                continue

            # Add domain to sub-domain list.
            sub_domain_info_dict = {}
            sub_domain_info_dict[domain] = {'IP Address': domain_info_dict[domain]['IP Address'],
                                            'DNS': domain_info_dict[domain]['DNS'],
                                            'Access Status': 'N/A'}

            # Explore sub-domain using Google Custom Search.
            sub_domain_list, query = google_hack.search_domain(domain, max_search_num=self.max_search_num)
            sub_domain_list.append(domain)
            sub_domain_list.append('www.' + domain)
            for sub_idx, sub_domain in enumerate(list(set(sub_domain_list))):
                self.utility.print_message(OK, 'Search ""{}""'.format(sub_domain))
                # Get DNS record and IP address of sub-domain.
                sub_domain_info = self.get_sub_domain_dns_record(sub_domain)
                sub_domain_info_dict[sub_domain] = sub_domain_info

            # Add sub-domain information to domain dict.
            domain_info_dict[domain]['Sub-domain'] = sub_domain_info_dict
            domain_info_dict[domain]['Note'] = query

            # Save domain information to temporary json file.
            with codecs.open(os.path.join(self.tmp_inventory_dir, domain), 'w', 'utf-8') as fout:
                json.dump(domain_info_dict[domain], fout, indent=4)","sub_domain_info_dict[domain] = {'IP Address': domain_info_dict[domain]['IP Address'], 'DNS': domain_info_dict[domain]['DNS'], 'Access Status': 'N/A'}
(sub_domain_list, query) = google_hack.search_domain(domain, max_search_num=self.max_search_num)","sub_domain_info_dict[domain], (sub_domain_list, query) = {'IP Address': domain_info_dict[domain]['IP Address'], 'DNS': domain_info_dict[domain]['DNS'], 'Access Status': 'N/A'}, google_hack.search_domain(domain, max_search_num=self.max_search_num)","sub_domain_info_dict[domain] = zejun1
(sub_domain_list, query) = zejun2",Cannot refactor,-1,1,,,
devpi,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/devpi/client/testing/test_use.py,https://github.com/devpi/devpi/tree/master/client/testing/test_use.py,TestUnit,test_auth_multisite$253,"def test_auth_multisite(self):
        current = Current()
        login1 = ""http://site.com/+login""
        login2 = ""http://site2.com/+login""
        current.login = login1
        current.set_auth(""hello"", ""pass1"")
        current.login = login2
        current.set_auth(""hello"", ""pass2"")
        assert current.get_auth(login1) == (""hello"", ""pass1"")
        assert current.get_auth(login2) == (""hello"", ""pass2"")
        current.login = login1
        current.del_auth()
        assert not current.get_auth(login1)
        assert current.get_auth(login2) == (""hello"", ""pass2"")
        current.login = login2
        current.del_auth()
        assert not current.get_auth(login2)","current = Current()
login1 = 'http://site.com/+login'
login2 = 'http://site2.com/+login'","current, login1, login2 = Current(), 'http://site.com/+login', 'http://site2.com/+login'","current = zejun1
login1 = zejun2
login2 = zejun3",Cannot refactor,-1,1,,,
data-driven-web-apps-with-flask,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/data-driven-web-apps-with-flask/app/ch11_migrations/starter/pypi_org/bin/load_data.py,https://github.com/talkpython/data-driven-web-apps-with-flask/tree/master/app/ch11_migrations/starter/pypi_org/bin/load_data.py,,build_releases$303,"def build_releases(package_id: str, releases: dict) -> List[Release]:
    db_releases = []
    for k in releases.keys():
        all_releases_for_version = releases.get(k)
        if not all_releases_for_version:
            continue

        v = all_releases_for_version[-1]

        r = Release()
        r.package_id = package_id
        r.major_ver, r.minor_ver, r.build_ver = make_version_num(k)
        r.created_date = parse(v.get('upload_time'))
        r.comment = v.get('comment_text')
        r.url = v.get('url')
        r.size = int(v.get('size', 0))

        db_releases.append(r)

    return db_releases","r.package_id = package_id
(r.major_ver, r.minor_ver, r.build_ver) = make_version_num(k)
r.created_date = parse(v.get('upload_time'))
r.comment = v.get('comment_text')
r.url = v.get('url')
r.size = int(v.get('size', 0))","r.package_id, (r.major_ver, r.minor_ver, r.build_ver), r.created_date, r.comment, r.url, r.size = package_id, make_version_num(k), parse(v.get('upload_time')), v.get('comment_text'), v.get('url'), int(v.get('size', 0))","r.package_id = zejun1
(r.major_ver, r.minor_ver, r.build_ver) = zejun2
r.created_date = zejun3
r.comment = zejun4
r.url = zejun5
r.size = zejun6",Cannot refactor,-1,1,,,
not-youtube-dl,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/not-youtube-dl/youtube_dl/extractor/cspan.py,https://github.com/scastillo/not-youtube-dl/tree/master/youtube_dl/extractor/cspan.py,CSpanIE,_real_extract$79,"def _real_extract(self, url):
        video_id = self._match_id(url)
        video_type = None
        webpage = self._download_webpage(url, video_id)

        ustream_url = UstreamIE._extract_url(webpage)
        if ustream_url:
            return self.url_result(ustream_url, UstreamIE.ie_key())

        if '&vod' not in url:
            bc = self._search_regex(
                r""(<[^>]+id='brightcove-player-embed'[^>]+>)"",
                webpage, 'brightcove embed', default=None)
            if bc:
                bc_attr = extract_attributes(bc)
                bc_url = self.BRIGHTCOVE_URL_TEMPLATE % (
                    bc_attr.get('data-bcaccountid', '3162030207001'),
                    bc_attr.get('data-noprebcplayerid', 'SyGGpuJy3g'),
                    bc_attr.get('data-newbcplayerid', 'default'),
                    bc_attr['data-bcid'])
                return self.url_result(smuggle_url(bc_url, {'source_url': url}))

        # We first look for clipid, because clipprog always appears before
        patterns = [r'id=\'clip(%s)\'\s*value=\'([0-9]+)\'' % t for t in ('id', 'prog')]
        results = list(filter(None, (re.search(p, webpage) for p in patterns)))
        if results:
            matches = results[0]
            video_type, video_id = matches.groups()
            video_type = 'clip' if video_type == 'id' else 'program'
        else:
            m = re.search(r'data-(?P<type>clip|prog)id=[""\'](?P<id>\d+)', webpage)
            if m:
                video_id = m.group('id')
                video_type = 'program' if m.group('type') == 'prog' else 'clip'
            else:
                senate_isvp_url = SenateISVPIE._search_iframe_url(webpage)
                if senate_isvp_url:
                    title = self._og_search_title(webpage)
                    surl = smuggle_url(senate_isvp_url, {'force_title': title})
                    return self.url_result(surl, 'SenateISVP', video_id, title)
                video_id = self._search_regex(
                    r'jwsetup\.clipprog\s*=\s*(\d+);',
                    webpage, 'jwsetup program id', default=None)
                if video_id:
                    video_type = 'program'
        if video_type is None or video_id is None:
            error_message = get_element_by_class('VLplayer-error-message', webpage)
            if error_message:
                raise ExtractorError(error_message)
            raise ExtractorError('unable to find video id and type')

        def get_text_attr(d, attr):
            return d.get(attr, {}).get('#text')

        data = self._download_json(
            'http://www.c-span.org/assets/player/ajax-player.php?os=android&html5=%s&id=%s' % (video_type, video_id),
            video_id)['video']
        if data['@status'] != 'Success':
            raise ExtractorError('%s said: %s' % (self.IE_NAME, get_text_attr(data, 'error')), expected=True)

        doc = self._download_xml(
            'http://www.c-span.org/common/services/flashXml.php?%sid=%s' % (video_type, video_id),
            video_id)

        description = self._html_search_meta('description', webpage)

        title = find_xpath_attr(doc, './/string', 'name', 'title').text
        thumbnail = find_xpath_attr(doc, './/string', 'name', 'poster').text

        files = data['files']
        capfile = get_text_attr(data, 'capfile')

        entries = []
        for partnum, f in enumerate(files):
            formats = []
            for quality in f.get('qualities', []):
                formats.append({
                    'format_id': '%s-%sp' % (get_text_attr(quality, 'bitrate'), get_text_attr(quality, 'height')),
                    'url': unescapeHTML(get_text_attr(quality, 'file')),
                    'height': int_or_none(get_text_attr(quality, 'height')),
                    'tbr': int_or_none(get_text_attr(quality, 'bitrate')),
                })
            if not formats:
                path = unescapeHTML(get_text_attr(f, 'path'))
                if not path:
                    continue
                formats = self._extract_m3u8_formats(
                    path, video_id, 'mp4', entry_protocol='m3u8_native',
                    m3u8_id='hls') if determine_ext(path) == 'm3u8' else [{'url': path, }]
            self._sort_formats(formats)
            entries.append({
                'id': '%s_%d' % (video_id, partnum + 1),
                'title': (
                    title if len(files) == 1 else
                    '%s part %d' % (title, partnum + 1)),
                'formats': formats,
                'description': description,
                'thumbnail': thumbnail,
                'duration': int_or_none(get_text_attr(f, 'length')),
                'subtitles': {
                    'en': [{
                        'url': capfile,
                        'ext': determine_ext(capfile, 'dfxp')
                    }],
                } if capfile else None,
            })

        if len(entries) == 1:
            entry = dict(entries[0])
            entry['id'] = 'c' + video_id if video_type == 'clip' else video_id
            return entry
        else:
            return {
                '_type': 'playlist',
                'entries': entries,
                'title': title,
                'id': 'c' + video_id if video_type == 'clip' else video_id,
            }","video_id = self._match_id(url)
video_type = None","video_id, video_type= self._match_id(url), None","video_id = zejun1
video_type = zejun2",Cannot refactor,-1,1,,,
mayavi,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/mayavi/mayavi/tools/helper_functions.py,https://github.com/enthought/mayavi/tree/master/mayavi/tools/helper_functions.py,,test_mesh$881,"def test_mesh():
    """"""A very pretty picture of spherical harmonics translated from
    the octaviz example.""""""
    pi = np.pi
    cos = np.cos
    sin = np.sin
    dphi, dtheta = pi / 250.0, pi / 250.0
    [phi, theta] = np.mgrid[0:pi + dphi * 1.5:dphi,
                            0:2 * pi + dtheta * 1.5:dtheta]
    m0 = 4
    m1 = 3
    m2 = 2
    m3 = 3
    m4 = 6
    m5 = 2
    m6 = 6
    m7 = 4
    r = sin(m0 * phi) ** m1 + cos(m2 * phi) ** m3 + \
        sin(m4 * theta) ** m5 + cos(m6 * theta) ** m7
    x = r * sin(phi) * cos(theta)
    y = r * cos(phi)
    z = r * sin(phi) * sin(theta)

    return mesh(x, y, z, colormap=""bone"")","[phi, theta] = np.mgrid[0:pi + dphi * 1.5:dphi, 0:2 * pi + dtheta * 1.5:dtheta]
m0 = 4
m1 = 3
m2 = 2
m3 = 3
m4 = 6
m5 = 2
m6 = 6
m7 = 4","[phi, theta], m0, m1, m2, m3, m4, m5, m6, m7 = np.mgrid[0:pi + dphi * 1.5:dphi, 0:2 * pi + dtheta * 1.5:dtheta], 4, 3, 2, 3, 6, 2, 6, 4","[phi, theta] = zejun1
m0 = zejun2
m1 = zejun3
m2 = zejun4
m3 = zejun5
m4 = zejun6
m5 = zejun7
m6 = zejun8
m7 = zejun9",Cannot refactor,-1,1,,,
mayavi,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/mayavi/mayavi/tools/helper_functions.py,https://github.com/enthought/mayavi/tree/master/mayavi/tools/helper_functions.py,,test_mesh$881,"def test_mesh():
    """"""A very pretty picture of spherical harmonics translated from
    the octaviz example.""""""
    pi = np.pi
    cos = np.cos
    sin = np.sin
    dphi, dtheta = pi / 250.0, pi / 250.0
    [phi, theta] = np.mgrid[0:pi + dphi * 1.5:dphi,
                            0:2 * pi + dtheta * 1.5:dtheta]
    m0 = 4
    m1 = 3
    m2 = 2
    m3 = 3
    m4 = 6
    m5 = 2
    m6 = 6
    m7 = 4
    r = sin(m0 * phi) ** m1 + cos(m2 * phi) ** m3 + \
        sin(m4 * theta) ** m5 + cos(m6 * theta) ** m7
    x = r * sin(phi) * cos(theta)
    y = r * cos(phi)
    z = r * sin(phi) * sin(theta)

    return mesh(x, y, z, colormap=""bone"")","cos = np.cos
sin = np.sin
(dphi, dtheta) = (pi / 250.0, pi / 250.0)","cos, sin, (dphi, dtheta) = np.cos, np.sin, (pi / 250.0, pi / 250.0)","cos = zejun1
sin = zejun2
(dphi, dtheta) = zejun3",Cannot refactor,-1,1,,,
lxmert,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/lxmert/src/lxrt/modeling.py,https://github.com/airsplay/lxmert/tree/master/src/lxrt/modeling.py,LXRTXLayer,output_fc$467,"def output_fc(self, lang_input, visn_input):
        # FC layers
        lang_inter_output = self.lang_inter(lang_input)
        visn_inter_output = self.visn_inter(visn_input)

        # Layer output
        lang_output = self.lang_output(lang_inter_output, lang_input)
        visn_output = self.visn_output(visn_inter_output, visn_input)
        return lang_output, visn_output","lang_inter_output = self.lang_inter(lang_input)
visn_inter_output = self.visn_inter(visn_input)","lang_inter_output, visn_inter_output= self.lang_inter(lang_input), self.visn_inter(visn_input)","lang_inter_output = zejun1
visn_inter_output = zejun2",Cannot refactor,-1,1,,,
lxmert,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/lxmert/src/lxrt/modeling.py,https://github.com/airsplay/lxmert/tree/master/src/lxrt/modeling.py,LXRTXLayer,output_fc$467,"def output_fc(self, lang_input, visn_input):
        # FC layers
        lang_inter_output = self.lang_inter(lang_input)
        visn_inter_output = self.visn_inter(visn_input)

        # Layer output
        lang_output = self.lang_output(lang_inter_output, lang_input)
        visn_output = self.visn_output(visn_inter_output, visn_input)
        return lang_output, visn_output","visn_inter_output = self.visn_inter(visn_input)
lang_output = self.lang_output(lang_inter_output, lang_input)","visn_inter_output, lang_output= self.visn_inter(visn_input), self.lang_output(lang_inter_output, lang_input)","visn_inter_output = zejun1
lang_output = zejun2",Cannot refactor,-1,1,,,
FasterSeg,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/FasterSeg/search/dataloader.py,https://github.com/VITA-Group/FasterSeg/tree/master/search/dataloader.py,TrainPre,__call__$14,"def __call__(self, img, gt):
        img, gt = random_mirror(img, gt)
        if self.config.train_scale_array is not None:
            img, gt, scale = random_scale(img, gt, self.config.train_scale_array)

        img = normalize(img, self.img_mean, self.img_std)

        crop_size = (self.config.image_height, self.config.image_width)
        crop_pos = generate_random_crop_pos(img.shape[:2], crop_size)
        p_img, _ = random_crop_pad_to_shape(img, crop_pos, crop_size, 0)
        p_gt, _ = random_crop_pad_to_shape(gt, crop_pos, crop_size, 255)
        p_gt = cv2.resize(p_gt, (self.config.image_width // self.config.gt_down_sampling, self.config.image_height // self.config.gt_down_sampling), interpolation=cv2.INTER_NEAREST)

        p_img = p_img.transpose(2, 0, 1)

        extra_dict = None

        return p_img, p_gt, extra_dict","(p_img, _) = random_crop_pad_to_shape(img, crop_pos, crop_size, 0)
(p_gt, _) = random_crop_pad_to_shape(gt, crop_pos, crop_size, 255)","(p_img, _), (p_gt, _) = random_crop_pad_to_shape(img, crop_pos, crop_size, 0), random_crop_pad_to_shape(gt, crop_pos, crop_size, 255)","(p_img, _) = zejun1
(p_gt, _) = zejun2",Cannot refactor,-1,1,,,
adapter-transformers,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/adapter-transformers/src/transformers/data/datasets/language_modeling.py,https://github.com/Adapter-Hub/adapter-transformers/tree/master/src/transformers/data/datasets/language_modeling.py,TextDatasetForNextSentencePrediction,__init__$353,"def __init__(
        self,
        tokenizer: PreTrainedTokenizer,
        file_path: str,
        block_size: int,
        overwrite_cache=False,
        short_seq_probability=0.1,
        nsp_probability=0.5,
    ):
        warnings.warn(
            DEPRECATION_WARNING.format(
                ""https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py""
            ),
            FutureWarning,
        )
        if not os.path.isfile(file_path):
            raise ValueError(f""Input file path {file_path} not found"")

        self.short_seq_probability = short_seq_probability
        self.nsp_probability = nsp_probability

        directory, filename = os.path.split(file_path)
        cached_features_file = os.path.join(
            directory,
            f""cached_nsp_{tokenizer.__class__.__name__}_{block_size}_{filename}"",
        )

        self.tokenizer = tokenizer

        # Make sure only the first process in distributed training processes the dataset,
        # and the others will use the cache.
        lock_path = cached_features_file + "".lock""

        # Input file format:
        # (1) One sentence per line. These should ideally be actual sentences, not
        # entire paragraphs or arbitrary spans of text. (Because we use the
        # sentence boundaries for the ""next sentence prediction"" task).
        # (2) Blank lines between documents. Document boundaries are needed so
        # that the ""next sentence prediction"" task doesn't span between documents.
        #
        # Example:
        # I am very happy.
        # Here is the second sentence.
        #
        # A new document.

        with FileLock(lock_path):
            if os.path.exists(cached_features_file) and not overwrite_cache:
                start = time.time()
                with open(cached_features_file, ""rb"") as handle:
                    self.examples = pickle.load(handle)
                logger.info(
                    f""Loading features from cached file {cached_features_file} [took %.3f s]"", time.time() - start
                )
            else:
                logger.info(f""Creating features from dataset file at {directory}"")

                self.documents = [[]]
                with open(file_path, encoding=""utf-8"") as f:
                    while True:
                        line = f.readline()
                        if not line:
                            break
                        line = line.strip()

                        # Empty lines are used as document delimiters
                        if not line and len(self.documents[-1]) != 0:
                            self.documents.append([])
                        tokens = tokenizer.tokenize(line)
                        tokens = tokenizer.convert_tokens_to_ids(tokens)
                        if tokens:
                            self.documents[-1].append(tokens)

                logger.info(f""Creating examples from {len(self.documents)} documents."")
                self.examples = []
                for doc_index, document in enumerate(self.documents):
                    self.create_examples_from_document(document, doc_index, block_size)

                start = time.time()
                with open(cached_features_file, ""wb"") as handle:
                    pickle.dump(self.examples, handle, protocol=pickle.HIGHEST_PROTOCOL)
                logger.info(
                    f""Saving features into cached file {cached_features_file} [took {time.time() - start:.3f} s]""
                )","self.short_seq_probability = short_seq_probability
self.nsp_probability = nsp_probability
(directory, filename) = os.path.split(file_path)","self.short_seq_probability, self.nsp_probability, (directory, filename) = short_seq_probability, nsp_probability, os.path.split(file_path)","self.short_seq_probability = zejun1
self.nsp_probability = zejun2
(directory, filename) = zejun3",Cannot refactor,-1,1,,,
adapter-transformers,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/adapter-transformers/src/transformers/data/datasets/language_modeling.py,https://github.com/Adapter-Hub/adapter-transformers/tree/master/src/transformers/data/datasets/language_modeling.py,TextDatasetForNextSentencePrediction,__init__$353,"def __init__(
        self,
        tokenizer: PreTrainedTokenizer,
        file_path: str,
        block_size: int,
        overwrite_cache=False,
        short_seq_probability=0.1,
        nsp_probability=0.5,
    ):
        warnings.warn(
            DEPRECATION_WARNING.format(
                ""https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py""
            ),
            FutureWarning,
        )
        if not os.path.isfile(file_path):
            raise ValueError(f""Input file path {file_path} not found"")

        self.short_seq_probability = short_seq_probability
        self.nsp_probability = nsp_probability

        directory, filename = os.path.split(file_path)
        cached_features_file = os.path.join(
            directory,
            f""cached_nsp_{tokenizer.__class__.__name__}_{block_size}_{filename}"",
        )

        self.tokenizer = tokenizer

        # Make sure only the first process in distributed training processes the dataset,
        # and the others will use the cache.
        lock_path = cached_features_file + "".lock""

        # Input file format:
        # (1) One sentence per line. These should ideally be actual sentences, not
        # entire paragraphs or arbitrary spans of text. (Because we use the
        # sentence boundaries for the ""next sentence prediction"" task).
        # (2) Blank lines between documents. Document boundaries are needed so
        # that the ""next sentence prediction"" task doesn't span between documents.
        #
        # Example:
        # I am very happy.
        # Here is the second sentence.
        #
        # A new document.

        with FileLock(lock_path):
            if os.path.exists(cached_features_file) and not overwrite_cache:
                start = time.time()
                with open(cached_features_file, ""rb"") as handle:
                    self.examples = pickle.load(handle)
                logger.info(
                    f""Loading features from cached file {cached_features_file} [took %.3f s]"", time.time() - start
                )
            else:
                logger.info(f""Creating features from dataset file at {directory}"")

                self.documents = [[]]
                with open(file_path, encoding=""utf-8"") as f:
                    while True:
                        line = f.readline()
                        if not line:
                            break
                        line = line.strip()

                        # Empty lines are used as document delimiters
                        if not line and len(self.documents[-1]) != 0:
                            self.documents.append([])
                        tokens = tokenizer.tokenize(line)
                        tokens = tokenizer.convert_tokens_to_ids(tokens)
                        if tokens:
                            self.documents[-1].append(tokens)

                logger.info(f""Creating examples from {len(self.documents)} documents."")
                self.examples = []
                for doc_index, document in enumerate(self.documents):
                    self.create_examples_from_document(document, doc_index, block_size)

                start = time.time()
                with open(cached_features_file, ""wb"") as handle:
                    pickle.dump(self.examples, handle, protocol=pickle.HIGHEST_PROTOCOL)
                logger.info(
                    f""Saving features into cached file {cached_features_file} [took {time.time() - start:.3f} s]""
                )","cached_features_file = os.path.join(directory, f'cached_nsp_{tokenizer.__class__.__name__}_{block_size}_{filename}')
self.tokenizer = tokenizer","cached_features_file, self.tokenizer = os.path.join(directory, f'cached_nsp_{tokenizer.__class__.__name__}_{block_size}_{filename}'), tokenizer","cached_features_file = zejun1
self.tokenizer = zejun2",Cannot refactor,-1,1,,,
CRNN_Chinese_Characters_Rec,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/CRNN_Chinese_Characters_Rec/lib/core/function.py,https://github.com/Sierkinhane/CRNN_Chinese_Characters_Rec/tree/master/lib/core/function.py,,train$27,"def train(config, train_loader, dataset, converter, model, criterion, optimizer, device, epoch, writer_dict=None, output_dict=None):

    batch_time = AverageMeter()
    data_time = AverageMeter()
    losses = AverageMeter()

    model.train()

    end = time.time()
    for i, (inp, idx) in enumerate(train_loader):
        # measure data time
        data_time.update(time.time() - end)

        labels = utils.get_batch_label(dataset, idx)
        inp = inp.to(device)

        # inference
        preds = model(inp).cpu()

        # compute loss
        batch_size = inp.size(0)
        text, length = converter.encode(labels)                    # length = 涓涓猙atch涓鐨勬诲瓧绗﹂暱搴, text = 涓涓猙atch涓鐨勫瓧绗︽墍瀵瑰簲鐨勪笅鏍
        preds_size = torch.IntTensor([preds.size(0)] * batch_size) # timestep * batchsize
        loss = criterion(preds, text, preds_size, length)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        losses.update(loss.item(), inp.size(0))

        batch_time.update(time.time()-end)
        if i % config.PRINT_FREQ == 0:
            msg = 'Epoch: [{0}][{1}/{2}]\t' \
                  'Time {batch_time.val:.3f}s ({batch_time.avg:.3f}s)\t' \
                  'Speed {speed:.1f} samples/s\t' \
                  'Data {data_time.val:.3f}s ({data_time.avg:.3f}s)\t' \
                  'Loss {loss.val:.5f} ({loss.avg:.5f})\t'.format(
                      epoch, i, len(train_loader), batch_time=batch_time,
                      speed=inp.size(0)/batch_time.val,
                      data_time=data_time, loss=losses)
            print(msg)

            if writer_dict:
                writer = writer_dict['writer']
                global_steps = writer_dict['train_global_steps']
                writer.add_scalar('train_loss', losses.avg, global_steps)
                writer_dict['train_global_steps'] = global_steps + 1

        end = time.time()","preds = model(inp).cpu()
batch_size = inp.size(0)
(text, length) = converter.encode(labels)","preds, batch_size, (text, length) = model(inp).cpu(), inp.size(0), converter.encode(labels)","preds = zejun1
batch_size = zejun2
(text, length) = zejun3",Cannot refactor,-1,1,,,
CRNN_Chinese_Characters_Rec,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/CRNN_Chinese_Characters_Rec/lib/core/function.py,https://github.com/Sierkinhane/CRNN_Chinese_Characters_Rec/tree/master/lib/core/function.py,,train$27,"def train(config, train_loader, dataset, converter, model, criterion, optimizer, device, epoch, writer_dict=None, output_dict=None):

    batch_time = AverageMeter()
    data_time = AverageMeter()
    losses = AverageMeter()

    model.train()

    end = time.time()
    for i, (inp, idx) in enumerate(train_loader):
        # measure data time
        data_time.update(time.time() - end)

        labels = utils.get_batch_label(dataset, idx)
        inp = inp.to(device)

        # inference
        preds = model(inp).cpu()

        # compute loss
        batch_size = inp.size(0)
        text, length = converter.encode(labels)                    # length = 涓涓猙atch涓鐨勬诲瓧绗﹂暱搴, text = 涓涓猙atch涓鐨勫瓧绗︽墍瀵瑰簲鐨勪笅鏍
        preds_size = torch.IntTensor([preds.size(0)] * batch_size) # timestep * batchsize
        loss = criterion(preds, text, preds_size, length)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        losses.update(loss.item(), inp.size(0))

        batch_time.update(time.time()-end)
        if i % config.PRINT_FREQ == 0:
            msg = 'Epoch: [{0}][{1}/{2}]\t' \
                  'Time {batch_time.val:.3f}s ({batch_time.avg:.3f}s)\t' \
                  'Speed {speed:.1f} samples/s\t' \
                  'Data {data_time.val:.3f}s ({data_time.avg:.3f}s)\t' \
                  'Loss {loss.val:.5f} ({loss.avg:.5f})\t'.format(
                      epoch, i, len(train_loader), batch_time=batch_time,
                      speed=inp.size(0)/batch_time.val,
                      data_time=data_time, loss=losses)
            print(msg)

            if writer_dict:
                writer = writer_dict['writer']
                global_steps = writer_dict['train_global_steps']
                writer.add_scalar('train_loss', losses.avg, global_steps)
                writer_dict['train_global_steps'] = global_steps + 1

        end = time.time()","(text, length) = converter.encode(labels)
preds_size = torch.IntTensor([preds.size(0)] * batch_size)","(text, length), preds_size = converter.encode(labels), torch.IntTensor([preds.size(0)] * batch_size)","(text, length) = zejun1
preds_size = zejun2",Cannot refactor,-1,1,,,
thinc,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/thinc/thinc/tests/layers/test_combinators.py,https://github.com/explosion/thinc/tree/master/thinc/tests/layers/test_combinators.py,,test_map_list$271,"def test_map_list():
    nI = 4
    nO = 9
    Xs = [numpy.zeros((6, nI), dtype=""f""), numpy.ones((3, nI), dtype=""f"")]
    Y_shapes = [(x.shape[0], nO) for x in Xs]
    model = map_list(Linear())
    model.initialize(X=Xs, Y=[numpy.zeros(shape, dtype=""f"") for shape in Y_shapes])
    Ys, backprop = model(Xs, is_train=True)
    assert isinstance(Ys, list)
    assert len(Ys) == len(Xs)
    layer = model.layers[0]
    for X, Y in zip(Xs, Ys):
        assert_allclose(layer.predict(X), Y)
    dXs = backprop(Ys)
    assert isinstance(dXs, list)
    assert len(dXs) == len(Xs)
    assert dXs[0].shape == Xs[0].shape
    assert dXs[1].shape == Xs[1].shape","nI = 4
nO = 9","nI, nO = 4, 9","nI = zejun1
nO = zejun2",Cannot refactor,-1,1,,,
salt,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/salt/tests/unit/modules/test_file.py,https://github.com/saltstack/salt/tree/master/tests/unit/modules/test_file.py,FilemodLineTests,test_if_not_location_or_before_but_after_then_line_should_be_inserted_after_after$1883,"def test_if_not_location_or_before_but_after_then_line_should_be_inserted_after_after(
        self,
    ):
        location = before = None
        after = ""indessed""
        content = ""roscivs""
        indent = ""\t\t\t   ""
        original_lines = [""foo"", indent + after, ""bar""]
        expected_lines = [""foo"", indent + after, indent + content, ""bar""]

        actual_lines = filemod._set_line(
            lines=original_lines,
            content=content,
            mode=""insert"",
            location=location,
            before=before,
            after=after,
        )

        self.assertEqual(actual_lines, expected_lines)","location = before = None
after = 'indessed'
content = 'roscivs'
indent = '\t\t\t   '","location = before = None; after, content, indent = 'indessed', 'roscivs', '\t\t\t   '","location = before = zejun1
after = zejun2
content = zejun3
indent = zejun4",Cannot refactor,-1,1,,,
super-resolution,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/super-resolution/VDSR/solver.py,https://github.com/icpm/super-resolution/tree/master/VDSR/solver.py,VDSRTrainer,img_preprocess$44,"def img_preprocess(self, data, interpolation='bicubic'):
        if interpolation == 'bicubic':
            interpolation = Image.BICUBIC
        elif interpolation == 'bilinear':
            interpolation = Image.BILINEAR
        elif interpolation == 'nearest':
            interpolation = Image.NEAREST

        size = list(data.shape)

        if len(size) == 4:
            target_height = int(size[2] * self.upscale_factor)
            target_width = int(size[3] * self.upscale_factor)
            out_data = torch.FloatTensor(size[0], size[1], target_height, target_width)
            for i, img in enumerate(data):
                transform = transforms.Compose([transforms.ToPILImage(),
                                                transforms.Resize((target_width, target_height), interpolation=interpolation),
                                                transforms.ToTensor()])

                out_data[i, :, :, :] = transform(img)
            return out_data
        else:
            target_height = int(size[1] * self.upscale_factor)
            target_width = int(size[2] * self.upscale_factor)
            transform = transforms.Compose([transforms.ToPILImage(),
                                            transforms.Resize((target_width, target_height), interpolation=interpolation),
                                            transforms.ToTensor()])
            return transform(data)","target_height = int(size[1] * self.upscale_factor)
target_width = int(size[2] * self.upscale_factor)","target_height, target_width= int(size[1] * self.upscale_factor), int(size[2] * self.upscale_factor)","target_height = zejun1
target_width = zejun2",Cannot refactor,-1,1,,,
torchdiffeq,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/torchdiffeq/torchdiffeq/_impl/solvers.py,https://github.com/rtqichen/torchdiffeq/tree/master/torchdiffeq/_impl/solvers.py,FixedGridODESolver,integrate_until_event$130,"def integrate_until_event(self, t0, event_fn):
        assert self.step_size is not None, ""Event handling for fixed step solvers currently requires `step_size` to be provided in options.""

        t0 = t0.type_as(self.y0)
        y0 = self.y0
        dt = self.step_size

        sign0 = torch.sign(event_fn(t0, y0))
        max_itrs = 20000
        itr = 0
        while True:
            itr += 1
            t1 = t0 + dt
            dy, f0 = self._step_func(self.func, t0, dt, t1, y0)
            y1 = y0 + dy

            sign1 = torch.sign(event_fn(t1, y1))

            if sign0 != sign1:
                if self.interp == ""linear"":
                    interp_fn = lambda t: self._linear_interp(t0, t1, y0, y1, t)
                elif self.interp == ""cubic"":
                    f1 = self.func(t1, y1)
                    interp_fn = lambda t: self._cubic_hermite_interp(t0, y0, f0, t1, y1, f1, t)
                else:
                    raise ValueError(f""Unknown interpolation method {self.interp}"")
                event_time, y1 = find_event(interp_fn, sign0, t0, t1, event_fn, float(self.atol))
                break
            else:
                t0, y0 = t1, y1

            if itr >= max_itrs:
                raise RuntimeError(f""Reached maximum number of iterations {max_itrs}."")
        solution = torch.stack([self.y0, y1], dim=0)
        return event_time, solution","t0 = t0.type_as(self.y0)
y0 = self.y0
dt = self.step_size","t0, y0, dt = t0.type_as(self.y0), self.y0, self.step_size","t0 = zejun1
y0 = zejun2
dt = zejun3",Cannot refactor,-1,1,,,
video-classification-3d-cnn-pytorch,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/video-classification-3d-cnn-pytorch/spatial_transforms.py,https://github.com/kenshohara/video-classification-3d-cnn-pytorch/tree/master//spatial_transforms.py,CenterCrop,__call__$164,"def __call__(self, img):
        """"""
        Args:
            img (PIL.Image): Image to be cropped.
        Returns:
            PIL.Image: Cropped image.
        """"""
        w, h = img.size
        th, tw = self.size
        x1 = int(round((w - tw) / 2.))
        y1 = int(round((h - th) / 2.))
        return img.crop((x1, y1, x1 + tw, y1 + th))","(w, h) = img.size
(th, tw) = self.size","(w, h), (th, tw) = img.size, self.size","(w, h) = zejun1
(th, tw) = zejun2",Cannot refactor,-1,1,,,
Machine-Learning-Collection,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/Machine-Learning-Collection/ML/Projects/DeepSort/utils.py,https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/Projects/DeepSort/utils.py,,sort_array$10,"def sort_array(encoder, decoder, device, arr=None):
    """"""
    A very simple example of use of the model
    Input: encoder nn.Module
           decoder nn.Module
           device
           array to sort (optional)
    """"""

    if arr is None:
        arr = ask_user()

    with torch.no_grad():
        while arr != ""q"":
            # Avoid numerical errors by rounding to max_len
            arr = eval(arr)
            lengths = [
                len(str(elem).split(""."")[1]) if len(str(elem).split(""."")) > 1 else 0
                for elem in arr
            ]
            max_len = max(lengths)
            source = torch.tensor(arr, dtype=torch.float).to(device).unsqueeze(1)
            batch_size = source.shape[1]
            target_len = source.shape[0] + 1

            outputs = torch.zeros(target_len, batch_size, target_len - 1).to(device)
            encoder_states, hidden, cell = encoder(source)

            # First input will be <SOS> token
            x = torch.tensor([-1], dtype=torch.float).to(device)
            predictions = torch.zeros((target_len)).to(device)

            for t in range(1, target_len):
                # At every time step use encoder_states and update hidden, cell
                attention, energy, hidden, cell = decoder(
                    x, encoder_states, hidden, cell
                )

                # Store prediction for current time step
                outputs[t] = energy.permute(1, 0)

                # Get the best word the Decoder predicted (index in the vocabulary)
                best_guess = attention.argmax(0)
                predictions[t] = best_guess.item()
                x = torch.tensor([best_guess.item()], dtype=torch.float).to(device)

            output = [
                round(source[predictions[1:].long()][i, :].item(), max_len)
                for i in range(source.shape[0])
            ]

            print(f""Here's the result: {output}"")
            arr = ask_user()","outputs = torch.zeros(target_len, batch_size, target_len - 1).to(device)
(encoder_states, hidden, cell) = encoder(source)
x = torch.tensor([-1], dtype=torch.float).to(device)
predictions = torch.zeros(target_len).to(device)","outputs, (encoder_states, hidden, cell), x, predictions = torch.zeros(target_len, batch_size, target_len - 1).to(device), encoder(source), torch.tensor([-1], dtype=torch.float).to(device), torch.zeros(target_len).to(device)","outputs = zejun1
(encoder_states, hidden, cell) = zejun2
x = zejun3
predictions = zejun4",Cannot refactor,-1,1,,,
rotki,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/rotki/rotkehlchen/tests/api/test_exchanges.py,https://github.com/rotki/rotki/tree/master/rotkehlchen/tests/api/test_exchanges.py,,test_exchange_query_balances$482,"def test_exchange_query_balances(rotkehlchen_api_server_with_exchanges):
    """"""Test that using the exchange balances query endpoint works fine""""""
    async_query = random.choice([False, True])
    rotki = rotkehlchen_api_server_with_exchanges.rest_api.rotkehlchen
    # query balances of one specific exchange
    server = rotkehlchen_api_server_with_exchanges
    binance = try_get_first_exchange(rotki.exchange_manager, Location.BINANCE)

    binance_patch = patch_binance_balances_query(binance)
    with binance_patch:
        response = requests.get(api_url_for(
            server,
            'named_exchanges_balances_resource',
            location='binance',
        ), json={'async_query': async_query})
        if async_query:
            task_id = assert_ok_async_response(response)
            outcome = wait_for_async_task_with_result(server, task_id)
        else:
            outcome = assert_proper_response_with_result(response)
    assert_binance_balances_result(outcome)

    # query balances of all setup exchanges
    poloniex = try_get_first_exchange(rotki.exchange_manager, Location.POLONIEX)
    poloniex_patch = patch_poloniex_balances_query(poloniex)
    with binance_patch, poloniex_patch:
        response = requests.get(
            api_url_for(server, 'exchangebalancesresource'),
            json={'async_query': async_query},
        )
        if async_query:
            task_id = assert_ok_async_response(response)
            result = wait_for_async_task_with_result(server, task_id)
        else:
            result = assert_proper_response_with_result(response)

    assert_binance_balances_result(result['binance'])
    assert_poloniex_balances_result(result['poloniex'])","async_query = random.choice([False, True])
rotki = rotkehlchen_api_server_with_exchanges.rest_api.rotkehlchen
server = rotkehlchen_api_server_with_exchanges","async_query, rotki, server = random.choice([False, True]), rotkehlchen_api_server_with_exchanges.rest_api.rotkehlchen, rotkehlchen_api_server_with_exchanges","async_query = zejun1
rotki = zejun2
server = zejun3",Cannot refactor,-1,1,,,
hand-graph-cnn,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/hand-graph-cnn/hand_shape_pose/data/dataset/STB_dataset.py,https://github.com/3d-hand-shape/hand-graph-cnn/tree/master/hand_shape_pose/data/dataset/STB_dataset.py,,SK_rot_mx$35,"def SK_rot_mx(rot_vec):
    """"""
    use Rodrigues' rotation formula to transform the rotation vector into rotation matrix
    :param rot_vec:
    :return:
    """"""
    theta = LA.norm(rot_vec)
    vector = np.array(rot_vec) * math.sin(theta / 2.0) / theta
    a = math.cos(theta / 2.0)
    b = -vector[0]
    c = -vector[1]
    d = -vector[2]
    return np.array([[a * a + b * b - c * c - d * d, 2 * (b * c + a * d), 2 * (b * d - a * c)],
                     [2 * (b * c - a * d), a * a + c * c - b * b - d * d, 2 * (c * d + a * b)],
                     [2 * (b * d + a * c), 2 * (c * d - a * b), a * a + d * d - b * b - c * c]])","vector = np.array(rot_vec) * math.sin(theta / 2.0) / theta
a = math.cos(theta / 2.0)","vector, a = np.array(rot_vec) * math.sin(theta / 2.0) / theta, math.cos(theta / 2.0)","vector = zejun1
a = zejun2",Cannot refactor,-1,1,,,
espnet,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/espnet/espnet2/gan_tts/joint/joint_text2wav.py,https://github.com/espnet/espnet/tree/master/espnet2/gan_tts/joint/joint_text2wav.py,JointText2Wav,_forward_discrminator$511,"def _forward_discrminator(
        self,
        text: torch.Tensor,
        text_lengths: torch.Tensor,
        feats: torch.Tensor,
        feats_lengths: torch.Tensor,
        speech: torch.Tensor,
        speech_lengths: torch.Tensor,
        **kwargs,
    ) -> Dict[str, Any]:
        """"""Perform discriminator forward.

        Args:
            text (Tensor): Text index tensor (B, T_text).
            text_lengths (Tensor): Text length tensor (B,).
            feats (Tensor): Feature tensor (B, T_feats, aux_channels).
            feats_lengths (Tensor): Feature length tensor (B,).
            speech (Tensor): Speech waveform tensor (B, T_wav).
            speech_lengths (Tensor): Speech length tensor (B,).

        Returns:
            Dict[str, Any]:
                * loss (Tensor): Loss scalar tensor.
                * stats (Dict[str, float]): Statistics to be monitored.
                * weight (Tensor): Weight tensor to summarize losses.
                * optim_idx (int): Optimizer index (0 for G and 1 for D).

        """"""
        # setup
        batch_size = text.size(0)
        speech = speech.unsqueeze(1)

        # calculate generator outputs
        reuse_cache = True
        if not self.cache_generator_outputs or self._cache is None:
            reuse_cache = False
            # calculate text2mel outputs
            text2mel_loss, stats, feats_gen = self.generator[""text2mel""](
                text=text,
                text_lengths=text_lengths,
                feats=feats,
                feats_lengths=feats_lengths,
                joint_training=True,
                **kwargs,
            )
            # get random segments
            feats_gen_, start_idxs = get_random_segments(
                x=feats_gen.transpose(1, 2),
                x_lengths=feats_lengths,
                segment_size=self.segment_size,
            )
            # calculate vocoder outputs
            speech_hat_ = self.generator[""vocoder""](feats_gen_)
            if self.use_pqmf:
                speech_hat_ = self.pqmf.synthesis(speech_hat_)
        else:
            _, _, speech_hat_, start_idxs = self._cache

        # store cache
        if self.cache_generator_outputs and not reuse_cache:
            self._cache = (text2mel_loss, stats, speech_hat_, start_idxs)

        # parse outputs
        speech_ = get_segments(
            x=speech,
            start_idxs=start_idxs * self.generator[""vocoder""].upsample_factor,
            segment_size=self.segment_size * self.generator[""vocoder""].upsample_factor,
        )

        # calculate discriminator outputs
        p_hat = self.discriminator(speech_hat_.detach())
        p = self.discriminator(speech_)

        # calculate losses
        real_loss, fake_loss = self.discriminator_adv_loss(p_hat, p)
        loss = real_loss + fake_loss

        stats = dict(
            discriminator_loss=loss.item(),
            real_loss=real_loss.item(),
            fake_loss=fake_loss.item(),
        )
        loss, stats, weight = force_gatherable((loss, stats, batch_size), loss.device)

        # reset cache
        if reuse_cache or not self.training:
            self._cache = None

        return {
            ""loss"": loss,
            ""stats"": stats,
            ""weight"": weight,
            ""optim_idx"": 1,  # needed for trainer
        }","speech_ = get_segments(x=speech, start_idxs=start_idxs * self.generator['vocoder'].upsample_factor, segment_size=self.segment_size * self.generator['vocoder'].upsample_factor)
p_hat = self.discriminator(speech_hat_.detach())","speech_, p_hat= get_segments(x=speech, start_idxs=start_idxs * self.generator['vocoder'].upsample_factor, segment_size=self.segment_size * self.generator['vocoder'].upsample_factor), self.discriminator(speech_hat_.detach())","speech_ = zejun1
p_hat = zejun2",Cannot refactor,-1,1,,,
unilm,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/unilm/xtune/src/transformers/data/processors/xtreme.py,https://github.com/microsoft/unilm/tree/master/xtune/src/transformers/data/processors/xtreme.py,,xtreme_convert_examples_to_features$31,"def xtreme_convert_examples_to_features(
        examples,
        tokenizer,
        max_length=512,
        task=None,
        label_list=None,
        output_mode=None,
        pad_on_left=False,
        pad_token=0,
        pad_token_segment_id=0,
        mask_padding_with_zero=True,
        word_dropout_rate=0.0,
):
    """"""
    Loads a data file into a list of ``InputFeatures``

    Args:
        examples: List of ``InputExamples`` or ``tf.data.Dataset`` containing the examples.
        tokenizer: Instance of a tokenizer that will tokenize the examples
        max_length: Maximum example length
        task: GLUE task
        label_list: List of labels. Can be obtained from the processor using the ``processor.get_labels()`` method
        output_mode: String indicating the output mode. Either ``regression`` or ``classification``
        pad_on_left: If set to ``True``, the examples will be padded on the left rather than on the right (default)
        pad_token: Padding token
        pad_token_segment_id: The segment ID for the padding token (It is usually 0, but can vary such as for XLNet where it is 4)
        mask_padding_with_zero: If set to ``True``, the attention mask will be filled by ``1`` for actual values
            and by ``0`` for padded values. If set to ``False``, inverts it (``1`` for padded values, ``0`` for
            actual values)

    Returns:
        If the ``examples`` input is a ``tf.data.Dataset``, will return a ``tf.data.Dataset``
        containing the task-specific features. If the input is a list of ``InputExamples``, will return
        a list of task-specific ``InputFeatures`` which can be fed to the model.

    """"""
    is_tf_dataset = False
    if is_tf_available() and isinstance(examples, tf.data.Dataset):
        is_tf_dataset = True

    if task is not None:
        processor = xtreme_processors[task]()
        if label_list is None:
            label_list = processor.get_labels()
            logger.info(""Using label list %s for task %s"" % (label_list, task))
        if output_mode is None:
            output_mode = xtreme_output_modes[task]
            logger.info(""Using output mode %s for task %s"" % (output_mode, task))

    label_map = {label: i for i, label in enumerate(label_list)}

    features = []
    for (ex_index, example) in enumerate(examples):
        len_examples = 0
        if is_tf_dataset:
            example = processor.get_example_from_tensor_dict(example)
            example = processor.tfds_map(example)
            len_examples = tf.data.experimental.cardinality(examples)
        else:
            len_examples = len(examples)
        if ex_index % 10000 == 0:
            logger.info(""Writing example %d/%d"" % (ex_index, len_examples))

        inputs = tokenizer.encode_plus(example.text_a, example.text_b, add_special_tokens=True, max_length=max_length, word_dropout_rate=word_dropout_rate,)
        input_ids, token_type_ids = inputs[""input_ids""], inputs[""token_type_ids""]

        # The mask has 1 for real tokens and 0 for padding tokens. Only real
        # tokens are attended to.
        attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)

        # Zero-pad up to the sequence length.
        padding_length = max_length - len(input_ids)
        if pad_on_left:
            input_ids = ([pad_token] * padding_length) + input_ids
            attention_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + attention_mask
            token_type_ids = ([pad_token_segment_id] * padding_length) + token_type_ids
        else:
            input_ids = input_ids + ([pad_token] * padding_length)
            attention_mask = attention_mask + ([0 if mask_padding_with_zero else 1] * padding_length)
            token_type_ids = token_type_ids + ([pad_token_segment_id] * padding_length)

        assert len(input_ids) == max_length, ""Error with input length {} vs {}"".format(len(input_ids), max_length)
        assert len(attention_mask) == max_length, ""Error with input length {} vs {}"".format(
            len(attention_mask), max_length
        )
        assert len(token_type_ids) == max_length, ""Error with input length {} vs {}"".format(
            len(token_type_ids), max_length
        )

        if output_mode == ""classification"":
            label = label_map[example.label]
        elif output_mode == ""regression"":
            label = float(example.label)
        else:
            raise KeyError(output_mode)

        if ex_index < 5:
            logger.info(""*** Example ***"")
            logger.info(""guid: %s"" % (example.guid))
            logger.info(""text a: %s"" % (example.text_a))
            logger.info(""text b: %s"" % (example.text_b))
            logger.info(""input_ids: %s"" % "" "".join([str(x) for x in input_ids]))
            logger.info(""attention_mask: %s"" % "" "".join([str(x) for x in attention_mask]))
            logger.info(""token_type_ids: %s"" % "" "".join([str(x) for x in token_type_ids]))
            logger.info(""label: %s (id = %d)"" % (example.label, label))

        features.append(
            InputFeatures(
                input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=label,
                guid=example.guid
            )
        )

    if is_tf_available() and is_tf_dataset:

        def gen():
            for ex in features:
                yield (
                    {
                        ""input_ids"": ex.input_ids,
                        ""attention_mask"": ex.attention_mask,
                        ""token_type_ids"": ex.token_type_ids,
                    },
                    ex.label,
                )

        return tf.data.Dataset.from_generator(
            gen,
            ({""input_ids"": tf.int32, ""attention_mask"": tf.int32, ""token_type_ids"": tf.int32}, tf.int64),
            (
                {
                    ""input_ids"": tf.TensorShape([None]),
                    ""attention_mask"": tf.TensorShape([None]),
                    ""token_type_ids"": tf.TensorShape([None]),
                },
                tf.TensorShape([]),
            ),
        )

    return features","input_ids = input_ids + [pad_token] * padding_length
attention_mask = attention_mask + [0 if mask_padding_with_zero else 1] * padding_length
token_type_ids = token_type_ids + [pad_token_segment_id] * padding_length","input_ids, attention_mask, token_type_ids = input_ids + [pad_token] * padding_length, attention_mask + [0 if mask_padding_with_zero else 1] * padding_length, token_type_ids + [pad_token_segment_id] * padding_length","input_ids = zejun1
attention_mask = zejun2
token_type_ids = zejun3",Cannot refactor,-1,1,,,
deprecated-binaryninja-python,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/deprecated-binaryninja-python/Analysis.py,https://github.com/Vector35/deprecated-binaryninja-python/tree/master//Analysis.py,X86Instruction,format_text$82,"def format_text(self, block, options):
		old_lines = []
		old_tokens = []
		self.text.lines = []
		self.text.tokens = []

		line = []
		tokens = []
		x = 0
		instr = self.disasm

		if ""address"" in options:
			string = ""%.8x   "" % self.addr
			line += [[string, QColor(0, 0, 128)]]
			x += len(string)

		if instr.operation == None:
			line += [[""??"", Qt.black]]
			self.text.lines += [line]
			self.text.tokens += [tokens]
			return (old_lines != self.text.lines) or (old_tokens != self.text.tokens)

		result = """"
		operation = """"
		if instr.flags & X86.FLAG_LOCK:
			operation += ""lock ""
		if instr.flags & X86.FLAG_ANY_REP:
			operation += ""rep""
			if instr.flags & X86.FLAG_REPNE:
				operation += ""ne""
			elif instr.flags & X86.FLAG_REPE:
				operation += ""e""
			operation += "" ""
		operation += instr.operation
		if len(operation) < 7:
			operation += "" "" * (7 - len(operation))
		result += operation + "" ""

		for j in range(0, len(instr.operands)):
			if j != 0:
				result += "", ""
			if instr.operands[j].operand == ""imm"":
				value = instr.operands[j].immediate & ((1 << (instr.operands[j].size * 8)) - 1)
				numfmt = ""0x%%.%dx"" % (instr.operands[j].size * 2)
				string = numfmt % value
				if (instr.operands[j].size == self.addr_size) and (block.analysis.functions.has_key(value)):
					# Pointer to existing function
					func = block.analysis.functions[value]
					string = func.name
					if func.plt:
						color = QColor(192, 0, 192)
					else:
						color = QColor(0, 0, 192)
					if len(result) > 0:
						line += [[result, Qt.black]]
						x += len(result)
						result = """"
					line += [[string, color]]
					tokens += [[x, len(string), ""ptr"", value, string]]
					x += len(string)
				elif (instr.operands[j].size == self.addr_size) and (value >= block.exe.start()) and (value < block.exe.end()) and (not self.isLocalJump()):
					# Pointer within module
					if len(result) > 0:
						line += [[result, Qt.black]]
						x += len(result)
						result = """"
					if value in block.exe.symbols_by_addr:
						string = block.exe.symbols_by_addr[value]
					line += [[string, QColor(0, 0, 192)]]
					tokens += [[x, len(string), ""ptr"", value, string]]
					x += len(string)
				else:
					result += string
			elif instr.operands[j].operand == ""mem"":
				plus = False
				result += X86.get_size_string(instr.operands[j].size)
				if (instr.segment != None) or (instr.operands[j].segment == ""es""):
					result += instr.operands[j].segment + "":""
				result += '['
				if instr.operands[j].components[0] != None:
					tokens += [[x + len(result), len(instr.operands[j].components[0]), ""reg"", instr.operands[j].components[0]]]
					result += instr.operands[j].components[0]
					plus = True
				if instr.operands[j].components[1] != None:
					if plus:
						tokens += [[x + len(result) + 1, len(instr.operands[j].components[1]), ""reg"", instr.operands[j].components[1]]]
					else:
						tokens += [[x + len(result), len(instr.operands[j].components[1]), ""reg"", instr.operands[j].components[1]]]
					result += X86.get_operand_string(instr.operands[j].components[1],
						instr.operands[j].scale, plus)
					plus = True
				if (instr.operands[j].immediate != 0) or ((instr.operands[j].components[0] == None) and (instr.operands[j].components[1] == None)):
					if plus and (instr.operands[j].immediate >= -0x80) and (instr.operands[j].immediate < 0):
						result += '-'
						result += ""0x%.2x"" % (-instr.operands[j].immediate)
					elif plus and (instr.operands[j].immediate > 0) and (instr.operands[j].immediate <= 0x7f):
						result += '+'
						result += ""0x%.2x"" % instr.operands[j].immediate
					elif plus and (instr.operands[j].immediate >= -0x8000) and (instr.operands[j].immediate < 0):
						result += '-'
						result += ""0x%.8x"" % (-instr.operands[j].immediate)
					elif instr.flags & X86.FLAG_64BIT_ADDRESS:
						if plus:
							result += '+'
						value = instr.operands[j].immediate
						string = ""0x%.16x"" % instr.operands[j].immediate
						if hasattr(block.exe, ""plt"") and block.exe.plt.has_key(value):
							# Pointer to PLT entry
							self.plt = block.exe.plt[value]
							if len(result) > 0:
								line += [[result, Qt.black]]
								x += len(result)
								result = """"
							string = self.plt + ""@PLT""
							line += [[string, QColor(0, 0, 192)]]
							tokens += [[x, len(string), ""ptr"", value, string]]
							x += len(string)
						elif (value >= block.exe.start()) and (value < block.exe.end()):
							# Pointer within module
							if len(result) > 0:
								line += [[result, Qt.black]]
								x += len(result)
								result = """"
							if value in block.exe.symbols_by_addr:
								string = block.exe.symbols_by_addr[value]
							line += [[string, QColor(0, 0, 192)]]
							tokens += [[x, len(string), ""ptr"", value, string]]
							x += len(string)
						else:
							result += string
					else:
						if plus:
							result += '+'
						value = instr.operands[j].immediate & 0xffffffff
						string = ""0x%.8x"" % value
						if (self.addr_size == 4) and hasattr(block.exe, ""plt"") and block.exe.plt.has_key(value):
							# Pointer to PLT entry
							self.plt = block.exe.plt[value]
							if len(result) > 0:
								line += [[result, Qt.black]]
								x += len(result)
								result = """"
							string = block.exe.decorate_plt_name(self.plt)
							line += [[string, QColor(0, 0, 192)]]
							tokens += [[x, len(string), ""ptr"", value, string]]
							x += len(string)
						elif (self.addr_size == 4) and (value >= block.exe.start()) and (value < block.exe.end()):
							# Pointer within module
							if len(result) > 0:
								line += [[result, Qt.black]]
								x += len(result)
								result = """"
							if value in block.exe.symbols_by_addr:
								string = block.exe.symbols_by_addr[value]
							line += [[string, QColor(0, 0, 192)]]
							tokens += [[x, len(string), ""ptr"", value, string]]
							x += len(string)
						else:
							result += string
				result += ']'
			else:
				tokens += [[x + len(result), len(instr.operands[j].operand), ""reg"", instr.operands[j].operand]]
				result += instr.operands[j].operand

		if len(result) > 0:
			line += [[result, Qt.black]]
		self.text.lines += [line]
		self.text.tokens += [tokens]

		return (old_lines != self.text.lines) or (old_tokens != self.text.tokens)","line = []
tokens = []
x = 0
instr = self.disasm","line, tokens, x, instr = [], [], 0, self.disasm","line = zejun1
tokens = zejun2
x = zejun3
instr = zejun4",Cannot refactor,-1,1,,,
imaginaire,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/imaginaire/imaginaire/datasets/paired_videos.py,https://github.com/NVlabs/imaginaire/tree/master/imaginaire/datasets/paired_videos.py,Dataset,_create_mapping$116,"def _create_mapping(self):
        r""""""Creates mapping from idx to key in LMDB.

        Returns:
            (tuple):
              - self.mapping (dict): Dict of seq_len to list of sequences.
              - self.epoch_length (int): Number of samples in an epoch.
        """"""
        # Create dict mapping length to sequence.
        length_to_key, num_selected_seq = {}, 0
        total_num_of_frames = 0
        for lmdb_idx, sequence_list in enumerate(self.sequence_lists):
            for sequence_name, filenames in sequence_list.items():
                if len(filenames) >= self.sequence_length:
                    total_num_of_frames += len(filenames)
                    if len(filenames) not in length_to_key:
                        length_to_key[len(filenames)] = []
                    length_to_key[len(filenames)].append({
                        'lmdb_root': self.lmdb_roots[lmdb_idx],
                        'lmdb_idx': lmdb_idx,
                        'sequence_name': sequence_name,
                        'filenames': filenames,
                    })
                    num_selected_seq += 1
        self.mapping = length_to_key
        self.epoch_length = num_selected_seq
        if not self.is_inference and self.epoch_length < \
                self.cfgdata.train.batch_size * 8:
            self.epoch_length = total_num_of_frames

        # At inference time, we want to use all sequences,
        # irrespective of length.
        if self.is_inference:
            sequence_list = []
            for key, sequences in self.mapping.items():
                sequence_list.extend(sequences)
            self.mapping = sequence_list

        return self.mapping, self.epoch_length","(length_to_key, num_selected_seq) = ({}, 0)
total_num_of_frames = 0","(length_to_key, num_selected_seq, total_num_of_frames) = ({}, 0) + (0,)","(length_to_key, num_selected_seq) = zejun1
total_num_of_frames = zejun2",Cannot refactor,-1,1,,,
satpy,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/satpy/satpy/readers/yaml_reader.py,https://github.com/pytroll/satpy/tree/master/satpy/readers/yaml_reader.py,,_set_orientation$979,"def _set_orientation(dataset, upper_right_corner):
    """"""Set the orientation of geostationary datasets.

    Allows to flip geostationary imagery when loading the datasets.
    Example call: scn.load(['VIS008'], upper_right_corner='NE')

    Args:
        dataset: Dataset to be flipped.
        upper_right_corner (str): Direction of the upper right corner of the image after flipping.
                                Possible options are 'NW', 'NE', 'SW', 'SE', or 'native'.
                                The common upright image orientation corresponds to 'NE'.
                                Defaults to 'native' (no flipping is applied).

    """"""
    # do some checks and early returns
    if upper_right_corner == 'native':
        logger.debug(""Requested orientation for Dataset {} is 'native' (default). ""
                     ""No flipping is applied."".format(dataset.attrs.get('name')))
        return dataset

    if upper_right_corner not in ['NW', 'NE', 'SE', 'SW', 'native']:
        raise ValueError(""Target orientation for Dataset {} not recognized. ""
                         ""Kwarg upper_right_corner should be ""
                         ""'NW', 'NE', 'SW', 'SE' or 'native'."".format(dataset.attrs.get('name', 'unknown_name')))

    if 'area' not in dataset.attrs:
        logger.info(""Dataset {} is missing the area attribute ""
                    ""and will not be flipped."".format(dataset.attrs.get('name', 'unknown_name')))
        return dataset

    if isinstance(dataset.attrs['area'], SwathDefinition):
        logger.info(""Dataset {} is in a SwathDefinition ""
                    ""and will not be flipped."".format(dataset.attrs.get('name', 'unknown_name')))
        return dataset

    projection_type = _get_projection_type(dataset.attrs['area'])
    accepted_geos_proj_types = ['Geostationary Satellite (Sweep Y)', 'Geostationary Satellite (Sweep X)']
    if projection_type not in accepted_geos_proj_types:
        logger.info(""Dataset {} is not in one of the known geostationary projections {} ""
                    ""and cannot be flipped."".format(dataset.attrs.get('name', 'unknown_name'),
                                                    accepted_geos_proj_types))
        return dataset

    target_eastright, target_northup = _get_target_scene_orientation(upper_right_corner)

    area_extents_to_update = _get_dataset_area_extents_array(dataset.attrs['area'])
    current_eastright, current_northup = _get_current_scene_orientation(area_extents_to_update)

    if target_northup == current_northup and target_eastright == current_eastright:
        logger.info(""Dataset {} is already in the target orientation ""
                    ""and will not be flipped."".format(dataset.attrs.get('name', 'unknown_name')))
        return dataset

    if target_northup != current_northup:
        dataset, area_extents_to_update = _flip_dataset_data_and_area_extents(dataset, area_extents_to_update,
                                                                              'upsidedown')
    if target_eastright != current_eastright:
        dataset, area_extents_to_update = _flip_dataset_data_and_area_extents(dataset, area_extents_to_update,
                                                                              'leftright')

    dataset.attrs['area'] = _get_new_flipped_area_definition(dataset.attrs['area'], area_extents_to_update,
                                                             flip_areadef_stacking=target_northup != current_northup)

    return dataset","(target_eastright, target_northup) = _get_target_scene_orientation(upper_right_corner)
area_extents_to_update = _get_dataset_area_extents_array(dataset.attrs['area'])","(target_eastright, target_northup), area_extents_to_update = _get_target_scene_orientation(upper_right_corner), _get_dataset_area_extents_array(dataset.attrs['area'])","(target_eastright, target_northup) = zejun1
area_extents_to_update = zejun2",Cannot refactor,-1,1,,,
audio,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/audio/test/torchaudio_unittest/backend/sox_io/smoke_test.py,https://github.com/pytorch/audio/tree/master/test/torchaudio_unittest/backend/sox_io/smoke_test.py,SmokeTest,run_smoke_test$22,"def run_smoke_test(self, ext, sample_rate, num_channels, *, compression=None, dtype=""float32""):
        duration = 1
        num_frames = sample_rate * duration
        path = self.get_temp_path(f""test.{ext}"")
        original = get_wav_data(dtype, num_channels, normalize=False, num_frames=num_frames)

        # 1. run save
        sox_io_backend.save(path, original, sample_rate, compression=compression)
        # 2. run info
        info = sox_io_backend.info(path)
        assert info.sample_rate == sample_rate
        assert info.num_channels == num_channels
        # 3. run load
        loaded, sr = sox_io_backend.load(path, normalize=False)
        assert sr == sample_rate
        assert loaded.shape[0] == num_channels","num_frames = sample_rate * duration
path = self.get_temp_path(f'test.{ext}')","num_frames, path= sample_rate * duration, self.get_temp_path(f'test.{ext}')","num_frames = zejun1
path = zejun2",Cannot refactor,-1,1,,,
open_model_zoo,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/open_model_zoo/demos/place_recognition_demo/python/place_recognition_demo.py,https://github.com/openvinotoolkit/open_model_zoo/tree/master/demos/place_recognition_demo/python/place_recognition_demo.py,,time_elapsed$81,"def time_elapsed(func, *args):
    """""" Auxiliary function that helps to measure elapsed time. """"""

    start_time = perf_counter()
    res = func(*args)
    elapsed = perf_counter() - start_time
    return elapsed, res","start_time = perf_counter()
res = func(*args)","start_time, res= perf_counter(), func(*args)","start_time = zejun1
res = zejun2",Cannot refactor,-1,1,,,
slither,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/slither/slither/solc_parsing/declarations/function.py,https://github.com/crytic/slither/tree/master/slither/solc_parsing/declarations/function.py,FunctionSolc,analyze_params$252,"def analyze_params(self):
        # Can be re-analyzed due to inheritance
        if self._params_was_analyzed:
            return

        self._params_was_analyzed = True

        self._analyze_attributes()

        if self.is_compact_ast:
            params = self._functionNotParsed[""parameters""]
            returns = self._functionNotParsed[""returnParameters""]
        else:
            children = self._functionNotParsed[self.get_children(""children"")]
            # It uses to be
            # params = children[0]
            # returns = children[1]
            # But from Solidity 0.6.3 to 0.6.10 (included)
            # Comment above a function might be added in the children
            child_iter = iter(
                [child for child in children if child[self.get_key()] == ""ParameterList""]
            )
            params = next(child_iter)
            returns = next(child_iter)

        if params:
            self._parse_params(params)
        if returns:
            self._parse_returns(returns)","params = next(child_iter)
returns = next(child_iter)","params, returns = next(child_iter), next(child_iter)","params = zejun1
returns = zejun1",Cannot refactor,-1,1,,,
pandas,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pandas/pandas/tests/indexes/datetimes/test_constructors.py,https://github.com/pandas-dev/pandas/tree/master/pandas/tests/indexes/datetimes/test_constructors.py,TestDatetimeIndex,test_categorical_preserves_tz$97,"def test_categorical_preserves_tz(self):
        # GH#18664 retain tz when going DTI-->Categorical-->DTI
        dti = DatetimeIndex(
            [pd.NaT, ""2015-01-01"", ""1999-04-06 15:14:13"", ""2015-01-01""], tz=""US/Eastern""
        )

        for dtobj in [dti, dti._data]:
            # works for DatetimeIndex or DatetimeArray

            ci = pd.CategoricalIndex(dtobj)
            carr = pd.Categorical(dtobj)
            cser = pd.Series(ci)

            for obj in [ci, carr, cser]:
                result = DatetimeIndex(obj)
                tm.assert_index_equal(result, dti)","ci = pd.CategoricalIndex(dtobj)
carr = pd.Categorical(dtobj)","ci, carr= pd.CategoricalIndex(dtobj), pd.Categorical(dtobj)","ci = zejun1
carr = zejun2",Cannot refactor,-1,1,,,
FastFCN,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/FastFCN/encoding/datasets/coco.py,https://github.com/wuhuikai/FastFCN/tree/master/encoding/datasets/coco.py,COCOSegmentation,__init__$15,"def __init__(self, root=os.path.expanduser('~/.encoding/data'), split='train',
                 mode=None, transform=None, target_transform=None, **kwargs):
        super(COCOSegmentation, self).__init__(
            root, split, mode, transform, target_transform, **kwargs)
        from pycocotools.coco import COCO
        from pycocotools import mask
        if split == 'train':
            print('train set')
            ann_file = os.path.join(root, 'annotations/instances_train2017.json')
            ids_file = os.path.join(root, 'annotations/train_ids.pth')
            self.root = os.path.join(root, 'train2017')
        else:
            print('val set')
            ann_file = os.path.join(root, 'annotations/instances_val2017.json')
            ids_file = os.path.join(root, 'annotations/val_ids.pth')
            self.root = os.path.join(root, 'val2017')
        self.coco = COCO(ann_file)
        self.coco_mask = mask
        if os.path.exists(ids_file):
            self.ids = torch.load(ids_file)
        else:
            ids = list(self.coco.imgs.keys())
            self.ids = self._preprocess(ids, ids_file)
        self.transform = transform
        self.target_transform = target_transform","ann_file = os.path.join(root, 'annotations/instances_val2017.json')
ids_file = os.path.join(root, 'annotations/val_ids.pth')
self.root = os.path.join(root, 'val2017')","ann_file, ids_file, self.root = os.path.join(root, 'annotations/instances_val2017.json'), os.path.join(root, 'annotations/val_ids.pth'), os.path.join(root, 'val2017')","ann_file = zejun1
ids_file = zejun2
self.root = zejun3",Cannot refactor,-1,1,,,
AzurLaneAutoScript,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/AzurLaneAutoScript/module/map/fleet.py,https://github.com/LmeSzinc/AzurLaneAutoScript/tree/master/module/map/fleet.py,Fleet,track_movable$596,"def track_movable(self, enemy_cleared=True, siren=True):
        """"""
        Track enemy moving and predict missing enemies.

        Args:
            enemy_cleared (bool): True if cleared an enemy and need to scan spawn enemies.
                                  False if just a simple walk and only need to scan movable enemies.
            siren (bool): True if track sirens, false if track normal enemies
        """"""
        # Track siren moving
        before = self.movable_before if siren else self.movable_before_normal
        after = self.map.select(is_siren=True) if siren else self.map.select(is_enemy=True)
        step = self.config.MOVABLE_ENEMY_FLEET_STEP if siren else 1
        spawn = self.map.select(may_siren=True) if siren else self.map.select(may_enemy=True)
        matched_before, matched_after = match_movable(
            before=before.location,
            spawn=spawn.location,
            after=after.location,
            fleets=[self.fleet_current] if enemy_cleared else [],
            fleet_step=step
        )
        matched_before = self.map.to_selected(matched_before)
        matched_after = self.map.to_selected(matched_after)
        logger.info(f'Movable enemy {before} -> {after}')
        logger.info(f'Tracked enemy {matched_before} -> {matched_after}')

        # Delete wrong prediction
        for grid in after.delete(matched_after):
            if not grid.may_siren:
                logger.warning(f'Wrong detection: {grid}')
                grid.wipe_out()

        # Predict missing siren
        diff = before.delete(matched_before)
        _, missing = self.map.missing_get(
            self.battle_count, self.mystery_count, self.siren_count, self.carrier_count, mode='normal')
        missing = missing['siren'] if siren else missing['enemy']
        if diff and missing != 0:
            logger.warning(f'Movable enemy tracking lost: {diff}')
            covered = self.map.grid_covered(self.map[self.fleet_current], location=[(0, -2)])
            if self.fleet_1_location:
                covered = covered.add(self.map.grid_covered(self.map[self.fleet_1_location], location=[(0, -1)]))
            if self.fleet_2_location:
                covered = covered.add(self.map.grid_covered(self.map[self.fleet_2_location], location=[(0, -1)]))
            if siren:
                for grid in after:
                    covered = covered.add(self.map.grid_covered(grid))
            else:
                for grid in self.map.select(is_siren=True):
                    covered = covered.add(self.map.grid_covered(grid))
            logger.attr('enemy_covered', covered)
            accessible = SelectedGrids([])
            for grid in diff:
                self.map.find_path_initial(grid, has_ambush=False)
                accessible = accessible.add(self.map.select(cost=0)).add(self.map.select(cost=1))
                if siren:
                    accessible = accessible.add(self.map.select(cost=2))
            self.map.find_path_initial(self.fleet_current, has_ambush=self.config.MAP_HAS_AMBUSH)
            logger.attr('enemy_accessible', accessible)
            predict = accessible.intersect(covered).select(is_sea=True, is_fleet=False)
            logger.info(f'Movable enemy predict: {predict}')
            matched_after = matched_after.add(predict)
            for grid in predict:
                if siren:
                    grid.is_siren = True
                grid.is_enemy = True
        elif missing == 0:
            logger.info(f'Movable enemy tracking drop: {diff}')

        for grid in matched_after:
            if grid.location != self.fleet_current:
                grid.is_movable = True","diff = before.delete(matched_before)
(_, missing) = self.map.missing_get(self.battle_count, self.mystery_count, self.siren_count, self.carrier_count, mode='normal')","diff, (_, missing) = before.delete(matched_before), self.map.missing_get(self.battle_count, self.mystery_count, self.siren_count, self.carrier_count, mode='normal')","diff = zejun1
(_, missing) = zejun2",Cannot refactor,-1,1,,,
TradingGym,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/TradingGym/trading_env/envs/backtest_v1.py,https://github.com/Yvictor/TradingGym/tree/master/trading_env/envs/backtest_v1.py,trading_env,render$342,"def render(self, save=False):
        if self.render_on == 0:
            matplotlib.style.use('dark_background')
            self.render_on = 1

            left, width = 0.1, 0.8
            rect1 = [left, 0.4, width, 0.55]
            rect2 = [left, 0.2, width, 0.2]
            rect3 = [left, 0.05, width, 0.15]

            self.fig = plt.figure(figsize=(15,8))
            self.fig.suptitle('%s'%self.df_sample['datetime'].iloc[0].date(), fontsize=14, fontweight='bold')
            #self.ax = self.fig.add_subplot(1,1,1)
            self.ax = self.fig.add_axes(rect1)  # left, bottom, width, height
            self.ax2 = self.fig.add_axes(rect2, sharex=self.ax)
            self.ax3 = self.fig.add_axes(rect3, sharex=self.ax)
            self.ax.grid(color='gray', linestyle='-', linewidth=0.5)
            self.ax2.grid(color='gray', linestyle='-', linewidth=0.5)
            self.ax3.grid(color='gray', linestyle='-', linewidth=0.5)
            self.features_color = [c.rgb+(0.9,) for c in Color('yellow').range_to(Color('cyan'), self.feature_len)]
            #fig, ax = plt.subplots()
            self._plot_trading()

            self.ax.set_xlim(0,len(self.price[:self.step_st+self.obs_len])+200)
            plt.ion()
            #self.fig.tight_layout()
            plt.show()
            if save:
                self.fig.savefig('fig/%s.png' % str(self.t_index))

        elif self.render_on == 1:
            self.ax.lines.remove(self.price_plot[0])
            [self.ax3.lines.remove(plot) for plot in self.features_plot]
            self.fluc_reward_plot_p.remove()
            self.fluc_reward_plot_n.remove()
            self.target_box.remove()
            self.reward_plot_p.remove()
            self.reward_plot_n.remove()
            self.posi_plot_long.remove()
            self.posi_plot_short.remove()
            self.trade_plot_buy.remove()
            self.trade_plot_sell.remove()

            self._plot_trading()

            self.ax.set_xlim(0,len(self.price[:self.step_st+self.obs_len])+200)
            if save:
                self.fig.savefig('fig/%s.png' % str(self.t_index))
            plt.pause(0.0001)","self.render_on = 1
(left, width) = (0.1, 0.8)","self.render_on, (left, width) = 1, (0.1, 0.8)","self.render_on = zejun1
(left, width) = zejun2",Cannot refactor,-1,1,,,
binarytree,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/binarytree/tests/test_tree.py,https://github.com/joowani/binarytree/tree/master/tests/test_tree.py,,test_get_index_utility_function$1463,"def test_get_index_utility_function() -> None:
    root = Node(0)
    root.left = Node(1)
    root.right = Node(2)
    root.left.left = Node(3)
    root.right.right = Node(4)

    assert get_index(root, root) == 0
    assert get_index(root, root.left) == 1
    assert get_index(root, root.right) == 2
    assert get_index(root, root.left.left) == 3
    assert get_index(root, root.right.right) == 6

    with pytest.raises(NodeReferenceError) as err1:
        get_index(root.left, root.right)
    assert str(err1.value) == ""given nodes are not in the same tree""

    with pytest.raises(NodeTypeError) as err2:
        get_index(root, None)  # type: ignore
    assert str(err2.value) == ""descendent must be a Node instance""

    with pytest.raises(NodeTypeError) as err3:
        get_index(None, root.left)  # type: ignore
    assert str(err3.value) == ""root must be a Node instance""","root.left = Node(1)
root.right = Node(2)
root.left.left = Node(3)
root.right.right = Node(4)","root.left, root.right, root.left.left, root.right.right = Node(1), Node(2), Node(3), Node(4)","root.left = zejun1
root.right = zejun2
root.left.left = zejun3
root.right.right = zejun4",Cannot refactor,-1,1,,,
pycraft,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pycraft/pycraft/world/world.py,https://github.com/traverseda/pycraft/tree/master/pycraft/world/world.py,World,initial_sector$253,"def initial_sector(self, coords):
        """"""
        Creates initial sectors in spiral, to speed up rendering in front of the player
        :param coords:
        :return:
        """"""
        x, y = 0, 0
        dx, dy = 0, -1
        X = coords[0] + 4
        Y = coords[2] + 4
        for i in range(max(X, Y) ** 2):
            if (-X / 2 < x <= X / 2) and (-Y / 2 < y <= Y / 2):
                self.show_sector((x, coords[1], y))
            if x == y or (x < 0 and x == -y) or (x > 0 and x == 1 - y):
                dx, dy = -dy, dx  # Corner change direction
            x, y = x + dx, y + dy","(x, y) = (0, 0)
(dx, dy) = (0, -1)
X = coords[0] + 4
Y = coords[2] + 4","(x, y), (dx, dy), X, Y = (0, 0), (0, -1), coords[0] + 4, coords[2] + 4","(x, y) = zejun1
(dx, dy) = zejun2
X = zejun3
Y = zejun4",Cannot refactor,-1,1,,,
st2,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/st2/st2client/tests/unit/test_util_strutil.py,https://github.com/StackStorm/st2/tree/master/st2client/tests/unit/test_util_strutil.py,StrUtilTestCase,test_unescape$27,"def test_unescape(self):
        in_str = 'Action execution result double escape \\""stuffs\\"".\\r\\n'
        expected = 'Action execution result double escape ""stuffs"".\r\n'
        out_str = strutil.unescape(in_str)
        self.assertEqual(out_str, expected)","in_str = 'Action execution result double escape \\""stuffs\\"".\\r\\n'
expected = 'Action execution result double escape ""stuffs"".\r\n'","in_str, expected = 'Action execution result double escape \\""stuffs\\"".\\r\\n', 'Action execution result double escape ""stuffs"".\r\n'","in_str = zejun1
expected = zejun2",Cannot refactor,-1,1,,,
MixNMatch,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/MixNMatch/code/eval.py,https://github.com/Yuheng-Li/MixNMatch/tree/master/code/eval.py,,eval_feature$125,"def eval_feature():

    names = [ os.path.join(MODELS,'G.pth'), os.path.join(MODELS,'E.pth'), os.path.join(MODELS,'EX.pth')  ]
    netG, encoder, extractor = load_network(names)   
    
       
    real_img_b  = get_images(B) 
    real_img_p  = get_images(P)            
    real_img_c  = get_images(C)            


    with torch.no_grad():
        shape_feature = extractor( real_img_p.to(device) )
        fake_z1, fake_b, _, _ = encoder( real_img_b.to(device), 'softmax' )
        _, _, _, fake_c = encoder( real_img_c.to(device), 'softmax' )     
        
        fake_imgs, _, _, _ = netG(fake_z1, None, fake_c, shape_feature, fake_b, 'feature' )
        img = fake_imgs[2]       


    save_img(img, OUT)","(netG, encoder, extractor) = load_network(names)
real_img_b = get_images(B)
real_img_p = get_images(P)
real_img_c = get_images(C)","(netG, encoder, extractor), real_img_b, real_img_p, real_img_c = load_network(names), get_images(B), get_images(P), get_images(C)","(netG, encoder, extractor) = zejun1
real_img_b = zejun2
real_img_p = zejun3
real_img_c = zejun4",Cannot refactor,-1,1,,,
MixNMatch,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/MixNMatch/code/eval.py,https://github.com/Yuheng-Li/MixNMatch/tree/master/code/eval.py,,eval_feature$125,"def eval_feature():

    names = [ os.path.join(MODELS,'G.pth'), os.path.join(MODELS,'E.pth'), os.path.join(MODELS,'EX.pth')  ]
    netG, encoder, extractor = load_network(names)   
    
       
    real_img_b  = get_images(B) 
    real_img_p  = get_images(P)            
    real_img_c  = get_images(C)            


    with torch.no_grad():
        shape_feature = extractor( real_img_p.to(device) )
        fake_z1, fake_b, _, _ = encoder( real_img_b.to(device), 'softmax' )
        _, _, _, fake_c = encoder( real_img_c.to(device), 'softmax' )     
        
        fake_imgs, _, _, _ = netG(fake_z1, None, fake_c, shape_feature, fake_b, 'feature' )
        img = fake_imgs[2]       


    save_img(img, OUT)","shape_feature = extractor(real_img_p.to(device))
(fake_z1, fake_b, _, _) = encoder(real_img_b.to(device), 'softmax')
(_, _, _, fake_c) = encoder(real_img_c.to(device), 'softmax')","shape_feature, (fake_z1, fake_b, _, _), (_, _, _, fake_c) = extractor(real_img_p.to(device)), encoder(real_img_b.to(device), 'softmax'), encoder(real_img_c.to(device), 'softmax')","shape_feature = zejun1
(fake_z1, fake_b, _, _) = zejun2
(_, _, _, fake_c) = zejun3",Cannot refactor,-1,1,,,
tensorflow-fcn,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/tensorflow-fcn/loss.py,https://github.com/MarvinTeichmann/tensorflow-fcn/tree/master//loss.py,,loss$15,"def loss(logits, labels, num_classes, head=None):
    """"""Calculate the loss from the logits and the labels.

    Args:
      logits: tensor, float - [batch_size, width, height, num_classes].
          Use vgg_fcn.upscore as logits.
      labels: Labels tensor, int32 - [batch_size, width, height, num_classes].
          The ground truth of your data.
      head: numpy array - [num_classes]
          Weighting the loss of each class
          Optional: Prioritize some classes

    Returns:
      loss: Loss tensor of type float.
    """"""
    with tf.name_scope('loss'):
        logits = tf.reshape(logits, (-1, num_classes))
        epsilon = tf.constant(value=1e-4)
        labels = tf.to_float(tf.reshape(labels, (-1, num_classes)))

        softmax = tf.nn.softmax(logits) + epsilon

        if head is not None:
            cross_entropy = -tf.reduce_sum(tf.multiply(labels * tf.log(softmax),
                                           head), reduction_indices=[1])
        else:
            cross_entropy = -tf.reduce_sum(
                labels * tf.log(softmax), reduction_indices=[1])

        cross_entropy_mean = tf.reduce_mean(cross_entropy,
                                            name='xentropy_mean')
        tf.add_to_collection('losses', cross_entropy_mean)

        loss = tf.add_n(tf.get_collection('losses'), name='total_loss')
    return loss","logits = tf.reshape(logits, (-1, num_classes))
epsilon = tf.constant(value=0.0001)
labels = tf.to_float(tf.reshape(labels, (-1, num_classes)))","logits, epsilon, labels = tf.reshape(logits, (-1, num_classes)), tf.constant(value=0.0001), tf.to_float(tf.reshape(labels, (-1, num_classes)))","logits = zejun1
epsilon = zejun2
labels = zejun3",Cannot refactor,-1,1,,,
viper,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/viper/viper/core/ui/console.py,https://github.com/viper-framework/viper/tree/master/viper/core/ui/console.py,Console,parse$76,"def parse(self, data):
        root = """"
        args = []

        # Split words by white space.
        words = data.split()
        # First word is the root command.
        root = words[0]

        # If there are more words, populate the arguments list.
        if len(words) > 1:
            args = words[1:]

        return (root, args)","root = ''
args = []
words = data.split()","root, args, words = '', [], data.split()","root = zejun1
args = zejun2
words = zejun3",Cannot refactor,-1,1,,,
requests-oauthlib,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/requests-oauthlib/tests/test_compliance_fixes.py,https://github.com/requests/requests-oauthlib/tree/master/tests/test_compliance_fixes.py,MailChimpComplianceFixTest,test_fetch_access_token$115,"def test_fetch_access_token(self):
        token = self.session.fetch_token(
            ""https://login.mailchimp.com/oauth2/token"",
            client_secret=""someclientsecret"",
            authorization_response=""https://i.b/?code=hello"",
        )
        # Times should be close
        approx_expires_at = time.time() + 3600
        actual_expires_at = token.pop(""expires_at"")
        self.assertAlmostEqual(actual_expires_at, approx_expires_at, places=2)

        # Other token values exact
        self.assertEqual(token, {""access_token"": ""mailchimp"", ""expires_in"": 3600})

        # And no scope at all
        self.assertNotIn(""scope"", token)","token = self.session.fetch_token('https://login.mailchimp.com/oauth2/token', client_secret='someclientsecret', authorization_response='https://i.b/?code=hello')
approx_expires_at = time.time() + 3600","token, approx_expires_at= self.session.fetch_token('https://login.mailchimp.com/oauth2/token', client_secret='someclientsecret', authorization_response='https://i.b/?code=hello'), time.time() + 3600","token = zejun1
approx_expires_at = zejun2",Cannot refactor,-1,1,,,
plantcv,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/plantcv/plantcv/plantcv/cluster_contours.py,https://github.com/danforthcenter/plantcv/tree/master/plantcv/plantcv/cluster_contours.py,,cluster_contours$9,"def cluster_contours(img, roi_objects, roi_obj_hierarchy, nrow=1, ncol=1, show_grid=False):
    """"""
    This function take a image with multiple contours and clusters them based on user input of rows and columns

    Inputs:
    img                     = RGB or grayscale image data for plotting
    roi_objects             = object contours in an image that are needed to be clustered.
    roi_obj_hierarchy       = object hierarchy
    nrow                    = number of rows to cluster (this should be the approximate  number of desired rows
                              in the entire image (even if there isn't a literal row of plants)
    ncol                    = number of columns to cluster (this should be the approximate number of desired columns
                              in the entire image (even if there isn't a literal row of plants)
    show_grid               = if True then the grid will get plot to show how plants are being clustered

    Returns:
    grouped_contour_indexes = contours grouped
    contours                = All inputed contours

    :param img: numpy.ndarray
    :param roi_objects: list
    :param roi_obj_hierarchy: numpy.ndarray
    :param nrow: int
    :param ncol: int
    :param show_grid: bool
    :return grouped_contour_indexes: list
    :return contours: list
    :return roi_obj_hierarchy: list
    """"""

    if len(np.shape(img)) == 3:
        iy, ix, iz = np.shape(img)
    else:
        iy, ix, = np.shape(img)

    # get the break groups
    if nrow == 1:
        rbreaks = [0, iy]
    else:
        rstep = np.rint(iy / nrow)
        rstep1 = int(rstep)
        rbreaks = range(0, iy, rstep1)
    if ncol == 1:
        cbreaks = [0, ix]
    else:
        cstep = np.rint(ix / ncol)
        cstep1 = int(cstep)
        cbreaks = range(0, ix, cstep1)

    # categorize what bin the center of mass of each contour
    def digitize(a, step):
        # The way cbreaks and rbreaks are calculated, step will never be an integer
        # if isinstance(step, int):
        #     i = step
        # else:
        num_bins = len(step)
        for x in range(0, num_bins):
            if x == 0:
                if a >= 0 and a < step[1]:
                    return 1
            else:
                if a >= step[x - 1] and a < step[x]:
                    return x
                elif a >= np.max(step):
                    return num_bins

    dtype = [('cx', int), ('cy', int), ('rowbin', int), ('colbin', int), ('index', int)]
    coord = []
    for i in range(0, len(roi_objects)):
        m = cv2.moments(roi_objects[i])
        if m['m00'] == 0:
            pass
        else:
            cx = int(m['m10'] / m['m00'])
            cy = int(m['m01'] / m['m00'])
            colbin = digitize(cx, cbreaks)
            rowbin = digitize(cy, rbreaks)
            a = (cx, cy, colbin, rowbin, i)
            coord.append(a)
    coord1 = np.array(coord, dtype=dtype)
    coord2 = np.sort(coord1, order=('colbin', 'rowbin'))

    # get the list of unique coordinates and group the contours with the same bin coordinates
    groups = []
    for i, y in enumerate(coord2):
        col = y[3]
        row = y[2]
        location = str(row) + ',' + str(col)
        groups.append(location)

    unigroup = np.unique(groups)
    coordgroups = []

    for i, y in enumerate(unigroup):
        col_row = y.split(',')
        col = int(col_row[0])
        row = int(col_row[1])
        for a, b in enumerate(coord2):
            if b[2] == col and b[3] == row:
                grp = i
                contour = b[4]
                coordgroups.append((grp, contour))
            else:
                pass

    coordlist = [[y[1] for y in coordgroups if y[0] == x] for x in range(0, (len(unigroup)))]

    contours = roi_objects
    grouped_contour_indexes = coordlist

    # Debug image is rainbow printed contours

    if params.debug is not None:
        if len(np.shape(img)) == 3:
            img_copy = np.copy(img)
        else:
            iy, ix = np.shape(img)
            img_copy = np.zeros((iy, ix, 3), dtype=np.uint8)

        rand_color = color_palette(len(coordlist))
        for i, x in enumerate(coordlist):
            for a in x:
                if roi_obj_hierarchy[0][a][3] > -1:
                    pass
                else:
                    cv2.drawContours(img_copy, roi_objects, a, rand_color[i], -1, hierarchy=roi_obj_hierarchy)
        if show_grid:
            for y in rbreaks:
                cv2.line(img_copy, (0, y), (ix, y), (255, 0, 0), params.line_thickness)
            for x in cbreaks:
                cv2.line(img_copy, (x, 0), (x, iy), (255, 0, 0), params.line_thickness)
    else:
        img_copy = img  # for _debug

    _debug(visual=img_copy,  # keep this outside if statement to avoid additional test
           filename=os.path.join(params.debug_outdir, str(params.device) + '_clusters.png'))

    return grouped_contour_indexes, contours, roi_obj_hierarchy","coordlist = [[y[1] for y in coordgroups if y[0] == x] for x in range(0, len(unigroup))]
contours = roi_objects","coordlist, contours= [[y[1] for y in coordgroups if y[0] == x] for x in range(0, len(unigroup))], roi_objects","coordlist = zejun1
contours = zejun2",Cannot refactor,-1,1,,,
plantcv,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/plantcv/plantcv/plantcv/cluster_contours.py,https://github.com/danforthcenter/plantcv/tree/master/plantcv/plantcv/cluster_contours.py,,cluster_contours$9,"def cluster_contours(img, roi_objects, roi_obj_hierarchy, nrow=1, ncol=1, show_grid=False):
    """"""
    This function take a image with multiple contours and clusters them based on user input of rows and columns

    Inputs:
    img                     = RGB or grayscale image data for plotting
    roi_objects             = object contours in an image that are needed to be clustered.
    roi_obj_hierarchy       = object hierarchy
    nrow                    = number of rows to cluster (this should be the approximate  number of desired rows
                              in the entire image (even if there isn't a literal row of plants)
    ncol                    = number of columns to cluster (this should be the approximate number of desired columns
                              in the entire image (even if there isn't a literal row of plants)
    show_grid               = if True then the grid will get plot to show how plants are being clustered

    Returns:
    grouped_contour_indexes = contours grouped
    contours                = All inputed contours

    :param img: numpy.ndarray
    :param roi_objects: list
    :param roi_obj_hierarchy: numpy.ndarray
    :param nrow: int
    :param ncol: int
    :param show_grid: bool
    :return grouped_contour_indexes: list
    :return contours: list
    :return roi_obj_hierarchy: list
    """"""

    if len(np.shape(img)) == 3:
        iy, ix, iz = np.shape(img)
    else:
        iy, ix, = np.shape(img)

    # get the break groups
    if nrow == 1:
        rbreaks = [0, iy]
    else:
        rstep = np.rint(iy / nrow)
        rstep1 = int(rstep)
        rbreaks = range(0, iy, rstep1)
    if ncol == 1:
        cbreaks = [0, ix]
    else:
        cstep = np.rint(ix / ncol)
        cstep1 = int(cstep)
        cbreaks = range(0, ix, cstep1)

    # categorize what bin the center of mass of each contour
    def digitize(a, step):
        # The way cbreaks and rbreaks are calculated, step will never be an integer
        # if isinstance(step, int):
        #     i = step
        # else:
        num_bins = len(step)
        for x in range(0, num_bins):
            if x == 0:
                if a >= 0 and a < step[1]:
                    return 1
            else:
                if a >= step[x - 1] and a < step[x]:
                    return x
                elif a >= np.max(step):
                    return num_bins

    dtype = [('cx', int), ('cy', int), ('rowbin', int), ('colbin', int), ('index', int)]
    coord = []
    for i in range(0, len(roi_objects)):
        m = cv2.moments(roi_objects[i])
        if m['m00'] == 0:
            pass
        else:
            cx = int(m['m10'] / m['m00'])
            cy = int(m['m01'] / m['m00'])
            colbin = digitize(cx, cbreaks)
            rowbin = digitize(cy, rbreaks)
            a = (cx, cy, colbin, rowbin, i)
            coord.append(a)
    coord1 = np.array(coord, dtype=dtype)
    coord2 = np.sort(coord1, order=('colbin', 'rowbin'))

    # get the list of unique coordinates and group the contours with the same bin coordinates
    groups = []
    for i, y in enumerate(coord2):
        col = y[3]
        row = y[2]
        location = str(row) + ',' + str(col)
        groups.append(location)

    unigroup = np.unique(groups)
    coordgroups = []

    for i, y in enumerate(unigroup):
        col_row = y.split(',')
        col = int(col_row[0])
        row = int(col_row[1])
        for a, b in enumerate(coord2):
            if b[2] == col and b[3] == row:
                grp = i
                contour = b[4]
                coordgroups.append((grp, contour))
            else:
                pass

    coordlist = [[y[1] for y in coordgroups if y[0] == x] for x in range(0, (len(unigroup)))]

    contours = roi_objects
    grouped_contour_indexes = coordlist

    # Debug image is rainbow printed contours

    if params.debug is not None:
        if len(np.shape(img)) == 3:
            img_copy = np.copy(img)
        else:
            iy, ix = np.shape(img)
            img_copy = np.zeros((iy, ix, 3), dtype=np.uint8)

        rand_color = color_palette(len(coordlist))
        for i, x in enumerate(coordlist):
            for a in x:
                if roi_obj_hierarchy[0][a][3] > -1:
                    pass
                else:
                    cv2.drawContours(img_copy, roi_objects, a, rand_color[i], -1, hierarchy=roi_obj_hierarchy)
        if show_grid:
            for y in rbreaks:
                cv2.line(img_copy, (0, y), (ix, y), (255, 0, 0), params.line_thickness)
            for x in cbreaks:
                cv2.line(img_copy, (x, 0), (x, iy), (255, 0, 0), params.line_thickness)
    else:
        img_copy = img  # for _debug

    _debug(visual=img_copy,  # keep this outside if statement to avoid additional test
           filename=os.path.join(params.debug_outdir, str(params.device) + '_clusters.png'))

    return grouped_contour_indexes, contours, roi_obj_hierarchy","cx = int(m['m10'] / m['m00'])
cy = int(m['m01'] / m['m00'])","cx, cy= int(m['m10'] / m['m00']), int(m['m01'] / m['m00'])","cx = zejun1
cy = zejun2",Cannot refactor,-1,1,,,
plantcv,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/plantcv/plantcv/plantcv/cluster_contours.py,https://github.com/danforthcenter/plantcv/tree/master/plantcv/plantcv/cluster_contours.py,,cluster_contours$9,"def cluster_contours(img, roi_objects, roi_obj_hierarchy, nrow=1, ncol=1, show_grid=False):
    """"""
    This function take a image with multiple contours and clusters them based on user input of rows and columns

    Inputs:
    img                     = RGB or grayscale image data for plotting
    roi_objects             = object contours in an image that are needed to be clustered.
    roi_obj_hierarchy       = object hierarchy
    nrow                    = number of rows to cluster (this should be the approximate  number of desired rows
                              in the entire image (even if there isn't a literal row of plants)
    ncol                    = number of columns to cluster (this should be the approximate number of desired columns
                              in the entire image (even if there isn't a literal row of plants)
    show_grid               = if True then the grid will get plot to show how plants are being clustered

    Returns:
    grouped_contour_indexes = contours grouped
    contours                = All inputed contours

    :param img: numpy.ndarray
    :param roi_objects: list
    :param roi_obj_hierarchy: numpy.ndarray
    :param nrow: int
    :param ncol: int
    :param show_grid: bool
    :return grouped_contour_indexes: list
    :return contours: list
    :return roi_obj_hierarchy: list
    """"""

    if len(np.shape(img)) == 3:
        iy, ix, iz = np.shape(img)
    else:
        iy, ix, = np.shape(img)

    # get the break groups
    if nrow == 1:
        rbreaks = [0, iy]
    else:
        rstep = np.rint(iy / nrow)
        rstep1 = int(rstep)
        rbreaks = range(0, iy, rstep1)
    if ncol == 1:
        cbreaks = [0, ix]
    else:
        cstep = np.rint(ix / ncol)
        cstep1 = int(cstep)
        cbreaks = range(0, ix, cstep1)

    # categorize what bin the center of mass of each contour
    def digitize(a, step):
        # The way cbreaks and rbreaks are calculated, step will never be an integer
        # if isinstance(step, int):
        #     i = step
        # else:
        num_bins = len(step)
        for x in range(0, num_bins):
            if x == 0:
                if a >= 0 and a < step[1]:
                    return 1
            else:
                if a >= step[x - 1] and a < step[x]:
                    return x
                elif a >= np.max(step):
                    return num_bins

    dtype = [('cx', int), ('cy', int), ('rowbin', int), ('colbin', int), ('index', int)]
    coord = []
    for i in range(0, len(roi_objects)):
        m = cv2.moments(roi_objects[i])
        if m['m00'] == 0:
            pass
        else:
            cx = int(m['m10'] / m['m00'])
            cy = int(m['m01'] / m['m00'])
            colbin = digitize(cx, cbreaks)
            rowbin = digitize(cy, rbreaks)
            a = (cx, cy, colbin, rowbin, i)
            coord.append(a)
    coord1 = np.array(coord, dtype=dtype)
    coord2 = np.sort(coord1, order=('colbin', 'rowbin'))

    # get the list of unique coordinates and group the contours with the same bin coordinates
    groups = []
    for i, y in enumerate(coord2):
        col = y[3]
        row = y[2]
        location = str(row) + ',' + str(col)
        groups.append(location)

    unigroup = np.unique(groups)
    coordgroups = []

    for i, y in enumerate(unigroup):
        col_row = y.split(',')
        col = int(col_row[0])
        row = int(col_row[1])
        for a, b in enumerate(coord2):
            if b[2] == col and b[3] == row:
                grp = i
                contour = b[4]
                coordgroups.append((grp, contour))
            else:
                pass

    coordlist = [[y[1] for y in coordgroups if y[0] == x] for x in range(0, (len(unigroup)))]

    contours = roi_objects
    grouped_contour_indexes = coordlist

    # Debug image is rainbow printed contours

    if params.debug is not None:
        if len(np.shape(img)) == 3:
            img_copy = np.copy(img)
        else:
            iy, ix = np.shape(img)
            img_copy = np.zeros((iy, ix, 3), dtype=np.uint8)

        rand_color = color_palette(len(coordlist))
        for i, x in enumerate(coordlist):
            for a in x:
                if roi_obj_hierarchy[0][a][3] > -1:
                    pass
                else:
                    cv2.drawContours(img_copy, roi_objects, a, rand_color[i], -1, hierarchy=roi_obj_hierarchy)
        if show_grid:
            for y in rbreaks:
                cv2.line(img_copy, (0, y), (ix, y), (255, 0, 0), params.line_thickness)
            for x in cbreaks:
                cv2.line(img_copy, (x, 0), (x, iy), (255, 0, 0), params.line_thickness)
    else:
        img_copy = img  # for _debug

    _debug(visual=img_copy,  # keep this outside if statement to avoid additional test
           filename=os.path.join(params.debug_outdir, str(params.device) + '_clusters.png'))

    return grouped_contour_indexes, contours, roi_obj_hierarchy","cy = int(m['m01'] / m['m00'])
colbin = digitize(cx, cbreaks)","cy, colbin= int(m['m01'] / m['m00']), digitize(cx, cbreaks)","cy = zejun1
colbin = zejun2",Cannot refactor,-1,1,,,
plantcv,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/plantcv/plantcv/plantcv/cluster_contours.py,https://github.com/danforthcenter/plantcv/tree/master/plantcv/plantcv/cluster_contours.py,,cluster_contours$9,"def cluster_contours(img, roi_objects, roi_obj_hierarchy, nrow=1, ncol=1, show_grid=False):
    """"""
    This function take a image with multiple contours and clusters them based on user input of rows and columns

    Inputs:
    img                     = RGB or grayscale image data for plotting
    roi_objects             = object contours in an image that are needed to be clustered.
    roi_obj_hierarchy       = object hierarchy
    nrow                    = number of rows to cluster (this should be the approximate  number of desired rows
                              in the entire image (even if there isn't a literal row of plants)
    ncol                    = number of columns to cluster (this should be the approximate number of desired columns
                              in the entire image (even if there isn't a literal row of plants)
    show_grid               = if True then the grid will get plot to show how plants are being clustered

    Returns:
    grouped_contour_indexes = contours grouped
    contours                = All inputed contours

    :param img: numpy.ndarray
    :param roi_objects: list
    :param roi_obj_hierarchy: numpy.ndarray
    :param nrow: int
    :param ncol: int
    :param show_grid: bool
    :return grouped_contour_indexes: list
    :return contours: list
    :return roi_obj_hierarchy: list
    """"""

    if len(np.shape(img)) == 3:
        iy, ix, iz = np.shape(img)
    else:
        iy, ix, = np.shape(img)

    # get the break groups
    if nrow == 1:
        rbreaks = [0, iy]
    else:
        rstep = np.rint(iy / nrow)
        rstep1 = int(rstep)
        rbreaks = range(0, iy, rstep1)
    if ncol == 1:
        cbreaks = [0, ix]
    else:
        cstep = np.rint(ix / ncol)
        cstep1 = int(cstep)
        cbreaks = range(0, ix, cstep1)

    # categorize what bin the center of mass of each contour
    def digitize(a, step):
        # The way cbreaks and rbreaks are calculated, step will never be an integer
        # if isinstance(step, int):
        #     i = step
        # else:
        num_bins = len(step)
        for x in range(0, num_bins):
            if x == 0:
                if a >= 0 and a < step[1]:
                    return 1
            else:
                if a >= step[x - 1] and a < step[x]:
                    return x
                elif a >= np.max(step):
                    return num_bins

    dtype = [('cx', int), ('cy', int), ('rowbin', int), ('colbin', int), ('index', int)]
    coord = []
    for i in range(0, len(roi_objects)):
        m = cv2.moments(roi_objects[i])
        if m['m00'] == 0:
            pass
        else:
            cx = int(m['m10'] / m['m00'])
            cy = int(m['m01'] / m['m00'])
            colbin = digitize(cx, cbreaks)
            rowbin = digitize(cy, rbreaks)
            a = (cx, cy, colbin, rowbin, i)
            coord.append(a)
    coord1 = np.array(coord, dtype=dtype)
    coord2 = np.sort(coord1, order=('colbin', 'rowbin'))

    # get the list of unique coordinates and group the contours with the same bin coordinates
    groups = []
    for i, y in enumerate(coord2):
        col = y[3]
        row = y[2]
        location = str(row) + ',' + str(col)
        groups.append(location)

    unigroup = np.unique(groups)
    coordgroups = []

    for i, y in enumerate(unigroup):
        col_row = y.split(',')
        col = int(col_row[0])
        row = int(col_row[1])
        for a, b in enumerate(coord2):
            if b[2] == col and b[3] == row:
                grp = i
                contour = b[4]
                coordgroups.append((grp, contour))
            else:
                pass

    coordlist = [[y[1] for y in coordgroups if y[0] == x] for x in range(0, (len(unigroup)))]

    contours = roi_objects
    grouped_contour_indexes = coordlist

    # Debug image is rainbow printed contours

    if params.debug is not None:
        if len(np.shape(img)) == 3:
            img_copy = np.copy(img)
        else:
            iy, ix = np.shape(img)
            img_copy = np.zeros((iy, ix, 3), dtype=np.uint8)

        rand_color = color_palette(len(coordlist))
        for i, x in enumerate(coordlist):
            for a in x:
                if roi_obj_hierarchy[0][a][3] > -1:
                    pass
                else:
                    cv2.drawContours(img_copy, roi_objects, a, rand_color[i], -1, hierarchy=roi_obj_hierarchy)
        if show_grid:
            for y in rbreaks:
                cv2.line(img_copy, (0, y), (ix, y), (255, 0, 0), params.line_thickness)
            for x in cbreaks:
                cv2.line(img_copy, (x, 0), (x, iy), (255, 0, 0), params.line_thickness)
    else:
        img_copy = img  # for _debug

    _debug(visual=img_copy,  # keep this outside if statement to avoid additional test
           filename=os.path.join(params.debug_outdir, str(params.device) + '_clusters.png'))

    return grouped_contour_indexes, contours, roi_obj_hierarchy","colbin = digitize(cx, cbreaks)
rowbin = digitize(cy, rbreaks)","colbin, rowbin= digitize(cx, cbreaks), digitize(cy, rbreaks)","colbin = zejun1
rowbin = zejun2",Cannot refactor,-1,1,,,
MxShop,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/MxShop/apps/trade/views.py,https://github.com/derek-zhang123/MxShop/tree/master/apps/trade/views.py,AlipayView,get$117,"def get(self, request):
        """"""
        澶勭悊鏀浠樺疂鐨剅eturn_url杩斿洖
        """"""
        processed_dict = {}
        # 1. 鑾峰彇GET涓鍙傛暟
        for key, value in request.GET.items():
            processed_dict[key] = value
        # 2. 鍙栧嚭sign
        sign = processed_dict.pop(""sign"", None)

        # 3. 鐢熸垚ALipay瀵硅薄
        alipay = AliPay(
            appid=""2016091500517456"",
            app_notify_url=""http://47.93.198.159:8000/alipay/return/"",
            app_private_key_path=private_key_path,
            alipay_public_key_path=ali_pub_key_path,  # 鏀浠樺疂鐨勫叕閽ワ紝楠岃瘉鏀浠樺疂鍥炰紶娑堟伅浣跨敤锛屼笉鏄浣犺嚜宸辩殑鍏閽,
            debug=True,  # 榛樿False,
            return_url=""http://47.93.198.159:8000/alipay/return/""
        )

        verify_re = alipay.verify(processed_dict, sign)

        # 杩欓噷鍙浠ヤ笉鍋氭搷浣溿傚洜涓轰笉绠″彂涓嶅彂return url銆俷otify url閮戒細淇鏀硅㈠崟鐘舵併
        if verify_re is True:
            order_sn = processed_dict.get('out_trade_no', None)
            trade_no = processed_dict.get('trade_no', None)
            trade_status = processed_dict.get('trade_status', None)

            existed_orders = OrderInfo.objects.filter(order_sn=order_sn)
            for existed_order in existed_orders:
                existed_order.pay_status = trade_status
                existed_order.trade_no = trade_no
                existed_order.pay_time = datetime.now()
                existed_order.save()

            response = redirect(""/index/#/app/home/member/order"")
            return response

        else:
            response = redirect(""index"")
            return response","order_sn = processed_dict.get('out_trade_no', None)
trade_no = processed_dict.get('trade_no', None)
trade_status = processed_dict.get('trade_status', None)","order_sn, trade_no, trade_status = processed_dict.get('out_trade_no', None), processed_dict.get('trade_no', None), processed_dict.get('trade_status', None)","order_sn = zejun1
trade_no = zejun2
trade_status = zejun3",Cannot refactor,-1,1,,,
PaddleSlim,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/PaddleSlim/paddleslim/dygraph/prune/pruning_plan.py,https://github.com/PaddlePaddle/PaddleSlim/tree/master/paddleslim/dygraph/prune/pruning_plan.py,PruningPlan,_restore_opt$137,"def _restore_opt(self, param_name, sub_layer, opt):
        if opt is None:
            return
        for k, v in opt._accumulators.items():
            var_tmp = v.get(param_name)
            if var_tmp is None: continue
            backup_name = var_tmp.name.replace(""."", ""_"") + ""_backup""
            if backup_name in sub_layer._buffers:
                _logger.debug(""Restore values of variable: {}"".format(
                    var_tmp.name))
                t_value = var_tmp.value().get_tensor()
                t_backup = sub_layer._buffers[backup_name].value().get_tensor()

                p = t_value._place()
                if p.is_cpu_place():
                    place = paddle.CPUPlace()
                elif p.is_cuda_pinned_place():
                    place = paddle.CUDAPinnedPlace()
                else:
                    p = paddle.framework.core.Place()
                    p.set_place(t_value._place())
                    place = paddle.CUDAPlace(p.gpu_device_id())

                t_value.set(np.array(t_backup).astype(""float32""), place)
                del sub_layer._buffers[backup_name]","t_value = var_tmp.value().get_tensor()
t_backup = sub_layer._buffers[backup_name].value().get_tensor()","t_value, t_backup= var_tmp.value().get_tensor(), sub_layer._buffers[backup_name].value().get_tensor()","t_value = zejun1
t_backup = zejun2",Cannot refactor,-1,1,,,
DSView,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/DSView/libsigrokdecode4DSL/decoders/lpc/pd.py,https://github.com/DreamSourceLab/DSView/tree/master/libsigrokdecode4DSL/decoders/lpc/pd.py,Decoder,handle_get_fw_msize$278,"def handle_get_fw_msize(self):
        # LAD[3:0]: MSIZE field (1 clock cycle).
        self.es_block = self.samplenum
        s = 'MSIZE: 0x%%0%dx' % self.oldlad
        self.putb([3, [s % self.oldlad]])
        self.ss_block = self.samplenum
        self.msize = self.oldlad

        if self.direction == 1:
            self.state = 'GET FW DATA'
            self.cycle_count = 0
            self.dataword = 0
            self.cur_nibble = 0
        else:
            self.state = 'GET TAR'
            self.tar_count = 0","self.state = 'GET TAR'
self.tar_count = 0","self.state, self.tar_count= 'GET TAR', 0","self.state = zejun1
self.tar_count = zejun2",Cannot refactor,-1,1,,,
networkx,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/networkx/networkx/algorithms/centrality/tests/test_katz_centrality.py,https://github.com/networkx/networkx/tree/master/networkx/algorithms/centrality/tests/test_katz_centrality.py,TestKatzCentralityNumpy,test_P3_unweighted$234,"def test_P3_unweighted(self):
        """"""Katz centrality: P3""""""
        alpha = 0.1
        G = nx.path_graph(3)
        b_answer = {0: 0.5598852584152165, 1: 0.6107839182711449, 2: 0.5598852584152162}
        b = nx.katz_centrality_numpy(G, alpha, weight=None)
        for n in sorted(G):
            assert b[n] == pytest.approx(b_answer[n], abs=1e-4)","alpha = 0.1
G = nx.path_graph(3)
b_answer = {0: 0.5598852584152165, 1: 0.6107839182711449, 2: 0.5598852584152162}","alpha, G, b_answer = 0.1, nx.path_graph(3), {0: 0.5598852584152165, 1: 0.6107839182711449, 2: 0.5598852584152162}","alpha = zejun1
G = zejun2
b_answer = zejun3",Cannot refactor,-1,1,,,
cleanlab,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/cleanlab/examples/mnist/label_errors_mnist_train_cnn.py,https://github.com/cleanlab/cleanlab/tree/master/examples/mnist/label_errors_mnist_train_cnn.py,,imshow$77,"def imshow(inp, img_labels=None, img_pred=None, img_fns = None, figsize=(10,10), normalize=False, method_name = '', savefig = False):
    """"""Imshow for Tensor.""""""
    height, width = inp.shape[1:]
    xbins = 8
    ybins = int(np.ceil(len(img_labels)/xbins))
    xbin_width = width // xbins
    ybin_height = height // ybins
    
    inp = inp.numpy().transpose((1, 2, 0))
    if normalize:
        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])
        inp = std * inp + mean
        inp = np.clip(inp, 0, 1)
    
    ax = plt.figure(figsize=figsize).gca()
    ax.imshow(inp)
    pad_size = (8-len(img_pred)%8)%8
    img_labels = img_labels + ['']*pad_size #padding
    img_pred = img_pred + ['']*pad_size #padding
    img_fns = img_fns + ['']*pad_size #padding
#     grid = np.asarray(img_labels).reshape((ybins, xbins))
       
    num_red_boxes = 0
    for (j,i),idx in np.ndenumerate(np.arange(ybins*xbins).reshape((ybins, xbins))):
        prediction = img_pred[idx]
        label = img_labels[idx]
        img_fn = img_fns[idx]
        image_index = int(img_fn[13:])
        
        plt.hlines([j*ybin_height - .5], xmin=i*xbin_width, xmax=i*xbin_width + xbin_width, color = 'lightgray', linewidth=2)
        
        fontsize=max(min(1.4*figsize[0], .9*figsize[0]-.7*len(prediction)), 12) if prediction != '' else 1
        tt = ax.text(i*xbin_width + xbin_width/2,j*ybin_height + ybin_height/20,prediction,ha='center',va='center', fontsize=fontsize)
        tt.set_bbox(dict(facecolor='lime', alpha=0.8, edgecolor=None))
        
        fontsize=min(.5*figsize[0], 1.25*figsize[0]-len(img_fn)) if img_fn != '' else 1
        tt = ax.text(i*xbin_width + xbin_width/2.8,j*ybin_height + ybin_height/7,img_fn,ha='center',va='center', fontsize=fontsize)
        tt.set_bbox(dict(facecolor='lightgray', alpha=0.8, edgecolor=None))
        
        fontsize=max(min(1.4*figsize[0], .9*figsize[0]-.7*len(label)),12) if label != '' else 1
        t = ax.text(i*xbin_width + xbin_width/2,j*ybin_height + ybin_height/10*9,label,ha='center',va='center', fontsize=fontsize)
        t.set_bbox(dict(facecolor='cyan', alpha=0.8, edgecolor=None))
        
        
        if image_index in [21601, 40466, 29922, 40144, 51248, 43454, 59915, 57662, 25678, 2676, 24798, 31727, 7080, 26560, 10994, 53396, 54264]:#, 59701, 42566, 26940, 47759
            # Draw red bounding box
            plt.hlines([j*ybin_height + 0.5,(j+1)*ybin_height - 1.5], xmin=i*xbin_width - 0.3, xmax=i*xbin_width + xbin_width - 0.65, color = 'red', linewidth=15)
            plt.vlines([i*xbin_width + 0.5,(i+1)*xbin_width - 1.5], ymin=j*ybin_height + 0.5, ymax=j*ybin_height + ybin_height - 0.5, color = 'red', linewidth=15)
            num_red_boxes += 1
    
    print(""Number of red boxes:"", num_red_boxes)
    plt.axis('off')
    if savefig:
        plt.savefig('figs/mnist_training_label_errors'+str(len(img_pred))+""_""+method_name+'.pdf', pad_inches=0.0, bbox_inches='tight')
    plt.pause(0.001)","(height, width) = inp.shape[1:]
xbins = 8","(height, width), xbins = inp.shape[1:], 8","(height, width) = zejun1
xbins = zejun2",Cannot refactor,-1,1,,,
cleanlab,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/cleanlab/examples/mnist/label_errors_mnist_train_cnn.py,https://github.com/cleanlab/cleanlab/tree/master/examples/mnist/label_errors_mnist_train_cnn.py,,imshow$77,"def imshow(inp, img_labels=None, img_pred=None, img_fns = None, figsize=(10,10), normalize=False, method_name = '', savefig = False):
    """"""Imshow for Tensor.""""""
    height, width = inp.shape[1:]
    xbins = 8
    ybins = int(np.ceil(len(img_labels)/xbins))
    xbin_width = width // xbins
    ybin_height = height // ybins
    
    inp = inp.numpy().transpose((1, 2, 0))
    if normalize:
        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])
        inp = std * inp + mean
        inp = np.clip(inp, 0, 1)
    
    ax = plt.figure(figsize=figsize).gca()
    ax.imshow(inp)
    pad_size = (8-len(img_pred)%8)%8
    img_labels = img_labels + ['']*pad_size #padding
    img_pred = img_pred + ['']*pad_size #padding
    img_fns = img_fns + ['']*pad_size #padding
#     grid = np.asarray(img_labels).reshape((ybins, xbins))
       
    num_red_boxes = 0
    for (j,i),idx in np.ndenumerate(np.arange(ybins*xbins).reshape((ybins, xbins))):
        prediction = img_pred[idx]
        label = img_labels[idx]
        img_fn = img_fns[idx]
        image_index = int(img_fn[13:])
        
        plt.hlines([j*ybin_height - .5], xmin=i*xbin_width, xmax=i*xbin_width + xbin_width, color = 'lightgray', linewidth=2)
        
        fontsize=max(min(1.4*figsize[0], .9*figsize[0]-.7*len(prediction)), 12) if prediction != '' else 1
        tt = ax.text(i*xbin_width + xbin_width/2,j*ybin_height + ybin_height/20,prediction,ha='center',va='center', fontsize=fontsize)
        tt.set_bbox(dict(facecolor='lime', alpha=0.8, edgecolor=None))
        
        fontsize=min(.5*figsize[0], 1.25*figsize[0]-len(img_fn)) if img_fn != '' else 1
        tt = ax.text(i*xbin_width + xbin_width/2.8,j*ybin_height + ybin_height/7,img_fn,ha='center',va='center', fontsize=fontsize)
        tt.set_bbox(dict(facecolor='lightgray', alpha=0.8, edgecolor=None))
        
        fontsize=max(min(1.4*figsize[0], .9*figsize[0]-.7*len(label)),12) if label != '' else 1
        t = ax.text(i*xbin_width + xbin_width/2,j*ybin_height + ybin_height/10*9,label,ha='center',va='center', fontsize=fontsize)
        t.set_bbox(dict(facecolor='cyan', alpha=0.8, edgecolor=None))
        
        
        if image_index in [21601, 40466, 29922, 40144, 51248, 43454, 59915, 57662, 25678, 2676, 24798, 31727, 7080, 26560, 10994, 53396, 54264]:#, 59701, 42566, 26940, 47759
            # Draw red bounding box
            plt.hlines([j*ybin_height + 0.5,(j+1)*ybin_height - 1.5], xmin=i*xbin_width - 0.3, xmax=i*xbin_width + xbin_width - 0.65, color = 'red', linewidth=15)
            plt.vlines([i*xbin_width + 0.5,(i+1)*xbin_width - 1.5], ymin=j*ybin_height + 0.5, ymax=j*ybin_height + ybin_height - 0.5, color = 'red', linewidth=15)
            num_red_boxes += 1
    
    print(""Number of red boxes:"", num_red_boxes)
    plt.axis('off')
    if savefig:
        plt.savefig('figs/mnist_training_label_errors'+str(len(img_pred))+""_""+method_name+'.pdf', pad_inches=0.0, bbox_inches='tight')
    plt.pause(0.001)","ybins = int(np.ceil(len(img_labels) / xbins))
xbin_width = width // xbins","ybins, xbin_width= int(np.ceil(len(img_labels) / xbins)), width // xbins","ybins = zejun1
xbin_width = zejun2",Cannot refactor,-1,1,,,
Keras-TextClassification,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/Keras-TextClassification/keras_textclassification/m15_SWEM/predict.py,https://github.com/yongzhuo/Keras-TextClassification/tree/master/keras_textclassification/m15_SWEM/predict.py,,pred_input$88,"def pred_input(path_hyper_parameter=path_hyper_parameters):
    """"""
       杈撳叆棰勬祴
    :param path_hyper_parameter: str, 瓒呭弬瀛樻斁鍦板潃
    :return: None
    """"""
    # 鍔犺浇瓒呭弬鏁
    hyper_parameters = load_json(path_hyper_parameter)
    pt = PreprocessText(path_model_dir)
    # 妯″紡鍒濆嬪寲鍜屽姞杞
    graph = Graph(hyper_parameters)
    graph.load_model()
    ra_ed = graph.word_embedding
    ques = '鎴戣佹墦鐜嬭呰崳鑰'
    # str to token
    ques_embed = ra_ed.sentence2idx(ques)
    if hyper_parameters['embedding_type'] in ['bert', 'albert']:
        x_val_1 = np.array([ques_embed[0]])
        x_val_2 = np.array([ques_embed[1]])
        x_val = [x_val_1, x_val_2]
    else:
        x_val = ques_embed
    # 棰勬祴
    pred = graph.predict(x_val)
    # 鍙杋d to label and pred
    pre = pt.prereocess_idx(pred[0])
    print(pre)
    while True:
        print(""璇疯緭鍏: "")
        ques = input()
        ques_embed = ra_ed.sentence2idx(ques)
        print(ques_embed)
        if hyper_parameters['embedding_type'] in ['bert', 'albert']:
            x_val_1 = np.array([ques_embed[0]])
            x_val_2 = np.array([ques_embed[1]])
            x_val = [x_val_1, x_val_2]
        else:
            x_val = ques_embed
        pred = graph.predict(x_val)
        pre = pt.prereocess_idx(pred[0])
        print(pre)","hyper_parameters = load_json(path_hyper_parameter)
pt = PreprocessText(path_model_dir)","hyper_parameters, pt= load_json(path_hyper_parameter), PreprocessText(path_model_dir)","hyper_parameters = zejun1
pt = zejun2",Cannot refactor,-1,1,,,
moto,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/moto/tests/test_ec2/test_network_acls.py,https://github.com/spulec/moto/tree/master/tests/test_ec2/test_network_acls.py,,test_new_subnet_associates_with_default_network_acl_boto3$77,"def test_new_subnet_associates_with_default_network_acl_boto3():
    if settings.TEST_SERVER_MODE:
        raise SkipTest(""ServerMode will have conflicting CidrBlocks"")
    client = boto3.client(""ec2"", region_name=""us-east-1"")
    ec2 = boto3.resource(""ec2"", region_name=""us-east-1"")
    default_vpc = client.describe_vpcs()[""Vpcs""][0]

    subnet = ec2.create_subnet(VpcId=default_vpc[""VpcId""], CidrBlock=""172.31.112.0/20"")
    all_network_acls = client.describe_network_acls()[""NetworkAcls""]
    all_network_acls.should.have.length_of(1)

    acl = all_network_acls[0]
    acl[""Associations""].should.have.length_of(7)
    [a[""SubnetId""] for a in acl[""Associations""]].should.contain(subnet.id)","client = boto3.client('ec2', region_name='us-east-1')
ec2 = boto3.resource('ec2', region_name='us-east-1')","client, ec2 = boto3.client('ec2', region_name='us-east-1'), boto3.resource('ec2', region_name='us-east-1')","client = zejun1
ec2 = zejun2",Cannot refactor,-1,1,,,
attn2d,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/attn2d/fairseq/sequence_generator.py,https://github.com/elbayadm/attn2d/tree/master/fairseq/sequence_generator.py,SequenceGeneratorWithAlignment,generate$825,"def generate(self, models, sample, **kwargs):
        self.model.reset_incremental_state()
        finalized = super()._generate(sample, **kwargs)

        src_tokens = sample[""net_input""][""src_tokens""]
        bsz = src_tokens.shape[0]
        beam_size = self.beam_size
        src_tokens, src_lengths, prev_output_tokens, tgt_tokens = self._prepare_batch_for_alignment(
            sample, finalized
        )
        if any(getattr(m, ""full_context_alignment"", False) for m in self.model.models):
            attn = self.model.forward_align(src_tokens, src_lengths, prev_output_tokens)
        else:
            attn = [
                finalized[i // beam_size][i % beam_size][""attention""].transpose(1, 0)
                for i in range(bsz * beam_size)
            ]

        # Process the attn matrix to extract hard alignments.
        for i in range(bsz * beam_size):
            alignment = utils.extract_hard_alignment(
                attn[i], src_tokens[i], tgt_tokens[i], self.pad, self.eos
            )
            finalized[i // beam_size][i % beam_size][""alignment""] = alignment
        return finalized","bsz = src_tokens.shape[0]
beam_size = self.beam_size
(src_tokens, src_lengths, prev_output_tokens, tgt_tokens) = self._prepare_batch_for_alignment(sample, finalized)","bsz, beam_size, (src_tokens, src_lengths, prev_output_tokens, tgt_tokens) = src_tokens.shape[0], self.beam_size, self._prepare_batch_for_alignment((sample, finalized))","bsz = zejun1
beam_size = zejun2
(src_tokens, src_lengths, prev_output_tokens, tgt_tokens) = self._prepare_batch_for_alignment(zejun3)",Cannot refactor,-1,1,,,
mlxtend,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/mlxtend/mlxtend/classifier/tests/test_ensemble_vote_classifier.py,https://github.com/rasbt/mlxtend/tree/master/mlxtend/classifier/tests/test_ensemble_vote_classifier.py,,test_sample_weight$87,"def test_sample_weight():
    # with no weight
    np.random.seed(123)
    clf1 = LogisticRegression(solver='liblinear', multi_class='ovr')
    clf2 = RandomForestClassifier(n_estimators=10)
    clf3 = GaussianNB()
    eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], voting='hard')
    prob1 = eclf.fit(X, y).predict_proba(X)

    # with weight = 1
    w = np.ones(len(y))
    np.random.seed(123)
    clf1 = LogisticRegression(solver='liblinear', multi_class='ovr')
    clf2 = RandomForestClassifier(n_estimators=10)
    clf3 = GaussianNB()
    eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], voting='hard')
    prob2 = eclf.fit(X, y, sample_weight=w).predict_proba(X)

    # with random weight
    random.seed(87)
    w = np.array([random.random() for _ in range(len(y))])
    np.random.seed(123)
    clf1 = LogisticRegression(solver='liblinear', multi_class='ovr')
    clf2 = RandomForestClassifier(n_estimators=10)
    clf3 = GaussianNB()
    eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], voting='hard')
    prob3 = eclf.fit(X, y, sample_weight=w).predict_proba(X)

    diff12 = np.max(np.abs(prob1 - prob2))
    diff23 = np.max(np.abs(prob2 - prob3))
    assert diff12 < 1e-3, ""max diff is %.4f"" % diff12
    assert diff23 > 1e-3, ""max diff is %.4f"" % diff23","prob3 = eclf.fit(X, y, sample_weight=w).predict_proba(X)
diff12 = np.max(np.abs(prob1 - prob2))","prob3, diff12= eclf.fit(X, y, sample_weight=w).predict_proba(X), np.max(np.abs(prob1 - prob2))","prob3 = zejun1
diff12 = zejun2",Cannot refactor,-1,1,,,
ansible-modules-core,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/ansible-modules-core/cloud/docker/docker_container.py,https://github.com/ansible/ansible-modules-core/tree/master/cloud/docker/docker_container.py,TaskParameters,_parse_exposed_ports$1016,"def _parse_exposed_ports(self, published_ports):
        '''
        Parse exposed ports from docker CLI-style ports syntax.
        '''
        exposed = []
        if self.exposed_ports:
            for port in self.exposed_ports:
                port = str(port).strip()
                protocol = 'tcp'
                match = re.search(r'(/.+$)', port)
                if match:
                    protocol = match.group(1).replace('/', '')
                    port = re.sub(r'/.+$', '', port)
                exposed.append((port, protocol))
        if published_ports:
            # Any published port should also be exposed
            for publish_port in published_ports:
                match = False
                if isinstance(publish_port, basestring) and '/' in publish_port:
                    port, protocol = publish_port.split('/')
                    port = int(port)
                else:
                    protocol = 'tcp'
                    port = int(publish_port)
                for exposed_port in exposed:
                    if isinstance(exposed_port[0], basestring) and '-' in exposed_port[0]:
                        start_port, end_port = exposed_port[0].split('-')
                        if int(start_port) <= port <= int(end_port):
                            match = True
                    elif exposed_port[0] == port:
                        match = True
                if not match:
                    exposed.append((port, protocol))
        return exposed","port = str(port).strip()
protocol = 'tcp'","port, protocol= str(port).strip(), 'tcp'","port = zejun1
protocol = zejun2",Cannot refactor,-1,1,,,
ansible-modules-core,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/ansible-modules-core/cloud/docker/docker_container.py,https://github.com/ansible/ansible-modules-core/tree/master/cloud/docker/docker_container.py,TaskParameters,_parse_exposed_ports$1016,"def _parse_exposed_ports(self, published_ports):
        '''
        Parse exposed ports from docker CLI-style ports syntax.
        '''
        exposed = []
        if self.exposed_ports:
            for port in self.exposed_ports:
                port = str(port).strip()
                protocol = 'tcp'
                match = re.search(r'(/.+$)', port)
                if match:
                    protocol = match.group(1).replace('/', '')
                    port = re.sub(r'/.+$', '', port)
                exposed.append((port, protocol))
        if published_ports:
            # Any published port should also be exposed
            for publish_port in published_ports:
                match = False
                if isinstance(publish_port, basestring) and '/' in publish_port:
                    port, protocol = publish_port.split('/')
                    port = int(port)
                else:
                    protocol = 'tcp'
                    port = int(publish_port)
                for exposed_port in exposed:
                    if isinstance(exposed_port[0], basestring) and '-' in exposed_port[0]:
                        start_port, end_port = exposed_port[0].split('-')
                        if int(start_port) <= port <= int(end_port):
                            match = True
                    elif exposed_port[0] == port:
                        match = True
                if not match:
                    exposed.append((port, protocol))
        return exposed","protocol = 'tcp'
port = int(publish_port)","protocol, port= 'tcp', int(publish_port)","protocol = zejun1
port = zejun2",Cannot refactor,-1,1,,,
sdc,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/sdc/sdc/tests/test_utils.py,https://github.com/IntelPython/sdc/tree/master/sdc/tests/test_utils.py,,msg_and_func$181,"def msg_and_func(msg_or_func=None):
    if msg_or_func is None:
        # No signature, no function
        func = None
        msg = None
    elif isinstance(msg_or_func, str):
        # A message is passed
        func = None
        msg = msg_or_func
    else:
        # A function is passed
        func = msg_or_func
        msg = None
    return msg, func","func = msg_or_func
msg = None","func, msg= msg_or_func, None","func = zejun1
msg = zejun2",Cannot refactor,-1,1,,,
Advanced-Deep-Learning-with-Keras,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/Advanced-Deep-Learning-with-Keras/chapter5-improved-gan/acgan-mnist-5.3.1.py,https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras/tree/master/chapter5-improved-gan/acgan-mnist-5.3.1.py,,train$37,"def train(models, data, params):
    """"""Train the discriminator and adversarial Networks

    Alternately train discriminator and adversarial 
    networks by batch.
    Discriminator is trained first with real and fake 
    images and corresponding one-hot labels.
    Adversarial is trained next with fake images pretending 
    to be real and corresponding one-hot labels.
    Generate sample images per save_interval.

    # Arguments
        models (list): Generator, Discriminator,
            Adversarial models
        data (list): x_train, y_train data
        params (list): Network parameters

    """"""
    # the GAN models
    generator, discriminator, adversarial = models
    # images and their one-hot labels
    x_train, y_train = data
    # network parameters
    batch_size, latent_size, train_steps, num_labels, model_name \
            = params
    # the generator image is saved every 500 steps
    save_interval = 500
    # noise vector to see how the generator 
    # output evolves during training
    noise_input = np.random.uniform(-1.0,
                                    1.0, 
                                    size=[16, latent_size])
    # class labels are 0, 1, 2, 3, 4, 5, 
    # 6, 7, 8, 9, 0, 1, 2, 3, 4, 5
    # the generator must produce these MNIST digits
    noise_label = np.eye(num_labels)[np.arange(0, 16) % num_labels]
    # number of elements in train dataset
    train_size = x_train.shape[0]
    print(model_name,
          ""Labels for generated images: "",
          np.argmax(noise_label, axis=1))

    for i in range(train_steps):
        # train the discriminator for 1 batch
        # 1 batch of real (label=1.0) and fake images (label=0.0)
        # randomly pick real images and 
        # corresponding labels from dataset 
        rand_indexes = np.random.randint(0,
                                         train_size,
                                         size=batch_size)
        real_images = x_train[rand_indexes]
        real_labels = y_train[rand_indexes]
        # generate fake images from noise using generator
        # generate noise using uniform distribution
        noise = np.random.uniform(-1.0,
                                  1.0,
                                  size=[batch_size, latent_size])
        # randomly pick one-hot labels
        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,
                                                          batch_size)]
        # generate fake images
        fake_images = generator.predict([noise, fake_labels])
        # real + fake images = 1 batch of train data
        x = np.concatenate((real_images, fake_images))
        # real + fake labels = 1 batch of train data labels
        labels = np.concatenate((real_labels, fake_labels))

        # label real and fake images
        # real images label is 1.0
        y = np.ones([2 * batch_size, 1])
        # fake images label is 0.0
        y[batch_size:, :] = 0
        # train discriminator network, log the loss and accuracy
        # ['loss', 'activation_1_loss', 
        # 'label_loss', 'activation_1_acc', 'label_acc']
        metrics  = discriminator.train_on_batch(x, [y, labels])
        fmt = ""%d: [disc loss: %f, srcloss: %f,"" 
        fmt += ""lblloss: %f, srcacc: %f, lblacc: %f]"" 
        log = fmt % (i, metrics[0], metrics[1], \
                metrics[2], metrics[3], metrics[4])

        # train the adversarial network for 1 batch
        # 1 batch of fake images with label=1.0 and
        # corresponding one-hot label or class 
        # since the discriminator weights are frozen 
        # in adversarial network only the generator is trained
        # generate noise using uniform distribution
        noise = np.random.uniform(-1.0,
                                  1.0, 
                                  size=[batch_size, latent_size])
        # randomly pick one-hot labels
        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,
                                                          batch_size)]
        # label fake images as real
        y = np.ones([batch_size, 1])
        # train the adversarial network 
        # note that unlike in discriminator training, 
        # we do not save the fake images in a variable
        # the fake images go to the discriminator input 
        # of the adversarial for classification
        # log the loss and accuracy
        metrics  = adversarial.train_on_batch([noise, fake_labels],
                                              [y, fake_labels])
        fmt = ""%s [advr loss: %f, srcloss: %f,""
        fmt += ""lblloss: %f, srcacc: %f, lblacc: %f]"" 
        log = fmt % (log, metrics[0], metrics[1],\
                metrics[2], metrics[3], metrics[4])
        print(log)
        if (i + 1) % save_interval == 0:
            # plot generator images on a periodic basis
            gan.plot_images(generator,
                        noise_input=noise_input,
                        noise_label=noise_label,
                        show=False,
                        step=(i + 1),
                        model_name=model_name)

    # save the model after training the generator
    # the trained generator can be reloaded 
    # for future MNIST digit generation
    generator.save(model_name + "".h5"")","(generator, discriminator, adversarial) = models
(x_train, y_train) = data
(batch_size, latent_size, train_steps, num_labels, model_name) = params
save_interval = 500","(generator, discriminator, adversarial), (x_train, y_train), (batch_size, latent_size, train_steps, num_labels, model_name), save_interval = models, data, params, 500","(generator, discriminator, adversarial) = zejun1
(x_train, y_train) = zejun2
(batch_size, latent_size, train_steps, num_labels, model_name) = zejun3
save_interval = zejun4",Cannot refactor,-1,1,,,
python,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/python/kubernetes/client/api/core_v1_api.py,https://github.com/zhanghe06/python/tree/master/kubernetes/client/api/core_v1_api.py,CoreV1Api,list_namespaced_secret_with_http_info$16081,"def list_namespaced_secret_with_http_info(self, namespace, **kwargs):  # noqa: E501
        """"""list_namespaced_secret  # noqa: E501

        list or watch objects of kind Secret  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.list_namespaced_secret_with_http_info(namespace, async_req=True)
        >>> result = thread.get()

        :param async_req bool: execute request asynchronously
        :param str namespace: object name and auth scope, such as for teams and projects (required)
        :param str pretty: If 'true', then the output is pretty printed.
        :param bool allow_watch_bookmarks: allowWatchBookmarks requests watch events with type \""BOOKMARK\"". Servers that do not implement bookmarks may ignore this flag and bookmarks are sent at the server's discretion. Clients should not assume bookmarks are returned at any specific interval, nor may they assume the server will send any BOOKMARK event during a session. If this is not a watch, this field is ignored. If the feature gate WatchBookmarks is not enabled in apiserver, this field is ignored.
        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \""next key\"".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.
        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.
        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.
        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.
        :param str resource_version: resourceVersion sets a constraint on what resource versions a request may be served from. See https://kubernetes.io/docs/reference/using-api/api-concepts/#resource-versions for details.  Defaults to unset
        :param str resource_version_match: resourceVersionMatch determines how resourceVersion is applied to list calls. It is highly recommended that resourceVersionMatch be set for list calls where resourceVersion is set See https://kubernetes.io/docs/reference/using-api/api-concepts/#resource-versions for details.  Defaults to unset
        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.
        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.
        :param _return_http_data_only: response data without head status code
                                       and headers
        :param _preload_content: if False, the urllib3.HTTPResponse object will
                                 be returned without reading/decoding response
                                 data. Default is True.
        :param _request_timeout: timeout setting for this request. If one
                                 number provided, it will be total request
                                 timeout. It can also be a pair (tuple) of
                                 (connection, read) timeouts.
        :return: tuple(V1SecretList, status_code(int), headers(HTTPHeaderDict))
                 If the method is called asynchronously,
                 returns the request thread.
        """"""

        local_var_params = locals()

        all_params = [
            'namespace',
            'pretty',
            'allow_watch_bookmarks',
            '_continue',
            'field_selector',
            'label_selector',
            'limit',
            'resource_version',
            'resource_version_match',
            'timeout_seconds',
            'watch'
        ]
        all_params.extend(
            [
                'async_req',
                '_return_http_data_only',
                '_preload_content',
                '_request_timeout'
            ]
        )

        for key, val in six.iteritems(local_var_params['kwargs']):
            if key not in all_params:
                raise ApiTypeError(
                    ""Got an unexpected keyword argument '%s'""
                    "" to method list_namespaced_secret"" % key
                )
            local_var_params[key] = val
        del local_var_params['kwargs']
        # verify the required parameter 'namespace' is set
        if self.api_client.client_side_validation and ('namespace' not in local_var_params or  # noqa: E501
                                                        local_var_params['namespace'] is None):  # noqa: E501
            raise ApiValueError(""Missing the required parameter `namespace` when calling `list_namespaced_secret`"")  # noqa: E501

        collection_formats = {}

        path_params = {}
        if 'namespace' in local_var_params:
            path_params['namespace'] = local_var_params['namespace']  # noqa: E501

        query_params = []
        if 'pretty' in local_var_params and local_var_params['pretty'] is not None:  # noqa: E501
            query_params.append(('pretty', local_var_params['pretty']))  # noqa: E501
        if 'allow_watch_bookmarks' in local_var_params and local_var_params['allow_watch_bookmarks'] is not None:  # noqa: E501
            query_params.append(('allowWatchBookmarks', local_var_params['allow_watch_bookmarks']))  # noqa: E501
        if '_continue' in local_var_params and local_var_params['_continue'] is not None:  # noqa: E501
            query_params.append(('continue', local_var_params['_continue']))  # noqa: E501
        if 'field_selector' in local_var_params and local_var_params['field_selector'] is not None:  # noqa: E501
            query_params.append(('fieldSelector', local_var_params['field_selector']))  # noqa: E501
        if 'label_selector' in local_var_params and local_var_params['label_selector'] is not None:  # noqa: E501
            query_params.append(('labelSelector', local_var_params['label_selector']))  # noqa: E501
        if 'limit' in local_var_params and local_var_params['limit'] is not None:  # noqa: E501
            query_params.append(('limit', local_var_params['limit']))  # noqa: E501
        if 'resource_version' in local_var_params and local_var_params['resource_version'] is not None:  # noqa: E501
            query_params.append(('resourceVersion', local_var_params['resource_version']))  # noqa: E501
        if 'resource_version_match' in local_var_params and local_var_params['resource_version_match'] is not None:  # noqa: E501
            query_params.append(('resourceVersionMatch', local_var_params['resource_version_match']))  # noqa: E501
        if 'timeout_seconds' in local_var_params and local_var_params['timeout_seconds'] is not None:  # noqa: E501
            query_params.append(('timeoutSeconds', local_var_params['timeout_seconds']))  # noqa: E501
        if 'watch' in local_var_params and local_var_params['watch'] is not None:  # noqa: E501
            query_params.append(('watch', local_var_params['watch']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.select_header_accept(
            ['application/json', 'application/yaml', 'application/vnd.kubernetes.protobuf', 'application/json;stream=watch', 'application/vnd.kubernetes.protobuf;stream=watch'])  # noqa: E501

        # Authentication setting
        auth_settings = ['BearerToken']  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/namespaces/{namespace}/secrets', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type='V1SecretList',  # noqa: E501
            auth_settings=auth_settings,
            async_req=local_var_params.get('async_req'),
            _return_http_data_only=local_var_params.get('_return_http_data_only'),  # noqa: E501
            _preload_content=local_var_params.get('_preload_content', True),
            _request_timeout=local_var_params.get('_request_timeout'),
            collection_formats=collection_formats)","header_params = {}
form_params = []
local_var_files = {}
body_params = None","header_params, form_params, local_var_files, body_params = {}, [], {}, None","header_params = zejun1
form_params = zejun2
local_var_files = zejun3
body_params = zejun4",Cannot refactor,-1,1,,,
poetry,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/poetry/get-poetry.py,https://github.com/sheepzh/poetry/tree/master//get-poetry.py,Installer,_compare_versions$417,"def _compare_versions(x, y):
            mx = self.VERSION_REGEX.match(x)
            my = self.VERSION_REGEX.match(y)

            vx = tuple(int(p) for p in mx.groups()[:3]) + (mx.group(5),)
            vy = tuple(int(p) for p in my.groups()[:3]) + (my.group(5),)

            if vx < vy:
                return -1
            elif vx > vy:
                return 1

            return 0","mx = self.VERSION_REGEX.match(x)
my = self.VERSION_REGEX.match(y)","mx, my = self.VERSION_REGEX.match(x), self.VERSION_REGEX.match(y)","mx = zejun1
my = zejun2",Cannot refactor,-1,1,,,
poetry,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/poetry/get-poetry.py,https://github.com/sheepzh/poetry/tree/master//get-poetry.py,Installer,_compare_versions$417,"def _compare_versions(x, y):
            mx = self.VERSION_REGEX.match(x)
            my = self.VERSION_REGEX.match(y)

            vx = tuple(int(p) for p in mx.groups()[:3]) + (mx.group(5),)
            vy = tuple(int(p) for p in my.groups()[:3]) + (my.group(5),)

            if vx < vy:
                return -1
            elif vx > vy:
                return 1

            return 0","my = self.VERSION_REGEX.match(y)
vx = tuple((int(p) for p in mx.groups()[:3])) + (mx.group(5),)","my, vx= self.VERSION_REGEX.match(y), tuple((int(p) for p in mx.groups()[:3])) + (mx.group(5),)","my = zejun1
vx = zejun2",Cannot refactor,-1,1,,,
toolkit,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/toolkit/got10k/experiments/lasot.py,https://github.com/got-10k/toolkit/tree/master/got10k/experiments/lasot.py,ExperimentLaSOT,plot_curves$163,"def plot_curves(self, tracker_names, extension='.png'):
        # assume tracker_names[0] is your tracker
        report_dir = os.path.join(self.report_dir, tracker_names[0])
        assert os.path.exists(report_dir), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'
        report_file = os.path.join(report_dir, 'performance.json')
        assert os.path.exists(report_file), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'

        # load pre-computed performance
        with open(report_file) as f:
            performance = json.load(f)

        succ_file = os.path.join(report_dir, 'success_plots'+extension)
        prec_file = os.path.join(report_dir, 'precision_plots'+extension)
        norm_prec_file = os.path.join(report_dir, 'norm_precision_plots'+extension)
        key = 'overall'

        # markers
        markers = ['-', '--', '-.']
        markers = [c + m for m in markers for c in [''] * 10]

        # filter performance by tracker_names
        performance = {k:v for k,v in performance.items() if k in tracker_names}

        # sort trackers by success score
        tracker_names = list(performance.keys())
        succ = [t[key]['success_score'] for t in performance.values()]
        inds = np.argsort(succ)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot success curves
        thr_iou = np.linspace(0, 1, self.nbins_iou)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_iou,
                            performance[name][key]['success_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['success_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower left', bbox_to_anchor=(0., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Overlap threshold',
               ylabel='Success rate',
               xlim=(0, 1), ylim=(0, 1),
               title='Success plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving success plots to', succ_file)
        fig.savefig(succ_file,
                    bbox_extra_artists=(legend,),
                    bbox_inches='tight',
                    dpi=300)

        # sort trackers by precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot precision curves
        thr_ce = np.arange(0, self.nbins_ce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_ce,
                            performance[name][key]['precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Location error threshold',
               ylabel='Precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving precision plots to', prec_file)
        fig.savefig(prec_file, dpi=300)

# added by user
        # sort trackers by normalized precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['normalized_precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot normalized precision curves
        thr_nce = np.arange(0, self.nbins_nce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_nce,
                            performance[name][key]['normalized_precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['normalized_precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Normalized location error threshold',
               ylabel='Normalized precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Normalized precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving normalized precision plots to', norm_prec_file)
        fig.savefig(norm_prec_file, dpi=300)","tracker_names = list(performance.keys())
succ = [t[key]['success_score'] for t in performance.values()]","tracker_names, succ = list(performance.keys()), [t[key]['success_score'] for t in performance.values()]","tracker_names = zejun1
succ = zejun2",Cannot refactor,-1,1,,,
toolkit,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/toolkit/got10k/experiments/lasot.py,https://github.com/got-10k/toolkit/tree/master/got10k/experiments/lasot.py,ExperimentLaSOT,plot_curves$163,"def plot_curves(self, tracker_names, extension='.png'):
        # assume tracker_names[0] is your tracker
        report_dir = os.path.join(self.report_dir, tracker_names[0])
        assert os.path.exists(report_dir), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'
        report_file = os.path.join(report_dir, 'performance.json')
        assert os.path.exists(report_file), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'

        # load pre-computed performance
        with open(report_file) as f:
            performance = json.load(f)

        succ_file = os.path.join(report_dir, 'success_plots'+extension)
        prec_file = os.path.join(report_dir, 'precision_plots'+extension)
        norm_prec_file = os.path.join(report_dir, 'norm_precision_plots'+extension)
        key = 'overall'

        # markers
        markers = ['-', '--', '-.']
        markers = [c + m for m in markers for c in [''] * 10]

        # filter performance by tracker_names
        performance = {k:v for k,v in performance.items() if k in tracker_names}

        # sort trackers by success score
        tracker_names = list(performance.keys())
        succ = [t[key]['success_score'] for t in performance.values()]
        inds = np.argsort(succ)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot success curves
        thr_iou = np.linspace(0, 1, self.nbins_iou)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_iou,
                            performance[name][key]['success_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['success_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower left', bbox_to_anchor=(0., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Overlap threshold',
               ylabel='Success rate',
               xlim=(0, 1), ylim=(0, 1),
               title='Success plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving success plots to', succ_file)
        fig.savefig(succ_file,
                    bbox_extra_artists=(legend,),
                    bbox_inches='tight',
                    dpi=300)

        # sort trackers by precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot precision curves
        thr_ce = np.arange(0, self.nbins_ce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_ce,
                            performance[name][key]['precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Location error threshold',
               ylabel='Precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving precision plots to', prec_file)
        fig.savefig(prec_file, dpi=300)

# added by user
        # sort trackers by normalized precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['normalized_precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot normalized precision curves
        thr_nce = np.arange(0, self.nbins_nce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_nce,
                            performance[name][key]['normalized_precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['normalized_precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Normalized location error threshold',
               ylabel='Normalized precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Normalized precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving normalized precision plots to', norm_prec_file)
        fig.savefig(norm_prec_file, dpi=300)","tracker_names = list(performance.keys())
prec = [t[key]['precision_score'] for t in performance.values()]","tracker_names, prec = list(performance.keys()), [t[key]['precision_score'] for t in performance.values()]","tracker_names = zejun1
prec = zejun2",Cannot refactor,-1,1,,,
toolkit,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/toolkit/got10k/experiments/lasot.py,https://github.com/got-10k/toolkit/tree/master/got10k/experiments/lasot.py,ExperimentLaSOT,plot_curves$163,"def plot_curves(self, tracker_names, extension='.png'):
        # assume tracker_names[0] is your tracker
        report_dir = os.path.join(self.report_dir, tracker_names[0])
        assert os.path.exists(report_dir), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'
        report_file = os.path.join(report_dir, 'performance.json')
        assert os.path.exists(report_file), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'

        # load pre-computed performance
        with open(report_file) as f:
            performance = json.load(f)

        succ_file = os.path.join(report_dir, 'success_plots'+extension)
        prec_file = os.path.join(report_dir, 'precision_plots'+extension)
        norm_prec_file = os.path.join(report_dir, 'norm_precision_plots'+extension)
        key = 'overall'

        # markers
        markers = ['-', '--', '-.']
        markers = [c + m for m in markers for c in [''] * 10]

        # filter performance by tracker_names
        performance = {k:v for k,v in performance.items() if k in tracker_names}

        # sort trackers by success score
        tracker_names = list(performance.keys())
        succ = [t[key]['success_score'] for t in performance.values()]
        inds = np.argsort(succ)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot success curves
        thr_iou = np.linspace(0, 1, self.nbins_iou)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_iou,
                            performance[name][key]['success_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['success_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower left', bbox_to_anchor=(0., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Overlap threshold',
               ylabel='Success rate',
               xlim=(0, 1), ylim=(0, 1),
               title='Success plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving success plots to', succ_file)
        fig.savefig(succ_file,
                    bbox_extra_artists=(legend,),
                    bbox_inches='tight',
                    dpi=300)

        # sort trackers by precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot precision curves
        thr_ce = np.arange(0, self.nbins_ce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_ce,
                            performance[name][key]['precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Location error threshold',
               ylabel='Precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving precision plots to', prec_file)
        fig.savefig(prec_file, dpi=300)

# added by user
        # sort trackers by normalized precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['normalized_precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot normalized precision curves
        thr_nce = np.arange(0, self.nbins_nce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_nce,
                            performance[name][key]['normalized_precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['normalized_precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Normalized location error threshold',
               ylabel='Normalized precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Normalized precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving normalized precision plots to', norm_prec_file)
        fig.savefig(norm_prec_file, dpi=300)","tracker_names = list(performance.keys())
prec = [t[key]['normalized_precision_score'] for t in performance.values()]","tracker_names, prec = list(performance.keys()), [t[key]['normalized_precision_score'] for t in performance.values()]","tracker_names = zejun1
prec = zejun2",Cannot refactor,-1,1,,,
habu,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/habu/habu/cli/cmd_arp_sniff.py,https://github.com/fportantier/habu/tree/master/habu/cli/cmd_arp_sniff.py,,procpkt$17,"def procpkt(pkt):

    now = time()
    output = '{seconds}\t{ip}\t{hwaddr}\t{vendor}'

    if conf.manufdb:
        manufdb_available = True
    else:
        manufdb_available = False

    if 'ARP' in pkt:
        hosts[pkt[ARP].psrc] = {}
        hosts[pkt[ARP].psrc]['hwaddr'] = pkt[ARP].hwsrc
        hosts[pkt[ARP].psrc]['time'] = time()

        if manufdb_available:
            hosts[pkt[ARP].psrc]['vendor'] = conf.manufdb._get_manuf(pkt[ARP].hwsrc)
        else:
            hosts[pkt[ARP].psrc]['vendor'] = 'unknown'

        click.clear()

        if not manufdb_available:
            click.echo('WARNING: manufdb is not available. Can\'t get vendor.')

        for ip in sorted(hosts):
            print(output.format(
                seconds = int(now - hosts[ip]['time']),
                ip = ip,
                hwaddr = hosts[ip]['hwaddr'],
                vendor = hosts[ip]['vendor']
            ))","hosts[pkt[ARP].psrc] = {}
hosts[pkt[ARP].psrc]['hwaddr'] = pkt[ARP].hwsrc
hosts[pkt[ARP].psrc]['time'] = time()","hosts[pkt[ARP].psrc] = {'hwaddr': pkt[ARP].hwsrc, 'time': time()}","hosts[zejun1] = {}
hosts[zejun1]['hwaddr'] = zejun2
hosts[zejun1]['time'] = zejun3",Cannot refactor,-1,1,,,
OWOD,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/OWOD/projects/DensePose/densepose/modeling/hrnet.py,https://github.com/JosephKJ/OWOD/tree/master/projects/DensePose/densepose/modeling/hrnet.py,PoseHigherResolutionNet,__init__$281,"def __init__(self, cfg, **kwargs):
        self.inplanes = cfg.MODEL.HRNET.STEM_INPLANES
        super(PoseHigherResolutionNet, self).__init__()

        # stem net
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)
        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)
        self.relu = nn.ReLU(inplace=True)
        self.layer1 = self._make_layer(Bottleneck, 64, 4)

        self.stage2_cfg = cfg.MODEL.HRNET.STAGE2
        num_channels = self.stage2_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage2_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition1 = self._make_transition_layer([256], num_channels)
        self.stage2, pre_stage_channels = self._make_stage(self.stage2_cfg, num_channels)

        self.stage3_cfg = cfg.MODEL.HRNET.STAGE3
        num_channels = self.stage3_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage3_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition2 = self._make_transition_layer(pre_stage_channels, num_channels)
        self.stage3, pre_stage_channels = self._make_stage(self.stage3_cfg, num_channels)

        self.stage4_cfg = cfg.MODEL.HRNET.STAGE4
        num_channels = self.stage4_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage4_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition3 = self._make_transition_layer(pre_stage_channels, num_channels)
        self.stage4, pre_stage_channels = self._make_stage(
            self.stage4_cfg, num_channels, multi_scale_output=True
        )

        self._out_features = []
        self._out_feature_channels = {}
        self._out_feature_strides = {}

        for i in range(cfg.MODEL.HRNET.STAGE4.NUM_BRANCHES):
            self._out_features.append(""p%d"" % (i + 1))
            self._out_feature_channels.update(
                {self._out_features[-1]: cfg.MODEL.HRNET.STAGE4.NUM_CHANNELS[i]}
            )
            self._out_feature_strides.update({self._out_features[-1]: 1})","(self.stage4, pre_stage_channels) = self._make_stage(self.stage4_cfg, num_channels, multi_scale_output=True)
self._out_features = []
self._out_feature_channels = {}
self._out_feature_strides = {}","(self.stage4, pre_stage_channels), self._out_features, self._out_feature_channels, self._out_feature_strides = self._make_stage(self.stage4_cfg, num_channels, multi_scale_output=True), [], {}, {}","(self.stage4, pre_stage_channels) = zejun1
self._out_features = zejun2
self._out_feature_channels = zejun3
self._out_feature_strides = zejun4",Cannot refactor,-1,1,,,
OWOD,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/OWOD/projects/DensePose/densepose/modeling/hrnet.py,https://github.com/JosephKJ/OWOD/tree/master/projects/DensePose/densepose/modeling/hrnet.py,PoseHigherResolutionNet,__init__$281,"def __init__(self, cfg, **kwargs):
        self.inplanes = cfg.MODEL.HRNET.STEM_INPLANES
        super(PoseHigherResolutionNet, self).__init__()

        # stem net
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)
        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)
        self.relu = nn.ReLU(inplace=True)
        self.layer1 = self._make_layer(Bottleneck, 64, 4)

        self.stage2_cfg = cfg.MODEL.HRNET.STAGE2
        num_channels = self.stage2_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage2_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition1 = self._make_transition_layer([256], num_channels)
        self.stage2, pre_stage_channels = self._make_stage(self.stage2_cfg, num_channels)

        self.stage3_cfg = cfg.MODEL.HRNET.STAGE3
        num_channels = self.stage3_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage3_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition2 = self._make_transition_layer(pre_stage_channels, num_channels)
        self.stage3, pre_stage_channels = self._make_stage(self.stage3_cfg, num_channels)

        self.stage4_cfg = cfg.MODEL.HRNET.STAGE4
        num_channels = self.stage4_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage4_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition3 = self._make_transition_layer(pre_stage_channels, num_channels)
        self.stage4, pre_stage_channels = self._make_stage(
            self.stage4_cfg, num_channels, multi_scale_output=True
        )

        self._out_features = []
        self._out_feature_channels = {}
        self._out_feature_strides = {}

        for i in range(cfg.MODEL.HRNET.STAGE4.NUM_BRANCHES):
            self._out_features.append(""p%d"" % (i + 1))
            self._out_feature_channels.update(
                {self._out_features[-1]: cfg.MODEL.HRNET.STAGE4.NUM_CHANNELS[i]}
            )
            self._out_feature_strides.update({self._out_features[-1]: 1})","num_channels = self.stage3_cfg.NUM_CHANNELS
block = blocks_dict[self.stage3_cfg.BLOCK]","num_channels, block = self.stage3_cfg.NUM_CHANNELS, blocks_dict[self.stage3_cfg.BLOCK]","num_channels = zejun1
block = zejun2",Cannot refactor,-1,1,,,
OWOD,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/OWOD/projects/DensePose/densepose/modeling/hrnet.py,https://github.com/JosephKJ/OWOD/tree/master/projects/DensePose/densepose/modeling/hrnet.py,PoseHigherResolutionNet,__init__$281,"def __init__(self, cfg, **kwargs):
        self.inplanes = cfg.MODEL.HRNET.STEM_INPLANES
        super(PoseHigherResolutionNet, self).__init__()

        # stem net
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)
        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)
        self.relu = nn.ReLU(inplace=True)
        self.layer1 = self._make_layer(Bottleneck, 64, 4)

        self.stage2_cfg = cfg.MODEL.HRNET.STAGE2
        num_channels = self.stage2_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage2_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition1 = self._make_transition_layer([256], num_channels)
        self.stage2, pre_stage_channels = self._make_stage(self.stage2_cfg, num_channels)

        self.stage3_cfg = cfg.MODEL.HRNET.STAGE3
        num_channels = self.stage3_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage3_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition2 = self._make_transition_layer(pre_stage_channels, num_channels)
        self.stage3, pre_stage_channels = self._make_stage(self.stage3_cfg, num_channels)

        self.stage4_cfg = cfg.MODEL.HRNET.STAGE4
        num_channels = self.stage4_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage4_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition3 = self._make_transition_layer(pre_stage_channels, num_channels)
        self.stage4, pre_stage_channels = self._make_stage(
            self.stage4_cfg, num_channels, multi_scale_output=True
        )

        self._out_features = []
        self._out_feature_channels = {}
        self._out_feature_strides = {}

        for i in range(cfg.MODEL.HRNET.STAGE4.NUM_BRANCHES):
            self._out_features.append(""p%d"" % (i + 1))
            self._out_feature_channels.update(
                {self._out_features[-1]: cfg.MODEL.HRNET.STAGE4.NUM_CHANNELS[i]}
            )
            self._out_feature_strides.update({self._out_features[-1]: 1})","num_channels = self.stage4_cfg.NUM_CHANNELS
block = blocks_dict[self.stage4_cfg.BLOCK]","num_channels, block = self.stage4_cfg.NUM_CHANNELS, blocks_dict[self.stage4_cfg.BLOCK]","num_channels = zejun1
block = zejun2",Cannot refactor,-1,1,,,
OWOD,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/OWOD/projects/DensePose/densepose/modeling/hrnet.py,https://github.com/JosephKJ/OWOD/tree/master/projects/DensePose/densepose/modeling/hrnet.py,PoseHigherResolutionNet,__init__$281,"def __init__(self, cfg, **kwargs):
        self.inplanes = cfg.MODEL.HRNET.STEM_INPLANES
        super(PoseHigherResolutionNet, self).__init__()

        # stem net
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)
        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)
        self.relu = nn.ReLU(inplace=True)
        self.layer1 = self._make_layer(Bottleneck, 64, 4)

        self.stage2_cfg = cfg.MODEL.HRNET.STAGE2
        num_channels = self.stage2_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage2_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition1 = self._make_transition_layer([256], num_channels)
        self.stage2, pre_stage_channels = self._make_stage(self.stage2_cfg, num_channels)

        self.stage3_cfg = cfg.MODEL.HRNET.STAGE3
        num_channels = self.stage3_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage3_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition2 = self._make_transition_layer(pre_stage_channels, num_channels)
        self.stage3, pre_stage_channels = self._make_stage(self.stage3_cfg, num_channels)

        self.stage4_cfg = cfg.MODEL.HRNET.STAGE4
        num_channels = self.stage4_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage4_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition3 = self._make_transition_layer(pre_stage_channels, num_channels)
        self.stage4, pre_stage_channels = self._make_stage(
            self.stage4_cfg, num_channels, multi_scale_output=True
        )

        self._out_features = []
        self._out_feature_channels = {}
        self._out_feature_strides = {}

        for i in range(cfg.MODEL.HRNET.STAGE4.NUM_BRANCHES):
            self._out_features.append(""p%d"" % (i + 1))
            self._out_feature_channels.update(
                {self._out_features[-1]: cfg.MODEL.HRNET.STAGE4.NUM_CHANNELS[i]}
            )
            self._out_feature_strides.update({self._out_features[-1]: 1})","num_channels = self.stage2_cfg.NUM_CHANNELS
block = blocks_dict[self.stage2_cfg.BLOCK]","num_channels, block = self.stage2_cfg.NUM_CHANNELS, blocks_dict[self.stage2_cfg.BLOCK]","num_channels = zejun1
block = zejun2",Cannot refactor,-1,1,,,
OWOD,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/OWOD/projects/DensePose/densepose/modeling/hrnet.py,https://github.com/JosephKJ/OWOD/tree/master/projects/DensePose/densepose/modeling/hrnet.py,PoseHigherResolutionNet,__init__$281,"def __init__(self, cfg, **kwargs):
        self.inplanes = cfg.MODEL.HRNET.STEM_INPLANES
        super(PoseHigherResolutionNet, self).__init__()

        # stem net
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)
        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)
        self.relu = nn.ReLU(inplace=True)
        self.layer1 = self._make_layer(Bottleneck, 64, 4)

        self.stage2_cfg = cfg.MODEL.HRNET.STAGE2
        num_channels = self.stage2_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage2_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition1 = self._make_transition_layer([256], num_channels)
        self.stage2, pre_stage_channels = self._make_stage(self.stage2_cfg, num_channels)

        self.stage3_cfg = cfg.MODEL.HRNET.STAGE3
        num_channels = self.stage3_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage3_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition2 = self._make_transition_layer(pre_stage_channels, num_channels)
        self.stage3, pre_stage_channels = self._make_stage(self.stage3_cfg, num_channels)

        self.stage4_cfg = cfg.MODEL.HRNET.STAGE4
        num_channels = self.stage4_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage4_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition3 = self._make_transition_layer(pre_stage_channels, num_channels)
        self.stage4, pre_stage_channels = self._make_stage(
            self.stage4_cfg, num_channels, multi_scale_output=True
        )

        self._out_features = []
        self._out_feature_channels = {}
        self._out_feature_strides = {}

        for i in range(cfg.MODEL.HRNET.STAGE4.NUM_BRANCHES):
            self._out_features.append(""p%d"" % (i + 1))
            self._out_feature_channels.update(
                {self._out_features[-1]: cfg.MODEL.HRNET.STAGE4.NUM_CHANNELS[i]}
            )
            self._out_feature_strides.update({self._out_features[-1]: 1})","(self.stage3, pre_stage_channels) = self._make_stage(self.stage3_cfg, num_channels)
self.stage4_cfg = cfg.MODEL.HRNET.STAGE4","(self.stage3, pre_stage_channels), self.stage4_cfg = self._make_stage(self.stage3_cfg, num_channels), cfg.MODEL.HRNET.STAGE4","(self.stage3, pre_stage_channels) = zejun1
self.stage4_cfg = zejun2",Cannot refactor,-1,1,,,
OWOD,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/OWOD/projects/DensePose/densepose/modeling/hrnet.py,https://github.com/JosephKJ/OWOD/tree/master/projects/DensePose/densepose/modeling/hrnet.py,PoseHigherResolutionNet,__init__$281,"def __init__(self, cfg, **kwargs):
        self.inplanes = cfg.MODEL.HRNET.STEM_INPLANES
        super(PoseHigherResolutionNet, self).__init__()

        # stem net
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)
        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)
        self.relu = nn.ReLU(inplace=True)
        self.layer1 = self._make_layer(Bottleneck, 64, 4)

        self.stage2_cfg = cfg.MODEL.HRNET.STAGE2
        num_channels = self.stage2_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage2_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition1 = self._make_transition_layer([256], num_channels)
        self.stage2, pre_stage_channels = self._make_stage(self.stage2_cfg, num_channels)

        self.stage3_cfg = cfg.MODEL.HRNET.STAGE3
        num_channels = self.stage3_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage3_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition2 = self._make_transition_layer(pre_stage_channels, num_channels)
        self.stage3, pre_stage_channels = self._make_stage(self.stage3_cfg, num_channels)

        self.stage4_cfg = cfg.MODEL.HRNET.STAGE4
        num_channels = self.stage4_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage4_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition3 = self._make_transition_layer(pre_stage_channels, num_channels)
        self.stage4, pre_stage_channels = self._make_stage(
            self.stage4_cfg, num_channels, multi_scale_output=True
        )

        self._out_features = []
        self._out_feature_channels = {}
        self._out_feature_strides = {}

        for i in range(cfg.MODEL.HRNET.STAGE4.NUM_BRANCHES):
            self._out_features.append(""p%d"" % (i + 1))
            self._out_feature_channels.update(
                {self._out_features[-1]: cfg.MODEL.HRNET.STAGE4.NUM_CHANNELS[i]}
            )
            self._out_feature_strides.update({self._out_features[-1]: 1})","(self.stage2, pre_stage_channels) = self._make_stage(self.stage2_cfg, num_channels)
self.stage3_cfg = cfg.MODEL.HRNET.STAGE3","(self.stage2, pre_stage_channels), self.stage3_cfg = self._make_stage(self.stage2_cfg, num_channels), cfg.MODEL.HRNET.STAGE3","(self.stage2, pre_stage_channels) = zejun1
self.stage3_cfg = zejun2",Cannot refactor,-1,1,,,
freemocap,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/freemocap/freemocap/fmc_anipose.py,https://github.com/jonmatthis/freemocap/tree/master/freemocap/fmc_anipose.py,CameraGroup,_initialize_params_triangulation_possible$1456,"def _initialize_params_triangulation_possible(self, p3ds, p2ds, **kwargs):
        # initialize params using above function
        # initialize alphas to 1 for first one and 0 for other possible

        n_cams, n_frames, n_joints, n_possible, _ = p2ds.shape
        good = ~np.isnan(p2ds[:, :, :, :, 0])

        alphas = np.zeros((n_cams, n_frames, n_joints, n_possible), dtype=""float64"")
        alphas[:, :, :, 0] = 0

        params = self._initialize_params_triangulation(p3ds, **kwargs)
        params_full = np.hstack([params, alphas[good]])

        return params_full","(n_cams, n_frames, n_joints, n_possible, _) = p2ds.shape
good = ~np.isnan(p2ds[:, :, :, :, 0])","(n_cams, n_frames, n_joints, n_possible, _), good = p2ds.shape, ~np.isnan(p2ds[:, :, :, :, 0])","(n_cams, n_frames, n_joints, n_possible, _) = zejun1
good = zejun2",Cannot refactor,-1,1,,,
DeepGBM,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/DeepGBM/models/deepgbm.py,https://github.com/motefly/DeepGBM/tree/master/models/deepgbm.py,DeepGBM,forward$55,"def forward(self, Xg, Xd):
        Xd = Xd.long()
        if self.num_model == 'gbdt2nn':
            gbdt2nn_out, gbdt2nn_pred = self.gbdt2nn(Xg)
        elif self.num_model == 'gbdt':
            gbdt2nn_out = Xg.float()
            gbdt2nn_pred = None
        else:
            gbdt2nn_out = self.gbdt2nn(Xg)
            gbdt2nn_pred = None
        deepfm_out = self.deepfm(Xd)

        if self.num_model != 'gbdt2nn':
            alpha = self.alpha+0.5
            beta = self.beta+0.5
        else:
            alpha = self.alpha+1
            beta = self.beta
        out = alpha * gbdt2nn_out.view(-1) + beta * deepfm_out.view(-1)
        if self.task != 'regression':
            return nn.Sigmoid()(out), gbdt2nn_pred
        return out, gbdt2nn_pred","alpha = self.alpha + 1
beta = self.beta","alpha, beta= self.alpha + 1, self.beta","alpha = zejun1
beta = zejun2",Cannot refactor,-1,1,,,
DeepGBM,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/DeepGBM/models/deepgbm.py,https://github.com/motefly/DeepGBM/tree/master/models/deepgbm.py,DeepGBM,forward$55,"def forward(self, Xg, Xd):
        Xd = Xd.long()
        if self.num_model == 'gbdt2nn':
            gbdt2nn_out, gbdt2nn_pred = self.gbdt2nn(Xg)
        elif self.num_model == 'gbdt':
            gbdt2nn_out = Xg.float()
            gbdt2nn_pred = None
        else:
            gbdt2nn_out = self.gbdt2nn(Xg)
            gbdt2nn_pred = None
        deepfm_out = self.deepfm(Xd)

        if self.num_model != 'gbdt2nn':
            alpha = self.alpha+0.5
            beta = self.beta+0.5
        else:
            alpha = self.alpha+1
            beta = self.beta
        out = alpha * gbdt2nn_out.view(-1) + beta * deepfm_out.view(-1)
        if self.task != 'regression':
            return nn.Sigmoid()(out), gbdt2nn_pred
        return out, gbdt2nn_pred","gbdt2nn_out = self.gbdt2nn(Xg)
gbdt2nn_pred = None","gbdt2nn_out, gbdt2nn_pred= self.gbdt2nn(Xg), None","gbdt2nn_out = zejun1
gbdt2nn_pred = zejun2",Cannot refactor,-1,1,,,
Paddle,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/Paddle/python/paddle/distributed/fleet/meta_optimizers/pipeline_optimizer.py,https://github.com/PaddlePaddle/Paddle/tree/master/python/paddle/distributed/fleet/meta_optimizers/pipeline_optimizer.py,PipelineOptimizer,minimize_impl$200,"def minimize_impl(
        self, loss, startup_program=None, parameter_list=None, no_grad_set=None
    ):
        self.endpoints = self.role_maker._get_trainer_endpoints()
        self.current_endpoint = self.endpoints[self.role_maker._worker_index()]
        self.rank = self.role_maker._worker_index()
        self.nranks = self.role_maker._worker_num()

        self.wrapped_opt = PO(
            self.inner_opt, num_microbatches=self.num_microbatches
        )
        orig_startup_program = (
            startup_program
            if startup_program
            else paddle.static.default_startup_program()
        )
        block = loss.block
        program = block.program

        program._pipeline_opt = dict()
        program._pipeline_opt['local_rank'] = self.rank
        program._pipeline_opt['global_ring_id'] = self.global_ring_id
        program._pipeline_opt['ring_id'] = self.start_pipeline_ring_id
        program._pipeline_opt['micro_batch_size'] = self.micro_batch_size
        program._pipeline_opt['schedule_mode'] = self.schedule_mode
        program._pipeline_opt['use_sharding'] = False
        program._pipeline_opt['mp_degree'] = 1
        program._pipeline_opt['mp_rank'] = 0
        (
            optimize_ops,
            params_grads,
            prog_list,
            pp_pair,
            ring_map,
        ) = self.wrapped_opt.minimize(
            loss, startup_program, parameter_list, no_grad_set
        )
        self.startup_program = orig_startup_program._pipeline_opt[
            'startup_program'
        ]
        self.inner_parallelism = program._pipeline_opt['inner_parallelism']
        assert self.nranks % self.inner_parallelism == 0
        assert prog_list
        self.pipeline_num = len(self.endpoints) // self.inner_parallelism

        self._init_process_group(pp_pair, ring_map)

        self.main_program_list = prog_list
        self.main_program = program
        if self.pipeline_num > 1:
            self._transpile_main_program(loss)
        return optimize_ops, params_grads","(optimize_ops, params_grads, prog_list, pp_pair, ring_map) = self.wrapped_opt.minimize(loss, startup_program, parameter_list, no_grad_set)
self.startup_program = orig_startup_program._pipeline_opt['startup_program']
self.inner_parallelism = program._pipeline_opt['inner_parallelism']","(optimize_ops, params_grads, prog_list, pp_pair, ring_map), self.startup_program, self.inner_parallelism = self.wrapped_opt.minimize(loss, startup_program, parameter_list, no_grad_set), orig_startup_program._pipeline_opt['startup_program'], program._pipeline_opt['inner_parallelism']","(optimize_ops, params_grads, prog_list, pp_pair, ring_map) = zejun1
self.startup_program = zejun2
self.inner_parallelism = zejun3",Cannot refactor,-1,1,,,
glTF-Blender-Exporter,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/glTF-Blender-Exporter/scripts/addons/io_scene_gltf2/gltf2_generate.py,https://github.com/KhronosGroup/glTF-Blender-Exporter/tree/master/scripts/addons/io_scene_gltf2/gltf2_generate.py,,generate_nodes$1720,"def generate_nodes(operator,
                   context,
                   export_settings,
                   glTF):
    """"""
    Generates the top level nodes entry.
    """"""

    nodes = []

    skins = []

    #
    #

    filtered_objects = export_settings['filtered_objects']

    for blender_object in filtered_objects:
        node = generate_node_instance(context, export_settings, glTF, nodes, blender_object, False)

        #
        #

        nodes.append(node)

    #
    #

    for blender_object in filtered_objects:
        if blender_object.dupli_type == 'GROUP' and blender_object.dupli_group != None:

            if export_settings['gltf_layers'] or (blender_object.layers[0] and blender_object.dupli_group.layers[0]):

                for blender_dupli_object in blender_object.dupli_group.objects:
                    node = generate_node_instance(context, export_settings, glTF, nodes, blender_dupli_object,
                                                  True)

                    node['name'] = 'Duplication_' + blender_object.name + '_' + blender_dupli_object.name

                    #
                    #

                    nodes.append(node)

                #

                node = {}

                node['name'] = 'Duplication_Offset_' + blender_object.name

                translation = convert_swizzle_location(blender_object.dupli_group.dupli_offset, export_settings)

                node['translation'] = [-translation[0], -translation[1], -translation[2]]

                nodes.append(node)

    #
    #

    if len(nodes) > 0:
        glTF['nodes'] = nodes

    #
    #

    if export_settings['gltf_skins']:
        for blender_object in filtered_objects:
            if blender_object.type != 'ARMATURE' or len(blender_object.pose.bones) == 0:
                continue

            temp_action = None

            if export_settings['gltf_bake_skins'] and not export_settings['gltf_animations']:
                if blender_object.animation_data is not None:
                    temp_action = blender_object.animation_data.action

                bpy.context.scene.objects.active = blender_object
                bpy.ops.object.mode_set(mode='POSE')
                bpy.ops.nla.bake(frame_start=bpy.context.scene.frame_current, frame_end=bpy.context.scene.frame_current,
                                 only_selected=False, visual_keying=True, clear_constraints=False,
                                 use_current_action=False, bake_types={'POSE'})

            joints = []

            joints_written = False

            #

            children_list = list(blender_object.children)

            for blender_check_object in filtered_objects:
                blender_check_armature = blender_check_object.find_armature()

                if blender_check_armature == blender_object and blender_check_object not in children_list:
                    children_list.append(blender_check_object)

            #

            for blender_object_child in children_list:
                #
                # Property: skin and node
                #

                inverse_matrices = []

                for blender_bone in blender_object.pose.bones:

                    if export_settings['gltf_yup']:
                        axis_basis_change = mathutils.Matrix(
                            ((1.0, 0.0, 0.0, 0.0), (0.0, 0.0, 1.0, 0.0), (0.0, -1.0, 0.0, 0.0), (0.0, 0.0, 0.0, 1.0)))
                    else:
                        axis_basis_change = mathutils.Matrix.Identity(4)

                    if not joints_written:
                        node = {}

                        if blender_bone.parent is None:
                            correction_matrix_local = axis_basis_change * blender_bone.bone.matrix_local
                        else:
                            correction_matrix_local = blender_bone.parent.bone.matrix_local.inverted() * blender_bone.bone.matrix_local

                        matrix_basis = blender_bone.matrix_basis

                        if export_settings['gltf_bake_skins']:
                            matrix_basis = blender_object.convert_space(blender_bone, blender_bone.matrix,
                                                                        from_space='POSE', to_space='LOCAL')

                        generate_node_parameter(export_settings, correction_matrix_local * matrix_basis, node, 'JOINT')

                        #

                        node['name'] = blender_object.name + ""_"" + blender_bone.name

                        #
                        #

                        joints.append(len(nodes))

                        nodes.append(node)

                    #
                    #

                    inverse_bind_matrix = axis_basis_change * blender_bone.bone.matrix_local

                    bind_shape_matrix = axis_basis_change * blender_object.matrix_world.inverted() * blender_object_child.matrix_world * axis_basis_change.inverted()

                    inverse_bind_matrix = inverse_bind_matrix.inverted() * bind_shape_matrix

                    for column in range(0, 4):
                        for row in range(0, 4):
                            inverse_matrices.append(inverse_bind_matrix[row][column])

                #

                joints_written = True

                #

                skin = {}

                skin['skeleton'] = get_node_index(glTF, blender_object.name)

                skin['joints'] = joints

                #
                count = len(inverse_matrices) // 16
                type = ""MAT4""

                inverseBindMatrices = create_accessor(
                    operator,
                    context,
                    export_settings,
                    glTF,
                    inverse_matrices,
                    GLTF_COMPONENT_TYPE_FLOAT,
                    count,
                    GLTF_DATA_TYPE_MAT4,
                    """"
                )

                skin['inverseBindMatrices'] = inverseBindMatrices

                #

                skins.append(skin)

            #

            if temp_action is not None:
                blender_object.animation_data.action = temp_action

    #
    #

    if len(skins) > 0:
        glTF['skins'] = skins

    #
    # Resolve children etc.
    #

    for blender_object in filtered_objects:
        node_index = get_node_index(glTF, blender_object.name)

        node = nodes[node_index]

        #

        if export_settings['gltf_skins']:
            blender_armature = blender_object.find_armature()
            if blender_armature is not None:

                if blender_object in blender_armature.children:
                    index_offset = blender_armature.children.index(blender_object)
                else:
                    index_local_offset = 0

                    for blender_check_object in filtered_objects:
                        blender_check_armature = blender_check_object.find_armature()
                        if blender_check_armature == blender_armature:
                            index_local_offset += 1

                        if blender_object == blender_check_object:
                            index_local_offset -= 1
                            break

                    index_offset = len(blender_armature.children) + index_local_offset

                node['skin'] = get_skin_index(glTF, blender_armature.name, index_offset)

        #

        children = []

        # Camera
        if export_settings['gltf_cameras']:
            if blender_object.type == 'CAMERA':
                child_index = get_node_index(glTF, 'Correction_' + blender_object.name)
                if child_index >= 0:
                    children.append(child_index)

        # Light
        if export_settings['gltf_lights']:
            if blender_object.type == 'LAMP':
                child_index = get_node_index(glTF, 'Correction_' + blender_object.name)
                if child_index >= 0:
                    children.append(child_index)

        # Nodes
        for blender_child_node in blender_object.children:
            child_index = get_node_index(glTF, blender_child_node.name)

            if blender_child_node.parent_type == 'BONE' and export_settings['gltf_skins']:
                continue

            if child_index < 0:
                continue

            children.append(child_index)

        # Duplications
        if blender_object.dupli_type == 'GROUP' and blender_object.dupli_group is not None:

            child_index = get_node_index(glTF, 'Duplication_Offset_' + blender_object.name)
            if child_index >= 0:
                children.append(child_index)

                duplication_node = nodes[child_index]

                duplication_children = []

                for blender_dupli_object in blender_object.dupli_group.objects:
                    child_index = get_node_index(
                        glTF,
                        'Duplication_' + blender_object.name + '_' + blender_dupli_object.name
                    )
                    if child_index >= 0:
                        duplication_children.append(child_index)

                duplication_node['children'] = duplication_children

                #

        if export_settings['gltf_skins']:
            # Joint
            if blender_object.type == 'ARMATURE' and len(blender_object.pose.bones) > 0:

                #

                blender_object_to_bone = {}

                if export_settings['gltf_skins']:
                    for blender_child_node in blender_object.children:
                        if blender_child_node.parent_type == 'BONE':
                            blender_object_to_bone[blender_child_node.name] = blender_child_node.parent_bone

                #

                for blender_bone in blender_object.pose.bones:

                    if blender_bone.parent:
                        continue

                    child_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone.name)

                    if child_index < 0:
                        continue

                    children.append(child_index)

                for blender_bone in blender_object.pose.bones:
                    joint_children = []
                    for blender_bone_child in blender_bone.children:
                        child_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone_child.name)

                        if child_index < 0:
                            continue

                        joint_children.append(child_index)

                    for blender_object_name in blender_object_to_bone:
                        blender_bone_name = blender_object_to_bone[blender_object_name]
                        if blender_bone_name == blender_bone.name:
                            child_index = get_node_index(glTF, blender_object_name)

                            if child_index < 0:
                                continue

                            joint_children.append(child_index)

                    if len(joint_children) > 0:
                        node_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone.name)

                        child_node = nodes[node_index]

                        child_node['children'] = joint_children

        if len(children) > 0:
            node['children'] = children","skin['skeleton'] = get_node_index(glTF, blender_object.name)
skin['joints'] = joints
count = len(inverse_matrices) // 16
type = 'MAT4'","skin['skeleton'], skin['joints'], count, type = get_node_index(glTF, blender_object.name), joints, len(inverse_matrices) // 16, 'MAT4'","skin['skeleton'] = zejun1
skin['joints'] = zejun2
count = zejun3
type = zejun4",Cannot refactor,-1,1,,,
ai-economist,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/ai-economist/tutorials/rllib/tf_models.py,https://github.com/salesforce/ai-economist/tree/master/tutorials/rllib/tf_models.py,RandomAction,__init__$393,"def __init__(self, obs_space, action_space, num_outputs, model_config, name):
        super().__init__(obs_space, action_space, num_outputs, model_config, name)

        if hasattr(obs_space, ""original_space""):
            original_space = obs_space.original_space
        else:
            assert isinstance(obs_space, Dict)
            original_space = obs_space

        mask = original_space.spaces[_MASK_NAME]
        mask_input = keras.layers.Input(shape=mask.shape, name=_MASK_NAME)

        self.inputs = [
            keras.layers.Input(shape=(1,), name=""observations""),
            mask_input,
        ]

        logits_and_value = keras.layers.Dense(
            num_outputs + 1, activation=None, name=""dummy_layer""
        )(self.inputs[0])

        unmasked_logits = logits_and_value[:, :num_outputs] * 0.0
        values = logits_and_value[:, -1]

        masked_logits = apply_logit_mask(unmasked_logits, mask_input)

        self.base_model = keras.Model(self.inputs, [masked_logits, values])
        self.register_variables(self.base_model.variables)

        # This will be set in the forward() call below
        self.values = None","unmasked_logits = logits_and_value[:, :num_outputs] * 0.0
values = logits_and_value[:, -1]","unmasked_logits, values= logits_and_value[:, :num_outputs] * 0.0, logits_and_value[:, -1]","unmasked_logits = zejun1
values = zejun2",Cannot refactor,-1,1,,,
mmdetection,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/mmdetection/mmdet/core/bbox/assigners/sim_ota_assigner.py,https://github.com/open-mmlab/mmdetection/tree/master/mmdet/core/bbox/assigners/sim_ota_assigner.py,SimOTAAssigner,dynamic_k_matching$230,"def dynamic_k_matching(self, cost, pairwise_ious, num_gt, valid_mask):
        matching_matrix = torch.zeros_like(cost, dtype=torch.uint8)
        # select candidate topk ious for dynamic-k calculation
        candidate_topk = min(self.candidate_topk, pairwise_ious.size(0))
        topk_ious, _ = torch.topk(pairwise_ious, candidate_topk, dim=0)
        # calculate dynamic k for each gt
        dynamic_ks = torch.clamp(topk_ious.sum(0).int(), min=1)
        for gt_idx in range(num_gt):
            _, pos_idx = torch.topk(
                cost[:, gt_idx], k=dynamic_ks[gt_idx], largest=False)
            matching_matrix[:, gt_idx][pos_idx] = 1

        del topk_ious, dynamic_ks, pos_idx

        prior_match_gt_mask = matching_matrix.sum(1) > 1
        if prior_match_gt_mask.sum() > 0:
            cost_min, cost_argmin = torch.min(
                cost[prior_match_gt_mask, :], dim=1)
            matching_matrix[prior_match_gt_mask, :] *= 0
            matching_matrix[prior_match_gt_mask, cost_argmin] = 1
        # get foreground mask inside box and center prior
        fg_mask_inboxes = matching_matrix.sum(1) > 0
        valid_mask[valid_mask.clone()] = fg_mask_inboxes

        matched_gt_inds = matching_matrix[fg_mask_inboxes, :].argmax(1)
        matched_pred_ious = (matching_matrix *
                             pairwise_ious).sum(1)[fg_mask_inboxes]
        return matched_pred_ious, matched_gt_inds","(_, pos_idx) = torch.topk(cost[:, gt_idx], k=dynamic_ks[gt_idx], largest=False)
matching_matrix[:, gt_idx][pos_idx] = 1","(_, pos_idx), matching_matrix[:, gt_idx][pos_idx] = torch.topk(cost[:, gt_idx], k=dynamic_ks[gt_idx], largest=False), 1","(_, pos_idx) = zejun1
matching_matrix[:, gt_idx][pos_idx] = zejun2",Cannot refactor,-1,1,,,
pandas,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pandas/pandas/tests/io/formats/style/test_to_latex.py,https://github.com/pandas-dev/pandas/tree/master/pandas/tests/io/formats/style/test_to_latex.py,,test_multi_options$335,"def test_multi_options(df_ext):
    cidx = MultiIndex.from_tuples([(""Z"", ""a""), (""Z"", ""b""), (""Y"", ""c"")])
    ridx = MultiIndex.from_tuples([(""A"", ""a""), (""A"", ""b""), (""B"", ""c"")])
    df_ext.index, df_ext.columns = ridx, cidx
    styler = df_ext.style.format(precision=2)

    expected = dedent(
        """"""\
     &  & \\multicolumn{2}{r}{Z} & Y \\\\
     &  & a & b & c \\\\
    \\multirow[c]{2}{*}{A} & a & 0 & -0.61 & ab \\\\
    """"""
    )
    result = styler.to_latex()
    assert expected in result

    with option_context(""styler.latex.multicol_align"", ""l""):
        assert "" &  & \\multicolumn{2}{l}{Z} & Y \\\\"" in styler.to_latex()

    with option_context(""styler.latex.multirow_align"", ""b""):
        assert ""\\multirow[b]{2}{*}{A} & a & 0 & -0.61 & ab \\\\"" in styler.to_latex()","styler = df_ext.style.format(precision=2)
expected = dedent('     &  & \\multicolumn{2}{r}{Z} & Y \\\\\n     &  & a & b & c \\\\\n    \\multirow[c]{2}{*}{A} & a & 0 & -0.61 & ab \\\\\n    ')","styler, expected = df_ext.style.format(precision=2), dedent('     &  & \\multicolumn{2}{r}{Z} & Y \\\\\n     &  & a & b & c \\\\\n    \\multirow[c]{2}{*}{A} & a & 0 & -0.61 & ab \\\\\n    ')","styler = zejun1
expected = zejun2",Cannot refactor,-1,1,,,
tvm,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/tvm/tests/python/contrib/test_ethosu/test_tir_to_cs_translator.py,https://github.com/apache/tvm/tree/master/tests/python/contrib/test_ethosu/test_tir_to_cs_translator.py,,test_assign_addresses$698,"def test_assign_addresses():
    test_cases = [
        {
            # Stimulus
            ""tir_module"": WeightStreamOnly,
            ""param_dict"": {
                WeightStreamOnly[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [128], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_3""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_4""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_5""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_6""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_7""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
            },
        },
        {
            # Stimulus
            ""tir_module"": MixedRead,
            ""param_dict"": {
                MixedRead[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [592], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [160], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_3""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_4""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_5""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_6""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_7""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_8""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_9""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
            },
        },
        {
            # Stimulus
            ""tir_module"": MixedConstantDatatypes,
            ""param_dict"": {
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [160], ""uint8""
                ),
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""int16"").min, np.iinfo(""int16"").max, [1], ""int16""
                ),
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [272], ""uint8""
                ),
            },
        },
    ]

    def extract_call_extern_list(mod):
        """"""This function will obtain all ethosu_conv2d
        calls from a NPU TIR module
        Parameters
        ----------
        mod : tvm.IRModule
            This is a NPU TIR Module

        Returns
        -------
        list
            of tvm.tir.Call objects
            that are tir extern calls
            for ethosu_conv2d
        """"""
        # There should only be a single function
        assert len(mod.functions.items()) == 1
        primfunc = mod.functions.items()[0][1]

        extern_calls = list()

        def populate_extern_calls(stmt):
            if isinstance(stmt, tvm.tir.Call) and stmt.op.name == ""tir.call_extern"":
                extern_calls.append(stmt)

        stmt_functor.post_order_visit(primfunc.body, populate_extern_calls)
        return extern_calls

    def collect_tir_buffer_info(npu_ops):
        """"""This is run prior to address assigning to collect tir buffer information
        for verification later on""""""
        _npu_op_tir_buffers = dict()
        for npu_op in npu_ops:
            if isinstance(npu_op, vapi.NpuDmaOperation):
                _npu_op_tir_buffers[npu_op] = (npu_op.src.address, npu_op.dest.address)
            elif issubclass(type(npu_op), vapi.NpuBlockOperation):
                _npu_op_tir_buffers[npu_op] = (
                    npu_op.ifm.tiles.addresses[0],
                    npu_op.ofm.tiles.addresses[0],
                    npu_op.weights,
                    npu_op.biases,
                )
        return _npu_op_tir_buffers

    def _check_buffer(address, region, length, buffer_var):
        """"""Checks whether the buffer information is valid with
        original tir buffers.
        - If its constant, this will check
          the slice in the constant tensor has the values.
        - If its scratch, this will check
          the slice is within scratch and does not have conflicts
          with other scratch tensors.
        - If its input/output, this will check the
          address is zero
        """"""
        inverse_region_map = {
            0: tir_to_cs_translator.BufferType.constant,
            1: tir_to_cs_translator.BufferType.scratch,
            3: tir_to_cs_translator.BufferType.input,
            4: tir_to_cs_translator.BufferType.output,
        }
        buffer_type = inverse_region_map[region]
        buffer_dtype = buffer_var.type_annotation.element_type.dtype
        dtype_bytes = np.iinfo(np.dtype(buffer_dtype)).bits // 8
        if buffer_type == tir_to_cs_translator.BufferType.constant:
            ref = buffer_info[buffer_var].values
            hex_from = address * dtype_bytes * 2
            hex_to = hex_from + length * dtype_bytes * 2
            constant_hex = constant_hex_string[hex_from:hex_to]
            constant_tensor = np.frombuffer(bytearray.fromhex(constant_hex), dtype=buffer_dtype)
            np.array_equal(constant_tensor, ref)
            # Every buffer is adjusted to align to 16 bytes
            length = util.round_up(length, 16)
            # Mark these constants are read at least once
            constant_tensor_read_mask[address : address + length] = np.ones(
                length, dtype=buffer_dtype
            )
        elif buffer_type == tir_to_cs_translator.BufferType.scratch:
            assert address < tvmbaw_workspace_size

            size_in_bytes = allocate_node_sizes[buffer_var]
            # Every buffer is adjusted to align to 16 bytes
            size_in_bytes = util.round_up(size_in_bytes, 16)
            assert address + size_in_bytes <= tvmbaw_workspace_size
            # The scratch area should not be used by any other buffer
            assert not tvmbaw_workspace_mask[address : address + size_in_bytes].any()
            # The scratch area is marked as used
            tvmbaw_workspace_mask[address : address + size_in_bytes] = np.ones(
                size_in_bytes, dtype=""uint8""
            )
        elif buffer_type == tir_to_cs_translator.BufferType.input:
            assert address == 0
        else:
            assert buffer_type == tir_to_cs_translator.BufferType.output
            assert address == 0

    def _get_allocate_node_sizes(mod):
        # There should only be a single function
        assert len(mod.functions.items()) == 1
        primfunc = mod.functions.items()[0][1]
        _allocate_node_sizes = dict()

        def analyze_remaining_allocates(stmt):
            if isinstance(stmt, tvm.tir.stmt.Allocate):
                allocate = stmt
                pointer_type = allocate.buffer_var.type_annotation
                storage_scope = pointer_type.storage_scope
                if storage_scope == ""global"":
                    dtype_bytes = np.iinfo(np.dtype(allocate.dtype)).bits // 8
                    size_in_bytes = int(dtype_bytes * np.prod(list(allocate.extents)))
                    # Every memory address the NPU access have to be 16 byte aligned
                    size_in_bytes = util.round_up(size_in_bytes, 16)
                    _allocate_node_sizes[allocate.buffer_var] = size_in_bytes

        tvm.tir.stmt_functor.post_order_visit(primfunc.body, analyze_remaining_allocates)
        return _allocate_node_sizes

    def verify(npu_ops):
        """"""This wrapper verifies the allocated addresses matches with original tir buffers""""""
        checked_buffers = set()

        def check_buffer(address, region, length, buffer_var):
            if buffer_var not in checked_buffers:
                _check_buffer(address, region, length, buffer_var)
                checked_buffers.add(buffer_var)

        for npu_op in npu_ops:
            if isinstance(npu_op, vapi.NpuDmaOperation):
                src_tir_buffer_var = npu_op_tir_buffers[npu_op][0].buffer.data
                check_buffer(
                    npu_op.src.address, npu_op.src.region, npu_op.src.length, src_tir_buffer_var
                )
                dest_tir_load = npu_op_tir_buffers[npu_op][1].buffer.data
                check_buffer(
                    npu_op.dest.address,
                    npu_op.dest.region,
                    npu_op.dest.length,
                    dest_tir_load,
                )
            elif issubclass(type(npu_op), vapi.NpuBlockOperation):
                ifm_tir_buffer_var = npu_op_tir_buffers[npu_op][0].buffer.data
                ifm_length = (
                    npu_op.ifm.shape.height * npu_op.ifm.shape.width * npu_op.ifm.shape.depth
                )
                check_buffer(
                    npu_op.ifm.tiles.addresses[0],
                    npu_op.ifm.region,
                    ifm_length,
                    ifm_tir_buffer_var,
                )
                ofm_tir_buffer_var = npu_op_tir_buffers[npu_op][1].buffer.data
                ofm_length = (
                    npu_op.ofm.shape.height * npu_op.ofm.shape.width * npu_op.ofm.shape.depth
                )
                check_buffer(
                    npu_op.ofm.tiles.addresses[0],
                    npu_op.ofm.region,
                    ofm_length,
                    ofm_tir_buffer_var,
                )
                for idx, weight in enumerate(npu_op_tir_buffers[npu_op][2]):
                    assert isinstance(weight, vapi.NpuAddressRange)
                    check_buffer(
                        npu_op.weights[idx].address,
                        npu_op.weights[idx].region,
                        npu_op.weights[idx].length,
                        weight.address.buffer.data,
                    )
                for idx, bias in enumerate(npu_op_tir_buffers[npu_op][3]):
                    assert isinstance(bias, vapi.NpuAddressRange)
                    check_buffer(
                        npu_op.biases[idx].address,
                        npu_op.biases[idx].region,
                        npu_op.biases[idx].length,
                        bias.address.buffer.data,
                    )

    for test_case in test_cases:
        tir_mod = test_case[""tir_module""]
        tir_mod[""main""] = tir_mod[""main""].with_attr(""target"", tvm.target.Target(""ethos-u""))
        tir_mod = tvm.tir.transform.MakeUnpackedAPI()(tir_mod)
        candidate_regions_for_scratch = [5, 2, 1]
        (
            scratch_region_map,
            tvmbaw_workspace_size,
            _,
        ) = tir_to_cs_translator.analyze_scratch_memory_acesses(
            tir_mod, candidate_regions_for_scratch
        )
        allocate_node_sizes = _get_allocate_node_sizes(tir_mod)
        buffer_info = tir_to_cs_translator.extract_buffer_info(tir_mod, test_case[""param_dict""])
        extern_calls = extract_call_extern_list(tir_mod)
        _npu_ops = list()
        for extern_call in extern_calls:
            _npu_ops.append(tir_to_cs_translator.translate_ethosu_tir_call_extern(extern_call))
        npu_op_tir_buffers = collect_tir_buffer_info(_npu_ops)
        (_npu_ops, constant_hex_string) = tir_to_cs_translator.assign_addresses(
            buffer_info, _npu_ops, scratch_region_map
        )
        tvmbaw_workspace_mask = np.zeros(tvmbaw_workspace_size, dtype=""uint8"")
        constant_tensor_read_mask = np.zeros(len(constant_hex_string) // 2, dtype=""uint8"")
        verify(_npu_ops)
        # This will be only 1 if all allocated scratch is used.
        assert np.prod(tvmbaw_workspace_mask) == 1
        # This will be only 1 if all constant tensors is read at least once.
        assert np.prod(constant_tensor_read_mask) == 1","(scratch_region_map, tvmbaw_workspace_size, _) = tir_to_cs_translator.analyze_scratch_memory_acesses(tir_mod, candidate_regions_for_scratch)
allocate_node_sizes = _get_allocate_node_sizes(tir_mod)
buffer_info = tir_to_cs_translator.extract_buffer_info(tir_mod, test_case['param_dict'])
extern_calls = extract_call_extern_list(tir_mod)
_npu_ops = list()","(scratch_region_map, tvmbaw_workspace_size, _, buffer_info, extern_calls, _npu_ops) = tir_to_cs_translator.analyze_scratch_memory_acesses(tir_mod, candidate_regions_for_scratch), tir_to_cs_translator.extract_buffer_info(tir_mod, test_case['param_dict']), extract_call_extern_list(tir_mod), list()","(scratch_region_map, tvmbaw_workspace_size, _) = zejun1
buffer_info = zejun3
extern_calls = zejun4
_npu_ops = zejun5",Cannot refactor,-1,1,,,
tvm,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/tvm/tests/python/contrib/test_ethosu/test_tir_to_cs_translator.py,https://github.com/apache/tvm/tree/master/tests/python/contrib/test_ethosu/test_tir_to_cs_translator.py,,test_assign_addresses$698,"def test_assign_addresses():
    test_cases = [
        {
            # Stimulus
            ""tir_module"": WeightStreamOnly,
            ""param_dict"": {
                WeightStreamOnly[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [128], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_3""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_4""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_5""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_6""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_7""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
            },
        },
        {
            # Stimulus
            ""tir_module"": MixedRead,
            ""param_dict"": {
                MixedRead[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [592], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [160], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_3""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_4""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_5""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_6""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_7""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_8""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_9""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
            },
        },
        {
            # Stimulus
            ""tir_module"": MixedConstantDatatypes,
            ""param_dict"": {
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [160], ""uint8""
                ),
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""int16"").min, np.iinfo(""int16"").max, [1], ""int16""
                ),
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [272], ""uint8""
                ),
            },
        },
    ]

    def extract_call_extern_list(mod):
        """"""This function will obtain all ethosu_conv2d
        calls from a NPU TIR module
        Parameters
        ----------
        mod : tvm.IRModule
            This is a NPU TIR Module

        Returns
        -------
        list
            of tvm.tir.Call objects
            that are tir extern calls
            for ethosu_conv2d
        """"""
        # There should only be a single function
        assert len(mod.functions.items()) == 1
        primfunc = mod.functions.items()[0][1]

        extern_calls = list()

        def populate_extern_calls(stmt):
            if isinstance(stmt, tvm.tir.Call) and stmt.op.name == ""tir.call_extern"":
                extern_calls.append(stmt)

        stmt_functor.post_order_visit(primfunc.body, populate_extern_calls)
        return extern_calls

    def collect_tir_buffer_info(npu_ops):
        """"""This is run prior to address assigning to collect tir buffer information
        for verification later on""""""
        _npu_op_tir_buffers = dict()
        for npu_op in npu_ops:
            if isinstance(npu_op, vapi.NpuDmaOperation):
                _npu_op_tir_buffers[npu_op] = (npu_op.src.address, npu_op.dest.address)
            elif issubclass(type(npu_op), vapi.NpuBlockOperation):
                _npu_op_tir_buffers[npu_op] = (
                    npu_op.ifm.tiles.addresses[0],
                    npu_op.ofm.tiles.addresses[0],
                    npu_op.weights,
                    npu_op.biases,
                )
        return _npu_op_tir_buffers

    def _check_buffer(address, region, length, buffer_var):
        """"""Checks whether the buffer information is valid with
        original tir buffers.
        - If its constant, this will check
          the slice in the constant tensor has the values.
        - If its scratch, this will check
          the slice is within scratch and does not have conflicts
          with other scratch tensors.
        - If its input/output, this will check the
          address is zero
        """"""
        inverse_region_map = {
            0: tir_to_cs_translator.BufferType.constant,
            1: tir_to_cs_translator.BufferType.scratch,
            3: tir_to_cs_translator.BufferType.input,
            4: tir_to_cs_translator.BufferType.output,
        }
        buffer_type = inverse_region_map[region]
        buffer_dtype = buffer_var.type_annotation.element_type.dtype
        dtype_bytes = np.iinfo(np.dtype(buffer_dtype)).bits // 8
        if buffer_type == tir_to_cs_translator.BufferType.constant:
            ref = buffer_info[buffer_var].values
            hex_from = address * dtype_bytes * 2
            hex_to = hex_from + length * dtype_bytes * 2
            constant_hex = constant_hex_string[hex_from:hex_to]
            constant_tensor = np.frombuffer(bytearray.fromhex(constant_hex), dtype=buffer_dtype)
            np.array_equal(constant_tensor, ref)
            # Every buffer is adjusted to align to 16 bytes
            length = util.round_up(length, 16)
            # Mark these constants are read at least once
            constant_tensor_read_mask[address : address + length] = np.ones(
                length, dtype=buffer_dtype
            )
        elif buffer_type == tir_to_cs_translator.BufferType.scratch:
            assert address < tvmbaw_workspace_size

            size_in_bytes = allocate_node_sizes[buffer_var]
            # Every buffer is adjusted to align to 16 bytes
            size_in_bytes = util.round_up(size_in_bytes, 16)
            assert address + size_in_bytes <= tvmbaw_workspace_size
            # The scratch area should not be used by any other buffer
            assert not tvmbaw_workspace_mask[address : address + size_in_bytes].any()
            # The scratch area is marked as used
            tvmbaw_workspace_mask[address : address + size_in_bytes] = np.ones(
                size_in_bytes, dtype=""uint8""
            )
        elif buffer_type == tir_to_cs_translator.BufferType.input:
            assert address == 0
        else:
            assert buffer_type == tir_to_cs_translator.BufferType.output
            assert address == 0

    def _get_allocate_node_sizes(mod):
        # There should only be a single function
        assert len(mod.functions.items()) == 1
        primfunc = mod.functions.items()[0][1]
        _allocate_node_sizes = dict()

        def analyze_remaining_allocates(stmt):
            if isinstance(stmt, tvm.tir.stmt.Allocate):
                allocate = stmt
                pointer_type = allocate.buffer_var.type_annotation
                storage_scope = pointer_type.storage_scope
                if storage_scope == ""global"":
                    dtype_bytes = np.iinfo(np.dtype(allocate.dtype)).bits // 8
                    size_in_bytes = int(dtype_bytes * np.prod(list(allocate.extents)))
                    # Every memory address the NPU access have to be 16 byte aligned
                    size_in_bytes = util.round_up(size_in_bytes, 16)
                    _allocate_node_sizes[allocate.buffer_var] = size_in_bytes

        tvm.tir.stmt_functor.post_order_visit(primfunc.body, analyze_remaining_allocates)
        return _allocate_node_sizes

    def verify(npu_ops):
        """"""This wrapper verifies the allocated addresses matches with original tir buffers""""""
        checked_buffers = set()

        def check_buffer(address, region, length, buffer_var):
            if buffer_var not in checked_buffers:
                _check_buffer(address, region, length, buffer_var)
                checked_buffers.add(buffer_var)

        for npu_op in npu_ops:
            if isinstance(npu_op, vapi.NpuDmaOperation):
                src_tir_buffer_var = npu_op_tir_buffers[npu_op][0].buffer.data
                check_buffer(
                    npu_op.src.address, npu_op.src.region, npu_op.src.length, src_tir_buffer_var
                )
                dest_tir_load = npu_op_tir_buffers[npu_op][1].buffer.data
                check_buffer(
                    npu_op.dest.address,
                    npu_op.dest.region,
                    npu_op.dest.length,
                    dest_tir_load,
                )
            elif issubclass(type(npu_op), vapi.NpuBlockOperation):
                ifm_tir_buffer_var = npu_op_tir_buffers[npu_op][0].buffer.data
                ifm_length = (
                    npu_op.ifm.shape.height * npu_op.ifm.shape.width * npu_op.ifm.shape.depth
                )
                check_buffer(
                    npu_op.ifm.tiles.addresses[0],
                    npu_op.ifm.region,
                    ifm_length,
                    ifm_tir_buffer_var,
                )
                ofm_tir_buffer_var = npu_op_tir_buffers[npu_op][1].buffer.data
                ofm_length = (
                    npu_op.ofm.shape.height * npu_op.ofm.shape.width * npu_op.ofm.shape.depth
                )
                check_buffer(
                    npu_op.ofm.tiles.addresses[0],
                    npu_op.ofm.region,
                    ofm_length,
                    ofm_tir_buffer_var,
                )
                for idx, weight in enumerate(npu_op_tir_buffers[npu_op][2]):
                    assert isinstance(weight, vapi.NpuAddressRange)
                    check_buffer(
                        npu_op.weights[idx].address,
                        npu_op.weights[idx].region,
                        npu_op.weights[idx].length,
                        weight.address.buffer.data,
                    )
                for idx, bias in enumerate(npu_op_tir_buffers[npu_op][3]):
                    assert isinstance(bias, vapi.NpuAddressRange)
                    check_buffer(
                        npu_op.biases[idx].address,
                        npu_op.biases[idx].region,
                        npu_op.biases[idx].length,
                        bias.address.buffer.data,
                    )

    for test_case in test_cases:
        tir_mod = test_case[""tir_module""]
        tir_mod[""main""] = tir_mod[""main""].with_attr(""target"", tvm.target.Target(""ethos-u""))
        tir_mod = tvm.tir.transform.MakeUnpackedAPI()(tir_mod)
        candidate_regions_for_scratch = [5, 2, 1]
        (
            scratch_region_map,
            tvmbaw_workspace_size,
            _,
        ) = tir_to_cs_translator.analyze_scratch_memory_acesses(
            tir_mod, candidate_regions_for_scratch
        )
        allocate_node_sizes = _get_allocate_node_sizes(tir_mod)
        buffer_info = tir_to_cs_translator.extract_buffer_info(tir_mod, test_case[""param_dict""])
        extern_calls = extract_call_extern_list(tir_mod)
        _npu_ops = list()
        for extern_call in extern_calls:
            _npu_ops.append(tir_to_cs_translator.translate_ethosu_tir_call_extern(extern_call))
        npu_op_tir_buffers = collect_tir_buffer_info(_npu_ops)
        (_npu_ops, constant_hex_string) = tir_to_cs_translator.assign_addresses(
            buffer_info, _npu_ops, scratch_region_map
        )
        tvmbaw_workspace_mask = np.zeros(tvmbaw_workspace_size, dtype=""uint8"")
        constant_tensor_read_mask = np.zeros(len(constant_hex_string) // 2, dtype=""uint8"")
        verify(_npu_ops)
        # This will be only 1 if all allocated scratch is used.
        assert np.prod(tvmbaw_workspace_mask) == 1
        # This will be only 1 if all constant tensors is read at least once.
        assert np.prod(constant_tensor_read_mask) == 1","npu_op_tir_buffers = collect_tir_buffer_info(_npu_ops)
(_npu_ops, constant_hex_string) = tir_to_cs_translator.assign_addresses(buffer_info, _npu_ops, scratch_region_map)
tvmbaw_workspace_mask = np.zeros(tvmbaw_workspace_size, dtype='uint8')","npu_op_tir_buffers, (_npu_ops, constant_hex_string), tvmbaw_workspace_mask = collect_tir_buffer_info(_npu_ops), tir_to_cs_translator.assign_addresses(buffer_info, _npu_ops, scratch_region_map), np.zeros(tvmbaw_workspace_size, dtype='uint8')","npu_op_tir_buffers = zejun1
(_npu_ops, constant_hex_string) = zejun2
tvmbaw_workspace_mask = zejun3",Cannot refactor,-1,1,,,
pydicom,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pydicom/pydicom/tests/test_fileset.py,https://github.com/pydicom/pydicom/tree/master/pydicom/tests/test_fileset.py,TestFileSet_Copy,test_copy$2465,"def test_copy(self, dicomdir, tdir):
        """"""Test FileSet.copy()""""""
        orig_root = Path(dicomdir.filename).parent
        fs = FileSet(dicomdir)

        fs.ID = ""NEW ID""
        uid = fs.UID = generate_uid()
        fs.descriptor_file_id = ""README""
        fs.descriptor_character_set = ""ISO_IR 100""
        cp, ds, paths = copy_fs(fs, tdir.name)
        assert 31 == len(paths)
        assert (
            ('PT000000', 'ST000000', 'SE000000', 'IM000000')
        ) == paths[0].parts[-4:]
        assert (
            ('PT000001', 'ST000003', 'SE000002', 'IM000006')
        ) == paths[-1].parts[-4:]

        # Check existing File-set remains the same
        assert ""NEW ID"" == fs.ID
        assert dicomdir.file_meta.TransferSyntaxUID == ExplicitVRLittleEndian
        assert uid == fs.UID
        assert dicomdir.file_meta.MediaStorageSOPInstanceUID == fs.UID
        assert ""README"" == fs.descriptor_file_id
        assert ""ISO_IR 100"" == fs.descriptor_character_set
        assert not bool(fs._stage['+'])
        assert not bool(fs._stage['-'])
        assert fs.is_staged
        paths = list(orig_root.glob('98892001/**/*'))
        paths += list(orig_root.glob('98892003/**/*'))
        paths += list(orig_root.glob('77654033/**/*'))
        paths = [p for p in paths if p.is_file()]

        # Test new File-set
        assert len(fs) == len(cp)
        for ref, instance in zip(fs, cp):
            assert ref.SOPInstanceUID == instance.SOPInstanceUID

        assert ds.file_meta.TransferSyntaxUID == ExplicitVRLittleEndian
        assert not ds.is_implicit_VR
        assert ds.is_little_endian
        assert not cp.is_staged
        assert ""NEW ID"" == cp.ID
        assert uid == cp.UID
        assert ds.file_meta.MediaStorageSOPInstanceUID == cp.UID
        assert ""README"" == cp.descriptor_file_id
        assert ""ISO_IR 100"" == cp.descriptor_character_set","fs.ID = 'NEW ID'
uid = fs.UID = generate_uid()
fs.descriptor_file_id = 'README'
fs.descriptor_character_set = 'ISO_IR 100'","fs.ID, uid, fs.descriptor_file_id, fs.descriptor_character_set = 'NEW ID', generate_uid(), 'README', 'ISO_IR 100'","fs.ID = zejun1
uid = fs.UID = zejun2
fs.descriptor_file_id = zejun3
fs.descriptor_character_set = zejun4",Cannot refactor,-1,1,,,
Chainer_Realtime_Multi-Person_Pose_Estimation,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/Chainer_Realtime_Multi-Person_Pose_Estimation/pose_detector.py,https://github.com/DeNA/Chainer_Realtime_Multi-Person_Pose_Estimation/tree/master//pose_detector.py,PoseDetector,crop_person$311,"def crop_person(self, img, person_pose, unit_length):
        top_joint_priority = [4, 5, 6, 12, 16, 7, 13, 17, 8, 10, 14, 9, 11, 15, 2, 3, 0, 1, sys.maxsize]
        bottom_joint_priority = [9, 6, 7, 14, 16, 8, 15, 17, 4, 2, 0, 5, 3, 1, 10, 11, 12, 13, sys.maxsize]

        top_joint_index = len(top_joint_priority) - 1
        bottom_joint_index = len(bottom_joint_priority) - 1
        left_joint_index = 0
        right_joint_index = 0
        top_pos = sys.maxsize
        bottom_pos = 0
        left_pos = sys.maxsize
        right_pos = 0

        for i, joint in enumerate(person_pose):
            if joint[2] > 0:
                if top_joint_priority[i] < top_joint_priority[top_joint_index]:
                    top_joint_index = i
                elif bottom_joint_priority[i] < bottom_joint_priority[bottom_joint_index]:
                    bottom_joint_index = i
                if joint[1] < top_pos:
                    top_pos = joint[1]
                elif joint[1] > bottom_pos:
                    bottom_pos = joint[1]

                if joint[0] < left_pos:
                    left_pos = joint[0]
                    left_joint_index = i
                elif joint[0] > right_pos:
                    right_pos = joint[0]
                    right_joint_index = i

        top_padding_radio = [0.9, 1.9, 1.9, 2.9, 3.7, 1.9, 2.9, 3.7, 4.0, 5.5, 7.0, 4.0, 5.5, 7.0, 0.7, 0.8, 0.7, 0.8]
        bottom_padding_radio = [6.9, 5.9, 5.9, 4.9, 4.1, 5.9, 4.9, 4.1, 3.8, 2.3, 0.8, 3.8, 2.3, 0.8, 7.1, 7.0, 7.1, 7.0]

        left = (left_pos - 0.3 * unit_length).astype(int)
        right = (right_pos + 0.3 * unit_length).astype(int)
        top = (top_pos - top_padding_radio[top_joint_index] * unit_length).astype(int)
        bottom = (bottom_pos + bottom_padding_radio[bottom_joint_index] * unit_length).astype(int)
        bbox = (left, top, right, bottom)

        cropped_img = self.crop_image(img, bbox)
        return cropped_img, bbox","bottom_joint_priority = [9, 6, 7, 14, 16, 8, 15, 17, 4, 2, 0, 5, 3, 1, 10, 11, 12, 13, sys.maxsize]
top_joint_index = len(top_joint_priority) - 1","bottom_joint_priority, top_joint_index= [9, 6, 7, 14, 16, 8, 15, 17, 4, 2, 0, 5, 3, 1, 10, 11, 12, 13, sys.maxsize], len(top_joint_priority) - 1","bottom_joint_priority = zejun1
top_joint_index = zejun2",Cannot refactor,-1,1,,,
Chainer_Realtime_Multi-Person_Pose_Estimation,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/Chainer_Realtime_Multi-Person_Pose_Estimation/pose_detector.py,https://github.com/DeNA/Chainer_Realtime_Multi-Person_Pose_Estimation/tree/master//pose_detector.py,PoseDetector,crop_person$311,"def crop_person(self, img, person_pose, unit_length):
        top_joint_priority = [4, 5, 6, 12, 16, 7, 13, 17, 8, 10, 14, 9, 11, 15, 2, 3, 0, 1, sys.maxsize]
        bottom_joint_priority = [9, 6, 7, 14, 16, 8, 15, 17, 4, 2, 0, 5, 3, 1, 10, 11, 12, 13, sys.maxsize]

        top_joint_index = len(top_joint_priority) - 1
        bottom_joint_index = len(bottom_joint_priority) - 1
        left_joint_index = 0
        right_joint_index = 0
        top_pos = sys.maxsize
        bottom_pos = 0
        left_pos = sys.maxsize
        right_pos = 0

        for i, joint in enumerate(person_pose):
            if joint[2] > 0:
                if top_joint_priority[i] < top_joint_priority[top_joint_index]:
                    top_joint_index = i
                elif bottom_joint_priority[i] < bottom_joint_priority[bottom_joint_index]:
                    bottom_joint_index = i
                if joint[1] < top_pos:
                    top_pos = joint[1]
                elif joint[1] > bottom_pos:
                    bottom_pos = joint[1]

                if joint[0] < left_pos:
                    left_pos = joint[0]
                    left_joint_index = i
                elif joint[0] > right_pos:
                    right_pos = joint[0]
                    right_joint_index = i

        top_padding_radio = [0.9, 1.9, 1.9, 2.9, 3.7, 1.9, 2.9, 3.7, 4.0, 5.5, 7.0, 4.0, 5.5, 7.0, 0.7, 0.8, 0.7, 0.8]
        bottom_padding_radio = [6.9, 5.9, 5.9, 4.9, 4.1, 5.9, 4.9, 4.1, 3.8, 2.3, 0.8, 3.8, 2.3, 0.8, 7.1, 7.0, 7.1, 7.0]

        left = (left_pos - 0.3 * unit_length).astype(int)
        right = (right_pos + 0.3 * unit_length).astype(int)
        top = (top_pos - top_padding_radio[top_joint_index] * unit_length).astype(int)
        bottom = (bottom_pos + bottom_padding_radio[bottom_joint_index] * unit_length).astype(int)
        bbox = (left, top, right, bottom)

        cropped_img = self.crop_image(img, bbox)
        return cropped_img, bbox","top_joint_priority = [4, 5, 6, 12, 16, 7, 13, 17, 8, 10, 14, 9, 11, 15, 2, 3, 0, 1, sys.maxsize]
bottom_joint_priority = [9, 6, 7, 14, 16, 8, 15, 17, 4, 2, 0, 5, 3, 1, 10, 11, 12, 13, sys.maxsize]","top_joint_priority, bottom_joint_priority= [4, 5, 6, 12, 16, 7, 13, 17, 8, 10, 14, 9, 11, 15, 2, 3, 0, 1, sys.maxsize], [9, 6, 7, 14, 16, 8, 15, 17, 4, 2, 0, 5, 3, 1, 10, 11, 12, 13, sys.maxsize]","top_joint_priority = zejun1
bottom_joint_priority = zejun2",Cannot refactor,-1,1,,,
Chainer_Realtime_Multi-Person_Pose_Estimation,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/Chainer_Realtime_Multi-Person_Pose_Estimation/pose_detector.py,https://github.com/DeNA/Chainer_Realtime_Multi-Person_Pose_Estimation/tree/master//pose_detector.py,PoseDetector,crop_person$311,"def crop_person(self, img, person_pose, unit_length):
        top_joint_priority = [4, 5, 6, 12, 16, 7, 13, 17, 8, 10, 14, 9, 11, 15, 2, 3, 0, 1, sys.maxsize]
        bottom_joint_priority = [9, 6, 7, 14, 16, 8, 15, 17, 4, 2, 0, 5, 3, 1, 10, 11, 12, 13, sys.maxsize]

        top_joint_index = len(top_joint_priority) - 1
        bottom_joint_index = len(bottom_joint_priority) - 1
        left_joint_index = 0
        right_joint_index = 0
        top_pos = sys.maxsize
        bottom_pos = 0
        left_pos = sys.maxsize
        right_pos = 0

        for i, joint in enumerate(person_pose):
            if joint[2] > 0:
                if top_joint_priority[i] < top_joint_priority[top_joint_index]:
                    top_joint_index = i
                elif bottom_joint_priority[i] < bottom_joint_priority[bottom_joint_index]:
                    bottom_joint_index = i
                if joint[1] < top_pos:
                    top_pos = joint[1]
                elif joint[1] > bottom_pos:
                    bottom_pos = joint[1]

                if joint[0] < left_pos:
                    left_pos = joint[0]
                    left_joint_index = i
                elif joint[0] > right_pos:
                    right_pos = joint[0]
                    right_joint_index = i

        top_padding_radio = [0.9, 1.9, 1.9, 2.9, 3.7, 1.9, 2.9, 3.7, 4.0, 5.5, 7.0, 4.0, 5.5, 7.0, 0.7, 0.8, 0.7, 0.8]
        bottom_padding_radio = [6.9, 5.9, 5.9, 4.9, 4.1, 5.9, 4.9, 4.1, 3.8, 2.3, 0.8, 3.8, 2.3, 0.8, 7.1, 7.0, 7.1, 7.0]

        left = (left_pos - 0.3 * unit_length).astype(int)
        right = (right_pos + 0.3 * unit_length).astype(int)
        top = (top_pos - top_padding_radio[top_joint_index] * unit_length).astype(int)
        bottom = (bottom_pos + bottom_padding_radio[bottom_joint_index] * unit_length).astype(int)
        bbox = (left, top, right, bottom)

        cropped_img = self.crop_image(img, bbox)
        return cropped_img, bbox","top_padding_radio = [0.9, 1.9, 1.9, 2.9, 3.7, 1.9, 2.9, 3.7, 4.0, 5.5, 7.0, 4.0, 5.5, 7.0, 0.7, 0.8, 0.7, 0.8]
bottom_padding_radio = [6.9, 5.9, 5.9, 4.9, 4.1, 5.9, 4.9, 4.1, 3.8, 2.3, 0.8, 3.8, 2.3, 0.8, 7.1, 7.0, 7.1, 7.0]
left = (left_pos - 0.3 * unit_length).astype(int)
right = (right_pos + 0.3 * unit_length).astype(int)","top_padding_radio, bottom_padding_radio, left, right = [0.9, 1.9, 1.9, 2.9, 3.7, 1.9, 2.9, 3.7, 4.0, 5.5, 7.0, 4.0, 5.5, 7.0, 0.7, 0.8, 0.7, 0.8], [6.9, 5.9, 5.9, 4.9, 4.1, 5.9, 4.9, 4.1, 3.8, 2.3, 0.8, 3.8, 2.3, 0.8, 7.1, 7.0, 7.1, 7.0], (left_pos - 0.3 * unit_length).astype(int), (right_pos + 0.3 * unit_length).astype(int)","top_padding_radio = zejun1
bottom_padding_radio = zejun2
left = zejun3
right = zejun4",Cannot refactor,-1,1,,,
Chainer_Realtime_Multi-Person_Pose_Estimation,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/Chainer_Realtime_Multi-Person_Pose_Estimation/pose_detector.py,https://github.com/DeNA/Chainer_Realtime_Multi-Person_Pose_Estimation/tree/master//pose_detector.py,PoseDetector,crop_person$311,"def crop_person(self, img, person_pose, unit_length):
        top_joint_priority = [4, 5, 6, 12, 16, 7, 13, 17, 8, 10, 14, 9, 11, 15, 2, 3, 0, 1, sys.maxsize]
        bottom_joint_priority = [9, 6, 7, 14, 16, 8, 15, 17, 4, 2, 0, 5, 3, 1, 10, 11, 12, 13, sys.maxsize]

        top_joint_index = len(top_joint_priority) - 1
        bottom_joint_index = len(bottom_joint_priority) - 1
        left_joint_index = 0
        right_joint_index = 0
        top_pos = sys.maxsize
        bottom_pos = 0
        left_pos = sys.maxsize
        right_pos = 0

        for i, joint in enumerate(person_pose):
            if joint[2] > 0:
                if top_joint_priority[i] < top_joint_priority[top_joint_index]:
                    top_joint_index = i
                elif bottom_joint_priority[i] < bottom_joint_priority[bottom_joint_index]:
                    bottom_joint_index = i
                if joint[1] < top_pos:
                    top_pos = joint[1]
                elif joint[1] > bottom_pos:
                    bottom_pos = joint[1]

                if joint[0] < left_pos:
                    left_pos = joint[0]
                    left_joint_index = i
                elif joint[0] > right_pos:
                    right_pos = joint[0]
                    right_joint_index = i

        top_padding_radio = [0.9, 1.9, 1.9, 2.9, 3.7, 1.9, 2.9, 3.7, 4.0, 5.5, 7.0, 4.0, 5.5, 7.0, 0.7, 0.8, 0.7, 0.8]
        bottom_padding_radio = [6.9, 5.9, 5.9, 4.9, 4.1, 5.9, 4.9, 4.1, 3.8, 2.3, 0.8, 3.8, 2.3, 0.8, 7.1, 7.0, 7.1, 7.0]

        left = (left_pos - 0.3 * unit_length).astype(int)
        right = (right_pos + 0.3 * unit_length).astype(int)
        top = (top_pos - top_padding_radio[top_joint_index] * unit_length).astype(int)
        bottom = (bottom_pos + bottom_padding_radio[bottom_joint_index] * unit_length).astype(int)
        bbox = (left, top, right, bottom)

        cropped_img = self.crop_image(img, bbox)
        return cropped_img, bbox","bottom_padding_radio = [6.9, 5.9, 5.9, 4.9, 4.1, 5.9, 4.9, 4.1, 3.8, 2.3, 0.8, 3.8, 2.3, 0.8, 7.1, 7.0, 7.1, 7.0]
left = (left_pos - 0.3 * unit_length).astype(int)
right = (right_pos + 0.3 * unit_length).astype(int)
top = (top_pos - top_padding_radio[top_joint_index] * unit_length).astype(int)","bottom_padding_radio, left, right, top = [6.9, 5.9, 5.9, 4.9, 4.1, 5.9, 4.9, 4.1, 3.8, 2.3, 0.8, 3.8, 2.3, 0.8, 7.1, 7.0, 7.1, 7.0], (left_pos - 0.3 * unit_length).astype(int), (right_pos + 0.3 * unit_length).astype(int), (top_pos - top_padding_radio[top_joint_index] * unit_length).astype(int)","bottom_padding_radio = zejun1
left = zejun2
right = zejun3
top = zejun4",Cannot refactor,-1,1,,,
rq,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/rq/rq/queue.py,https://github.com/rq/rq/tree/master/rq/queue.py,Queue,__init__$73,"def __init__(self, name='default', default_timeout=None, connection: t.Optional['Redis'] = None,
                 is_async=True, job_class=None, serializer=None, **kwargs):
        self.connection = resolve_connection(connection)
        prefix = self.redis_queue_namespace_prefix
        self.name = name
        self._key = '{0}{1}'.format(prefix, name)
        self._default_timeout = parse_timeout(default_timeout) or self.DEFAULT_TIMEOUT
        self._is_async = is_async

        if 'async' in kwargs:
            self._is_async = kwargs['async']
            warnings.warn('The `async` keyword is deprecated. Use `is_async` instead', DeprecationWarning)

        # override class attribute job_class if one was passed
        if job_class is not None:
            if isinstance(job_class, string_types):
                job_class = import_attribute(job_class)
            self.job_class = job_class

        self.serializer = resolve_serializer(serializer)
        self.redis_server_version = None","prefix = self.redis_queue_namespace_prefix
self.name = name","prefix, self.name= self.redis_queue_namespace_prefix, name","prefix = zejun1
self.name = zejun2",Cannot refactor,-1,1,,,
shuup,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/shuup/shuup/front/checkout/methods.py,https://github.com/shuup/shuup/tree/master/shuup/front/checkout/methods.py,MethodsPhase,process$121,"def process(self):
        shipping_method = ShippingMethod.objects.filter(pk=self.storage.get(""shipping_method_id"")).first()
        payment_method = PaymentMethod.objects.filter(pk=self.storage.get(""payment_method_id"")).first()

        self.basket.shipping_method = shipping_method if shipping_method else None
        self.basket.payment_method = payment_method if payment_method else None

        # force recalculate lines
        self.basket.uncache()","payment_method = PaymentMethod.objects.filter(pk=self.storage.get('payment_method_id')).first()
self.basket.shipping_method = shipping_method if shipping_method else None","payment_method, self.basket.shipping_method = PaymentMethod.objects.filter(pk=self.storage.get('payment_method_id')).first(), shipping_method if shipping_method else None","payment_method = zejun1
self.basket.shipping_method = zejun2",Cannot refactor,-1,1,,,
shuup,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/shuup/shuup/front/checkout/methods.py,https://github.com/shuup/shuup/tree/master/shuup/front/checkout/methods.py,MethodsPhase,process$121,"def process(self):
        shipping_method = ShippingMethod.objects.filter(pk=self.storage.get(""shipping_method_id"")).first()
        payment_method = PaymentMethod.objects.filter(pk=self.storage.get(""payment_method_id"")).first()

        self.basket.shipping_method = shipping_method if shipping_method else None
        self.basket.payment_method = payment_method if payment_method else None

        # force recalculate lines
        self.basket.uncache()","shipping_method = ShippingMethod.objects.filter(pk=self.storage.get('shipping_method_id')).first()
payment_method = PaymentMethod.objects.filter(pk=self.storage.get('payment_method_id')).first()","shipping_method, payment_method= ShippingMethod.objects.filter(pk=self.storage.get('shipping_method_id')).first(), PaymentMethod.objects.filter(pk=self.storage.get('payment_method_id')).first()","shipping_method = zejun1
payment_method = zejun2",Cannot refactor,-1,1,,,
GPflow,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/GPflow/gpflow/quadrature/gauss_hermite.py,https://github.com/GPflow/GPflow/tree/master/gpflow/quadrature/gauss_hermite.py,NDiagGHQuadrature,_build_X_W$126,"def _build_X_W(self, mean: TensorType, var: TensorType) -> Tuple[tf.Tensor, tf.Tensor]:
        """"""
        :param mean: Array/Tensor with shape [b1, b2, ..., bX, dim], usually [N, dim],
            representing the mean of a dim-Variate Gaussian distribution
        :param var: Array/Tensor with shape b1, b2, ..., bX, dim], usually [N, dim],
            representing the variance of a dim-Variate Gaussian distribution
        :return: points X, Tensor with shape [n_gh_total, b1, b2, ..., bX, dim],
            usually [n_gh_total, N, dim],
            and weights W, a Tensor with shape [n_gh_total, b1, b2, ..., bX, 1],
            usually [n_gh_total, N, 1]
        """"""

        batch_shape_broadcast = tf.ones(tf.rank(mean) - 1, dtype=tf.int32)
        shape_aux = tf.concat([[self.n_gh_total], batch_shape_broadcast], axis=0)

        # mean, var: [b1, b2, ..., bX, dim], usually [N, dim]
        mean = tf.expand_dims(mean, 0)
        stddev = tf.expand_dims(tf.sqrt(var), 0)
        # mean, stddev: [1, b1, b2, ..., bX, dim], usually [1, N, dim]

        Z = tf.cast(tf.reshape(self.Z, tf.concat([shape_aux, [self.dim]], axis=0)), mean.dtype)
        dZ = tf.cast(tf.reshape(self.dZ, tf.concat([shape_aux, [1]], axis=0)), mean.dtype)

        X = mean + stddev * Z
        W = dZ
        # X: [n_gh_total, b1, b2, ..., bX, dim], usually [n_gh_total, N, dim]
        # W: [n_gh_total,  1,  1, ...,  1,   1], usually [n_gh_total, N,   1]

        return X, W","dZ = tf.cast(tf.reshape(self.dZ, tf.concat([shape_aux, [1]], axis=0)), mean.dtype)
X = mean + stddev * Z","dZ, X = tf.cast(tf.reshape(self.dZ, tf.concat([shape_aux, [1]], axis=0)), mean.dtype), mean + stddev * Z","dZ = zejun1
X = zejun2",Cannot refactor,-1,1,,,
GPflow,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/GPflow/gpflow/quadrature/gauss_hermite.py,https://github.com/GPflow/GPflow/tree/master/gpflow/quadrature/gauss_hermite.py,NDiagGHQuadrature,_build_X_W$126,"def _build_X_W(self, mean: TensorType, var: TensorType) -> Tuple[tf.Tensor, tf.Tensor]:
        """"""
        :param mean: Array/Tensor with shape [b1, b2, ..., bX, dim], usually [N, dim],
            representing the mean of a dim-Variate Gaussian distribution
        :param var: Array/Tensor with shape b1, b2, ..., bX, dim], usually [N, dim],
            representing the variance of a dim-Variate Gaussian distribution
        :return: points X, Tensor with shape [n_gh_total, b1, b2, ..., bX, dim],
            usually [n_gh_total, N, dim],
            and weights W, a Tensor with shape [n_gh_total, b1, b2, ..., bX, 1],
            usually [n_gh_total, N, 1]
        """"""

        batch_shape_broadcast = tf.ones(tf.rank(mean) - 1, dtype=tf.int32)
        shape_aux = tf.concat([[self.n_gh_total], batch_shape_broadcast], axis=0)

        # mean, var: [b1, b2, ..., bX, dim], usually [N, dim]
        mean = tf.expand_dims(mean, 0)
        stddev = tf.expand_dims(tf.sqrt(var), 0)
        # mean, stddev: [1, b1, b2, ..., bX, dim], usually [1, N, dim]

        Z = tf.cast(tf.reshape(self.Z, tf.concat([shape_aux, [self.dim]], axis=0)), mean.dtype)
        dZ = tf.cast(tf.reshape(self.dZ, tf.concat([shape_aux, [1]], axis=0)), mean.dtype)

        X = mean + stddev * Z
        W = dZ
        # X: [n_gh_total, b1, b2, ..., bX, dim], usually [n_gh_total, N, dim]
        # W: [n_gh_total,  1,  1, ...,  1,   1], usually [n_gh_total, N,   1]

        return X, W","shape_aux = tf.concat([[self.n_gh_total], batch_shape_broadcast], axis=0)
mean = tf.expand_dims(mean, 0)
stddev = tf.expand_dims(tf.sqrt(var), 0)","shape_aux, mean, stddev = tf.concat([[self.n_gh_total], batch_shape_broadcast], axis=0), tf.expand_dims(mean, 0), tf.expand_dims(tf.sqrt(var), 0)","shape_aux = zejun1
mean = zejun2
stddev = zejun3",Cannot refactor,-1,1,,,
GPflow,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/GPflow/gpflow/quadrature/gauss_hermite.py,https://github.com/GPflow/GPflow/tree/master/gpflow/quadrature/gauss_hermite.py,NDiagGHQuadrature,_build_X_W$126,"def _build_X_W(self, mean: TensorType, var: TensorType) -> Tuple[tf.Tensor, tf.Tensor]:
        """"""
        :param mean: Array/Tensor with shape [b1, b2, ..., bX, dim], usually [N, dim],
            representing the mean of a dim-Variate Gaussian distribution
        :param var: Array/Tensor with shape b1, b2, ..., bX, dim], usually [N, dim],
            representing the variance of a dim-Variate Gaussian distribution
        :return: points X, Tensor with shape [n_gh_total, b1, b2, ..., bX, dim],
            usually [n_gh_total, N, dim],
            and weights W, a Tensor with shape [n_gh_total, b1, b2, ..., bX, 1],
            usually [n_gh_total, N, 1]
        """"""

        batch_shape_broadcast = tf.ones(tf.rank(mean) - 1, dtype=tf.int32)
        shape_aux = tf.concat([[self.n_gh_total], batch_shape_broadcast], axis=0)

        # mean, var: [b1, b2, ..., bX, dim], usually [N, dim]
        mean = tf.expand_dims(mean, 0)
        stddev = tf.expand_dims(tf.sqrt(var), 0)
        # mean, stddev: [1, b1, b2, ..., bX, dim], usually [1, N, dim]

        Z = tf.cast(tf.reshape(self.Z, tf.concat([shape_aux, [self.dim]], axis=0)), mean.dtype)
        dZ = tf.cast(tf.reshape(self.dZ, tf.concat([shape_aux, [1]], axis=0)), mean.dtype)

        X = mean + stddev * Z
        W = dZ
        # X: [n_gh_total, b1, b2, ..., bX, dim], usually [n_gh_total, N, dim]
        # W: [n_gh_total,  1,  1, ...,  1,   1], usually [n_gh_total, N,   1]

        return X, W","stddev = tf.expand_dims(tf.sqrt(var), 0)
Z = tf.cast(tf.reshape(self.Z, tf.concat([shape_aux, [self.dim]], axis=0)), mean.dtype)
dZ = tf.cast(tf.reshape(self.dZ, tf.concat([shape_aux, [1]], axis=0)), mean.dtype)","stddev, Z, dZ = tf.expand_dims(tf.sqrt(var), 0), tf.cast(tf.reshape(self.Z, tf.concat([shape_aux, [self.dim]], axis=0)), mean.dtype), tf.cast(tf.reshape(self.dZ, tf.concat([shape_aux, [1]], axis=0)), mean.dtype)","stddev = zejun1
Z = zejun2
dZ = zejun3",Cannot refactor,-1,1,,,
tvm,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/tvm/tests/python/unittest/test_tir_schedule_compute_at.py,https://github.com/apache/tvm/tree/master/tests/python/unittest/test_tir_schedule_compute_at.py,,non_uniform_tiled_conv$882,"def non_uniform_tiled_conv(x: T.Buffer[(1, 3, 100, 100), ""float32""],
                           w: T.Buffer[(16, 3, 3, 3), ""float32""],
                           y: T.Buffer[(1, 16, 98, 98), ""float32""]) -> None:
    x_global = T.alloc_buffer([1, 3, 100, 100], dtype=""float32"")
    for ax0, ax1, ax2, ax3 in T.grid(1, 3, 100, 100):
        with T.block(""cache""):
            v0, v1, v2, v3 = T.axis.remap(""SSSS"", [ax0, ax1, ax2, ax3])
            x_global[v0, v1, v2, v3] = x[v0, v1, v2, v3]
    for h_o, w_o, n, c_o, h_i, w_i, c_i, kh, kw in T.grid(7, 7, 1, 16, 15, 15, 3, 3, 3):
        with T.block(""compute""):
            nn = T.axis.spatial(1, 0)
            cc = T.axis.spatial(16, c_o)
            hh = T.axis.spatial(98, h_o * 15 + h_i)
            ww = T.axis.spatial(98, w_o * 15 + w_i)
            rc, rh, rw = T.axis.remap(""RRR"", [c_i, kh, kw])
            T.where(h_o * 15 + h_i < 98 and w_o * 15 + w_i < 98)
            with T.init():
                y[nn, cc, hh, ww] = T.float32(0)
            y[nn, cc, hh, ww] = y[nn, cc, hh, ww] + \
                x_global[nn, cc // 16 * 3 + rc, hh + rh, ww + rw] * w[cc, rc, rh, rw]","nn = T.axis.spatial(1, 0)
cc = T.axis.spatial(16, c_o)
hh = T.axis.spatial(98, h_o * 15 + h_i)
ww = T.axis.spatial(98, w_o * 15 + w_i)
(rc, rh, rw) = T.axis.remap('RRR', [c_i, kh, kw])","nn, cc, hh, ww, (rc, rh, rw) = T.axis.spatial(1, 0), T.axis.spatial(16, c_o), T.axis.spatial(98, h_o * 15 + h_i), T.axis.spatial(98, w_o * 15 + w_i), T.axis.remap('RRR', [c_i, kh, kw])","nn = zejun1
cc = zejun2
hh = zejun3
ww = zejun4
(rc, rh, rw) = zejun5",Cannot refactor,-1,1,,,
checkov,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/checkov/tests/terraform/graph/variable_rendering/test_string_evaluation.py,https://github.com/bridgecrewio/checkov/tree/master/tests/terraform/graph/variable_rendering/test_string_evaluation.py,TestTerraformEvaluation,test_matchkeys$194,"def test_matchkeys(self):
        input_str = 'matchkeys([""i-123"", ""i-abc"", ""i-def""], [""us-west"", ""us-east"", ""us-east""], [""us-east""])'
        expected = [""i-abc"", ""i-def""]
        actual = evaluate_terraform(input_str)
        for elem in actual:
            if elem not in expected:
                self.fail(f'expected to find {elem} in {expected}. Got {actual}')","input_str = 'matchkeys([""i-123"", ""i-abc"", ""i-def""], [""us-west"", ""us-east"", ""us-east""], [""us-east""])'
expected = ['i-abc', 'i-def']","input_str, expected = 'matchkeys([""i-123"", ""i-abc"", ""i-def""], [""us-west"", ""us-east"", ""us-east""], [""us-east""])', ['i-abc', 'i-def']","input_str = zejun1
expected = zejun2",Cannot refactor,-1,1,,,
zipline,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/zipline/tests/test_finance.py,https://github.com/quantopian/zipline/tree/master/tests/test_finance.py,FinanceTestCase,transaction_sim$163,"def transaction_sim(self, **params):
        """"""This is a utility method that asserts expected
        results for conversion of orders to transactions given a
        trade history
        """"""
        trade_count = params['trade_count']
        trade_interval = params['trade_interval']
        order_count = params['order_count']
        order_amount = params['order_amount']
        order_interval = params['order_interval']
        expected_txn_count = params['expected_txn_count']
        expected_txn_volume = params['expected_txn_volume']

        # optional parameters
        # ---------------------
        # if present, alternate between long and short sales
        alternate = params.get('alternate')

        # if present, expect transaction amounts to match orders exactly.
        complete_fill = params.get('complete_fill')

        asset1 = self.asset_finder.retrieve_asset(1)
        with TempDirectory() as tempdir:

            if trade_interval < timedelta(days=1):
                sim_params = factory.create_simulation_parameters(
                    start=self.start,
                    end=self.end,
                    data_frequency=""minute""
                )

                minutes = self.trading_calendar.minutes_window(
                    sim_params.first_open,
                    int((trade_interval.total_seconds() / 60) * trade_count)
                    + 100)

                price_data = np.array([10.1] * len(minutes))
                assets = {
                    asset1.sid: pd.DataFrame({
                        ""open"": price_data,
                        ""high"": price_data,
                        ""low"": price_data,
                        ""close"": price_data,
                        ""volume"": np.array([100] * len(minutes)),
                        ""dt"": minutes
                    }).set_index(""dt"")
                }

                write_bcolz_minute_data(
                    self.trading_calendar,
                    self.trading_calendar.sessions_in_range(
                        self.trading_calendar.minute_to_session_label(
                            minutes[0]
                        ),
                        self.trading_calendar.minute_to_session_label(
                            minutes[-1]
                        )
                    ),
                    tempdir.path,
                    iteritems(assets),
                )

                equity_minute_reader = BcolzMinuteBarReader(tempdir.path)

                data_portal = DataPortal(
                    self.asset_finder, self.trading_calendar,
                    first_trading_day=equity_minute_reader.first_trading_day,
                    equity_minute_reader=equity_minute_reader,
                )
            else:
                sim_params = factory.create_simulation_parameters(
                    data_frequency=""daily""
                )

                days = sim_params.sessions

                assets = {
                    1: pd.DataFrame({
                        ""open"": [10.1] * len(days),
                        ""high"": [10.1] * len(days),
                        ""low"": [10.1] * len(days),
                        ""close"": [10.1] * len(days),
                        ""volume"": [100] * len(days),
                        ""day"": [day.value for day in days]
                    }, index=days)
                }

                path = os.path.join(tempdir.path, ""testdata.bcolz"")
                BcolzDailyBarWriter(path, self.trading_calendar, days[0],
                                    days[-1]).write(
                    assets.items()
                )

                equity_daily_reader = BcolzDailyBarReader(path)

                data_portal = DataPortal(
                    self.asset_finder, self.trading_calendar,
                    first_trading_day=equity_daily_reader.first_trading_day,
                    equity_daily_reader=equity_daily_reader,
                )

            if ""default_slippage"" not in params or \
               not params[""default_slippage""]:
                slippage_func = FixedBasisPointsSlippage()
            else:
                slippage_func = None

            blotter = SimulationBlotter(slippage_func)

            start_date = sim_params.first_open

            if alternate:
                alternator = -1
            else:
                alternator = 1

            tracker = MetricsTracker(
                trading_calendar=self.trading_calendar,
                first_session=sim_params.start_session,
                last_session=sim_params.end_session,
                capital_base=sim_params.capital_base,
                emission_rate=sim_params.emission_rate,
                data_frequency=sim_params.data_frequency,
                asset_finder=self.asset_finder,
                metrics=load_metrics_set('none'),
            )

            # replicate what tradesim does by going through every minute or day
            # of the simulation and processing open orders each time
            if sim_params.data_frequency == ""minute"":
                ticks = minutes
            else:
                ticks = days

            transactions = []

            order_list = []
            order_date = start_date
            for tick in ticks:
                blotter.current_dt = tick
                if tick >= order_date and len(order_list) < order_count:
                    # place an order
                    direction = alternator ** len(order_list)
                    order_id = blotter.order(
                        asset1,
                        order_amount * direction,
                        MarketOrder(),
                    )
                    order_list.append(blotter.orders[order_id])
                    order_date = order_date + order_interval
                    # move after market orders to just after market next
                    # market open.
                    if order_date.hour >= 21:
                        if order_date.minute >= 00:
                            order_date = order_date + timedelta(days=1)
                            order_date = order_date.replace(hour=14, minute=30)
                else:
                    bar_data = BarData(
                        data_portal=data_portal,
                        simulation_dt_func=lambda: tick,
                        data_frequency=sim_params.data_frequency,
                        trading_calendar=self.trading_calendar,
                        restrictions=NoRestrictions(),
                    )
                    txns, _, closed_orders = blotter.get_transactions(bar_data)
                    for txn in txns:
                        tracker.process_transaction(txn)
                        transactions.append(txn)

                    blotter.prune_orders(closed_orders)

            for i in range(order_count):
                order = order_list[i]
                self.assertEqual(order.asset, asset1)
                self.assertEqual(order.amount, order_amount * alternator ** i)

            if complete_fill:
                self.assertEqual(len(transactions), len(order_list))

            total_volume = 0
            for i in range(len(transactions)):
                txn = transactions[i]
                total_volume += txn.amount
                if complete_fill:
                    order = order_list[i]
                    self.assertEqual(order.amount, txn.amount)

            self.assertEqual(total_volume, expected_txn_volume)

            self.assertEqual(len(transactions), expected_txn_count)

            if total_volume == 0:
                self.assertRaises(KeyError, lambda: tracker.positions[asset1])
            else:
                cumulative_pos = tracker.positions[asset1]
                self.assertEqual(total_volume, cumulative_pos.amount)

            # the open orders should not contain the asset.
            oo = blotter.open_orders
            self.assertNotIn(
                asset1,
                oo,
                ""Entry is removed when no open orders""
            )","assets = {1: pd.DataFrame({'open': [10.1] * len(days), 'high': [10.1] * len(days), 'low': [10.1] * len(days), 'close': [10.1] * len(days), 'volume': [100] * len(days), 'day': [day.value for day in days]}, index=days)}
path = os.path.join(tempdir.path, 'testdata.bcolz')","assets, path = {1: pd.DataFrame({'open': [10.1] * len(days), 'high': [10.1] * len(days), 'low': [10.1] * len(days), 'close': [10.1] * len(days), 'volume': [100] * len(days), 'day': [day.value for day in days]}, index=days)}, os.path.join(tempdir.path, 'testdata.bcolz')","assets = {1: zejun1}
path = zejun2",Cannot refactor,-1,1,,,
nibabel,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/nibabel/nibabel/tests/test_round_trip.py,https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_round_trip.py,,check_arr$123,"def check_arr(test_id, V_in, in_type, out_type, scaling_type):
    arr, arr_dash, slope, inter = check_params(V_in, in_type, out_type)
    if arr_dash is None:
        # Scaling causes a header or writer error
        return
    nzs = arr != 0  # avoid divide by zero error
    if not np.any(nzs):
        if DEBUG:
            raise ValueError('Array all zero')
        return
    arr = arr[nzs]
    arr_dash_L = arr_dash.astype(BIG_FLOAT)[nzs]
    top = arr - arr_dash_L
    if not np.any(top != 0):
        return
    rel_err = np.abs(top / arr)
    abs_err = np.abs(top)
    if slope == 1:  # integers output, offset only scaling
        if {in_type, out_type} == {np.int64, np.uint64}:
            # Scaling to or from 64 bit ints can go outside range of continuous
            # integers for float64 and thus lose precision; take this into
            # account
            A = arr.astype(float)
            Ai = A - inter
            ulps = [big_bad_ulp(A), big_bad_ulp(Ai)]
            exp_abs_err = np.max(ulps, axis=0)
        else:  # floats can give full precision - no error!
            exp_abs_err = np.zeros_like(abs_err)
        rel_thresh = 0
    else:
        # Error from integer rounding
        inting_err = np.abs(scaling_type(slope) / 2)
        inting_err = inting_err + ulp(inting_err)
        # Error from calculation of inter
        inter_err = ulp(scaling_type(inter))
        # Max abs error from floating point
        with np.errstate(over='ignore'):
            Ai = arr - scaling_type(inter)
        Ais = Ai / scaling_type(slope)
        exp_abs_err = inting_err + inter_err + (
            big_bad_ulp(Ai) + big_bad_ulp(Ais))
        # Relative scaling error from calculation of slope
        # This threshold needs to be 2 x larger on windows 32 bit and PPC for
        # some reason
        rel_thresh = ulp(scaling_type(1))
    test_vals = (abs_err <= exp_abs_err) | (rel_err <= rel_thresh)
    this_test = np.all(test_vals)
    if DEBUG:
        abs_fails = (abs_err > exp_abs_err)
        rel_fails = (rel_err > rel_thresh)
        all_fails = abs_fails & rel_fails
        if np.any(rel_fails):
            abs_mx_e = abs_err[rel_fails].max()
            exp_abs_mx_e = exp_abs_err[rel_fails].max()
        else:
            abs_mx_e = None
            exp_abs_mx_e = None
        if np.any(abs_fails):
            rel_mx_e = rel_err[abs_fails].max()
        else:
            rel_mx_e = None
        print((test_id,
               np.dtype(in_type).str,
               np.dtype(out_type).str,
               exp_abs_mx_e,
               abs_mx_e,
               rel_thresh,
               rel_mx_e,
               slope, inter))
        # To help debugging failures with --pdb-failure
        np.nonzero(all_fails)
    assert this_test","inting_err = inting_err + ulp(inting_err)
inter_err = ulp(scaling_type(inter))","inting_err, inter_err= inting_err + ulp(inting_err), ulp(scaling_type(inter))","inting_err = zejun1
inter_err = zejun2",Cannot refactor,-1,1,,,
nibabel,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/nibabel/nibabel/tests/test_round_trip.py,https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_round_trip.py,,check_arr$123,"def check_arr(test_id, V_in, in_type, out_type, scaling_type):
    arr, arr_dash, slope, inter = check_params(V_in, in_type, out_type)
    if arr_dash is None:
        # Scaling causes a header or writer error
        return
    nzs = arr != 0  # avoid divide by zero error
    if not np.any(nzs):
        if DEBUG:
            raise ValueError('Array all zero')
        return
    arr = arr[nzs]
    arr_dash_L = arr_dash.astype(BIG_FLOAT)[nzs]
    top = arr - arr_dash_L
    if not np.any(top != 0):
        return
    rel_err = np.abs(top / arr)
    abs_err = np.abs(top)
    if slope == 1:  # integers output, offset only scaling
        if {in_type, out_type} == {np.int64, np.uint64}:
            # Scaling to or from 64 bit ints can go outside range of continuous
            # integers for float64 and thus lose precision; take this into
            # account
            A = arr.astype(float)
            Ai = A - inter
            ulps = [big_bad_ulp(A), big_bad_ulp(Ai)]
            exp_abs_err = np.max(ulps, axis=0)
        else:  # floats can give full precision - no error!
            exp_abs_err = np.zeros_like(abs_err)
        rel_thresh = 0
    else:
        # Error from integer rounding
        inting_err = np.abs(scaling_type(slope) / 2)
        inting_err = inting_err + ulp(inting_err)
        # Error from calculation of inter
        inter_err = ulp(scaling_type(inter))
        # Max abs error from floating point
        with np.errstate(over='ignore'):
            Ai = arr - scaling_type(inter)
        Ais = Ai / scaling_type(slope)
        exp_abs_err = inting_err + inter_err + (
            big_bad_ulp(Ai) + big_bad_ulp(Ais))
        # Relative scaling error from calculation of slope
        # This threshold needs to be 2 x larger on windows 32 bit and PPC for
        # some reason
        rel_thresh = ulp(scaling_type(1))
    test_vals = (abs_err <= exp_abs_err) | (rel_err <= rel_thresh)
    this_test = np.all(test_vals)
    if DEBUG:
        abs_fails = (abs_err > exp_abs_err)
        rel_fails = (rel_err > rel_thresh)
        all_fails = abs_fails & rel_fails
        if np.any(rel_fails):
            abs_mx_e = abs_err[rel_fails].max()
            exp_abs_mx_e = exp_abs_err[rel_fails].max()
        else:
            abs_mx_e = None
            exp_abs_mx_e = None
        if np.any(abs_fails):
            rel_mx_e = rel_err[abs_fails].max()
        else:
            rel_mx_e = None
        print((test_id,
               np.dtype(in_type).str,
               np.dtype(out_type).str,
               exp_abs_mx_e,
               abs_mx_e,
               rel_thresh,
               rel_mx_e,
               slope, inter))
        # To help debugging failures with --pdb-failure
        np.nonzero(all_fails)
    assert this_test","exp_abs_err = inting_err + inter_err + (big_bad_ulp(Ai) + big_bad_ulp(Ais))
rel_thresh = ulp(scaling_type(1))","exp_abs_err, rel_thresh= inting_err + inter_err + (big_bad_ulp(Ai) + big_bad_ulp(Ais)), ulp(scaling_type(1))","exp_abs_err = zejun1
rel_thresh = zejun2",Cannot refactor,-1,1,,,
vega,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/vega/vega/datasets/common/auto_lane_datasets.py,https://github.com/huawei-noah/vega/tree/master/vega/datasets/common/auto_lane_datasets.py,AutoLaneDataset,prepare_test_img$201,"def prepare_test_img(self, idx):
        """"""Prepare an image for testing.

        :param idx: index
        :type idx: int
        :return: an item of data according to the index
        :rtype: dict
        """"""
        target_pair = self.image_annot_path_pairs[idx]
        image_arr = imread(target_pair['image_path'])
        lane_object = self.read_annot(target_pair['annot_path'])
        whc = get_img_whc(image_arr)
        network_input_image = bgr2rgb(resize_by_wh(img=image_arr, width=512, height=288))
        item = dict(
            net_input_image=imagenet_normalize(img=network_input_image),
            net_input_image_mode='RGB',
            net_input_image_shape=dict(width=512, height=288, channel=3),
            src_image_shape=whc,
            src_image_path=target_pair['image_path'],
            annotation_path=target_pair['annot_path'],
            annotation_src_content=lane_object,
            regression_groundtruth=None,
            classfication_groundtruth=None
        )

        result = dict(image=np.transpose(item['net_input_image'], (2, 0, 1)).astype('float32'),
                      net_input_image_shape=json.dumps(item['net_input_image_shape']),
                      src_image_shape=json.dumps(item['src_image_shape']),
                      annot=json.dumps(item['annotation_src_content']),
                      src_image_path=item['src_image_path'],
                      annotation_path=item['annotation_path'])

        return result","image_arr = imread(target_pair['image_path'])
lane_object = self.read_annot(target_pair['annot_path'])","image_arr, lane_object = imread(target_pair['image_path']), self.read_annot(target_pair['annot_path'])","image_arr = zejun1
lane_object = zejun2",Cannot refactor,-1,1,,,
no_find,,,,,,,,,,,,,,
text_classification,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/text_classification/a04_TextRCNN/p71_TextRCNN_mode2.py,https://github.com/brightmart/text_classification/tree/master/a04_TextRCNN/p71_TextRCNN_mode2.py,,test$195,"def test():
    #below is a function test; if you use this for text classifiction, you need to tranform sentence to indices of vocabulary first. then feed data to the graph.
    num_classes=10
    learning_rate=0.01
    batch_size=8
    decay_steps=1000
    decay_rate=0.9
    sequence_length=5
    vocab_size=10000
    embed_size=100
    is_training=True
    dropout_keep_prob=1#0.5
    textRNN=TextRCNN(num_classes, learning_rate, batch_size, decay_steps, decay_rate,sequence_length,vocab_size,embed_size,is_training)
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for i in range(100):
            input_x=np.zeros((batch_size,sequence_length)) #[None, self.sequence_length]
            input_y=input_y=np.array([1,0,1,1,1,2,1,1]) #np.zeros((batch_size),dtype=np.int32) #[None, self.sequence_length]
            loss,acc,predict,_=sess.run([textRNN.loss_val,textRNN.accuracy,textRNN.predictions,textRNN.train_op],
                                        feed_dict={textRNN.input_x:input_x,textRNN.input_y:input_y,textRNN.dropout_keep_prob:dropout_keep_prob})
            print(""loss:"",loss,""acc:"",acc,""label:"",input_y,""prediction:"",predict)","num_classes = 10
learning_rate = 0.01
batch_size = 8
decay_steps = 1000
decay_rate = 0.9
sequence_length = 5
vocab_size = 10000
embed_size = 100
is_training = True","(num_classes, learning_rate, batch_size, decay_steps, decay_rate, sequence_length, vocab_size, embed_size, is_training) = (10, 0.01, 8, 1000, 0.9, 5, 10000, 100, True)",0,,,,,,
pyro,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pyro/pyro/infer/csis.py,https://github.com/pyro-ppl/pyro/tree/master/pyro/infer/csis.py,CSIS,_get_matched_trace$161,"def _get_matched_trace(self, model_trace, *args, **kwargs):
        """"""
        :param model_trace: a trace from the model
        :type model_trace: pyro.poutine.trace_struct.Trace
        :returns: guide trace with sampled values matched to model_trace
        :rtype: pyro.poutine.trace_struct.Trace

        Returns a guide trace with values at sample and observe statements
        matched to those in model_trace.

        `args` and `kwargs` are passed to the guide.
        """"""
        kwargs[""observations""] = {}
        for node in itertools.chain(
            model_trace.stochastic_nodes, model_trace.observation_nodes
        ):
            if ""was_observed"" in model_trace.nodes[node][""infer""]:
                model_trace.nodes[node][""is_observed""] = True
                kwargs[""observations""][node] = model_trace.nodes[node][""value""]

        guide_trace = poutine.trace(poutine.replay(self.guide, model_trace)).get_trace(
            *args, **kwargs
        )

        check_model_guide_match(model_trace, guide_trace)
        guide_trace = prune_subsample_sites(guide_trace)

        return guide_trace","model_trace.nodes[node]['is_observed'] = True
kwargs['observations'][node] = model_trace.nodes[node]['value']","(model_trace.nodes[node]['is_observed'], kwargs['observations'][node]) = (True, model_trace.nodes[node]['value'])",0,,,,,,
data-driven-web-apps-with-flask,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/data-driven-web-apps-with-flask/app/ch11_migrations/starter/pypi_org/bin/load_data.py,https://github.com/talkpython/data-driven-web-apps-with-flask/tree/master/app/ch11_migrations/starter/pypi_org/bin/load_data.py,,build_releases$303,"def build_releases(package_id: str, releases: dict) -> List[Release]:
    db_releases = []
    for k in releases.keys():
        all_releases_for_version = releases.get(k)
        if not all_releases_for_version:
            continue

        v = all_releases_for_version[-1]

        r = Release()
        r.package_id = package_id
        r.major_ver, r.minor_ver, r.build_ver = make_version_num(k)
        r.created_date = parse(v.get('upload_time'))
        r.comment = v.get('comment_text')
        r.url = v.get('url')
        r.size = int(v.get('size', 0))

        db_releases.append(r)

    return db_releases","r.created_date = parse(v.get('upload_time'))
r.comment = v.get('comment_text')
r.url = v.get('url')
r.size = int(v.get('size', 0))","(r.created_date, r.comment, r.url, r.size) = (parse(v.get('upload_time')), v.get('comment_text'), v.get('url'), int(v.get('size', 0)))",0,,,,,,
mayavi,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/mayavi/mayavi/tools/helper_functions.py,https://github.com/enthought/mayavi/tree/master/mayavi/tools/helper_functions.py,,test_mesh$881,"def test_mesh():
    """"""A very pretty picture of spherical harmonics translated from
    the octaviz example.""""""
    pi = np.pi
    cos = np.cos
    sin = np.sin
    dphi, dtheta = pi / 250.0, pi / 250.0
    [phi, theta] = np.mgrid[0:pi + dphi * 1.5:dphi,
                            0:2 * pi + dtheta * 1.5:dtheta]
    m0 = 4
    m1 = 3
    m2 = 2
    m3 = 3
    m4 = 6
    m5 = 2
    m6 = 6
    m7 = 4
    r = sin(m0 * phi) ** m1 + cos(m2 * phi) ** m3 + \
        sin(m4 * theta) ** m5 + cos(m6 * theta) ** m7
    x = r * sin(phi) * cos(theta)
    y = r * cos(phi)
    z = r * sin(phi) * sin(theta)

    return mesh(x, y, z, colormap=""bone"")","m0 = 4
m1 = 3
m2 = 2
m3 = 3
m4 = 6
m5 = 2
m6 = 6
m7 = 4","(m0, m1, m2, m3, m4, m5, m6, m7) = (4, 3, 2, 3, 6, 2, 6, 4)",0,,,,,,
adapter-transformers,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/adapter-transformers/src/transformers/data/datasets/language_modeling.py,https://github.com/Adapter-Hub/adapter-transformers/tree/master/src/transformers/data/datasets/language_modeling.py,TextDatasetForNextSentencePrediction,__init__$353,"def __init__(
        self,
        tokenizer: PreTrainedTokenizer,
        file_path: str,
        block_size: int,
        overwrite_cache=False,
        short_seq_probability=0.1,
        nsp_probability=0.5,
    ):
        warnings.warn(
            DEPRECATION_WARNING.format(
                ""https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py""
            ),
            FutureWarning,
        )
        if not os.path.isfile(file_path):
            raise ValueError(f""Input file path {file_path} not found"")

        self.short_seq_probability = short_seq_probability
        self.nsp_probability = nsp_probability

        directory, filename = os.path.split(file_path)
        cached_features_file = os.path.join(
            directory,
            f""cached_nsp_{tokenizer.__class__.__name__}_{block_size}_{filename}"",
        )

        self.tokenizer = tokenizer

        # Make sure only the first process in distributed training processes the dataset,
        # and the others will use the cache.
        lock_path = cached_features_file + "".lock""

        # Input file format:
        # (1) One sentence per line. These should ideally be actual sentences, not
        # entire paragraphs or arbitrary spans of text. (Because we use the
        # sentence boundaries for the ""next sentence prediction"" task).
        # (2) Blank lines between documents. Document boundaries are needed so
        # that the ""next sentence prediction"" task doesn't span between documents.
        #
        # Example:
        # I am very happy.
        # Here is the second sentence.
        #
        # A new document.

        with FileLock(lock_path):
            if os.path.exists(cached_features_file) and not overwrite_cache:
                start = time.time()
                with open(cached_features_file, ""rb"") as handle:
                    self.examples = pickle.load(handle)
                logger.info(
                    f""Loading features from cached file {cached_features_file} [took %.3f s]"", time.time() - start
                )
            else:
                logger.info(f""Creating features from dataset file at {directory}"")

                self.documents = [[]]
                with open(file_path, encoding=""utf-8"") as f:
                    while True:
                        line = f.readline()
                        if not line:
                            break
                        line = line.strip()

                        # Empty lines are used as document delimiters
                        if not line and len(self.documents[-1]) != 0:
                            self.documents.append([])
                        tokens = tokenizer.tokenize(line)
                        tokens = tokenizer.convert_tokens_to_ids(tokens)
                        if tokens:
                            self.documents[-1].append(tokens)

                logger.info(f""Creating examples from {len(self.documents)} documents."")
                self.examples = []
                for doc_index, document in enumerate(self.documents):
                    self.create_examples_from_document(document, doc_index, block_size)

                start = time.time()
                with open(cached_features_file, ""wb"") as handle:
                    pickle.dump(self.examples, handle, protocol=pickle.HIGHEST_PROTOCOL)
                logger.info(
                    f""Saving features into cached file {cached_features_file} [took {time.time() - start:.3f} s]""
                )","self.short_seq_probability = short_seq_probability
self.nsp_probability = nsp_probability","(self.short_seq_probability, self.nsp_probability) = (short_seq_probability, nsp_probability)",0,,,,,,
CRNN_Chinese_Characters_Rec,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/CRNN_Chinese_Characters_Rec/lib/core/function.py,https://github.com/Sierkinhane/CRNN_Chinese_Characters_Rec/tree/master/lib/core/function.py,,train$27,"def train(config, train_loader, dataset, converter, model, criterion, optimizer, device, epoch, writer_dict=None, output_dict=None):

    batch_time = AverageMeter()
    data_time = AverageMeter()
    losses = AverageMeter()

    model.train()

    end = time.time()
    for i, (inp, idx) in enumerate(train_loader):
        # measure data time
        data_time.update(time.time() - end)

        labels = utils.get_batch_label(dataset, idx)
        inp = inp.to(device)

        # inference
        preds = model(inp).cpu()

        # compute loss
        batch_size = inp.size(0)
        text, length = converter.encode(labels)                    # length = 涓涓猙atch涓鐨勬诲瓧绗﹂暱搴, text = 涓涓猙atch涓鐨勫瓧绗︽墍瀵瑰簲鐨勪笅鏍
        preds_size = torch.IntTensor([preds.size(0)] * batch_size) # timestep * batchsize
        loss = criterion(preds, text, preds_size, length)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        losses.update(loss.item(), inp.size(0))

        batch_time.update(time.time()-end)
        if i % config.PRINT_FREQ == 0:
            msg = 'Epoch: [{0}][{1}/{2}]\t' \
                  'Time {batch_time.val:.3f}s ({batch_time.avg:.3f}s)\t' \
                  'Speed {speed:.1f} samples/s\t' \
                  'Data {data_time.val:.3f}s ({data_time.avg:.3f}s)\t' \
                  'Loss {loss.val:.5f} ({loss.avg:.5f})\t'.format(
                      epoch, i, len(train_loader), batch_time=batch_time,
                      speed=inp.size(0)/batch_time.val,
                      data_time=data_time, loss=losses)
            print(msg)

            if writer_dict:
                writer = writer_dict['writer']
                global_steps = writer_dict['train_global_steps']
                writer.add_scalar('train_loss', losses.avg, global_steps)
                writer_dict['train_global_steps'] = global_steps + 1

        end = time.time()","preds = model(inp).cpu()
batch_size = inp.size(0)","(preds, batch_size) = (model(inp).cpu(), inp.size(0))",0,,,,,,
salt,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/salt/tests/unit/modules/test_file.py,https://github.com/saltstack/salt/tree/master/tests/unit/modules/test_file.py,FilemodLineTests,test_if_not_location_or_before_but_after_then_line_should_be_inserted_after_after$1883,"def test_if_not_location_or_before_but_after_then_line_should_be_inserted_after_after(
        self,
    ):
        location = before = None
        after = ""indessed""
        content = ""roscivs""
        indent = ""\t\t\t   ""
        original_lines = [""foo"", indent + after, ""bar""]
        expected_lines = [""foo"", indent + after, indent + content, ""bar""]

        actual_lines = filemod._set_line(
            lines=original_lines,
            content=content,
            mode=""insert"",
            location=location,
            before=before,
            after=after,
        )

        self.assertEqual(actual_lines, expected_lines)","after = 'indessed'
content = 'roscivs'
indent = '\t\t\t   '","(after, content, indent) = ('indessed', 'roscivs', '\t\t\t   ')",0,,,,,,
torchdiffeq,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/torchdiffeq/torchdiffeq/_impl/solvers.py,https://github.com/rtqichen/torchdiffeq/tree/master/torchdiffeq/_impl/solvers.py,FixedGridODESolver,integrate_until_event$130,"def integrate_until_event(self, t0, event_fn):
        assert self.step_size is not None, ""Event handling for fixed step solvers currently requires `step_size` to be provided in options.""

        t0 = t0.type_as(self.y0)
        y0 = self.y0
        dt = self.step_size

        sign0 = torch.sign(event_fn(t0, y0))
        max_itrs = 20000
        itr = 0
        while True:
            itr += 1
            t1 = t0 + dt
            dy, f0 = self._step_func(self.func, t0, dt, t1, y0)
            y1 = y0 + dy

            sign1 = torch.sign(event_fn(t1, y1))

            if sign0 != sign1:
                if self.interp == ""linear"":
                    interp_fn = lambda t: self._linear_interp(t0, t1, y0, y1, t)
                elif self.interp == ""cubic"":
                    f1 = self.func(t1, y1)
                    interp_fn = lambda t: self._cubic_hermite_interp(t0, y0, f0, t1, y1, f1, t)
                else:
                    raise ValueError(f""Unknown interpolation method {self.interp}"")
                event_time, y1 = find_event(interp_fn, sign0, t0, t1, event_fn, float(self.atol))
                break
            else:
                t0, y0 = t1, y1

            if itr >= max_itrs:
                raise RuntimeError(f""Reached maximum number of iterations {max_itrs}."")
        solution = torch.stack([self.y0, y1], dim=0)
        return event_time, solution","t0 = t0.type_as(self.y0)
y0 = self.y0","(t0, y0) = (t0.type_as(self.y0), self.y0)",0,,,,,,
Machine-Learning-Collection,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/Machine-Learning-Collection/ML/Projects/DeepSort/utils.py,https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/Projects/DeepSort/utils.py,,sort_array$10,"def sort_array(encoder, decoder, device, arr=None):
    """"""
    A very simple example of use of the model
    Input: encoder nn.Module
           decoder nn.Module
           device
           array to sort (optional)
    """"""

    if arr is None:
        arr = ask_user()

    with torch.no_grad():
        while arr != ""q"":
            # Avoid numerical errors by rounding to max_len
            arr = eval(arr)
            lengths = [
                len(str(elem).split(""."")[1]) if len(str(elem).split(""."")) > 1 else 0
                for elem in arr
            ]
            max_len = max(lengths)
            source = torch.tensor(arr, dtype=torch.float).to(device).unsqueeze(1)
            batch_size = source.shape[1]
            target_len = source.shape[0] + 1

            outputs = torch.zeros(target_len, batch_size, target_len - 1).to(device)
            encoder_states, hidden, cell = encoder(source)

            # First input will be <SOS> token
            x = torch.tensor([-1], dtype=torch.float).to(device)
            predictions = torch.zeros((target_len)).to(device)

            for t in range(1, target_len):
                # At every time step use encoder_states and update hidden, cell
                attention, energy, hidden, cell = decoder(
                    x, encoder_states, hidden, cell
                )

                # Store prediction for current time step
                outputs[t] = energy.permute(1, 0)

                # Get the best word the Decoder predicted (index in the vocabulary)
                best_guess = attention.argmax(0)
                predictions[t] = best_guess.item()
                x = torch.tensor([best_guess.item()], dtype=torch.float).to(device)

            output = [
                round(source[predictions[1:].long()][i, :].item(), max_len)
                for i in range(source.shape[0])
            ]

            print(f""Here's the result: {output}"")
            arr = ask_user()","x = torch.tensor([-1], dtype=torch.float).to(device)
predictions = torch.zeros(target_len).to(device)","(x, predictions) = (torch.tensor([-1], dtype=torch.float).to(device), torch.zeros(target_len).to(device))",0,,,,,,
rotki,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/rotki/rotkehlchen/tests/api/test_exchanges.py,https://github.com/rotki/rotki/tree/master/rotkehlchen/tests/api/test_exchanges.py,,test_exchange_query_balances$482,"def test_exchange_query_balances(rotkehlchen_api_server_with_exchanges):
    """"""Test that using the exchange balances query endpoint works fine""""""
    async_query = random.choice([False, True])
    rotki = rotkehlchen_api_server_with_exchanges.rest_api.rotkehlchen
    # query balances of one specific exchange
    server = rotkehlchen_api_server_with_exchanges
    binance = try_get_first_exchange(rotki.exchange_manager, Location.BINANCE)

    binance_patch = patch_binance_balances_query(binance)
    with binance_patch:
        response = requests.get(api_url_for(
            server,
            'named_exchanges_balances_resource',
            location='binance',
        ), json={'async_query': async_query})
        if async_query:
            task_id = assert_ok_async_response(response)
            outcome = wait_for_async_task_with_result(server, task_id)
        else:
            outcome = assert_proper_response_with_result(response)
    assert_binance_balances_result(outcome)

    # query balances of all setup exchanges
    poloniex = try_get_first_exchange(rotki.exchange_manager, Location.POLONIEX)
    poloniex_patch = patch_poloniex_balances_query(poloniex)
    with binance_patch, poloniex_patch:
        response = requests.get(
            api_url_for(server, 'exchangebalancesresource'),
            json={'async_query': async_query},
        )
        if async_query:
            task_id = assert_ok_async_response(response)
            result = wait_for_async_task_with_result(server, task_id)
        else:
            result = assert_proper_response_with_result(response)

    assert_binance_balances_result(result['binance'])
    assert_poloniex_balances_result(result['poloniex'])","async_query = random.choice([False, True])
rotki = rotkehlchen_api_server_with_exchanges.rest_api.rotkehlchen","(async_query, rotki) = (random.choice([False, True]), rotkehlchen_api_server_with_exchanges.rest_api.rotkehlchen)",0,,,,,,
errbot,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/errbot/errbot/backends/irc.py,https://github.com/errbotio/errbot/tree/master/errbot/backends/irc.py,IRCBackend,__init__$706,"def __init__(self, config):
        if hasattr(config, ""IRC_ACL_PATTERN""):
            IRCBackend.aclpattern = config.IRC_ACL_PATTERN

        identity = config.BOT_IDENTITY
        nickname = identity[""nickname""]
        server = identity[""server""]
        port = identity.get(""port"", 6667)
        password = identity.get(""password"", None)
        ssl = identity.get(""ssl"", False)
        bind_address = identity.get(""bind_address"", None)
        ipv6 = identity.get(""ipv6"", False)
        username = identity.get(""username"", None)
        nickserv_password = identity.get(""nickserv_password"", None)

        compact = config.COMPACT_OUTPUT if hasattr(config, ""COMPACT_OUTPUT"") else True
        enable_format(""irc"", IRC_CHRS, borders=not compact)

        private_rate = getattr(config, ""IRC_PRIVATE_RATE"", 1)
        channel_rate = getattr(config, ""IRC_CHANNEL_RATE"", 1)
        reconnect_on_kick = getattr(config, ""IRC_RECONNECT_ON_KICK"", 5)
        reconnect_on_disconnect = getattr(config, ""IRC_RECONNECT_ON_DISCONNECT"", 5)

        self.bot_identifier = IRCPerson(nickname + ""!"" + nickname + ""@"" + server)
        super().__init__(config)
        self.conn = IRCConnection(
            bot=self,
            nickname=nickname,
            server=server,
            port=port,
            ssl=ssl,
            bind_address=bind_address,
            ipv6=ipv6,
            password=password,
            username=username,
            nickserv_password=nickserv_password,
            private_rate=private_rate,
            channel_rate=channel_rate,
            reconnect_on_kick=reconnect_on_kick,
            reconnect_on_disconnect=reconnect_on_disconnect,
        )
        self.md = irc_md()","nickname = identity['nickname']
server = identity['server']
port = identity.get('port', 6667)
password = identity.get('password', None)
ssl = identity.get('ssl', False)
bind_address = identity.get('bind_address', None)
ipv6 = identity.get('ipv6', False)
username = identity.get('username', None)
nickserv_password = identity.get('nickserv_password', None)
compact = config.COMPACT_OUTPUT if hasattr(config, 'COMPACT_OUTPUT') else True","(nickname, server, port, password, ssl, bind_address, ipv6, username, nickserv_password, compact) = (identity['nickname'], identity['server'], identity.get('port', 6667), identity.get('password', None), identity.get('ssl', False), identity.get('bind_address', None), identity.get('ipv6', False), identity.get('username', None), identity.get('nickserv_password', None), config.COMPACT_OUTPUT if hasattr(config, 'COMPACT_OUTPUT') else True)",0,,,,,,
deprecated-binaryninja-python,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/deprecated-binaryninja-python/Analysis.py,https://github.com/Vector35/deprecated-binaryninja-python/tree/master//Analysis.py,X86Instruction,format_text$82,"def format_text(self, block, options):
		old_lines = []
		old_tokens = []
		self.text.lines = []
		self.text.tokens = []

		line = []
		tokens = []
		x = 0
		instr = self.disasm

		if ""address"" in options:
			string = ""%.8x   "" % self.addr
			line += [[string, QColor(0, 0, 128)]]
			x += len(string)

		if instr.operation == None:
			line += [[""??"", Qt.black]]
			self.text.lines += [line]
			self.text.tokens += [tokens]
			return (old_lines != self.text.lines) or (old_tokens != self.text.tokens)

		result = """"
		operation = """"
		if instr.flags & X86.FLAG_LOCK:
			operation += ""lock ""
		if instr.flags & X86.FLAG_ANY_REP:
			operation += ""rep""
			if instr.flags & X86.FLAG_REPNE:
				operation += ""ne""
			elif instr.flags & X86.FLAG_REPE:
				operation += ""e""
			operation += "" ""
		operation += instr.operation
		if len(operation) < 7:
			operation += "" "" * (7 - len(operation))
		result += operation + "" ""

		for j in range(0, len(instr.operands)):
			if j != 0:
				result += "", ""
			if instr.operands[j].operand == ""imm"":
				value = instr.operands[j].immediate & ((1 << (instr.operands[j].size * 8)) - 1)
				numfmt = ""0x%%.%dx"" % (instr.operands[j].size * 2)
				string = numfmt % value
				if (instr.operands[j].size == self.addr_size) and (block.analysis.functions.has_key(value)):
					# Pointer to existing function
					func = block.analysis.functions[value]
					string = func.name
					if func.plt:
						color = QColor(192, 0, 192)
					else:
						color = QColor(0, 0, 192)
					if len(result) > 0:
						line += [[result, Qt.black]]
						x += len(result)
						result = """"
					line += [[string, color]]
					tokens += [[x, len(string), ""ptr"", value, string]]
					x += len(string)
				elif (instr.operands[j].size == self.addr_size) and (value >= block.exe.start()) and (value < block.exe.end()) and (not self.isLocalJump()):
					# Pointer within module
					if len(result) > 0:
						line += [[result, Qt.black]]
						x += len(result)
						result = """"
					if value in block.exe.symbols_by_addr:
						string = block.exe.symbols_by_addr[value]
					line += [[string, QColor(0, 0, 192)]]
					tokens += [[x, len(string), ""ptr"", value, string]]
					x += len(string)
				else:
					result += string
			elif instr.operands[j].operand == ""mem"":
				plus = False
				result += X86.get_size_string(instr.operands[j].size)
				if (instr.segment != None) or (instr.operands[j].segment == ""es""):
					result += instr.operands[j].segment + "":""
				result += '['
				if instr.operands[j].components[0] != None:
					tokens += [[x + len(result), len(instr.operands[j].components[0]), ""reg"", instr.operands[j].components[0]]]
					result += instr.operands[j].components[0]
					plus = True
				if instr.operands[j].components[1] != None:
					if plus:
						tokens += [[x + len(result) + 1, len(instr.operands[j].components[1]), ""reg"", instr.operands[j].components[1]]]
					else:
						tokens += [[x + len(result), len(instr.operands[j].components[1]), ""reg"", instr.operands[j].components[1]]]
					result += X86.get_operand_string(instr.operands[j].components[1],
						instr.operands[j].scale, plus)
					plus = True
				if (instr.operands[j].immediate != 0) or ((instr.operands[j].components[0] == None) and (instr.operands[j].components[1] == None)):
					if plus and (instr.operands[j].immediate >= -0x80) and (instr.operands[j].immediate < 0):
						result += '-'
						result += ""0x%.2x"" % (-instr.operands[j].immediate)
					elif plus and (instr.operands[j].immediate > 0) and (instr.operands[j].immediate <= 0x7f):
						result += '+'
						result += ""0x%.2x"" % instr.operands[j].immediate
					elif plus and (instr.operands[j].immediate >= -0x8000) and (instr.operands[j].immediate < 0):
						result += '-'
						result += ""0x%.8x"" % (-instr.operands[j].immediate)
					elif instr.flags & X86.FLAG_64BIT_ADDRESS:
						if plus:
							result += '+'
						value = instr.operands[j].immediate
						string = ""0x%.16x"" % instr.operands[j].immediate
						if hasattr(block.exe, ""plt"") and block.exe.plt.has_key(value):
							# Pointer to PLT entry
							self.plt = block.exe.plt[value]
							if len(result) > 0:
								line += [[result, Qt.black]]
								x += len(result)
								result = """"
							string = self.plt + ""@PLT""
							line += [[string, QColor(0, 0, 192)]]
							tokens += [[x, len(string), ""ptr"", value, string]]
							x += len(string)
						elif (value >= block.exe.start()) and (value < block.exe.end()):
							# Pointer within module
							if len(result) > 0:
								line += [[result, Qt.black]]
								x += len(result)
								result = """"
							if value in block.exe.symbols_by_addr:
								string = block.exe.symbols_by_addr[value]
							line += [[string, QColor(0, 0, 192)]]
							tokens += [[x, len(string), ""ptr"", value, string]]
							x += len(string)
						else:
							result += string
					else:
						if plus:
							result += '+'
						value = instr.operands[j].immediate & 0xffffffff
						string = ""0x%.8x"" % value
						if (self.addr_size == 4) and hasattr(block.exe, ""plt"") and block.exe.plt.has_key(value):
							# Pointer to PLT entry
							self.plt = block.exe.plt[value]
							if len(result) > 0:
								line += [[result, Qt.black]]
								x += len(result)
								result = """"
							string = block.exe.decorate_plt_name(self.plt)
							line += [[string, QColor(0, 0, 192)]]
							tokens += [[x, len(string), ""ptr"", value, string]]
							x += len(string)
						elif (self.addr_size == 4) and (value >= block.exe.start()) and (value < block.exe.end()):
							# Pointer within module
							if len(result) > 0:
								line += [[result, Qt.black]]
								x += len(result)
								result = """"
							if value in block.exe.symbols_by_addr:
								string = block.exe.symbols_by_addr[value]
							line += [[string, QColor(0, 0, 192)]]
							tokens += [[x, len(string), ""ptr"", value, string]]
							x += len(string)
						else:
							result += string
				result += ']'
			else:
				tokens += [[x + len(result), len(instr.operands[j].operand), ""reg"", instr.operands[j].operand]]
				result += instr.operands[j].operand

		if len(result) > 0:
			line += [[result, Qt.black]]
		self.text.lines += [line]
		self.text.tokens += [tokens]

		return (old_lines != self.text.lines) or (old_tokens != self.text.tokens)","old_lines = []
old_tokens = []
self.text.lines = []
self.text.tokens = []
line = []
tokens = []
x = 0
instr = self.disasm","(old_lines, old_tokens, self.text.lines, self.text.tokens, line, tokens, x, instr) = ([], [], [], [], [], [], 0, self.disasm)",0,,,,,,
sympy,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/sympy/sympy/simplify/tests/test_radsimp.py,https://github.com/sympy/sympy/tree/master/sympy/simplify/tests/test_radsimp.py,,test_collect_Wild$320,"def test_collect_Wild():
    """"""Collect with respect to functions with Wild argument""""""
    a, b, x, y = symbols('a b x y')
    f = Function('f')
    w1 = Wild('.1')
    w2 = Wild('.2')
    assert collect(f(x) + a*f(x), f(w1)) == (1 + a)*f(x)
    assert collect(f(x, y) + a*f(x, y), f(w1)) == f(x, y) + a*f(x, y)
    assert collect(f(x, y) + a*f(x, y), f(w1, w2)) == (1 + a)*f(x, y)
    assert collect(f(x, y) + a*f(x, y), f(w1, w1)) == f(x, y) + a*f(x, y)
    assert collect(f(x, x) + a*f(x, x), f(w1, w1)) == (1 + a)*f(x, x)
    assert collect(a*(x + 1)**y + (x + 1)**y, w1**y) == (1 + a)*(x + 1)**y
    assert collect(a*(x + 1)**y + (x + 1)**y, w1**b) == \
        a*(x + 1)**y + (x + 1)**y
    assert collect(a*(x + 1)**y + (x + 1)**y, (x + 1)**w2) == \
        (1 + a)*(x + 1)**y
    assert collect(a*(x + 1)**y + (x + 1)**y, w1**w2) == (1 + a)*(x + 1)**y","f = Function('f')
w1 = Wild('.1')
w2 = Wild('.2')","(f, w1, w2) = (Function('f'), Wild('.1'), Wild('.2'))",0,,,,,,
binarytree,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/binarytree/tests/test_tree.py,https://github.com/joowani/binarytree/tree/master/tests/test_tree.py,,test_get_index_utility_function$1463,"def test_get_index_utility_function() -> None:
    root = Node(0)
    root.left = Node(1)
    root.right = Node(2)
    root.left.left = Node(3)
    root.right.right = Node(4)

    assert get_index(root, root) == 0
    assert get_index(root, root.left) == 1
    assert get_index(root, root.right) == 2
    assert get_index(root, root.left.left) == 3
    assert get_index(root, root.right.right) == 6

    with pytest.raises(NodeReferenceError) as err1:
        get_index(root.left, root.right)
    assert str(err1.value) == ""given nodes are not in the same tree""

    with pytest.raises(NodeTypeError) as err2:
        get_index(root, None)  # type: ignore
    assert str(err2.value) == ""descendent must be a Node instance""

    with pytest.raises(NodeTypeError) as err3:
        get_index(None, root.left)  # type: ignore
    assert str(err3.value) == ""root must be a Node instance""","root.left.left = Node(3)
root.right.right = Node(4)","(root.left.left, root.right.right) = (Node(3), Node(4))",0,,,,,,
pycraft,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pycraft/pycraft/world/world.py,https://github.com/traverseda/pycraft/tree/master/pycraft/world/world.py,World,initial_sector$253,"def initial_sector(self, coords):
        """"""
        Creates initial sectors in spiral, to speed up rendering in front of the player
        :param coords:
        :return:
        """"""
        x, y = 0, 0
        dx, dy = 0, -1
        X = coords[0] + 4
        Y = coords[2] + 4
        for i in range(max(X, Y) ** 2):
            if (-X / 2 < x <= X / 2) and (-Y / 2 < y <= Y / 2):
                self.show_sector((x, coords[1], y))
            if x == y or (x < 0 and x == -y) or (x > 0 and x == 1 - y):
                dx, dy = -dy, dx  # Corner change direction
            x, y = x + dx, y + dy","X = coords[0] + 4
Y = coords[2] + 4","(X, Y) = (coords[0] + 4, coords[2] + 4)",0,,,,,,
MixNMatch,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/MixNMatch/code/eval.py,https://github.com/Yuheng-Li/MixNMatch/tree/master/code/eval.py,,eval_feature$125,"def eval_feature():

    names = [ os.path.join(MODELS,'G.pth'), os.path.join(MODELS,'E.pth'), os.path.join(MODELS,'EX.pth')  ]
    netG, encoder, extractor = load_network(names)   
    
       
    real_img_b  = get_images(B) 
    real_img_p  = get_images(P)            
    real_img_c  = get_images(C)            


    with torch.no_grad():
        shape_feature = extractor( real_img_p.to(device) )
        fake_z1, fake_b, _, _ = encoder( real_img_b.to(device), 'softmax' )
        _, _, _, fake_c = encoder( real_img_c.to(device), 'softmax' )     
        
        fake_imgs, _, _, _ = netG(fake_z1, None, fake_c, shape_feature, fake_b, 'feature' )
        img = fake_imgs[2]       


    save_img(img, OUT)","real_img_b = get_images(B)
real_img_p = get_images(P)
real_img_c = get_images(C)","(real_img_b, real_img_p, real_img_c) = (get_images(B), get_images(P), get_images(C))",0,,,,,,
tensorflow-fcn,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/tensorflow-fcn/loss.py,https://github.com/MarvinTeichmann/tensorflow-fcn/tree/master//loss.py,,loss$15,"def loss(logits, labels, num_classes, head=None):
    """"""Calculate the loss from the logits and the labels.

    Args:
      logits: tensor, float - [batch_size, width, height, num_classes].
          Use vgg_fcn.upscore as logits.
      labels: Labels tensor, int32 - [batch_size, width, height, num_classes].
          The ground truth of your data.
      head: numpy array - [num_classes]
          Weighting the loss of each class
          Optional: Prioritize some classes

    Returns:
      loss: Loss tensor of type float.
    """"""
    with tf.name_scope('loss'):
        logits = tf.reshape(logits, (-1, num_classes))
        epsilon = tf.constant(value=1e-4)
        labels = tf.to_float(tf.reshape(labels, (-1, num_classes)))

        softmax = tf.nn.softmax(logits) + epsilon

        if head is not None:
            cross_entropy = -tf.reduce_sum(tf.multiply(labels * tf.log(softmax),
                                           head), reduction_indices=[1])
        else:
            cross_entropy = -tf.reduce_sum(
                labels * tf.log(softmax), reduction_indices=[1])

        cross_entropy_mean = tf.reduce_mean(cross_entropy,
                                            name='xentropy_mean')
        tf.add_to_collection('losses', cross_entropy_mean)

        loss = tf.add_n(tf.get_collection('losses'), name='total_loss')
    return loss","logits = tf.reshape(logits, (-1, num_classes))
epsilon = tf.constant(value=0.0001)","(logits, epsilon) = (tf.reshape(logits, (-1, num_classes)), tf.constant(value=0.0001))",0,,,,,,
viper,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/viper/viper/core/ui/console.py,https://github.com/viper-framework/viper/tree/master/viper/core/ui/console.py,Console,parse$76,"def parse(self, data):
        root = """"
        args = []

        # Split words by white space.
        words = data.split()
        # First word is the root command.
        root = words[0]

        # If there are more words, populate the arguments list.
        if len(words) > 1:
            args = words[1:]

        return (root, args)","args = []
words = data.split()","(args, words) = ([], data.split())",0,,,,,,
dm_control,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/dm_control/dm_control/locomotion/arenas/bowl.py,https://github.com/deepmind/dm_control/tree/master/dm_control/locomotion/arenas/bowl.py,Bowl,initialize_episode$100,"def initialize_episode(self, physics, random_state):
    if self._regenerate:
      self._regenerate = False

      # Get heightfield resolution, assert that it is square.
      res = physics.bind(self._hfield).nrow
      assert res == physics.bind(self._hfield).ncol

      # Sinusoidal bowl shape.
      row_grid, col_grid = np.ogrid[-1:1:res*1j, -1:1:res*1j]
      radius = np.clip(np.sqrt(col_grid**2 + row_grid**2), .1, 1)
      bowl_shape = .5 - np.cos(2*np.pi*radius)/2

      # Random smooth bumps.
      terrain_size = 2 * physics.bind(self._hfield).size[0]
      bump_res = int(terrain_size / _TERRAIN_BUMP_SCALE)
      bumps = random_state.uniform(_TERRAIN_SMOOTHNESS, 1, (bump_res, bump_res))
      smooth_bumps = ndimage.zoom(bumps, res / float(bump_res))

      # Terrain is elementwise product.
      terrain = bowl_shape * smooth_bumps
      start_idx = physics.bind(self._hfield).adr
      physics.model.hfield_data[start_idx:start_idx+res**2] = terrain.ravel()

      # If we have a rendering context, we need to re-upload the modified
      # heightfield data.
      if physics.contexts:
        with physics.contexts.gl.make_current() as ctx:
          ctx.call(mjlib.mjr_uploadHField,
                   physics.model.ptr,
                   physics.contexts.mujoco.ptr,
                   physics.bind(self._hfield).element_id)","self._regenerate = False
res = physics.bind(self._hfield).nrow","(self._regenerate, res) = (False, physics.bind(self._hfield).nrow)",0,,,,,,
DSView,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/DSView/libsigrokdecode4DSL/decoders/lpc/pd.py,https://github.com/DreamSourceLab/DSView/tree/master/libsigrokdecode4DSL/decoders/lpc/pd.py,Decoder,handle_get_fw_msize$278,"def handle_get_fw_msize(self):
        # LAD[3:0]: MSIZE field (1 clock cycle).
        self.es_block = self.samplenum
        s = 'MSIZE: 0x%%0%dx' % self.oldlad
        self.putb([3, [s % self.oldlad]])
        self.ss_block = self.samplenum
        self.msize = self.oldlad

        if self.direction == 1:
            self.state = 'GET FW DATA'
            self.cycle_count = 0
            self.dataword = 0
            self.cur_nibble = 0
        else:
            self.state = 'GET TAR'
            self.tar_count = 0","self.ss_block = self.samplenum
self.msize = self.oldlad","(self.ss_block, self.msize) = (self.samplenum, self.oldlad)",0,,,,,,
pyradio,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pyradio/pyradio/config_window.py,https://github.com/coderholic/pyradio/tree/master/pyradio/config_window.py,PyRadioConfigWindow,_load_default_values$295,"def _load_default_values(self):
        self._config_options['general_title'][1] = ''
        self._config_options['player'][1] = 'mpv,mplayer,vlc'
        self._config_options['open_last_playlist'][1] = 'False'
        self._config_options['default_playlist'][1] = 'stations'
        self._config_options['default_station'][1] = 'False'
        self._config_options['default_encoding'][1] = 'utf-8'
        self._config_options['enable_mouse'][1] = 'False'
        self._config_options['connection_timeout'][1] = '10'
        self._config_options['theme_title'][1] = ''
        ''' Transparency '''
        #self._old_use_transparency = self._config_options['use_transparency'][1]
        self._config_options['use_transparency'][1] = False
        self._config_options['force_http'][1] = False
        self._toggle_transparency_function(changed_from_config_window=True, force_value=False)
        self._config_options['playlist_manngement_title'][1] = ''
        self._config_options['confirm_station_deletion'][1] = True
        self._config_options['confirm_playlist_reload'][1] = True
        self._config_options['auto_save_playlist'][1] = False
        self._config_options['requested_player'][1] = ''
        ''' Theme
            Put this AFTER applying transparency, so that _do_init_pairs in
            _toggle_transparency does not overwrite pairs with applied theme values
        '''
        self._config_options['theme'][1] = 'dark'
        self._apply_a_theme('dark', False)
        self._check_if_config_is_dirty()","self._config_options['playlist_manngement_title'][1] = ''
self._config_options['confirm_station_deletion'][1] = True
self._config_options['confirm_playlist_reload'][1] = True
self._config_options['auto_save_playlist'][1] = False
self._config_options['requested_player'][1] = ''","(self._config_options['playlist_manngement_title'][1], self._config_options['confirm_station_deletion'][1], self._config_options['confirm_playlist_reload'][1], self._config_options['auto_save_playlist'][1], self._config_options['requested_player'][1]) = ('', True, True, False, '')",0,,,,,,
networkx,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/networkx/networkx/algorithms/centrality/tests/test_katz_centrality.py,https://github.com/networkx/networkx/tree/master/networkx/algorithms/centrality/tests/test_katz_centrality.py,TestKatzCentralityNumpy,test_P3_unweighted$234,"def test_P3_unweighted(self):
        """"""Katz centrality: P3""""""
        alpha = 0.1
        G = nx.path_graph(3)
        b_answer = {0: 0.5598852584152165, 1: 0.6107839182711449, 2: 0.5598852584152162}
        b = nx.katz_centrality_numpy(G, alpha, weight=None)
        for n in sorted(G):
            assert b[n] == pytest.approx(b_answer[n], abs=1e-4)","alpha = 0.1
G = nx.path_graph(3)","(alpha, G) = (0.1, nx.path_graph(3))",0,,,,,,
attn2d,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/attn2d/fairseq/sequence_generator.py,https://github.com/elbayadm/attn2d/tree/master/fairseq/sequence_generator.py,SequenceGeneratorWithAlignment,generate$825,"def generate(self, models, sample, **kwargs):
        self.model.reset_incremental_state()
        finalized = super()._generate(sample, **kwargs)

        src_tokens = sample[""net_input""][""src_tokens""]
        bsz = src_tokens.shape[0]
        beam_size = self.beam_size
        src_tokens, src_lengths, prev_output_tokens, tgt_tokens = self._prepare_batch_for_alignment(
            sample, finalized
        )
        if any(getattr(m, ""full_context_alignment"", False) for m in self.model.models):
            attn = self.model.forward_align(src_tokens, src_lengths, prev_output_tokens)
        else:
            attn = [
                finalized[i // beam_size][i % beam_size][""attention""].transpose(1, 0)
                for i in range(bsz * beam_size)
            ]

        # Process the attn matrix to extract hard alignments.
        for i in range(bsz * beam_size):
            alignment = utils.extract_hard_alignment(
                attn[i], src_tokens[i], tgt_tokens[i], self.pad, self.eos
            )
            finalized[i // beam_size][i % beam_size][""alignment""] = alignment
        return finalized","bsz = src_tokens.shape[0]
beam_size = self.beam_size","(bsz, beam_size) = (src_tokens.shape[0], self.beam_size)",0,,,,,,
toolkit,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/toolkit/got10k/experiments/lasot.py,https://github.com/got-10k/toolkit/tree/master/got10k/experiments/lasot.py,ExperimentLaSOT,plot_curves$163,"def plot_curves(self, tracker_names, extension='.png'):
        # assume tracker_names[0] is your tracker
        report_dir = os.path.join(self.report_dir, tracker_names[0])
        assert os.path.exists(report_dir), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'
        report_file = os.path.join(report_dir, 'performance.json')
        assert os.path.exists(report_file), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'

        # load pre-computed performance
        with open(report_file) as f:
            performance = json.load(f)

        succ_file = os.path.join(report_dir, 'success_plots'+extension)
        prec_file = os.path.join(report_dir, 'precision_plots'+extension)
        norm_prec_file = os.path.join(report_dir, 'norm_precision_plots'+extension)
        key = 'overall'

        # markers
        markers = ['-', '--', '-.']
        markers = [c + m for m in markers for c in [''] * 10]

        # filter performance by tracker_names
        performance = {k:v for k,v in performance.items() if k in tracker_names}

        # sort trackers by success score
        tracker_names = list(performance.keys())
        succ = [t[key]['success_score'] for t in performance.values()]
        inds = np.argsort(succ)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot success curves
        thr_iou = np.linspace(0, 1, self.nbins_iou)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_iou,
                            performance[name][key]['success_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['success_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower left', bbox_to_anchor=(0., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Overlap threshold',
               ylabel='Success rate',
               xlim=(0, 1), ylim=(0, 1),
               title='Success plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving success plots to', succ_file)
        fig.savefig(succ_file,
                    bbox_extra_artists=(legend,),
                    bbox_inches='tight',
                    dpi=300)

        # sort trackers by precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot precision curves
        thr_ce = np.arange(0, self.nbins_ce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_ce,
                            performance[name][key]['precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Location error threshold',
               ylabel='Precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving precision plots to', prec_file)
        fig.savefig(prec_file, dpi=300)

# added by user
        # sort trackers by normalized precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['normalized_precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot normalized precision curves
        thr_nce = np.arange(0, self.nbins_nce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_nce,
                            performance[name][key]['normalized_precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['normalized_precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Normalized location error threshold',
               ylabel='Normalized precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Normalized precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving normalized precision plots to', norm_prec_file)
        fig.savefig(norm_prec_file, dpi=300)","tracker_names = [tracker_names[i] for i in inds]
thr_iou = np.linspace(0, 1, self.nbins_iou)","(tracker_names, thr_iou) = ([tracker_names[i] for i in inds], np.linspace(0, 1, self.nbins_iou))",0,,,,,,
toolkit,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/toolkit/got10k/experiments/lasot.py,https://github.com/got-10k/toolkit/tree/master/got10k/experiments/lasot.py,ExperimentLaSOT,plot_curves$163,"def plot_curves(self, tracker_names, extension='.png'):
        # assume tracker_names[0] is your tracker
        report_dir = os.path.join(self.report_dir, tracker_names[0])
        assert os.path.exists(report_dir), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'
        report_file = os.path.join(report_dir, 'performance.json')
        assert os.path.exists(report_file), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'

        # load pre-computed performance
        with open(report_file) as f:
            performance = json.load(f)

        succ_file = os.path.join(report_dir, 'success_plots'+extension)
        prec_file = os.path.join(report_dir, 'precision_plots'+extension)
        norm_prec_file = os.path.join(report_dir, 'norm_precision_plots'+extension)
        key = 'overall'

        # markers
        markers = ['-', '--', '-.']
        markers = [c + m for m in markers for c in [''] * 10]

        # filter performance by tracker_names
        performance = {k:v for k,v in performance.items() if k in tracker_names}

        # sort trackers by success score
        tracker_names = list(performance.keys())
        succ = [t[key]['success_score'] for t in performance.values()]
        inds = np.argsort(succ)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot success curves
        thr_iou = np.linspace(0, 1, self.nbins_iou)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_iou,
                            performance[name][key]['success_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['success_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower left', bbox_to_anchor=(0., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Overlap threshold',
               ylabel='Success rate',
               xlim=(0, 1), ylim=(0, 1),
               title='Success plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving success plots to', succ_file)
        fig.savefig(succ_file,
                    bbox_extra_artists=(legend,),
                    bbox_inches='tight',
                    dpi=300)

        # sort trackers by precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot precision curves
        thr_ce = np.arange(0, self.nbins_ce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_ce,
                            performance[name][key]['precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Location error threshold',
               ylabel='Precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving precision plots to', prec_file)
        fig.savefig(prec_file, dpi=300)

# added by user
        # sort trackers by normalized precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['normalized_precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot normalized precision curves
        thr_nce = np.arange(0, self.nbins_nce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_nce,
                            performance[name][key]['normalized_precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['normalized_precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Normalized location error threshold',
               ylabel='Normalized precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Normalized precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving normalized precision plots to', norm_prec_file)
        fig.savefig(norm_prec_file, dpi=300)","lines = []
legends = []","(lines, legends) = ([], [])",0,,,,,,
toolkit,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/toolkit/got10k/experiments/lasot.py,https://github.com/got-10k/toolkit/tree/master/got10k/experiments/lasot.py,ExperimentLaSOT,plot_curves$163,"def plot_curves(self, tracker_names, extension='.png'):
        # assume tracker_names[0] is your tracker
        report_dir = os.path.join(self.report_dir, tracker_names[0])
        assert os.path.exists(report_dir), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'
        report_file = os.path.join(report_dir, 'performance.json')
        assert os.path.exists(report_file), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'

        # load pre-computed performance
        with open(report_file) as f:
            performance = json.load(f)

        succ_file = os.path.join(report_dir, 'success_plots'+extension)
        prec_file = os.path.join(report_dir, 'precision_plots'+extension)
        norm_prec_file = os.path.join(report_dir, 'norm_precision_plots'+extension)
        key = 'overall'

        # markers
        markers = ['-', '--', '-.']
        markers = [c + m for m in markers for c in [''] * 10]

        # filter performance by tracker_names
        performance = {k:v for k,v in performance.items() if k in tracker_names}

        # sort trackers by success score
        tracker_names = list(performance.keys())
        succ = [t[key]['success_score'] for t in performance.values()]
        inds = np.argsort(succ)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot success curves
        thr_iou = np.linspace(0, 1, self.nbins_iou)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_iou,
                            performance[name][key]['success_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['success_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower left', bbox_to_anchor=(0., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Overlap threshold',
               ylabel='Success rate',
               xlim=(0, 1), ylim=(0, 1),
               title='Success plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving success plots to', succ_file)
        fig.savefig(succ_file,
                    bbox_extra_artists=(legend,),
                    bbox_inches='tight',
                    dpi=300)

        # sort trackers by precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot precision curves
        thr_ce = np.arange(0, self.nbins_ce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_ce,
                            performance[name][key]['precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Location error threshold',
               ylabel='Precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving precision plots to', prec_file)
        fig.savefig(prec_file, dpi=300)

# added by user
        # sort trackers by normalized precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['normalized_precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot normalized precision curves
        thr_nce = np.arange(0, self.nbins_nce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_nce,
                            performance[name][key]['normalized_precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['normalized_precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Normalized location error threshold',
               ylabel='Normalized precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Normalized precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving normalized precision plots to', norm_prec_file)
        fig.savefig(norm_prec_file, dpi=300)","tracker_names = [tracker_names[i] for i in inds]
thr_ce = np.arange(0, self.nbins_ce)","(tracker_names, thr_ce) = ([tracker_names[i] for i in inds], np.arange(0, self.nbins_ce))",0,,,,,,
toolkit,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/toolkit/got10k/experiments/lasot.py,https://github.com/got-10k/toolkit/tree/master/got10k/experiments/lasot.py,ExperimentLaSOT,plot_curves$163,"def plot_curves(self, tracker_names, extension='.png'):
        # assume tracker_names[0] is your tracker
        report_dir = os.path.join(self.report_dir, tracker_names[0])
        assert os.path.exists(report_dir), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'
        report_file = os.path.join(report_dir, 'performance.json')
        assert os.path.exists(report_file), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'

        # load pre-computed performance
        with open(report_file) as f:
            performance = json.load(f)

        succ_file = os.path.join(report_dir, 'success_plots'+extension)
        prec_file = os.path.join(report_dir, 'precision_plots'+extension)
        norm_prec_file = os.path.join(report_dir, 'norm_precision_plots'+extension)
        key = 'overall'

        # markers
        markers = ['-', '--', '-.']
        markers = [c + m for m in markers for c in [''] * 10]

        # filter performance by tracker_names
        performance = {k:v for k,v in performance.items() if k in tracker_names}

        # sort trackers by success score
        tracker_names = list(performance.keys())
        succ = [t[key]['success_score'] for t in performance.values()]
        inds = np.argsort(succ)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot success curves
        thr_iou = np.linspace(0, 1, self.nbins_iou)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_iou,
                            performance[name][key]['success_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['success_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower left', bbox_to_anchor=(0., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Overlap threshold',
               ylabel='Success rate',
               xlim=(0, 1), ylim=(0, 1),
               title='Success plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving success plots to', succ_file)
        fig.savefig(succ_file,
                    bbox_extra_artists=(legend,),
                    bbox_inches='tight',
                    dpi=300)

        # sort trackers by precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot precision curves
        thr_ce = np.arange(0, self.nbins_ce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_ce,
                            performance[name][key]['precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Location error threshold',
               ylabel='Precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving precision plots to', prec_file)
        fig.savefig(prec_file, dpi=300)

# added by user
        # sort trackers by normalized precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['normalized_precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot normalized precision curves
        thr_nce = np.arange(0, self.nbins_nce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_nce,
                            performance[name][key]['normalized_precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['normalized_precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Normalized location error threshold',
               ylabel='Normalized precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Normalized precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving normalized precision plots to', norm_prec_file)
        fig.savefig(norm_prec_file, dpi=300)","lines = []
legends = []","(lines, legends) = ([], [])",0,,,,,,
toolkit,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/toolkit/got10k/experiments/lasot.py,https://github.com/got-10k/toolkit/tree/master/got10k/experiments/lasot.py,ExperimentLaSOT,plot_curves$163,"def plot_curves(self, tracker_names, extension='.png'):
        # assume tracker_names[0] is your tracker
        report_dir = os.path.join(self.report_dir, tracker_names[0])
        assert os.path.exists(report_dir), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'
        report_file = os.path.join(report_dir, 'performance.json')
        assert os.path.exists(report_file), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'

        # load pre-computed performance
        with open(report_file) as f:
            performance = json.load(f)

        succ_file = os.path.join(report_dir, 'success_plots'+extension)
        prec_file = os.path.join(report_dir, 'precision_plots'+extension)
        norm_prec_file = os.path.join(report_dir, 'norm_precision_plots'+extension)
        key = 'overall'

        # markers
        markers = ['-', '--', '-.']
        markers = [c + m for m in markers for c in [''] * 10]

        # filter performance by tracker_names
        performance = {k:v for k,v in performance.items() if k in tracker_names}

        # sort trackers by success score
        tracker_names = list(performance.keys())
        succ = [t[key]['success_score'] for t in performance.values()]
        inds = np.argsort(succ)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot success curves
        thr_iou = np.linspace(0, 1, self.nbins_iou)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_iou,
                            performance[name][key]['success_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['success_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower left', bbox_to_anchor=(0., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Overlap threshold',
               ylabel='Success rate',
               xlim=(0, 1), ylim=(0, 1),
               title='Success plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving success plots to', succ_file)
        fig.savefig(succ_file,
                    bbox_extra_artists=(legend,),
                    bbox_inches='tight',
                    dpi=300)

        # sort trackers by precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot precision curves
        thr_ce = np.arange(0, self.nbins_ce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_ce,
                            performance[name][key]['precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Location error threshold',
               ylabel='Precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving precision plots to', prec_file)
        fig.savefig(prec_file, dpi=300)

# added by user
        # sort trackers by normalized precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['normalized_precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot normalized precision curves
        thr_nce = np.arange(0, self.nbins_nce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_nce,
                            performance[name][key]['normalized_precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['normalized_precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Normalized location error threshold',
               ylabel='Normalized precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Normalized precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving normalized precision plots to', norm_prec_file)
        fig.savefig(norm_prec_file, dpi=300)","tracker_names = [tracker_names[i] for i in inds]
thr_nce = np.arange(0, self.nbins_nce)","(tracker_names, thr_nce) = ([tracker_names[i] for i in inds], np.arange(0, self.nbins_nce))",0,,,,,,
toolkit,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/toolkit/got10k/experiments/lasot.py,https://github.com/got-10k/toolkit/tree/master/got10k/experiments/lasot.py,ExperimentLaSOT,plot_curves$163,"def plot_curves(self, tracker_names, extension='.png'):
        # assume tracker_names[0] is your tracker
        report_dir = os.path.join(self.report_dir, tracker_names[0])
        assert os.path.exists(report_dir), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'
        report_file = os.path.join(report_dir, 'performance.json')
        assert os.path.exists(report_file), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'

        # load pre-computed performance
        with open(report_file) as f:
            performance = json.load(f)

        succ_file = os.path.join(report_dir, 'success_plots'+extension)
        prec_file = os.path.join(report_dir, 'precision_plots'+extension)
        norm_prec_file = os.path.join(report_dir, 'norm_precision_plots'+extension)
        key = 'overall'

        # markers
        markers = ['-', '--', '-.']
        markers = [c + m for m in markers for c in [''] * 10]

        # filter performance by tracker_names
        performance = {k:v for k,v in performance.items() if k in tracker_names}

        # sort trackers by success score
        tracker_names = list(performance.keys())
        succ = [t[key]['success_score'] for t in performance.values()]
        inds = np.argsort(succ)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot success curves
        thr_iou = np.linspace(0, 1, self.nbins_iou)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_iou,
                            performance[name][key]['success_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['success_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower left', bbox_to_anchor=(0., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Overlap threshold',
               ylabel='Success rate',
               xlim=(0, 1), ylim=(0, 1),
               title='Success plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving success plots to', succ_file)
        fig.savefig(succ_file,
                    bbox_extra_artists=(legend,),
                    bbox_inches='tight',
                    dpi=300)

        # sort trackers by precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot precision curves
        thr_ce = np.arange(0, self.nbins_ce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_ce,
                            performance[name][key]['precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Location error threshold',
               ylabel='Precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving precision plots to', prec_file)
        fig.savefig(prec_file, dpi=300)

# added by user
        # sort trackers by normalized precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['normalized_precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot normalized precision curves
        thr_nce = np.arange(0, self.nbins_nce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_nce,
                            performance[name][key]['normalized_precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['normalized_precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Normalized location error threshold',
               ylabel='Normalized precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Normalized precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving normalized precision plots to', norm_prec_file)
        fig.savefig(norm_prec_file, dpi=300)","lines = []
legends = []","(lines, legends) = ([], [])",0,,,,,,
habu,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/habu/habu/cli/cmd_arp_sniff.py,https://github.com/fportantier/habu/tree/master/habu/cli/cmd_arp_sniff.py,,procpkt$17,"def procpkt(pkt):

    now = time()
    output = '{seconds}\t{ip}\t{hwaddr}\t{vendor}'

    if conf.manufdb:
        manufdb_available = True
    else:
        manufdb_available = False

    if 'ARP' in pkt:
        hosts[pkt[ARP].psrc] = {}
        hosts[pkt[ARP].psrc]['hwaddr'] = pkt[ARP].hwsrc
        hosts[pkt[ARP].psrc]['time'] = time()

        if manufdb_available:
            hosts[pkt[ARP].psrc]['vendor'] = conf.manufdb._get_manuf(pkt[ARP].hwsrc)
        else:
            hosts[pkt[ARP].psrc]['vendor'] = 'unknown'

        click.clear()

        if not manufdb_available:
            click.echo('WARNING: manufdb is not available. Can\'t get vendor.')

        for ip in sorted(hosts):
            print(output.format(
                seconds = int(now - hosts[ip]['time']),
                ip = ip,
                hwaddr = hosts[ip]['hwaddr'],
                vendor = hosts[ip]['vendor']
            ))","hosts[pkt[ARP].psrc]['hwaddr'] = pkt[ARP].hwsrc
hosts[pkt[ARP].psrc]['time'] = time()","(hosts[pkt[ARP].psrc]['hwaddr'], hosts[pkt[ARP].psrc]['time']) = (pkt[ARP].hwsrc, time())",0,,,,,,
OWOD,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/OWOD/projects/DensePose/densepose/modeling/hrnet.py,https://github.com/JosephKJ/OWOD/tree/master/projects/DensePose/densepose/modeling/hrnet.py,PoseHigherResolutionNet,__init__$281,"def __init__(self, cfg, **kwargs):
        self.inplanes = cfg.MODEL.HRNET.STEM_INPLANES
        super(PoseHigherResolutionNet, self).__init__()

        # stem net
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)
        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)
        self.relu = nn.ReLU(inplace=True)
        self.layer1 = self._make_layer(Bottleneck, 64, 4)

        self.stage2_cfg = cfg.MODEL.HRNET.STAGE2
        num_channels = self.stage2_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage2_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition1 = self._make_transition_layer([256], num_channels)
        self.stage2, pre_stage_channels = self._make_stage(self.stage2_cfg, num_channels)

        self.stage3_cfg = cfg.MODEL.HRNET.STAGE3
        num_channels = self.stage3_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage3_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition2 = self._make_transition_layer(pre_stage_channels, num_channels)
        self.stage3, pre_stage_channels = self._make_stage(self.stage3_cfg, num_channels)

        self.stage4_cfg = cfg.MODEL.HRNET.STAGE4
        num_channels = self.stage4_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage4_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition3 = self._make_transition_layer(pre_stage_channels, num_channels)
        self.stage4, pre_stage_channels = self._make_stage(
            self.stage4_cfg, num_channels, multi_scale_output=True
        )

        self._out_features = []
        self._out_feature_channels = {}
        self._out_feature_strides = {}

        for i in range(cfg.MODEL.HRNET.STAGE4.NUM_BRANCHES):
            self._out_features.append(""p%d"" % (i + 1))
            self._out_feature_channels.update(
                {self._out_features[-1]: cfg.MODEL.HRNET.STAGE4.NUM_CHANNELS[i]}
            )
            self._out_feature_strides.update({self._out_features[-1]: 1})","self._out_features = []
self._out_feature_channels = {}
self._out_feature_strides = {}","(self._out_features, self._out_feature_channels, self._out_feature_strides) = ([], {}, {})",0,,,,,,
spiderfoot,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/spiderfoot/test/unit/modules/test_sfp_ipregistry.py,https://github.com/smicallef/spiderfoot/tree/master/test/unit/modules/test_sfp_ipregistry.py,TestModuletemplate,test_handleEvent_no_api_key_should_set_errorState$37,"def test_handleEvent_no_api_key_should_set_errorState(self):
        """"""
        Test handleEvent(self, event)
        """"""
        sf = SpiderFoot(self.default_options)

        module = sfp_ipregistry()
        module.setup(sf, dict())

        target_value = ""example target value""
        target_type = ""IP_ADDRESS""
        target = SpiderFootTarget(target_value, target_type)
        module.setTarget(target)

        event_type = ""ROOT""
        event_data = ""example data""
        event_module = """"
        source_event = """"
        evt = SpiderFootEvent(event_type, event_data, event_module, source_event)

        result = module.handleEvent(evt)

        self.assertIsNone(result)
        self.assertTrue(module.errorState)","event_type = 'ROOT'
event_data = 'example data'
event_module = ''
source_event = ''","(event_type, event_data, event_module, source_event) = ('ROOT', 'example data', '', '')",0,,,,,,
MaskFormer,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/MaskFormer/mask_former/modeling/heads/mask_former_head.py,https://github.com/facebookresearch/MaskFormer/tree/master/mask_former/modeling/heads/mask_former_head.py,MaskFormerHead,__init__$48,"def __init__(
        self,
        input_shape: Dict[str, ShapeSpec],
        *,
        num_classes: int,
        pixel_decoder: nn.Module,
        loss_weight: float = 1.0,
        ignore_value: int = -1,
        # extra parameters
        transformer_predictor: nn.Module,
        transformer_in_feature: str,
    ):
        """"""
        NOTE: this interface is experimental.
        Args:
            input_shape: shapes (channels and stride) of the input features
            num_classes: number of classes to predict
            pixel_decoder: the pixel decoder module
            loss_weight: loss weight
            ignore_value: category id to be ignored during training.
            transformer_predictor: the transformer decoder that makes prediction
            transformer_in_feature: input feature name to the transformer_predictor
        """"""
        super().__init__()
        input_shape = sorted(input_shape.items(), key=lambda x: x[1].stride)
        self.in_features = [k for k, v in input_shape]
        feature_strides = [v.stride for k, v in input_shape]
        feature_channels = [v.channels for k, v in input_shape]

        self.ignore_value = ignore_value
        self.common_stride = 4
        self.loss_weight = loss_weight

        self.pixel_decoder = pixel_decoder
        self.predictor = transformer_predictor
        self.transformer_in_feature = transformer_in_feature

        self.num_classes = num_classes","self.in_features = [k for (k, v) in input_shape]
feature_strides = [v.stride for (k, v) in input_shape]
feature_channels = [v.channels for (k, v) in input_shape]
self.ignore_value = ignore_value
self.common_stride = 4
self.loss_weight = loss_weight
self.pixel_decoder = pixel_decoder
self.predictor = transformer_predictor
self.transformer_in_feature = transformer_in_feature
self.num_classes = num_classes","(self.in_features, feature_strides, feature_channels, self.ignore_value, self.common_stride, self.loss_weight, self.pixel_decoder, self.predictor, self.transformer_in_feature, self.num_classes) = ([k for (k, v) in input_shape], [v.stride for (k, v) in input_shape], [v.channels for (k, v) in input_shape], ignore_value, 4, loss_weight, pixel_decoder, transformer_predictor, transformer_in_feature, num_classes)",0,,,,,,
Paddle,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/Paddle/python/paddle/distributed/fleet/meta_optimizers/pipeline_optimizer.py,https://github.com/PaddlePaddle/Paddle/tree/master/python/paddle/distributed/fleet/meta_optimizers/pipeline_optimizer.py,PipelineOptimizer,minimize_impl$200,"def minimize_impl(
        self, loss, startup_program=None, parameter_list=None, no_grad_set=None
    ):
        self.endpoints = self.role_maker._get_trainer_endpoints()
        self.current_endpoint = self.endpoints[self.role_maker._worker_index()]
        self.rank = self.role_maker._worker_index()
        self.nranks = self.role_maker._worker_num()

        self.wrapped_opt = PO(
            self.inner_opt, num_microbatches=self.num_microbatches
        )
        orig_startup_program = (
            startup_program
            if startup_program
            else paddle.static.default_startup_program()
        )
        block = loss.block
        program = block.program

        program._pipeline_opt = dict()
        program._pipeline_opt['local_rank'] = self.rank
        program._pipeline_opt['global_ring_id'] = self.global_ring_id
        program._pipeline_opt['ring_id'] = self.start_pipeline_ring_id
        program._pipeline_opt['micro_batch_size'] = self.micro_batch_size
        program._pipeline_opt['schedule_mode'] = self.schedule_mode
        program._pipeline_opt['use_sharding'] = False
        program._pipeline_opt['mp_degree'] = 1
        program._pipeline_opt['mp_rank'] = 0
        (
            optimize_ops,
            params_grads,
            prog_list,
            pp_pair,
            ring_map,
        ) = self.wrapped_opt.minimize(
            loss, startup_program, parameter_list, no_grad_set
        )
        self.startup_program = orig_startup_program._pipeline_opt[
            'startup_program'
        ]
        self.inner_parallelism = program._pipeline_opt['inner_parallelism']
        assert self.nranks % self.inner_parallelism == 0
        assert prog_list
        self.pipeline_num = len(self.endpoints) // self.inner_parallelism

        self._init_process_group(pp_pair, ring_map)

        self.main_program_list = prog_list
        self.main_program = program
        if self.pipeline_num > 1:
            self._transpile_main_program(loss)
        return optimize_ops, params_grads","program._pipeline_opt['local_rank'] = self.rank
program._pipeline_opt['global_ring_id'] = self.global_ring_id
program._pipeline_opt['ring_id'] = self.start_pipeline_ring_id
program._pipeline_opt['micro_batch_size'] = self.micro_batch_size
program._pipeline_opt['schedule_mode'] = self.schedule_mode
program._pipeline_opt['use_sharding'] = False
program._pipeline_opt['mp_degree'] = 1
program._pipeline_opt['mp_rank'] = 0","(program._pipeline_opt['local_rank'], program._pipeline_opt['global_ring_id'], program._pipeline_opt['ring_id'], program._pipeline_opt['micro_batch_size'], program._pipeline_opt['schedule_mode'], program._pipeline_opt['use_sharding'], program._pipeline_opt['mp_degree'], program._pipeline_opt['mp_rank']) = (self.rank, self.global_ring_id, self.start_pipeline_ring_id, self.micro_batch_size, self.schedule_mode, False, 1, 0)",0,,,,,,
Paddle,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/Paddle/python/paddle/distributed/fleet/meta_optimizers/pipeline_optimizer.py,https://github.com/PaddlePaddle/Paddle/tree/master/python/paddle/distributed/fleet/meta_optimizers/pipeline_optimizer.py,PipelineOptimizer,minimize_impl$200,"def minimize_impl(
        self, loss, startup_program=None, parameter_list=None, no_grad_set=None
    ):
        self.endpoints = self.role_maker._get_trainer_endpoints()
        self.current_endpoint = self.endpoints[self.role_maker._worker_index()]
        self.rank = self.role_maker._worker_index()
        self.nranks = self.role_maker._worker_num()

        self.wrapped_opt = PO(
            self.inner_opt, num_microbatches=self.num_microbatches
        )
        orig_startup_program = (
            startup_program
            if startup_program
            else paddle.static.default_startup_program()
        )
        block = loss.block
        program = block.program

        program._pipeline_opt = dict()
        program._pipeline_opt['local_rank'] = self.rank
        program._pipeline_opt['global_ring_id'] = self.global_ring_id
        program._pipeline_opt['ring_id'] = self.start_pipeline_ring_id
        program._pipeline_opt['micro_batch_size'] = self.micro_batch_size
        program._pipeline_opt['schedule_mode'] = self.schedule_mode
        program._pipeline_opt['use_sharding'] = False
        program._pipeline_opt['mp_degree'] = 1
        program._pipeline_opt['mp_rank'] = 0
        (
            optimize_ops,
            params_grads,
            prog_list,
            pp_pair,
            ring_map,
        ) = self.wrapped_opt.minimize(
            loss, startup_program, parameter_list, no_grad_set
        )
        self.startup_program = orig_startup_program._pipeline_opt[
            'startup_program'
        ]
        self.inner_parallelism = program._pipeline_opt['inner_parallelism']
        assert self.nranks % self.inner_parallelism == 0
        assert prog_list
        self.pipeline_num = len(self.endpoints) // self.inner_parallelism

        self._init_process_group(pp_pair, ring_map)

        self.main_program_list = prog_list
        self.main_program = program
        if self.pipeline_num > 1:
            self._transpile_main_program(loss)
        return optimize_ops, params_grads","self.startup_program = orig_startup_program._pipeline_opt['startup_program']
self.inner_parallelism = program._pipeline_opt['inner_parallelism']","(self.startup_program, self.inner_parallelism) = (orig_startup_program._pipeline_opt['startup_program'], program._pipeline_opt['inner_parallelism'])",0,,,,,,
glTF-Blender-Exporter,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/glTF-Blender-Exporter/scripts/addons/io_scene_gltf2/gltf2_generate.py,https://github.com/KhronosGroup/glTF-Blender-Exporter/tree/master/scripts/addons/io_scene_gltf2/gltf2_generate.py,,generate_nodes$1720,"def generate_nodes(operator,
                   context,
                   export_settings,
                   glTF):
    """"""
    Generates the top level nodes entry.
    """"""

    nodes = []

    skins = []

    #
    #

    filtered_objects = export_settings['filtered_objects']

    for blender_object in filtered_objects:
        node = generate_node_instance(context, export_settings, glTF, nodes, blender_object, False)

        #
        #

        nodes.append(node)

    #
    #

    for blender_object in filtered_objects:
        if blender_object.dupli_type == 'GROUP' and blender_object.dupli_group != None:

            if export_settings['gltf_layers'] or (blender_object.layers[0] and blender_object.dupli_group.layers[0]):

                for blender_dupli_object in blender_object.dupli_group.objects:
                    node = generate_node_instance(context, export_settings, glTF, nodes, blender_dupli_object,
                                                  True)

                    node['name'] = 'Duplication_' + blender_object.name + '_' + blender_dupli_object.name

                    #
                    #

                    nodes.append(node)

                #

                node = {}

                node['name'] = 'Duplication_Offset_' + blender_object.name

                translation = convert_swizzle_location(blender_object.dupli_group.dupli_offset, export_settings)

                node['translation'] = [-translation[0], -translation[1], -translation[2]]

                nodes.append(node)

    #
    #

    if len(nodes) > 0:
        glTF['nodes'] = nodes

    #
    #

    if export_settings['gltf_skins']:
        for blender_object in filtered_objects:
            if blender_object.type != 'ARMATURE' or len(blender_object.pose.bones) == 0:
                continue

            temp_action = None

            if export_settings['gltf_bake_skins'] and not export_settings['gltf_animations']:
                if blender_object.animation_data is not None:
                    temp_action = blender_object.animation_data.action

                bpy.context.scene.objects.active = blender_object
                bpy.ops.object.mode_set(mode='POSE')
                bpy.ops.nla.bake(frame_start=bpy.context.scene.frame_current, frame_end=bpy.context.scene.frame_current,
                                 only_selected=False, visual_keying=True, clear_constraints=False,
                                 use_current_action=False, bake_types={'POSE'})

            joints = []

            joints_written = False

            #

            children_list = list(blender_object.children)

            for blender_check_object in filtered_objects:
                blender_check_armature = blender_check_object.find_armature()

                if blender_check_armature == blender_object and blender_check_object not in children_list:
                    children_list.append(blender_check_object)

            #

            for blender_object_child in children_list:
                #
                # Property: skin and node
                #

                inverse_matrices = []

                for blender_bone in blender_object.pose.bones:

                    if export_settings['gltf_yup']:
                        axis_basis_change = mathutils.Matrix(
                            ((1.0, 0.0, 0.0, 0.0), (0.0, 0.0, 1.0, 0.0), (0.0, -1.0, 0.0, 0.0), (0.0, 0.0, 0.0, 1.0)))
                    else:
                        axis_basis_change = mathutils.Matrix.Identity(4)

                    if not joints_written:
                        node = {}

                        if blender_bone.parent is None:
                            correction_matrix_local = axis_basis_change * blender_bone.bone.matrix_local
                        else:
                            correction_matrix_local = blender_bone.parent.bone.matrix_local.inverted() * blender_bone.bone.matrix_local

                        matrix_basis = blender_bone.matrix_basis

                        if export_settings['gltf_bake_skins']:
                            matrix_basis = blender_object.convert_space(blender_bone, blender_bone.matrix,
                                                                        from_space='POSE', to_space='LOCAL')

                        generate_node_parameter(export_settings, correction_matrix_local * matrix_basis, node, 'JOINT')

                        #

                        node['name'] = blender_object.name + ""_"" + blender_bone.name

                        #
                        #

                        joints.append(len(nodes))

                        nodes.append(node)

                    #
                    #

                    inverse_bind_matrix = axis_basis_change * blender_bone.bone.matrix_local

                    bind_shape_matrix = axis_basis_change * blender_object.matrix_world.inverted() * blender_object_child.matrix_world * axis_basis_change.inverted()

                    inverse_bind_matrix = inverse_bind_matrix.inverted() * bind_shape_matrix

                    for column in range(0, 4):
                        for row in range(0, 4):
                            inverse_matrices.append(inverse_bind_matrix[row][column])

                #

                joints_written = True

                #

                skin = {}

                skin['skeleton'] = get_node_index(glTF, blender_object.name)

                skin['joints'] = joints

                #
                count = len(inverse_matrices) // 16
                type = ""MAT4""

                inverseBindMatrices = create_accessor(
                    operator,
                    context,
                    export_settings,
                    glTF,
                    inverse_matrices,
                    GLTF_COMPONENT_TYPE_FLOAT,
                    count,
                    GLTF_DATA_TYPE_MAT4,
                    """"
                )

                skin['inverseBindMatrices'] = inverseBindMatrices

                #

                skins.append(skin)

            #

            if temp_action is not None:
                blender_object.animation_data.action = temp_action

    #
    #

    if len(skins) > 0:
        glTF['skins'] = skins

    #
    # Resolve children etc.
    #

    for blender_object in filtered_objects:
        node_index = get_node_index(glTF, blender_object.name)

        node = nodes[node_index]

        #

        if export_settings['gltf_skins']:
            blender_armature = blender_object.find_armature()
            if blender_armature is not None:

                if blender_object in blender_armature.children:
                    index_offset = blender_armature.children.index(blender_object)
                else:
                    index_local_offset = 0

                    for blender_check_object in filtered_objects:
                        blender_check_armature = blender_check_object.find_armature()
                        if blender_check_armature == blender_armature:
                            index_local_offset += 1

                        if blender_object == blender_check_object:
                            index_local_offset -= 1
                            break

                    index_offset = len(blender_armature.children) + index_local_offset

                node['skin'] = get_skin_index(glTF, blender_armature.name, index_offset)

        #

        children = []

        # Camera
        if export_settings['gltf_cameras']:
            if blender_object.type == 'CAMERA':
                child_index = get_node_index(glTF, 'Correction_' + blender_object.name)
                if child_index >= 0:
                    children.append(child_index)

        # Light
        if export_settings['gltf_lights']:
            if blender_object.type == 'LAMP':
                child_index = get_node_index(glTF, 'Correction_' + blender_object.name)
                if child_index >= 0:
                    children.append(child_index)

        # Nodes
        for blender_child_node in blender_object.children:
            child_index = get_node_index(glTF, blender_child_node.name)

            if blender_child_node.parent_type == 'BONE' and export_settings['gltf_skins']:
                continue

            if child_index < 0:
                continue

            children.append(child_index)

        # Duplications
        if blender_object.dupli_type == 'GROUP' and blender_object.dupli_group is not None:

            child_index = get_node_index(glTF, 'Duplication_Offset_' + blender_object.name)
            if child_index >= 0:
                children.append(child_index)

                duplication_node = nodes[child_index]

                duplication_children = []

                for blender_dupli_object in blender_object.dupli_group.objects:
                    child_index = get_node_index(
                        glTF,
                        'Duplication_' + blender_object.name + '_' + blender_dupli_object.name
                    )
                    if child_index >= 0:
                        duplication_children.append(child_index)

                duplication_node['children'] = duplication_children

                #

        if export_settings['gltf_skins']:
            # Joint
            if blender_object.type == 'ARMATURE' and len(blender_object.pose.bones) > 0:

                #

                blender_object_to_bone = {}

                if export_settings['gltf_skins']:
                    for blender_child_node in blender_object.children:
                        if blender_child_node.parent_type == 'BONE':
                            blender_object_to_bone[blender_child_node.name] = blender_child_node.parent_bone

                #

                for blender_bone in blender_object.pose.bones:

                    if blender_bone.parent:
                        continue

                    child_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone.name)

                    if child_index < 0:
                        continue

                    children.append(child_index)

                for blender_bone in blender_object.pose.bones:
                    joint_children = []
                    for blender_bone_child in blender_bone.children:
                        child_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone_child.name)

                        if child_index < 0:
                            continue

                        joint_children.append(child_index)

                    for blender_object_name in blender_object_to_bone:
                        blender_bone_name = blender_object_to_bone[blender_object_name]
                        if blender_bone_name == blender_bone.name:
                            child_index = get_node_index(glTF, blender_object_name)

                            if child_index < 0:
                                continue

                            joint_children.append(child_index)

                    if len(joint_children) > 0:
                        node_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone.name)

                        child_node = nodes[node_index]

                        child_node['children'] = joint_children

        if len(children) > 0:
            node['children'] = children","skin['skeleton'] = get_node_index(glTF, blender_object.name)
skin['joints'] = joints
count = len(inverse_matrices) // 16","(skin['skeleton'], skin['joints'], count) = (get_node_index(glTF, blender_object.name), joints, len(inverse_matrices) // 16)",0,,,,,,
tvm,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/tvm/tests/python/contrib/test_ethosu/test_tir_to_cs_translator.py,https://github.com/apache/tvm/tree/master/tests/python/contrib/test_ethosu/test_tir_to_cs_translator.py,,test_assign_addresses$698,"def test_assign_addresses():
    test_cases = [
        {
            # Stimulus
            ""tir_module"": WeightStreamOnly,
            ""param_dict"": {
                WeightStreamOnly[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [128], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_3""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_4""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_5""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_6""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_7""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
            },
        },
        {
            # Stimulus
            ""tir_module"": MixedRead,
            ""param_dict"": {
                MixedRead[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [592], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [160], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_3""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_4""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_5""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_6""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_7""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_8""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_9""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
            },
        },
        {
            # Stimulus
            ""tir_module"": MixedConstantDatatypes,
            ""param_dict"": {
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [160], ""uint8""
                ),
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""int16"").min, np.iinfo(""int16"").max, [1], ""int16""
                ),
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [272], ""uint8""
                ),
            },
        },
    ]

    def extract_call_extern_list(mod):
        """"""This function will obtain all ethosu_conv2d
        calls from a NPU TIR module
        Parameters
        ----------
        mod : tvm.IRModule
            This is a NPU TIR Module

        Returns
        -------
        list
            of tvm.tir.Call objects
            that are tir extern calls
            for ethosu_conv2d
        """"""
        # There should only be a single function
        assert len(mod.functions.items()) == 1
        primfunc = mod.functions.items()[0][1]

        extern_calls = list()

        def populate_extern_calls(stmt):
            if isinstance(stmt, tvm.tir.Call) and stmt.op.name == ""tir.call_extern"":
                extern_calls.append(stmt)

        stmt_functor.post_order_visit(primfunc.body, populate_extern_calls)
        return extern_calls

    def collect_tir_buffer_info(npu_ops):
        """"""This is run prior to address assigning to collect tir buffer information
        for verification later on""""""
        _npu_op_tir_buffers = dict()
        for npu_op in npu_ops:
            if isinstance(npu_op, vapi.NpuDmaOperation):
                _npu_op_tir_buffers[npu_op] = (npu_op.src.address, npu_op.dest.address)
            elif issubclass(type(npu_op), vapi.NpuBlockOperation):
                _npu_op_tir_buffers[npu_op] = (
                    npu_op.ifm.tiles.addresses[0],
                    npu_op.ofm.tiles.addresses[0],
                    npu_op.weights,
                    npu_op.biases,
                )
        return _npu_op_tir_buffers

    def _check_buffer(address, region, length, buffer_var):
        """"""Checks whether the buffer information is valid with
        original tir buffers.
        - If its constant, this will check
          the slice in the constant tensor has the values.
        - If its scratch, this will check
          the slice is within scratch and does not have conflicts
          with other scratch tensors.
        - If its input/output, this will check the
          address is zero
        """"""
        inverse_region_map = {
            0: tir_to_cs_translator.BufferType.constant,
            1: tir_to_cs_translator.BufferType.scratch,
            3: tir_to_cs_translator.BufferType.input,
            4: tir_to_cs_translator.BufferType.output,
        }
        buffer_type = inverse_region_map[region]
        buffer_dtype = buffer_var.type_annotation.element_type.dtype
        dtype_bytes = np.iinfo(np.dtype(buffer_dtype)).bits // 8
        if buffer_type == tir_to_cs_translator.BufferType.constant:
            ref = buffer_info[buffer_var].values
            hex_from = address * dtype_bytes * 2
            hex_to = hex_from + length * dtype_bytes * 2
            constant_hex = constant_hex_string[hex_from:hex_to]
            constant_tensor = np.frombuffer(bytearray.fromhex(constant_hex), dtype=buffer_dtype)
            np.array_equal(constant_tensor, ref)
            # Every buffer is adjusted to align to 16 bytes
            length = util.round_up(length, 16)
            # Mark these constants are read at least once
            constant_tensor_read_mask[address : address + length] = np.ones(
                length, dtype=buffer_dtype
            )
        elif buffer_type == tir_to_cs_translator.BufferType.scratch:
            assert address < tvmbaw_workspace_size

            size_in_bytes = allocate_node_sizes[buffer_var]
            # Every buffer is adjusted to align to 16 bytes
            size_in_bytes = util.round_up(size_in_bytes, 16)
            assert address + size_in_bytes <= tvmbaw_workspace_size
            # The scratch area should not be used by any other buffer
            assert not tvmbaw_workspace_mask[address : address + size_in_bytes].any()
            # The scratch area is marked as used
            tvmbaw_workspace_mask[address : address + size_in_bytes] = np.ones(
                size_in_bytes, dtype=""uint8""
            )
        elif buffer_type == tir_to_cs_translator.BufferType.input:
            assert address == 0
        else:
            assert buffer_type == tir_to_cs_translator.BufferType.output
            assert address == 0

    def _get_allocate_node_sizes(mod):
        # There should only be a single function
        assert len(mod.functions.items()) == 1
        primfunc = mod.functions.items()[0][1]
        _allocate_node_sizes = dict()

        def analyze_remaining_allocates(stmt):
            if isinstance(stmt, tvm.tir.stmt.Allocate):
                allocate = stmt
                pointer_type = allocate.buffer_var.type_annotation
                storage_scope = pointer_type.storage_scope
                if storage_scope == ""global"":
                    dtype_bytes = np.iinfo(np.dtype(allocate.dtype)).bits // 8
                    size_in_bytes = int(dtype_bytes * np.prod(list(allocate.extents)))
                    # Every memory address the NPU access have to be 16 byte aligned
                    size_in_bytes = util.round_up(size_in_bytes, 16)
                    _allocate_node_sizes[allocate.buffer_var] = size_in_bytes

        tvm.tir.stmt_functor.post_order_visit(primfunc.body, analyze_remaining_allocates)
        return _allocate_node_sizes

    def verify(npu_ops):
        """"""This wrapper verifies the allocated addresses matches with original tir buffers""""""
        checked_buffers = set()

        def check_buffer(address, region, length, buffer_var):
            if buffer_var not in checked_buffers:
                _check_buffer(address, region, length, buffer_var)
                checked_buffers.add(buffer_var)

        for npu_op in npu_ops:
            if isinstance(npu_op, vapi.NpuDmaOperation):
                src_tir_buffer_var = npu_op_tir_buffers[npu_op][0].buffer.data
                check_buffer(
                    npu_op.src.address, npu_op.src.region, npu_op.src.length, src_tir_buffer_var
                )
                dest_tir_load = npu_op_tir_buffers[npu_op][1].buffer.data
                check_buffer(
                    npu_op.dest.address,
                    npu_op.dest.region,
                    npu_op.dest.length,
                    dest_tir_load,
                )
            elif issubclass(type(npu_op), vapi.NpuBlockOperation):
                ifm_tir_buffer_var = npu_op_tir_buffers[npu_op][0].buffer.data
                ifm_length = (
                    npu_op.ifm.shape.height * npu_op.ifm.shape.width * npu_op.ifm.shape.depth
                )
                check_buffer(
                    npu_op.ifm.tiles.addresses[0],
                    npu_op.ifm.region,
                    ifm_length,
                    ifm_tir_buffer_var,
                )
                ofm_tir_buffer_var = npu_op_tir_buffers[npu_op][1].buffer.data
                ofm_length = (
                    npu_op.ofm.shape.height * npu_op.ofm.shape.width * npu_op.ofm.shape.depth
                )
                check_buffer(
                    npu_op.ofm.tiles.addresses[0],
                    npu_op.ofm.region,
                    ofm_length,
                    ofm_tir_buffer_var,
                )
                for idx, weight in enumerate(npu_op_tir_buffers[npu_op][2]):
                    assert isinstance(weight, vapi.NpuAddressRange)
                    check_buffer(
                        npu_op.weights[idx].address,
                        npu_op.weights[idx].region,
                        npu_op.weights[idx].length,
                        weight.address.buffer.data,
                    )
                for idx, bias in enumerate(npu_op_tir_buffers[npu_op][3]):
                    assert isinstance(bias, vapi.NpuAddressRange)
                    check_buffer(
                        npu_op.biases[idx].address,
                        npu_op.biases[idx].region,
                        npu_op.biases[idx].length,
                        bias.address.buffer.data,
                    )

    for test_case in test_cases:
        tir_mod = test_case[""tir_module""]
        tir_mod[""main""] = tir_mod[""main""].with_attr(""target"", tvm.target.Target(""ethos-u""))
        tir_mod = tvm.tir.transform.MakeUnpackedAPI()(tir_mod)
        candidate_regions_for_scratch = [5, 2, 1]
        (
            scratch_region_map,
            tvmbaw_workspace_size,
            _,
        ) = tir_to_cs_translator.analyze_scratch_memory_acesses(
            tir_mod, candidate_regions_for_scratch
        )
        allocate_node_sizes = _get_allocate_node_sizes(tir_mod)
        buffer_info = tir_to_cs_translator.extract_buffer_info(tir_mod, test_case[""param_dict""])
        extern_calls = extract_call_extern_list(tir_mod)
        _npu_ops = list()
        for extern_call in extern_calls:
            _npu_ops.append(tir_to_cs_translator.translate_ethosu_tir_call_extern(extern_call))
        npu_op_tir_buffers = collect_tir_buffer_info(_npu_ops)
        (_npu_ops, constant_hex_string) = tir_to_cs_translator.assign_addresses(
            buffer_info, _npu_ops, scratch_region_map
        )
        tvmbaw_workspace_mask = np.zeros(tvmbaw_workspace_size, dtype=""uint8"")
        constant_tensor_read_mask = np.zeros(len(constant_hex_string) // 2, dtype=""uint8"")
        verify(_npu_ops)
        # This will be only 1 if all allocated scratch is used.
        assert np.prod(tvmbaw_workspace_mask) == 1
        # This will be only 1 if all constant tensors is read at least once.
        assert np.prod(constant_tensor_read_mask) == 1","allocate_node_sizes = _get_allocate_node_sizes(tir_mod)
buffer_info = tir_to_cs_translator.extract_buffer_info(tir_mod, test_case['param_dict'])
extern_calls = extract_call_extern_list(tir_mod)
_npu_ops = list()","(allocate_node_sizes, buffer_info, extern_calls, _npu_ops) = (_get_allocate_node_sizes(tir_mod), tir_to_cs_translator.extract_buffer_info(tir_mod, test_case['param_dict']), extract_call_extern_list(tir_mod), list())",0,,,,,,
pydicom,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/pydicom/pydicom/tests/test_fileset.py,https://github.com/pydicom/pydicom/tree/master/pydicom/tests/test_fileset.py,TestFileSet_Copy,test_copy$2465,"def test_copy(self, dicomdir, tdir):
        """"""Test FileSet.copy()""""""
        orig_root = Path(dicomdir.filename).parent
        fs = FileSet(dicomdir)

        fs.ID = ""NEW ID""
        uid = fs.UID = generate_uid()
        fs.descriptor_file_id = ""README""
        fs.descriptor_character_set = ""ISO_IR 100""
        cp, ds, paths = copy_fs(fs, tdir.name)
        assert 31 == len(paths)
        assert (
            ('PT000000', 'ST000000', 'SE000000', 'IM000000')
        ) == paths[0].parts[-4:]
        assert (
            ('PT000001', 'ST000003', 'SE000002', 'IM000006')
        ) == paths[-1].parts[-4:]

        # Check existing File-set remains the same
        assert ""NEW ID"" == fs.ID
        assert dicomdir.file_meta.TransferSyntaxUID == ExplicitVRLittleEndian
        assert uid == fs.UID
        assert dicomdir.file_meta.MediaStorageSOPInstanceUID == fs.UID
        assert ""README"" == fs.descriptor_file_id
        assert ""ISO_IR 100"" == fs.descriptor_character_set
        assert not bool(fs._stage['+'])
        assert not bool(fs._stage['-'])
        assert fs.is_staged
        paths = list(orig_root.glob('98892001/**/*'))
        paths += list(orig_root.glob('98892003/**/*'))
        paths += list(orig_root.glob('77654033/**/*'))
        paths = [p for p in paths if p.is_file()]

        # Test new File-set
        assert len(fs) == len(cp)
        for ref, instance in zip(fs, cp):
            assert ref.SOPInstanceUID == instance.SOPInstanceUID

        assert ds.file_meta.TransferSyntaxUID == ExplicitVRLittleEndian
        assert not ds.is_implicit_VR
        assert ds.is_little_endian
        assert not cp.is_staged
        assert ""NEW ID"" == cp.ID
        assert uid == cp.UID
        assert ds.file_meta.MediaStorageSOPInstanceUID == cp.UID
        assert ""README"" == cp.descriptor_file_id
        assert ""ISO_IR 100"" == cp.descriptor_character_set","fs.descriptor_file_id = 'README'
fs.descriptor_character_set = 'ISO_IR 100'","(fs.descriptor_file_id, fs.descriptor_character_set) = ('README', 'ISO_IR 100')",0,,,,,,
rq,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/rq/rq/queue.py,https://github.com/rq/rq/tree/master/rq/queue.py,Queue,__init__$73,"def __init__(self, name='default', default_timeout=None, connection: t.Optional['Redis'] = None,
                 is_async=True, job_class=None, serializer=None, **kwargs):
        self.connection = resolve_connection(connection)
        prefix = self.redis_queue_namespace_prefix
        self.name = name
        self._key = '{0}{1}'.format(prefix, name)
        self._default_timeout = parse_timeout(default_timeout) or self.DEFAULT_TIMEOUT
        self._is_async = is_async

        if 'async' in kwargs:
            self._is_async = kwargs['async']
            warnings.warn('The `async` keyword is deprecated. Use `is_async` instead', DeprecationWarning)

        # override class attribute job_class if one was passed
        if job_class is not None:
            if isinstance(job_class, string_types):
                job_class = import_attribute(job_class)
            self.job_class = job_class

        self.serializer = resolve_serializer(serializer)
        self.redis_server_version = None","self.connection = resolve_connection(connection)
prefix = self.redis_queue_namespace_prefix","(self.connection, prefix) = (resolve_connection(connection), self.redis_queue_namespace_prefix)",0,,,,,,
GPflow,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/GPflow/gpflow/quadrature/gauss_hermite.py,https://github.com/GPflow/GPflow/tree/master/gpflow/quadrature/gauss_hermite.py,NDiagGHQuadrature,_build_X_W$126,"def _build_X_W(self, mean: TensorType, var: TensorType) -> Tuple[tf.Tensor, tf.Tensor]:
        """"""
        :param mean: Array/Tensor with shape [b1, b2, ..., bX, dim], usually [N, dim],
            representing the mean of a dim-Variate Gaussian distribution
        :param var: Array/Tensor with shape b1, b2, ..., bX, dim], usually [N, dim],
            representing the variance of a dim-Variate Gaussian distribution
        :return: points X, Tensor with shape [n_gh_total, b1, b2, ..., bX, dim],
            usually [n_gh_total, N, dim],
            and weights W, a Tensor with shape [n_gh_total, b1, b2, ..., bX, 1],
            usually [n_gh_total, N, 1]
        """"""

        batch_shape_broadcast = tf.ones(tf.rank(mean) - 1, dtype=tf.int32)
        shape_aux = tf.concat([[self.n_gh_total], batch_shape_broadcast], axis=0)

        # mean, var: [b1, b2, ..., bX, dim], usually [N, dim]
        mean = tf.expand_dims(mean, 0)
        stddev = tf.expand_dims(tf.sqrt(var), 0)
        # mean, stddev: [1, b1, b2, ..., bX, dim], usually [1, N, dim]

        Z = tf.cast(tf.reshape(self.Z, tf.concat([shape_aux, [self.dim]], axis=0)), mean.dtype)
        dZ = tf.cast(tf.reshape(self.dZ, tf.concat([shape_aux, [1]], axis=0)), mean.dtype)

        X = mean + stddev * Z
        W = dZ
        # X: [n_gh_total, b1, b2, ..., bX, dim], usually [n_gh_total, N, dim]
        # W: [n_gh_total,  1,  1, ...,  1,   1], usually [n_gh_total, N,   1]

        return X, W","shape_aux = tf.concat([[self.n_gh_total], batch_shape_broadcast], axis=0)
mean = tf.expand_dims(mean, 0)","(shape_aux, mean) = (tf.concat([[self.n_gh_total], batch_shape_broadcast], axis=0), tf.expand_dims(mean, 0))",0,,,,,,
GPflow,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/GPflow/gpflow/quadrature/gauss_hermite.py,https://github.com/GPflow/GPflow/tree/master/gpflow/quadrature/gauss_hermite.py,NDiagGHQuadrature,_build_X_W$126,"def _build_X_W(self, mean: TensorType, var: TensorType) -> Tuple[tf.Tensor, tf.Tensor]:
        """"""
        :param mean: Array/Tensor with shape [b1, b2, ..., bX, dim], usually [N, dim],
            representing the mean of a dim-Variate Gaussian distribution
        :param var: Array/Tensor with shape b1, b2, ..., bX, dim], usually [N, dim],
            representing the variance of a dim-Variate Gaussian distribution
        :return: points X, Tensor with shape [n_gh_total, b1, b2, ..., bX, dim],
            usually [n_gh_total, N, dim],
            and weights W, a Tensor with shape [n_gh_total, b1, b2, ..., bX, 1],
            usually [n_gh_total, N, 1]
        """"""

        batch_shape_broadcast = tf.ones(tf.rank(mean) - 1, dtype=tf.int32)
        shape_aux = tf.concat([[self.n_gh_total], batch_shape_broadcast], axis=0)

        # mean, var: [b1, b2, ..., bX, dim], usually [N, dim]
        mean = tf.expand_dims(mean, 0)
        stddev = tf.expand_dims(tf.sqrt(var), 0)
        # mean, stddev: [1, b1, b2, ..., bX, dim], usually [1, N, dim]

        Z = tf.cast(tf.reshape(self.Z, tf.concat([shape_aux, [self.dim]], axis=0)), mean.dtype)
        dZ = tf.cast(tf.reshape(self.dZ, tf.concat([shape_aux, [1]], axis=0)), mean.dtype)

        X = mean + stddev * Z
        W = dZ
        # X: [n_gh_total, b1, b2, ..., bX, dim], usually [n_gh_total, N, dim]
        # W: [n_gh_total,  1,  1, ...,  1,   1], usually [n_gh_total, N,   1]

        return X, W","stddev = tf.expand_dims(tf.sqrt(var), 0)
Z = tf.cast(tf.reshape(self.Z, tf.concat([shape_aux, [self.dim]], axis=0)), mean.dtype)","(stddev, Z) = (tf.expand_dims(tf.sqrt(var), 0), tf.cast(tf.reshape(self.Z, tf.concat([shape_aux, [self.dim]], axis=0)), mean.dtype))",0,,,,,,
tvm,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/tvm/tests/python/unittest/test_tir_schedule_compute_at.py,https://github.com/apache/tvm/tree/master/tests/python/unittest/test_tir_schedule_compute_at.py,,non_uniform_tiled_conv$882,"def non_uniform_tiled_conv(x: T.Buffer[(1, 3, 100, 100), ""float32""],
                           w: T.Buffer[(16, 3, 3, 3), ""float32""],
                           y: T.Buffer[(1, 16, 98, 98), ""float32""]) -> None:
    x_global = T.alloc_buffer([1, 3, 100, 100], dtype=""float32"")
    for ax0, ax1, ax2, ax3 in T.grid(1, 3, 100, 100):
        with T.block(""cache""):
            v0, v1, v2, v3 = T.axis.remap(""SSSS"", [ax0, ax1, ax2, ax3])
            x_global[v0, v1, v2, v3] = x[v0, v1, v2, v3]
    for h_o, w_o, n, c_o, h_i, w_i, c_i, kh, kw in T.grid(7, 7, 1, 16, 15, 15, 3, 3, 3):
        with T.block(""compute""):
            nn = T.axis.spatial(1, 0)
            cc = T.axis.spatial(16, c_o)
            hh = T.axis.spatial(98, h_o * 15 + h_i)
            ww = T.axis.spatial(98, w_o * 15 + w_i)
            rc, rh, rw = T.axis.remap(""RRR"", [c_i, kh, kw])
            T.where(h_o * 15 + h_i < 98 and w_o * 15 + w_i < 98)
            with T.init():
                y[nn, cc, hh, ww] = T.float32(0)
            y[nn, cc, hh, ww] = y[nn, cc, hh, ww] + \
                x_global[nn, cc // 16 * 3 + rc, hh + rh, ww + rw] * w[cc, rc, rh, rw]","nn = T.axis.spatial(1, 0)
cc = T.axis.spatial(16, c_o)
hh = T.axis.spatial(98, h_o * 15 + h_i)
ww = T.axis.spatial(98, w_o * 15 + w_i)","(nn, cc, hh, ww) = (T.axis.spatial(1, 0), T.axis.spatial(16, c_o), T.axis.spatial(98, h_o * 15 + h_i), T.axis.spatial(98, w_o * 15 + w_i))",0,,,,,,
zipline,/data1/zhangzejun/mnt/zejun/smp/data/python_star_2000repo/zipline/tests/test_finance.py,https://github.com/quantopian/zipline/tree/master/tests/test_finance.py,FinanceTestCase,transaction_sim$163,"def transaction_sim(self, **params):
        """"""This is a utility method that asserts expected
        results for conversion of orders to transactions given a
        trade history
        """"""
        trade_count = params['trade_count']
        trade_interval = params['trade_interval']
        order_count = params['order_count']
        order_amount = params['order_amount']
        order_interval = params['order_interval']
        expected_txn_count = params['expected_txn_count']
        expected_txn_volume = params['expected_txn_volume']

        # optional parameters
        # ---------------------
        # if present, alternate between long and short sales
        alternate = params.get('alternate')

        # if present, expect transaction amounts to match orders exactly.
        complete_fill = params.get('complete_fill')

        asset1 = self.asset_finder.retrieve_asset(1)
        with TempDirectory() as tempdir:

            if trade_interval < timedelta(days=1):
                sim_params = factory.create_simulation_parameters(
                    start=self.start,
                    end=self.end,
                    data_frequency=""minute""
                )

                minutes = self.trading_calendar.minutes_window(
                    sim_params.first_open,
                    int((trade_interval.total_seconds() / 60) * trade_count)
                    + 100)

                price_data = np.array([10.1] * len(minutes))
                assets = {
                    asset1.sid: pd.DataFrame({
                        ""open"": price_data,
                        ""high"": price_data,
                        ""low"": price_data,
                        ""close"": price_data,
                        ""volume"": np.array([100] * len(minutes)),
                        ""dt"": minutes
                    }).set_index(""dt"")
                }

                write_bcolz_minute_data(
                    self.trading_calendar,
                    self.trading_calendar.sessions_in_range(
                        self.trading_calendar.minute_to_session_label(
                            minutes[0]
                        ),
                        self.trading_calendar.minute_to_session_label(
                            minutes[-1]
                        )
                    ),
                    tempdir.path,
                    iteritems(assets),
                )

                equity_minute_reader = BcolzMinuteBarReader(tempdir.path)

                data_portal = DataPortal(
                    self.asset_finder, self.trading_calendar,
                    first_trading_day=equity_minute_reader.first_trading_day,
                    equity_minute_reader=equity_minute_reader,
                )
            else:
                sim_params = factory.create_simulation_parameters(
                    data_frequency=""daily""
                )

                days = sim_params.sessions

                assets = {
                    1: pd.DataFrame({
                        ""open"": [10.1] * len(days),
                        ""high"": [10.1] * len(days),
                        ""low"": [10.1] * len(days),
                        ""close"": [10.1] * len(days),
                        ""volume"": [100] * len(days),
                        ""day"": [day.value for day in days]
                    }, index=days)
                }

                path = os.path.join(tempdir.path, ""testdata.bcolz"")
                BcolzDailyBarWriter(path, self.trading_calendar, days[0],
                                    days[-1]).write(
                    assets.items()
                )

                equity_daily_reader = BcolzDailyBarReader(path)

                data_portal = DataPortal(
                    self.asset_finder, self.trading_calendar,
                    first_trading_day=equity_daily_reader.first_trading_day,
                    equity_daily_reader=equity_daily_reader,
                )

            if ""default_slippage"" not in params or \
               not params[""default_slippage""]:
                slippage_func = FixedBasisPointsSlippage()
            else:
                slippage_func = None

            blotter = SimulationBlotter(slippage_func)

            start_date = sim_params.first_open

            if alternate:
                alternator = -1
            else:
                alternator = 1

            tracker = MetricsTracker(
                trading_calendar=self.trading_calendar,
                first_session=sim_params.start_session,
                last_session=sim_params.end_session,
                capital_base=sim_params.capital_base,
                emission_rate=sim_params.emission_rate,
                data_frequency=sim_params.data_frequency,
                asset_finder=self.asset_finder,
                metrics=load_metrics_set('none'),
            )

            # replicate what tradesim does by going through every minute or day
            # of the simulation and processing open orders each time
            if sim_params.data_frequency == ""minute"":
                ticks = minutes
            else:
                ticks = days

            transactions = []

            order_list = []
            order_date = start_date
            for tick in ticks:
                blotter.current_dt = tick
                if tick >= order_date and len(order_list) < order_count:
                    # place an order
                    direction = alternator ** len(order_list)
                    order_id = blotter.order(
                        asset1,
                        order_amount * direction,
                        MarketOrder(),
                    )
                    order_list.append(blotter.orders[order_id])
                    order_date = order_date + order_interval
                    # move after market orders to just after market next
                    # market open.
                    if order_date.hour >= 21:
                        if order_date.minute >= 00:
                            order_date = order_date + timedelta(days=1)
                            order_date = order_date.replace(hour=14, minute=30)
                else:
                    bar_data = BarData(
                        data_portal=data_portal,
                        simulation_dt_func=lambda: tick,
                        data_frequency=sim_params.data_frequency,
                        trading_calendar=self.trading_calendar,
                        restrictions=NoRestrictions(),
                    )
                    txns, _, closed_orders = blotter.get_transactions(bar_data)
                    for txn in txns:
                        tracker.process_transaction(txn)
                        transactions.append(txn)

                    blotter.prune_orders(closed_orders)

            for i in range(order_count):
                order = order_list[i]
                self.assertEqual(order.asset, asset1)
                self.assertEqual(order.amount, order_amount * alternator ** i)

            if complete_fill:
                self.assertEqual(len(transactions), len(order_list))

            total_volume = 0
            for i in range(len(transactions)):
                txn = transactions[i]
                total_volume += txn.amount
                if complete_fill:
                    order = order_list[i]
                    self.assertEqual(order.amount, txn.amount)

            self.assertEqual(total_volume, expected_txn_volume)

            self.assertEqual(len(transactions), expected_txn_count)

            if total_volume == 0:
                self.assertRaises(KeyError, lambda: tracker.positions[asset1])
            else:
                cumulative_pos = tracker.positions[asset1]
                self.assertEqual(total_volume, cumulative_pos.amount)

            # the open orders should not contain the asset.
            oo = blotter.open_orders
            self.assertNotIn(
                asset1,
                oo,
                ""Entry is removed when no open orders""
            )","trade_count = params['trade_count']
trade_interval = params['trade_interval']
order_count = params['order_count']
order_amount = params['order_amount']
order_interval = params['order_interval']
expected_txn_count = params['expected_txn_count']
expected_txn_volume = params['expected_txn_volume']
alternate = params.get('alternate')
complete_fill = params.get('complete_fill')
asset1 = self.asset_finder.retrieve_asset(1)","(trade_count, trade_interval, order_count, order_amount, order_interval, expected_txn_count, expected_txn_volume, alternate, complete_fill, asset1) = (params['trade_count'], params['trade_interval'], params['order_count'], params['order_amount'], params['order_interval'], params['expected_txn_count'], params['expected_txn_volume'], params.get('alternate'), params.get('complete_fill'), self.asset_finder.retrieve_asset(1))",0,,,,,,
